[2025-09-19 14:37:48,331][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 1.816793285721235,  accuracy: 0.3830412662521198, gradient_norm : 1.7075514621377288
[2025-09-19 14:37:53,188][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.2215525301343675,  accuracy: 0.1424
[2025-09-19 14:37:55,669][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 1.8583256565861679,  accuracy: 0.3364958325944316, gradient_norm : 1.4045877107126368
[2025-09-19 14:38:00,310][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.132611654382991,  accuracy: 0.1791
[2025-09-19 14:38:02,648][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 1.5659498398322822,  accuracy: 0.4594617905813352, gradient_norm : 1.2511970246932667
[2025-09-19 14:38:07,212][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.034712952345325,  accuracy: 0.2254
[2025-09-19 14:38:09,776][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.4155725825349794,  accuracy: 0.5159723365717108, gradient_norm : 1.2347896989996132
[2025-09-19 14:38:14,374][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 1.983301444267479,  accuracy: 0.253
[2025-09-19 14:38:16,193][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.5037670592373251,  accuracy: 0.4643361581920904, gradient_norm : 1.3819080819864729
[2025-09-19 14:38:20,902][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 1.957568111253428,  accuracy: 0.2638
[2025-09-19 14:38:23,346][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 1.3101154642023622,  accuracy: 0.5500938726745178, gradient_norm : 1.3387219333436318
[2025-09-19 14:38:28,117][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 1.8856571032698095,  accuracy: 0.3076
[2025-09-19 14:38:30,249][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.6479224159334593,  accuracy: 0.4217171717171717, gradient_norm : 1.75426754613459
[2025-09-19 14:38:35,042][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.8248789571220816,  accuracy: 0.3372
[2025-09-19 14:38:37,016][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 1.1514468455558964,  accuracy: 0.5990364611847148, gradient_norm : 1.2885722579792822
[2025-09-19 14:38:41,747][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.8252287098615507,  accuracy: 0.3418
[2025-09-19 14:38:44,609][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.4940486479141413,  accuracy: 0.46944247299108904, gradient_norm : 1.2905543058214615
[2025-09-19 14:38:49,257][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 1.7327967593949747,  accuracy: 0.3829
[2025-09-19 14:38:51,299][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 1.3155388280041818,  accuracy: 0.5358752588622244, gradient_norm : 1.793626311543653
[2025-09-19 14:38:55,958][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.7109003473283564,  accuracy: 0.3999
[2025-09-19 14:38:57,941][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 1.1066823319188586,  accuracy: 0.6203414282279394, gradient_norm : 1.5168903904928273
[2025-09-19 14:39:02,650][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.6963246014575002,  accuracy: 0.4157
[2025-09-19 14:39:04,605][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 1.118283246128435,  accuracy: 0.6250142126208073, gradient_norm : 1.5938396217327655
[2025-09-19 14:39:10,897][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.6905404545947378,  accuracy: 0.432
[2025-09-19 14:39:14,232][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 1.218907056867694,  accuracy: 0.581811977478246, gradient_norm : 1.1818979503126275
[2025-09-19 14:39:20,851][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.6496148239309056,  accuracy: 0.4447
[2025-09-19 14:39:24,165][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 1.0779645510508011,  accuracy: 0.6281365313653137, gradient_norm : 1.476359856445364
[2025-09-19 14:39:30,792][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.626280180129722,  accuracy: 0.4473
[2025-09-19 14:39:32,717][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 1.083539445946826,  accuracy: 0.6254609587942921, gradient_norm : 1.6303057189564756
[2025-09-19 14:39:39,233][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.616868647579665,  accuracy: 0.4502
[2025-09-19 14:39:41,764][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 0.976880875953038,  accuracy: 0.6778821074595722, gradient_norm : 1.6837993814641714
[2025-09-19 14:39:47,564][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.6164493658913326,  accuracy: 0.4553
[2025-09-19 14:39:49,508][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 0.9839591114372329,  accuracy: 0.670110523786641, gradient_norm : 1.398958695443571
[2025-09-19 14:39:54,224][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.6228897821205686,  accuracy: 0.4581
[2025-09-19 14:39:56,471][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 0.8624545218611132,  accuracy: 0.7167019027484144, gradient_norm : 1.6773061349847997
[2025-09-19 14:40:01,279][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.6114763944603343,  accuracy: 0.4643
[2025-09-19 14:40:03,561][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 0.895319156506881,  accuracy: 0.7081810514478493, gradient_norm : 1.1636811653921402
[2025-09-19 14:40:08,386][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.5909950253471448,  accuracy: 0.4769
[2025-09-19 14:40:10,809][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 0.6432311188657146,  accuracy: 0.7990294817798937, gradient_norm : 1.5747685975147723
[2025-09-19 14:40:15,568][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.7565450900584176,  accuracy: 0.4776
[2025-09-19 14:40:17,946][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 0.6733196086392669,  accuracy: 0.7873905429071804, gradient_norm : 1.1287134264641223
[2025-09-19 14:40:22,737][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.7663203934240388,  accuracy: 0.4814
[2025-09-19 14:40:24,969][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 0.8801006706645492,  accuracy: 0.7160415342233524, gradient_norm : 1.594616782191767
[2025-09-19 14:40:29,778][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.7674450106072468,  accuracy: 0.482
[2025-09-19 14:40:32,228][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 0.6908293594075798,  accuracy: 0.7853873081411005, gradient_norm : 1.3611638929207341
[2025-09-19 14:40:36,977][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.8469283445916618,  accuracy: 0.4759
[2025-09-19 14:40:39,250][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 0.4794007026473862,  accuracy: 0.8521837562494105, gradient_norm : 1.0272348184451479
[2025-09-19 14:40:44,019][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.8462013518451694,  accuracy: 0.476
[2025-09-19 14:40:45,976][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 0.41570382073440804,  accuracy: 0.8838661069852546, gradient_norm : 1.0116589071738804
[2025-09-19 14:40:50,755][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.8710647824923574,  accuracy: 0.4685
[2025-09-19 14:40:53,252][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 0.658935740507686,  accuracy: 0.7857142857142857, gradient_norm : 1.0946980763582945
[2025-09-19 14:40:57,960][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.8554105498005828,  accuracy: 0.474
[2025-09-19 14:41:00,478][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 0.5009619211275803,  accuracy: 0.8416957120855961, gradient_norm : 0.9531492236442702
[2025-09-19 14:41:05,176][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.9226643051348673,  accuracy: 0.4753
[2025-09-19 14:41:07,210][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 0.6537831924122622,  accuracy: 0.7905826703934637, gradient_norm : 1.2962310554518242
[2025-09-19 14:41:11,972][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.988237894289809,  accuracy: 0.4721
[2025-09-19 14:41:14,148][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 0.40328113769146856,  accuracy: 0.8767031919961886, gradient_norm : 1.176124603078652
[2025-09-19 14:41:18,962][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.9465746694420285,  accuracy: 0.4743
[2025-09-19 14:41:21,253][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 0.44728403524914373,  accuracy: 0.8692150866462793, gradient_norm : 1.424590215089089
[2025-09-19 14:41:26,075][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.949480987723123,  accuracy: 0.4788
[2025-09-19 14:41:28,208][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 0.45134417337537364,  accuracy: 0.8671254632080466, gradient_norm : 1.3707494175766224
[2025-09-19 14:41:32,925][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.937238683586767,  accuracy: 0.4806
[2025-09-19 14:41:35,378][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 0.4483027200045334,  accuracy: 0.868132914405408, gradient_norm : 1.042987445087257
[2025-09-19 14:41:40,115][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.9569582621636499,  accuracy: 0.4852
[2025-09-19 14:41:42,402][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 0.7068843874743886,  accuracy: 0.7504149558836376, gradient_norm : 1.222523114971056
[2025-09-19 14:41:47,242][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.9308107398012926,  accuracy: 0.4998
[2025-09-19 14:41:49,097][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 0.29575886255912576,  accuracy: 0.9165864227250843, gradient_norm : 0.810928327981149
[2025-09-19 14:41:53,851][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.968390652571882,  accuracy: 0.4975
[2025-09-19 14:41:55,707][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 0.36240167069366314,  accuracy: 0.905650662890977, gradient_norm : 1.1976366276763897
[2025-09-19 14:42:00,497][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.8966937040626652,  accuracy: 0.5048
[2025-09-19 14:42:02,403][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 0.4262265008767063,  accuracy: 0.8832867665735331, gradient_norm : 1.6685911827560367
[2025-09-19 14:42:07,208][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.7656961895369143,  accuracy: 0.5095
[2025-09-19 14:42:09,415][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 0.2326889140801892,  accuracy: 0.9418746195982958, gradient_norm : 1.0591984292324716
[2025-09-19 14:42:14,183][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.7731826552383751,  accuracy: 0.5081
[2025-09-19 14:42:16,406][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 0.5403838779453106,  accuracy: 0.8188724510195922, gradient_norm : 0.6533957939488847
[2025-09-19 14:42:21,124][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.7441725867374815,  accuracy: 0.5128
[2025-09-19 14:42:23,572][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 0.41201395751553044,  accuracy: 0.8827243556567643, gradient_norm : 1.5136648351111908
[2025-09-19 14:42:28,269][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.697000972053019,  accuracy: 0.5151
[2025-09-19 14:42:30,354][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 0.26348154441932303,  accuracy: 0.9308708477619597, gradient_norm : 1.1005977920661532
[2025-09-19 14:42:35,090][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.701006596830694,  accuracy: 0.5178
[2025-09-19 14:42:38,581][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 0.25242857612750513,  accuracy: 0.9252117622753254, gradient_norm : 0.7931982550463945
[2025-09-19 14:42:43,271][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.6688022767059087,  accuracy: 0.5262
[2025-09-19 14:42:46,315][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 0.18053653938167907,  accuracy: 0.9534883720930233, gradient_norm : 0.8551528967917595
[2025-09-19 14:42:50,995][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.6499110925281129,  accuracy: 0.5241
[2025-09-19 14:42:53,920][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 0.09221493938204287,  accuracy: 0.9783005105762217, gradient_norm : 0.36300357590636645
[2025-09-19 14:42:58,608][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.6260444307680881,  accuracy: 0.5285
[2025-09-19 14:43:01,730][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 0.31147416720045196,  accuracy: 0.9068705957719411, gradient_norm : 1.266043612341542
[2025-09-19 14:43:06,504][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.7162831746485074,  accuracy: 0.5306
[2025-09-19 14:43:09,100][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 0.19908344374178766,  accuracy: 0.9511527529213601, gradient_norm : 1.2847094103862362
[2025-09-19 14:43:13,867][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.7164112765444224,  accuracy: 0.5377
[2025-09-19 14:43:16,972][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 0.2345430696935147,  accuracy: 0.9340858856962425, gradient_norm : 0.8025186816292987
[2025-09-19 14:43:21,712][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.7106675462578205,  accuracy: 0.5384
[2025-09-19 14:43:24,227][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 0.11997670569815846,  accuracy: 0.9778902779212728, gradient_norm : 0.8908649181097302
[2025-09-19 14:43:28,985][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.7098914402686027,  accuracy: 0.5381
[2025-09-19 14:43:31,541][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 0.235833484367469,  accuracy: 0.9376863753213368, gradient_norm : 0.9913004648010216
[2025-09-19 14:43:36,285][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.6664357283570832,  accuracy: 0.5419
[2025-09-19 14:43:38,895][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 0.14111468070280206,  accuracy: 0.9678714859437751, gradient_norm : 0.6152714892483832
[2025-09-19 14:43:43,614][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.7102069662497716,  accuracy: 0.54
[2025-09-19 14:43:45,745][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 0.18583373076317597,  accuracy: 0.9540700318326512, gradient_norm : 0.758251309573597
[2025-09-19 14:43:50,451][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.6890699641116738,  accuracy: 0.5449
[2025-09-19 14:43:53,085][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 0.1987160767668873,  accuracy: 0.945280574105452, gradient_norm : 0.5859987825081684
[2025-09-19 14:43:57,801][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.6294627770064802,  accuracy: 0.5565
[2025-09-19 14:44:00,355][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 0.11290850408904085,  accuracy: 0.9732360097323601, gradient_norm : 0.7661502000339453
[2025-09-19 14:44:05,128][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.6287419175153506,  accuracy: 0.5576
[2025-09-19 14:44:07,647][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 0.12067186189178332,  accuracy: 0.972179437812861, gradient_norm : 0.5551175532189173
[2025-09-19 14:44:12,399][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.639247052700063,  accuracy: 0.5572
[2025-09-19 14:44:15,291][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 0.09070527782569064,  accuracy: 0.9817142857142858, gradient_norm : 0.9605337940599153
[2025-09-19 14:44:19,995][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.6565639473256872,  accuracy: 0.5536
[2025-09-19 14:44:22,130][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 0.04268261762028628,  accuracy: 0.9978354978354979, gradient_norm : 0.6588303345151731
[2025-09-19 14:44:26,841][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.6554572912134136,  accuracy: 0.5511
[2025-09-19 14:44:29,839][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 0.06614777841406566,  accuracy: 0.9901888189559422, gradient_norm : 0.6548087235195604
[2025-09-19 14:44:34,599][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.6438784120243195,  accuracy: 0.5565
[2025-09-19 14:44:37,455][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 0.06857837223895998,  accuracy: 0.9886571852368903, gradient_norm : 0.5060034671875299
[2025-09-19 14:44:42,204][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.6306733205486739,  accuracy: 0.5568
[2025-09-19 14:44:44,992][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.10400093011995208,  accuracy: 0.9749953866026942, gradient_norm : 0.5069208073434369
[2025-09-19 14:44:49,766][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.676796944318818,  accuracy: 0.5548
[2025-09-19 14:44:52,168][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.0340098493588333,  accuracy: 0.9963624692414679, gradient_norm : 0.9116572102133375
[2025-09-19 14:44:56,847][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.6786418234616587,  accuracy: 0.5537
[2025-09-19 14:44:59,859][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 0.10097264399560452,  accuracy: 0.9793858160841534, gradient_norm : 0.8148690493312212
[2025-09-19 14:45:04,629][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.664521315436966,  accuracy: 0.5537
[2025-09-19 14:45:07,529][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.02559200746911035,  accuracy: 0.9970542508796334, gradient_norm : 0.37185087789052945
[2025-09-19 14:45:12,214][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.6720921481004756,  accuracy: 0.5527
[2025-09-19 14:45:14,986][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.04404911846890518,  accuracy: 0.9930146691946912, gradient_norm : 0.777861126083157
[2025-09-19 14:45:19,648][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.669158082812568,  accuracy: 0.556
[2025-09-19 14:45:22,051][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 0.0609286121022649,  accuracy: 0.9909237846574661, gradient_norm : 0.46103388603088546
[2025-09-19 14:45:28,143][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.6645771898116075,  accuracy: 0.557
[2025-09-19 14:45:31,130][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.05004780483904242,  accuracy: 0.9940041425923907, gradient_norm : 0.5383071861537614
[2025-09-19 14:45:37,790][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.674240617867848,  accuracy: 0.5563
[2025-09-19 14:45:40,796][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.12928974246728306,  accuracy: 0.9744423791821561, gradient_norm : 0.7070418536206222
[2025-09-19 14:45:47,658][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.7129124784193839,  accuracy: 0.5573
[2025-09-19 14:45:50,354][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.03527513157250131,  accuracy: 0.9965575072821962, gradient_norm : 0.6407393455667332
[2025-09-19 14:45:55,152][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.7781468147949782,  accuracy: 0.5557
[2025-09-19 14:45:57,666][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.09879082121566411,  accuracy: 0.979386208171566, gradient_norm : 0.7721994981536511
[2025-09-19 14:46:02,357][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.627529041380401,  accuracy: 0.565
[2025-09-19 14:46:04,880][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.14535188511551564,  accuracy: 0.9656703166617342, gradient_norm : 0.5684132592044046
[2025-09-19 14:46:09,615][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.6201669953549682,  accuracy: 0.5672
[2025-09-19 14:46:12,469][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.0651972595822044,  accuracy: 0.9831746552856205, gradient_norm : 0.3301236089619494
[2025-09-19 14:46:17,285][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.6166599807294326,  accuracy: 0.5669
[2025-09-19 14:46:19,511][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 0.06774464332341835,  accuracy: 0.9888507718696398, gradient_norm : 0.5546875336489314
[2025-09-19 14:46:24,339][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.62501030270677,  accuracy: 0.5656
[2025-09-19 14:46:26,716][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 0.01891097756035636,  accuracy: 0.999012724879333, gradient_norm : 0.45356476561976894
[2025-09-19 14:46:31,453][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.6268159408780054,  accuracy: 0.5657
[2025-09-19 14:46:33,777][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.03699002720360853,  accuracy: 0.994756628413138, gradient_norm : 0.4567327942661336
[2025-09-19 14:46:38,537][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.6147412902910627,  accuracy: 0.5668
[2025-09-19 14:46:41,282][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.15079083510986407,  accuracy: 0.9609729391521977, gradient_norm : 0.9342229336487256
[2025-09-19 14:46:46,057][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.6146857565705617,  accuracy: 0.5678
[2025-09-19 14:46:48,201][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.010861377991120287,  accuracy: 0.9996885705387729, gradient_norm : 0.2829677666058924
[2025-09-19 14:46:52,982][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.6109135176199598,  accuracy: 0.568
[2025-09-19 14:46:55,540][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.06665787898983976,  accuracy: 0.9866022216569151, gradient_norm : 0.4184849788255329
[2025-09-19 14:47:00,305][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.6424772941199859,  accuracy: 0.5694
[2025-09-19 14:47:02,531][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.01854988084790484,  accuracy: 0.9992431614228565, gradient_norm : 0.36125788432300326
[2025-09-19 14:47:07,205][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.6406677973863621,  accuracy: 0.5705
[2025-09-19 14:47:09,531][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.06925637667584504,  accuracy: 0.9886547811993517, gradient_norm : 0.8395787153717174
[2025-09-19 14:47:14,293][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.6499958282581109,  accuracy: 0.5685
[2025-09-19 14:47:16,189][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.10948474783942413,  accuracy: 0.9765171177851935, gradient_norm : 0.7794085904344815
[2025-09-19 14:47:21,042][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.6640694447597129,  accuracy: 0.5664
[2025-09-19 14:47:23,054][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.019849388105770208,  accuracy: 0.9990258158792011, gradient_norm : 0.4680254171746112
[2025-09-19 14:47:27,765][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.6504877239943432,  accuracy: 0.568
[2025-09-19 14:47:30,052][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.04481458322131169,  accuracy: 0.9909536373916321, gradient_norm : 0.17232272321537093
[2025-09-19 14:47:34,780][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.6498530080595002,  accuracy: 0.5694
[2025-09-19 14:47:37,427][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.03797543519432342,  accuracy: 0.9920740798869968, gradient_norm : 0.28672895691803063
[2025-09-19 14:47:42,216][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.689190960654394,  accuracy: 0.5643
[2025-09-19 14:47:44,499][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.017064262687086676,  accuracy: 0.9989716743012059, gradient_norm : 0.3516647830027205
[2025-09-19 14:47:49,329][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.688785172297732,  accuracy: 0.5645
[2025-09-19 14:47:51,639][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.05664374256384389,  accuracy: 0.9893012686991101, gradient_norm : 0.8290702463722084
[2025-09-19 14:47:56,415][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.7437331544603665,  accuracy: 0.5631
[2025-09-19 14:47:58,513][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.04029605697467125,  accuracy: 0.9946553835875738, gradient_norm : 0.4937239572450082
[2025-09-19 14:48:03,276][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.6974468807972232,  accuracy: 0.57
[2025-09-19 14:48:05,470][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.033285367224309886,  accuracy: 0.9946401225114855, gradient_norm : 0.6376252027283417
[2025-09-19 14:48:10,152][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.699898589730835,  accuracy: 0.5717
[2025-09-19 14:48:12,273][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.12532083786293516,  accuracy: 0.96579476861167, gradient_norm : 1.005446160910931
[2025-09-19 14:48:17,103][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.6332726833307507,  accuracy: 0.5733
[2025-09-19 14:48:19,397][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.016799149967061076,  accuracy: 0.9976943650281287, gradient_norm : 0.22596964305518713
[2025-09-19 14:48:24,175][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.6336584958654157,  accuracy: 0.5724
[2025-09-19 14:48:25,871][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.01071121733681863,  accuracy: 0.9997244799559168, gradient_norm : 0.3466847627634525
[2025-09-19 14:48:30,621][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.6315314320843928,  accuracy: 0.5721
[2025-09-19 14:48:33,119][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.020133941800274523,  accuracy: 0.9983851776304606, gradient_norm : 0.19955412462061617
[2025-09-19 14:48:37,889][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.6393957604168863,  accuracy: 0.5693
[2025-09-19 14:48:40,301][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.07858625407491121,  accuracy: 0.9802317028319235, gradient_norm : 0.5319638006734032
[2025-09-19 14:48:45,068][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.713232647578803,  accuracy: 0.56
[2025-09-19 14:48:47,221][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.03999134335514421,  accuracy: 0.9922080657049595, gradient_norm : 0.5285282471566056
[2025-09-19 14:48:51,977][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.6399028862788152,  accuracy: 0.5651
[2025-09-19 14:48:54,405][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.034132528898512364,  accuracy: 0.9946710928627588, gradient_norm : 0.3656705873483702
[2025-09-19 14:48:59,170][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.6525961700043634,  accuracy: 0.5641
[2025-09-19 14:49:01,369][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.017370693420993722,  accuracy: 0.9993731717509402, gradient_norm : 0.3810093615025094
[2025-09-19 14:49:06,220][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.6607992435456869,  accuracy: 0.5646
[2025-09-19 14:49:08,288][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.013696285559113645,  accuracy: 0.9993506493506493, gradient_norm : 0.507205579508533
[2025-09-19 14:49:13,047][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.6644549174091772,  accuracy: 0.5655
[2025-09-19 14:49:15,278][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.029841708270644814,  accuracy: 0.9978034047226798, gradient_norm : 0.581019022545378
[2025-09-19 14:49:19,996][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.6453446495179829,  accuracy: 0.567
[2025-09-19 14:49:22,392][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.026178906445020963,  accuracy: 0.9967301404116177, gradient_norm : 0.30125051845796835
[2025-09-19 14:49:27,095][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.6258161824178194,  accuracy: 0.5689
[2025-09-19 14:49:29,513][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.06066264589308052,  accuracy: 0.9940163858970819, gradient_norm : 1.1969586531991288
[2025-09-19 14:49:34,357][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.636170708935608,  accuracy: 0.5701
[2025-09-19 14:49:36,946][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.044232457916919606,  accuracy: 0.9974000962927299, gradient_norm : 0.8177539902268168
[2025-09-19 14:49:41,679][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.7274811811973956,  accuracy: 0.5691
[2025-09-19 14:49:44,292][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.01681697135463146,  accuracy: 0.9988642230252969, gradient_norm : 0.368915247371759
[2025-09-19 14:49:49,054][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.7239807137935663,  accuracy: 0.57
[2025-09-19 14:49:51,758][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.039629519247312055,  accuracy: 0.9949125312388433, gradient_norm : 0.6682888246727552
[2025-09-19 14:49:56,483][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.7194945850719983,  accuracy: 0.5702
[2025-09-19 14:49:59,436][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.02066524802351764,  accuracy: 0.9987713826670447, gradient_norm : 0.5718011277690421
[2025-09-19 14:50:04,191][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.7211956413070333,  accuracy: 0.5705
[2025-09-19 14:50:06,960][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.015676634724983624,  accuracy: 0.9979054730898825, gradient_norm : 0.19076750632425526
[2025-09-19 14:50:11,678][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.63066425923983,  accuracy: 0.575
[2025-09-19 14:50:14,448][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.009870762358738945,  accuracy: 0.9997174609154267, gradient_norm : 0.2895814257591573
[2025-09-19 14:50:19,227][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.606236582606811,  accuracy: 0.5766
[2025-09-19 14:50:22,156][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.03267512384126992,  accuracy: 0.9951465372409931, gradient_norm : 0.45119870242757026
[2025-09-19 14:50:26,909][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.5992763988530423,  accuracy: 0.5787
[2025-09-19 14:50:29,440][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.006027717622015002,  accuracy: 0.9997992975413948, gradient_norm : 0.17987332523337288
[2025-09-19 14:50:34,139][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.601415878222994,  accuracy: 0.5791
[2025-09-19 14:50:36,866][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.011730625627025744,  accuracy: 0.9997139588100686, gradient_norm : 0.5151496289657458
[2025-09-19 14:50:41,598][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.6634017956077176,  accuracy: 0.5747
[2025-09-19 14:50:44,471][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.007851352418119404,  accuracy: 0.9999092641321115, gradient_norm : 0.21512926927897819
[2025-09-19 14:50:49,223][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.6652730069219563,  accuracy: 0.5735
[2025-09-19 14:50:51,846][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.025215374675044356,  accuracy: 0.9975574010747436, gradient_norm : 0.38685509711444543
[2025-09-19 14:50:56,520][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.6556018433022248,  accuracy: 0.5723
[2025-09-19 14:50:59,074][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.018453072491078325,  accuracy: 0.9989029072956664, gradient_norm : 0.37865855761905065
[2025-09-19 14:51:03,834][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.6386597548748796,  accuracy: 0.5751
[2025-09-19 14:51:06,625][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.024979937902491575,  accuracy: 0.9963713080168777, gradient_norm : 0.3675476518404848
[2025-09-19 14:51:11,374][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.6147382453936334,  accuracy: 0.5799
[2025-09-19 14:51:14,573][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.007389268463345544,  accuracy: 0.9994258059224018, gradient_norm : 0.10086909693365005
[2025-09-19 14:51:19,242][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.6175267802019577,  accuracy: 0.5793
[2025-09-19 14:51:21,109][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.00981985517091924,  accuracy: 0.999361124421019, gradient_norm : 0.28687430625960675
[2025-09-19 14:51:25,811][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.6200653287571705,  accuracy: 0.5789
[2025-09-19 14:51:28,787][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.00605619236994311,  accuracy: 0.99984, gradient_norm : 0.2602309564831982
[2025-09-19 14:51:33,519][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.626382374406419,  accuracy: 0.58
[2025-09-19 14:51:36,274][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.016478497350973113,  accuracy: 0.9989182810502507, gradient_norm : 0.5441034655121708
[2025-09-19 14:51:41,109][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.6324645607121406,  accuracy: 0.5763
[2025-09-19 14:51:43,692][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.006182149313396161,  accuracy: 0.9997199925331343, gradient_norm : 0.10618429654908723
[2025-09-19 14:51:48,477][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.6341935567447596,  accuracy: 0.576
[2025-09-19 14:51:51,342][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.04989754103303643,  accuracy: 0.9858789157604285, gradient_norm : 0.1930170900354733
[2025-09-19 14:51:56,081][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.6968543890614936,  accuracy: 0.5715
[2025-09-19 14:51:58,623][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.013103216494504076,  accuracy: 0.9989530788997811, gradient_norm : 0.33090716811046433
[2025-09-19 14:52:03,319][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.7102955458245306,  accuracy: 0.5722
[2025-09-19 14:52:06,051][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.015146488861634543,  accuracy: 0.9982674982674983, gradient_norm : 0.29056545478376145
[2025-09-19 14:52:10,848][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.7032181112940736,  accuracy: 0.5729
[2025-09-19 14:52:13,386][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.010447915670939152,  accuracy: 0.9992647734583219, gradient_norm : 0.31612700921916137
[2025-09-19 14:52:18,197][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 1.693634230128688,  accuracy: 0.5736
[2025-09-19 14:52:20,605][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.011107215876048453,  accuracy: 0.9994267150773934, gradient_norm : 0.3428048336898383
[2025-09-19 14:52:25,355][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.6862054740261598,  accuracy: 0.573
[2025-09-19 14:52:27,946][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.015399773120842434,  accuracy: 0.999060856498873, gradient_norm : 0.40724972788305575
[2025-09-19 14:52:32,688][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.7170460351124965,  accuracy: 0.5688
[2025-09-19 14:52:34,727][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.025894697199334474,  accuracy: 0.9991440449987772, gradient_norm : 0.9409308438348055
[2025-09-19 14:52:39,501][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.7100862912466692,  accuracy: 0.5726
[2025-09-19 14:52:41,965][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.011901899638536204,  accuracy: 0.9981017807104764, gradient_norm : 0.27226839069901715
[2025-09-19 14:52:46,693][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.73814077962751,  accuracy: 0.5713
[2025-09-19 14:52:48,749][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.04412581439772052,  accuracy: 0.9981716235982447, gradient_norm : 0.7524739056678373
[2025-09-19 14:52:53,557][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.7689854339905065,  accuracy: 0.5721
[2025-09-19 14:52:55,728][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.004939033596460556,  accuracy: 1.0, gradient_norm : 0.19717343853425745
[2025-09-19 14:53:00,434][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 1.7701264612622334,  accuracy: 0.5716
[2025-09-19 14:53:02,943][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.005815673269645862,  accuracy: 0.9999203123754881, gradient_norm : 0.2067048295359366
[2025-09-19 14:53:07,660][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.7675630733805177,  accuracy: 0.5726
[2025-09-19 14:53:09,936][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.03283562727183103,  accuracy: 0.9961187832836899, gradient_norm : 0.6299905304907771
[2025-09-19 14:53:14,706][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.8255112725612133,  accuracy: 0.572
[2025-09-19 14:53:16,865][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.008046328598562696,  accuracy: 0.9997938356870426, gradient_norm : 0.3333824200851551
[2025-09-19 14:53:21,640][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.8439328153448906,  accuracy: 0.5708
[2025-09-19 14:53:24,041][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.007179688853579818,  accuracy: 0.9997261524418074, gradient_norm : 0.23871375680326137
[2025-09-19 14:53:28,807][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.789864294409514,  accuracy: 0.5755
[2025-09-19 14:53:31,421][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.00506609121406148,  accuracy: 0.9996846172041315, gradient_norm : 0.13193659785388226
[2025-09-19 14:53:36,251][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.7748932674650624,  accuracy: 0.576
[2025-09-19 14:53:38,652][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.004697858481521031,  accuracy: 0.9999116919816319, gradient_norm : 0.25293346984340304
[2025-09-19 14:53:43,375][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 1.7665540313701766,  accuracy: 0.5765
[2025-09-19 14:53:45,700][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.003262143004127998,  accuracy: 1.0, gradient_norm : 0.060790567511933964
[2025-09-19 14:53:50,450][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.767617550492976,  accuracy: 0.5762
[2025-09-19 14:53:53,203][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.034609818773358114,  accuracy: 0.9942384399468164, gradient_norm : 0.5223407326552038
[2025-09-19 14:53:58,028][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.7382390435081656,  accuracy: 0.5765
[2025-09-19 14:54:00,531][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.04859022596403815,  accuracy: 0.994478527607362, gradient_norm : 0.7607736103349843
[2025-09-19 14:54:05,371][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.725816644137893,  accuracy: 0.5739
[2025-09-19 14:54:08,036][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.033231007042570225,  accuracy: 0.9929773113134743, gradient_norm : 0.49638864462972115
[2025-09-19 14:54:12,740][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.6722727633185837,  accuracy: 0.5823
[2025-09-19 14:54:15,053][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.006508302058150761,  accuracy: 0.9996179195720699, gradient_norm : 0.3214739094095163
[2025-09-19 14:54:19,831][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.6519380780206776,  accuracy: 0.5831
[2025-09-19 14:54:22,347][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.025746904349212417,  accuracy: 0.9991521831284442, gradient_norm : 0.516869866738214
[2025-09-19 14:54:27,198][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 1.6765333387629842,  accuracy: 0.5797
[2025-09-19 14:54:29,283][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.018779455097457244,  accuracy: 0.9961329431438127, gradient_norm : 0.16677333699407734
[2025-09-19 14:54:34,075][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 1.675148895720195,  accuracy: 0.5815
[2025-09-19 14:54:36,917][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.015364137377792506,  accuracy: 0.99860529986053, gradient_norm : 0.35361083404712595
[2025-09-19 14:54:41,665][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 1.6736314001240982,  accuracy: 0.5785
[2025-09-19 14:54:44,369][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.0043592914305291795,  accuracy: 0.9998465316144874, gradient_norm : 0.13255478501656437
[2025-09-19 14:54:49,171][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 1.6725049890706511,  accuracy: 0.5799
[2025-09-19 14:54:51,265][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.06743767320695308,  accuracy: 0.9904620601949978, gradient_norm : 0.8008725726602179
[2025-09-19 14:54:56,043][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 1.65778118961628,  accuracy: 0.5822
[2025-09-19 14:54:58,248][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.004475950310230002,  accuracy: 1.0, gradient_norm : 0.06497607928437876
[2025-09-19 14:55:02,939][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 1.657045439230658,  accuracy: 0.5827
[2025-09-19 14:55:05,220][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.006098849924929792,  accuracy: 1.0, gradient_norm : 0.17173561551565408
[2025-09-19 14:55:09,990][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 1.6525897139011023,  accuracy: 0.5835
[2025-09-19 14:55:12,571][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.00494747238735376,  accuracy: 0.9999163669816844, gradient_norm : 0.27778603062724333
[2025-09-19 14:55:17,349][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 1.6579352656996444,  accuracy: 0.5809
[2025-09-19 14:55:19,322][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.06796866975568328,  accuracy: 0.9949202765627205, gradient_norm : 0.7257445299164114
[2025-09-19 14:55:24,128][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 1.6746592134193772,  accuracy: 0.5808
[2025-09-19 14:55:26,979][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.0023366030014582463,  accuracy: 1.0, gradient_norm : 0.027652669175744018
[2025-09-19 14:55:31,821][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 1.676810899572193,  accuracy: 0.581
[2025-09-19 14:55:34,289][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.008500832943273187,  accuracy: 0.9994204578383077, gradient_norm : 0.2068903482424391
[2025-09-19 14:55:39,047][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 1.6772774295738164,  accuracy: 0.5824
[2025-09-19 14:55:41,453][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.014611651091624166,  accuracy: 0.9989907145740815, gradient_norm : 0.7577412544933338
[2025-09-19 14:55:46,209][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 1.69083081196874,  accuracy: 0.5807
[2025-09-19 14:55:48,775][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.030455085240861,  accuracy: 0.9973175469429285, gradient_norm : 0.40644660570216495
[2025-09-19 14:55:53,465][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 1.6864337664145195,  accuracy: 0.583
[2025-09-19 14:55:56,184][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.011179476108274161,  accuracy: 0.9975251900300512, gradient_norm : 0.15857604603164385
[2025-09-19 14:56:00,945][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 1.6386202466288355,  accuracy: 0.5887
[2025-09-19 14:56:03,434][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.020110601339942233,  accuracy: 0.9984035122729994, gradient_norm : 0.5432598322225535
[2025-09-19 14:56:08,177][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 1.713391014359211,  accuracy: 0.5831
[2025-09-19 14:56:10,445][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.00997309618945637,  accuracy: 0.9989689540611754, gradient_norm : 0.31108829407649935
[2025-09-19 14:56:15,193][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 1.6423713546332572,  accuracy: 0.5879
[2025-09-19 14:56:18,462][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.010413112272746494,  accuracy: 0.9996003516905123, gradient_norm : 0.46370838331424524
[2025-09-19 14:56:23,214][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 1.6504677805026229,  accuracy: 0.5888
[2025-09-19 14:56:26,224][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.009131806494317817,  accuracy: 0.9985979670522257, gradient_norm : 0.19617723372705761
[2025-09-19 14:56:30,952][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 1.635128376542514,  accuracy: 0.5908
[2025-09-19 14:56:33,900][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.017042409031701723,  accuracy: 0.9975895316804407, gradient_norm : 0.5417287787849473
[2025-09-19 14:56:38,621][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 1.6520795472882615,  accuracy: 0.5912
[2025-09-19 14:56:41,792][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.0084032622924067,  accuracy: 0.9994541484716157, gradient_norm : 0.37965441866941213
[2025-09-19 14:56:46,499][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 1.66881295496925,  accuracy: 0.588
[2025-09-19 14:56:49,769][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.022703773407549765,  accuracy: 0.9976617303195635, gradient_norm : 0.8145408584256802
[2025-09-19 14:56:54,410][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 1.8042424906822754,  accuracy: 0.5815
[2025-09-19 14:56:57,303][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.010698931875315268,  accuracy: 0.9986397025482906, gradient_norm : 0.27419463129391514
[2025-09-19 14:57:02,084][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 1.7765128311159923,  accuracy: 0.5854
[2025-09-19 14:57:05,156][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.03013681108509958,  accuracy: 0.998440321786242, gradient_norm : 0.5400710204370438
[2025-09-19 14:57:09,840][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 1.6954560146771582,  accuracy: 0.5858
[2025-09-19 14:57:12,766][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.02161282232175697,  accuracy: 0.9994728055531148, gradient_norm : 0.45399560952765833
[2025-09-19 14:57:17,431][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 1.6951111489077433,  accuracy: 0.5843
[2025-09-19 14:57:20,091][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.005940586136087142,  accuracy: 0.9997743936830231, gradient_norm : 0.3873784645189337
[2025-09-19 14:57:24,802][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 1.6977700834572338,  accuracy: 0.5857
[2025-09-19 14:57:27,748][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.013377076576656259,  accuracy: 0.9996437477734236, gradient_norm : 0.3863244249316006
[2025-09-19 14:57:32,533][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 1.6787910092970753,  accuracy: 0.5885
[2025-09-19 14:57:35,200][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.004691675608508571,  accuracy: 0.9993875676227416, gradient_norm : 0.2632840633714568
[2025-09-19 14:57:39,955][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 1.6811613082302632,  accuracy: 0.5869
[2025-09-19 14:57:42,928][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.01964126335720083,  accuracy: 0.9987677725118483, gradient_norm : 0.9214986964825684
[2025-09-19 14:57:47,619][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 1.7526435453509315,  accuracy: 0.5831
[2025-09-19 14:57:50,450][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.0025671957843010893,  accuracy: 1.0, gradient_norm : 0.1066456841006298
[2025-09-19 14:57:55,201][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 1.7533910846158887,  accuracy: 0.5838
[2025-09-19 14:57:58,170][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.00470068662649639,  accuracy: 0.9994642857142857, gradient_norm : 0.11790017644007007
[2025-09-19 14:58:02,882][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 1.7303791242857802,  accuracy: 0.5866
[2025-09-19 14:58:05,435][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.004970919082873133,  accuracy: 0.9996844098464128, gradient_norm : 0.26626168630389135
[2025-09-19 14:58:10,254][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 1.7297630634018308,  accuracy: 0.5846
[2025-09-19 14:58:13,016][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.006300134395707316,  accuracy: 0.9999109686609686, gradient_norm : 0.339319564242466
[2025-09-19 14:58:17,800][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 1.7436917969169172,  accuracy: 0.5828
[2025-09-19 14:58:20,280][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.0034094664821363954,  accuracy: 0.9997790543526293, gradient_norm : 0.10977773432356006
[2025-09-19 14:58:24,954][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 1.747175981970425,  accuracy: 0.5825
[2025-09-19 14:58:27,381][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.015258434226274275,  accuracy: 0.9971451876019576, gradient_norm : 0.4272395043320644
[2025-09-19 14:58:32,119][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 1.700770207478201,  accuracy: 0.5832
[2025-09-19 14:58:34,672][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.00382625925264864,  accuracy: 1.0, gradient_norm : 0.10003953392552482
[2025-09-19 14:58:39,389][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 1.6988104159870556,  accuracy: 0.5833
[2025-09-19 14:58:41,679][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.002729503666286921,  accuracy: 0.999896190179591, gradient_norm : 0.052494088135132046
[2025-09-19 14:58:46,453][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 1.6975643980960193,  accuracy: 0.5839
[2025-09-19 14:58:49,303][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.0017094905852522828,  accuracy: 1.0, gradient_norm : 0.0253541989206553
[2025-09-19 14:58:54,062][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 1.6926792618565762,  accuracy: 0.5843
[2025-09-19 14:58:56,651][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.004824857962351239,  accuracy: 0.9998077292828302, gradient_norm : 0.2576412363802597
[2025-09-19 14:59:01,467][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 1.6974471651725973,  accuracy: 0.5833
[2025-09-19 14:59:04,075][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.005357088511560062,  accuracy: 0.999912739965096, gradient_norm : 0.3164085752428138
[2025-09-19 14:59:08,874][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 1.6909715701880184,  accuracy: 0.5847
[2025-09-19 14:59:11,476][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.012494112463983761,  accuracy: 0.996694214876033, gradient_norm : 0.11575524661792681
[2025-09-19 14:59:16,277][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 1.6365038699676722,  accuracy: 0.5912
[2025-09-19 14:59:18,763][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.022828299712594948,  accuracy: 0.9999076809453471, gradient_norm : 0.4473343041310389
[2025-09-19 14:59:23,505][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 1.6372482972733493,  accuracy: 0.5924
[2025-09-19 14:59:25,686][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.00969013889599671,  accuracy: 0.9980938261145822, gradient_norm : 0.24762739394081568
[2025-09-19 14:59:30,519][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 1.6446909630042752,  accuracy: 0.5934
[2025-09-19 14:59:32,989][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.025243336327234887,  accuracy: 0.9992960844698636, gradient_norm : 0.8306910328158345
[2025-09-19 14:59:37,764][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 1.7770097504995708,  accuracy: 0.5905
[2025-09-19 14:59:40,234][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.029214938097597763,  accuracy: 0.9950713800135962, gradient_norm : 0.5944837821695181
[2025-09-19 14:59:44,982][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 1.6500241931599815,  accuracy: 0.5914
[2025-09-19 14:59:47,322][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.00809695816733864,  accuracy: 0.9989232576350823, gradient_norm : 0.17030169399585915
[2025-09-19 14:59:52,097][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 1.642712875258569,  accuracy: 0.5916
[2025-09-19 14:59:54,757][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.006962470883948584,  accuracy: 0.9995970341715023, gradient_norm : 0.35661926579498066
[2025-09-19 14:59:59,556][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 1.6552545546496353,  accuracy: 0.5908
[2025-09-19 15:00:01,970][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.016092688356865562,  accuracy: 0.998467225678478, gradient_norm : 0.5284548880273631
[2025-09-19 15:00:06,700][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 1.6533805168722508,  accuracy: 0.5887
[2025-09-19 15:00:08,690][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.008373416476152118,  accuracy: 0.9995096236361407, gradient_norm : 0.3193076389789534
[2025-09-19 15:00:13,546][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 1.6447758878642758,  accuracy: 0.5912
[2025-09-19 15:00:15,947][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.025823861814480296,  accuracy: 0.9986616478460895, gradient_norm : 0.8662838065916096
[2025-09-19 15:00:20,789][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 1.6440151214266923,  accuracy: 0.5917
[2025-09-19 15:00:22,674][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.006352256858375408,  accuracy: 0.9997396850188728, gradient_norm : 0.2921428084227981
[2025-09-19 15:00:27,436][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 1.6516506550317114,  accuracy: 0.5912
[2025-09-19 15:00:29,803][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.0023099898103388005,  accuracy: 1.0, gradient_norm : 0.07050699161937328
[2025-09-19 15:00:34,634][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 1.651375219285064,  accuracy: 0.5905
[2025-09-19 15:00:37,129][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.0032013223890291725,  accuracy: 1.0, gradient_norm : 0.150261508395874
[2025-09-19 15:00:41,917][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 1.6459272459083527,  accuracy: 0.5904
[2025-09-19 15:00:44,245][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.025475381770558064,  accuracy: 0.9987480997943307, gradient_norm : 0.7823469091874525
[2025-09-19 15:00:48,997][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 1.6374966391110153,  accuracy: 0.5924
[2025-09-19 15:00:51,086][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.02589618995688698,  accuracy: 0.998745294855709, gradient_norm : 0.9332411406902413
[2025-09-19 15:00:55,837][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 1.6874824723792243,  accuracy: 0.5925
[2025-09-19 15:00:57,993][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.02123529908003552,  accuracy: 0.9988481916609077, gradient_norm : 0.7298905698394255
[2025-09-19 15:01:02,763][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 1.7110397013139584,  accuracy: 0.59
[2025-09-19 15:01:05,202][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.0033258828594375177,  accuracy: 0.9999116217410517, gradient_norm : 0.11999061202758628
[2025-09-19 15:01:09,900][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 1.7124473115988428,  accuracy: 0.5903
[2025-09-19 15:01:11,671][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.0027041034960571743,  accuracy: 1.0, gradient_norm : 0.11069667762721955
[2025-09-19 15:01:16,499][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 1.7125571369286856,  accuracy: 0.5903
[2025-09-19 15:01:18,809][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.007718605013109013,  accuracy: 0.9999122960884056, gradient_norm : 0.30597141932299915
[2025-09-19 15:01:23,602][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 1.711266072709277,  accuracy: 0.5906
[2025-09-19 15:01:25,876][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.0028799813922492715,  accuracy: 1.0, gradient_norm : 0.07958256022909185
[2025-09-19 15:01:30,757][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 1.7093621026575405,  accuracy: 0.5912
[2025-09-19 15:01:33,375][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.02641282852561389,  accuracy: 0.9986507936507937, gradient_norm : 1.1038696183935341
[2025-09-19 15:01:38,086][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 1.711398536438727,  accuracy: 0.5898
[2025-09-19 15:01:40,588][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.014484589939926929,  accuracy: 0.9982656954561221, gradient_norm : 0.4786347999964899
[2025-09-19 15:01:45,298][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 1.683778843013721,  accuracy: 0.5903
[2025-09-19 15:01:47,722][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.001756636972025602,  accuracy: 1.0, gradient_norm : 0.024266374484436103
[2025-09-19 15:01:52,471][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 1.6839264353943122,  accuracy: 0.59
[2025-09-19 15:01:54,888][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.01207066520483537,  accuracy: 0.9998161257699734, gradient_norm : 0.35701721735243824
[2025-09-19 15:01:59,608][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 1.672250969263539,  accuracy: 0.5912
[2025-09-19 15:02:01,906][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.008241841392163673,  accuracy: 0.9993482309124767, gradient_norm : 0.4144884592956029
[2025-09-19 15:02:06,459][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 1.6778313046032447,  accuracy: 0.5889
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 001: loss=1.8168, accuracy=0.3830, gradient_norm=1.7076, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 002: loss=1.8583, accuracy=0.3365, gradient_norm=1.4046, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 003: loss=1.5659, accuracy=0.4595, gradient_norm=1.2512, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 004: loss=1.4156, accuracy=0.5160, gradient_norm=1.2348, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 005: loss=1.5038, accuracy=0.4643, gradient_norm=1.3819, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 006: loss=1.3101, accuracy=0.5501, gradient_norm=1.3387, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 007: loss=1.6479, accuracy=0.4217, gradient_norm=1.7543, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 008: loss=1.1514, accuracy=0.5990, gradient_norm=1.2886, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 009: loss=1.4940, accuracy=0.4694, gradient_norm=1.2906, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 010: loss=1.3155, accuracy=0.5359, gradient_norm=1.7936, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 011: loss=1.1067, accuracy=0.6203, gradient_norm=1.5169, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 012: loss=1.1183, accuracy=0.6250, gradient_norm=1.5938, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 013: loss=1.2189, accuracy=0.5818, gradient_norm=1.1819, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 014: loss=1.0780, accuracy=0.6281, gradient_norm=1.4764, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 015: loss=1.0835, accuracy=0.6255, gradient_norm=1.6303, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 016: loss=0.9769, accuracy=0.6779, gradient_norm=1.6838, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 017: loss=0.9840, accuracy=0.6701, gradient_norm=1.3990, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 018: loss=0.8625, accuracy=0.7167, gradient_norm=1.6773, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 019: loss=0.8953, accuracy=0.7082, gradient_norm=1.1637, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 020: loss=0.6432, accuracy=0.7990, gradient_norm=1.5748, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 021: loss=0.6733, accuracy=0.7874, gradient_norm=1.1287, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 022: loss=0.8801, accuracy=0.7160, gradient_norm=1.5946, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 023: loss=0.6908, accuracy=0.7854, gradient_norm=1.3612, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 024: loss=0.4794, accuracy=0.8522, gradient_norm=1.0272, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 025: loss=0.4157, accuracy=0.8839, gradient_norm=1.0117, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 026: loss=0.6589, accuracy=0.7857, gradient_norm=1.0947, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 027: loss=0.5010, accuracy=0.8417, gradient_norm=0.9531, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 028: loss=0.6538, accuracy=0.7906, gradient_norm=1.2962, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 029: loss=0.4033, accuracy=0.8767, gradient_norm=1.1761, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 030: loss=0.4473, accuracy=0.8692, gradient_norm=1.4246, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 031: loss=0.4513, accuracy=0.8671, gradient_norm=1.3707, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 032: loss=0.4483, accuracy=0.8681, gradient_norm=1.0430, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 033: loss=0.7069, accuracy=0.7504, gradient_norm=1.2225, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 034: loss=0.2958, accuracy=0.9166, gradient_norm=0.8109, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 035: loss=0.3624, accuracy=0.9057, gradient_norm=1.1976, 
[2025-09-19 15:02:06,461][__main__][INFO] - Train, Round 036: loss=0.4262, accuracy=0.8833, gradient_norm=1.6686, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 037: loss=0.2327, accuracy=0.9419, gradient_norm=1.0592, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 038: loss=0.5404, accuracy=0.8189, gradient_norm=0.6534, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 039: loss=0.4120, accuracy=0.8827, gradient_norm=1.5137, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 040: loss=0.2635, accuracy=0.9309, gradient_norm=1.1006, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 041: loss=0.2524, accuracy=0.9252, gradient_norm=0.7932, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 042: loss=0.1805, accuracy=0.9535, gradient_norm=0.8552, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 043: loss=0.0922, accuracy=0.9783, gradient_norm=0.3630, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 044: loss=0.3115, accuracy=0.9069, gradient_norm=1.2660, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 045: loss=0.1991, accuracy=0.9512, gradient_norm=1.2847, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 046: loss=0.2345, accuracy=0.9341, gradient_norm=0.8025, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 047: loss=0.1200, accuracy=0.9779, gradient_norm=0.8909, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 048: loss=0.2358, accuracy=0.9377, gradient_norm=0.9913, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 049: loss=0.1411, accuracy=0.9679, gradient_norm=0.6153, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 050: loss=0.1858, accuracy=0.9541, gradient_norm=0.7583, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 051: loss=0.1987, accuracy=0.9453, gradient_norm=0.5860, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 052: loss=0.1129, accuracy=0.9732, gradient_norm=0.7662, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 053: loss=0.1207, accuracy=0.9722, gradient_norm=0.5551, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 054: loss=0.0907, accuracy=0.9817, gradient_norm=0.9605, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 055: loss=0.0427, accuracy=0.9978, gradient_norm=0.6588, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 056: loss=0.0661, accuracy=0.9902, gradient_norm=0.6548, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 057: loss=0.0686, accuracy=0.9887, gradient_norm=0.5060, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 058: loss=0.1040, accuracy=0.9750, gradient_norm=0.5069, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 059: loss=0.0340, accuracy=0.9964, gradient_norm=0.9117, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 060: loss=0.1010, accuracy=0.9794, gradient_norm=0.8149, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 061: loss=0.0256, accuracy=0.9971, gradient_norm=0.3719, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 062: loss=0.0440, accuracy=0.9930, gradient_norm=0.7779, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 063: loss=0.0609, accuracy=0.9909, gradient_norm=0.4610, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 064: loss=0.0500, accuracy=0.9940, gradient_norm=0.5383, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 065: loss=0.1293, accuracy=0.9744, gradient_norm=0.7070, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 066: loss=0.0353, accuracy=0.9966, gradient_norm=0.6407, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 067: loss=0.0988, accuracy=0.9794, gradient_norm=0.7722, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 068: loss=0.1454, accuracy=0.9657, gradient_norm=0.5684, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 069: loss=0.0652, accuracy=0.9832, gradient_norm=0.3301, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 070: loss=0.0677, accuracy=0.9889, gradient_norm=0.5547, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 071: loss=0.0189, accuracy=0.9990, gradient_norm=0.4536, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 072: loss=0.0370, accuracy=0.9948, gradient_norm=0.4567, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 073: loss=0.1508, accuracy=0.9610, gradient_norm=0.9342, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 074: loss=0.0109, accuracy=0.9997, gradient_norm=0.2830, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 075: loss=0.0667, accuracy=0.9866, gradient_norm=0.4185, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 076: loss=0.0185, accuracy=0.9992, gradient_norm=0.3613, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 077: loss=0.0693, accuracy=0.9887, gradient_norm=0.8396, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 078: loss=0.1095, accuracy=0.9765, gradient_norm=0.7794, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 079: loss=0.0198, accuracy=0.9990, gradient_norm=0.4680, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 080: loss=0.0448, accuracy=0.9910, gradient_norm=0.1723, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 081: loss=0.0380, accuracy=0.9921, gradient_norm=0.2867, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 082: loss=0.0171, accuracy=0.9990, gradient_norm=0.3517, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 083: loss=0.0566, accuracy=0.9893, gradient_norm=0.8291, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 084: loss=0.0403, accuracy=0.9947, gradient_norm=0.4937, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 085: loss=0.0333, accuracy=0.9946, gradient_norm=0.6376, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 086: loss=0.1253, accuracy=0.9658, gradient_norm=1.0054, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 087: loss=0.0168, accuracy=0.9977, gradient_norm=0.2260, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 088: loss=0.0107, accuracy=0.9997, gradient_norm=0.3467, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 089: loss=0.0201, accuracy=0.9984, gradient_norm=0.1996, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 090: loss=0.0786, accuracy=0.9802, gradient_norm=0.5320, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 091: loss=0.0400, accuracy=0.9922, gradient_norm=0.5285, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 092: loss=0.0341, accuracy=0.9947, gradient_norm=0.3657, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 093: loss=0.0174, accuracy=0.9994, gradient_norm=0.3810, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 094: loss=0.0137, accuracy=0.9994, gradient_norm=0.5072, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 095: loss=0.0298, accuracy=0.9978, gradient_norm=0.5810, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 096: loss=0.0262, accuracy=0.9967, gradient_norm=0.3013, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 097: loss=0.0607, accuracy=0.9940, gradient_norm=1.1970, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 098: loss=0.0442, accuracy=0.9974, gradient_norm=0.8178, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 099: loss=0.0168, accuracy=0.9989, gradient_norm=0.3689, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 100: loss=0.0396, accuracy=0.9949, gradient_norm=0.6683, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 101: loss=0.0207, accuracy=0.9988, gradient_norm=0.5718, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 102: loss=0.0157, accuracy=0.9979, gradient_norm=0.1908, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 103: loss=0.0099, accuracy=0.9997, gradient_norm=0.2896, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 104: loss=0.0327, accuracy=0.9951, gradient_norm=0.4512, 
[2025-09-19 15:02:06,462][__main__][INFO] - Train, Round 105: loss=0.0060, accuracy=0.9998, gradient_norm=0.1799, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 106: loss=0.0117, accuracy=0.9997, gradient_norm=0.5151, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 107: loss=0.0079, accuracy=0.9999, gradient_norm=0.2151, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 108: loss=0.0252, accuracy=0.9976, gradient_norm=0.3869, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 109: loss=0.0185, accuracy=0.9989, gradient_norm=0.3787, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 110: loss=0.0250, accuracy=0.9964, gradient_norm=0.3675, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 111: loss=0.0074, accuracy=0.9994, gradient_norm=0.1009, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 112: loss=0.0098, accuracy=0.9994, gradient_norm=0.2869, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 113: loss=0.0061, accuracy=0.9998, gradient_norm=0.2602, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 114: loss=0.0165, accuracy=0.9989, gradient_norm=0.5441, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 115: loss=0.0062, accuracy=0.9997, gradient_norm=0.1062, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 116: loss=0.0499, accuracy=0.9859, gradient_norm=0.1930, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 117: loss=0.0131, accuracy=0.9990, gradient_norm=0.3309, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 118: loss=0.0151, accuracy=0.9983, gradient_norm=0.2906, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 119: loss=0.0104, accuracy=0.9993, gradient_norm=0.3161, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 120: loss=0.0111, accuracy=0.9994, gradient_norm=0.3428, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 121: loss=0.0154, accuracy=0.9991, gradient_norm=0.4072, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 122: loss=0.0259, accuracy=0.9991, gradient_norm=0.9409, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 123: loss=0.0119, accuracy=0.9981, gradient_norm=0.2723, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 124: loss=0.0441, accuracy=0.9982, gradient_norm=0.7525, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 125: loss=0.0049, accuracy=1.0000, gradient_norm=0.1972, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 126: loss=0.0058, accuracy=0.9999, gradient_norm=0.2067, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 127: loss=0.0328, accuracy=0.9961, gradient_norm=0.6300, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 128: loss=0.0080, accuracy=0.9998, gradient_norm=0.3334, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 129: loss=0.0072, accuracy=0.9997, gradient_norm=0.2387, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 130: loss=0.0051, accuracy=0.9997, gradient_norm=0.1319, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 131: loss=0.0047, accuracy=0.9999, gradient_norm=0.2529, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 132: loss=0.0033, accuracy=1.0000, gradient_norm=0.0608, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 133: loss=0.0346, accuracy=0.9942, gradient_norm=0.5223, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 134: loss=0.0486, accuracy=0.9945, gradient_norm=0.7608, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 135: loss=0.0332, accuracy=0.9930, gradient_norm=0.4964, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 136: loss=0.0065, accuracy=0.9996, gradient_norm=0.3215, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 137: loss=0.0257, accuracy=0.9992, gradient_norm=0.5169, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 138: loss=0.0188, accuracy=0.9961, gradient_norm=0.1668, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 139: loss=0.0154, accuracy=0.9986, gradient_norm=0.3536, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 140: loss=0.0044, accuracy=0.9998, gradient_norm=0.1326, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 141: loss=0.0674, accuracy=0.9905, gradient_norm=0.8009, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 142: loss=0.0045, accuracy=1.0000, gradient_norm=0.0650, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 143: loss=0.0061, accuracy=1.0000, gradient_norm=0.1717, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 144: loss=0.0049, accuracy=0.9999, gradient_norm=0.2778, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 145: loss=0.0680, accuracy=0.9949, gradient_norm=0.7257, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 146: loss=0.0023, accuracy=1.0000, gradient_norm=0.0277, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 147: loss=0.0085, accuracy=0.9994, gradient_norm=0.2069, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 148: loss=0.0146, accuracy=0.9990, gradient_norm=0.7577, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 149: loss=0.0305, accuracy=0.9973, gradient_norm=0.4064, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 150: loss=0.0112, accuracy=0.9975, gradient_norm=0.1586, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 151: loss=0.0201, accuracy=0.9984, gradient_norm=0.5433, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 152: loss=0.0100, accuracy=0.9990, gradient_norm=0.3111, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 153: loss=0.0104, accuracy=0.9996, gradient_norm=0.4637, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 154: loss=0.0091, accuracy=0.9986, gradient_norm=0.1962, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 155: loss=0.0170, accuracy=0.9976, gradient_norm=0.5417, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 156: loss=0.0084, accuracy=0.9995, gradient_norm=0.3797, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 157: loss=0.0227, accuracy=0.9977, gradient_norm=0.8145, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 158: loss=0.0107, accuracy=0.9986, gradient_norm=0.2742, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 159: loss=0.0301, accuracy=0.9984, gradient_norm=0.5401, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 160: loss=0.0216, accuracy=0.9995, gradient_norm=0.4540, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 161: loss=0.0059, accuracy=0.9998, gradient_norm=0.3874, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 162: loss=0.0134, accuracy=0.9996, gradient_norm=0.3863, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 163: loss=0.0047, accuracy=0.9994, gradient_norm=0.2633, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 164: loss=0.0196, accuracy=0.9988, gradient_norm=0.9215, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 165: loss=0.0026, accuracy=1.0000, gradient_norm=0.1066, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 166: loss=0.0047, accuracy=0.9995, gradient_norm=0.1179, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 167: loss=0.0050, accuracy=0.9997, gradient_norm=0.2663, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 168: loss=0.0063, accuracy=0.9999, gradient_norm=0.3393, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 169: loss=0.0034, accuracy=0.9998, gradient_norm=0.1098, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 170: loss=0.0153, accuracy=0.9971, gradient_norm=0.4272, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 171: loss=0.0038, accuracy=1.0000, gradient_norm=0.1000, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 172: loss=0.0027, accuracy=0.9999, gradient_norm=0.0525, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 173: loss=0.0017, accuracy=1.0000, gradient_norm=0.0254, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 174: loss=0.0048, accuracy=0.9998, gradient_norm=0.2576, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 175: loss=0.0054, accuracy=0.9999, gradient_norm=0.3164, 
[2025-09-19 15:02:06,463][__main__][INFO] - Train, Round 176: loss=0.0125, accuracy=0.9967, gradient_norm=0.1158, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 177: loss=0.0228, accuracy=0.9999, gradient_norm=0.4473, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 178: loss=0.0097, accuracy=0.9981, gradient_norm=0.2476, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 179: loss=0.0252, accuracy=0.9993, gradient_norm=0.8307, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 180: loss=0.0292, accuracy=0.9951, gradient_norm=0.5945, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 181: loss=0.0081, accuracy=0.9989, gradient_norm=0.1703, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 182: loss=0.0070, accuracy=0.9996, gradient_norm=0.3566, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 183: loss=0.0161, accuracy=0.9985, gradient_norm=0.5285, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 184: loss=0.0084, accuracy=0.9995, gradient_norm=0.3193, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 185: loss=0.0258, accuracy=0.9987, gradient_norm=0.8663, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 186: loss=0.0064, accuracy=0.9997, gradient_norm=0.2921, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 187: loss=0.0023, accuracy=1.0000, gradient_norm=0.0705, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 188: loss=0.0032, accuracy=1.0000, gradient_norm=0.1503, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 189: loss=0.0255, accuracy=0.9987, gradient_norm=0.7823, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 190: loss=0.0259, accuracy=0.9987, gradient_norm=0.9332, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 191: loss=0.0212, accuracy=0.9988, gradient_norm=0.7299, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 192: loss=0.0033, accuracy=0.9999, gradient_norm=0.1200, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 193: loss=0.0027, accuracy=1.0000, gradient_norm=0.1107, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 194: loss=0.0077, accuracy=0.9999, gradient_norm=0.3060, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 195: loss=0.0029, accuracy=1.0000, gradient_norm=0.0796, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 196: loss=0.0264, accuracy=0.9987, gradient_norm=1.1039, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 197: loss=0.0145, accuracy=0.9983, gradient_norm=0.4786, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 198: loss=0.0018, accuracy=1.0000, gradient_norm=0.0243, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 199: loss=0.0121, accuracy=0.9998, gradient_norm=0.3570, 
[2025-09-19 15:02:06,464][__main__][INFO] - Train, Round 200: loss=0.0082, accuracy=0.9993, gradient_norm=0.4145, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 001: loss=2.2216, accuracy=0.1424, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 002: loss=2.1326, accuracy=0.1791, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 003: loss=2.0347, accuracy=0.2254, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 004: loss=1.9833, accuracy=0.2530, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 005: loss=1.9576, accuracy=0.2638, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 006: loss=1.8857, accuracy=0.3076, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 007: loss=1.8249, accuracy=0.3372, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 008: loss=1.8252, accuracy=0.3418, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 009: loss=1.7328, accuracy=0.3829, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 010: loss=1.7109, accuracy=0.3999, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 011: loss=1.6963, accuracy=0.4157, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 012: loss=1.6905, accuracy=0.4320, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 013: loss=1.6496, accuracy=0.4447, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 014: loss=1.6263, accuracy=0.4473, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 015: loss=1.6169, accuracy=0.4502, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 016: loss=1.6164, accuracy=0.4553, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 017: loss=1.6229, accuracy=0.4581, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 018: loss=1.6115, accuracy=0.4643, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 019: loss=1.5910, accuracy=0.4769, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 020: loss=1.7565, accuracy=0.4776, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 021: loss=1.7663, accuracy=0.4814, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 022: loss=1.7674, accuracy=0.4820, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 023: loss=1.8469, accuracy=0.4759, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 024: loss=1.8462, accuracy=0.4760, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 025: loss=1.8711, accuracy=0.4685, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 026: loss=1.8554, accuracy=0.4740, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 027: loss=1.9227, accuracy=0.4753, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 028: loss=1.9882, accuracy=0.4721, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 029: loss=1.9466, accuracy=0.4743, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 030: loss=1.9495, accuracy=0.4788, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 031: loss=1.9372, accuracy=0.4806, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 032: loss=1.9570, accuracy=0.4852, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 033: loss=1.9308, accuracy=0.4998, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 034: loss=1.9684, accuracy=0.4975, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 035: loss=1.8967, accuracy=0.5048, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 036: loss=1.7657, accuracy=0.5095, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 037: loss=1.7732, accuracy=0.5081, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 038: loss=1.7442, accuracy=0.5128, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 039: loss=1.6970, accuracy=0.5151, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 040: loss=1.7010, accuracy=0.5178, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 041: loss=1.6688, accuracy=0.5262, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 042: loss=1.6499, accuracy=0.5241, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 043: loss=1.6260, accuracy=0.5285, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 044: loss=1.7163, accuracy=0.5306, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 045: loss=1.7164, accuracy=0.5377, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 046: loss=1.7107, accuracy=0.5384, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 047: loss=1.7099, accuracy=0.5381, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 048: loss=1.6664, accuracy=0.5419, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 049: loss=1.7102, accuracy=0.5400, 
[2025-09-19 15:02:06,464][__main__][INFO] - Test, Round 050: loss=1.6891, accuracy=0.5449, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 051: loss=1.6295, accuracy=0.5565, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 052: loss=1.6287, accuracy=0.5576, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 053: loss=1.6392, accuracy=0.5572, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 054: loss=1.6566, accuracy=0.5536, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 055: loss=1.6555, accuracy=0.5511, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 056: loss=1.6439, accuracy=0.5565, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 057: loss=1.6307, accuracy=0.5568, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 058: loss=1.6768, accuracy=0.5548, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 059: loss=1.6786, accuracy=0.5537, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 060: loss=1.6645, accuracy=0.5537, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 061: loss=1.6721, accuracy=0.5527, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 062: loss=1.6692, accuracy=0.5560, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 063: loss=1.6646, accuracy=0.5570, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 064: loss=1.6742, accuracy=0.5563, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 065: loss=1.7129, accuracy=0.5573, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 066: loss=1.7781, accuracy=0.5557, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 067: loss=1.6275, accuracy=0.5650, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 068: loss=1.6202, accuracy=0.5672, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 069: loss=1.6167, accuracy=0.5669, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 070: loss=1.6250, accuracy=0.5656, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 071: loss=1.6268, accuracy=0.5657, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 072: loss=1.6147, accuracy=0.5668, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 073: loss=1.6147, accuracy=0.5678, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 074: loss=1.6109, accuracy=0.5680, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 075: loss=1.6425, accuracy=0.5694, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 076: loss=1.6407, accuracy=0.5705, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 077: loss=1.6500, accuracy=0.5685, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 078: loss=1.6641, accuracy=0.5664, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 079: loss=1.6505, accuracy=0.5680, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 080: loss=1.6499, accuracy=0.5694, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 081: loss=1.6892, accuracy=0.5643, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 082: loss=1.6888, accuracy=0.5645, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 083: loss=1.7437, accuracy=0.5631, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 084: loss=1.6974, accuracy=0.5700, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 085: loss=1.6999, accuracy=0.5717, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 086: loss=1.6333, accuracy=0.5733, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 087: loss=1.6337, accuracy=0.5724, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 088: loss=1.6315, accuracy=0.5721, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 089: loss=1.6394, accuracy=0.5693, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 090: loss=1.7132, accuracy=0.5600, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 091: loss=1.6399, accuracy=0.5651, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 092: loss=1.6526, accuracy=0.5641, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 093: loss=1.6608, accuracy=0.5646, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 094: loss=1.6645, accuracy=0.5655, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 095: loss=1.6453, accuracy=0.5670, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 096: loss=1.6258, accuracy=0.5689, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 097: loss=1.6362, accuracy=0.5701, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 098: loss=1.7275, accuracy=0.5691, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 099: loss=1.7240, accuracy=0.5700, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 100: loss=1.7195, accuracy=0.5702, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 101: loss=1.7212, accuracy=0.5705, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 102: loss=1.6307, accuracy=0.5750, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 103: loss=1.6062, accuracy=0.5766, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 104: loss=1.5993, accuracy=0.5787, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 105: loss=1.6014, accuracy=0.5791, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 106: loss=1.6634, accuracy=0.5747, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 107: loss=1.6653, accuracy=0.5735, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 108: loss=1.6556, accuracy=0.5723, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 109: loss=1.6387, accuracy=0.5751, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 110: loss=1.6147, accuracy=0.5799, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 111: loss=1.6175, accuracy=0.5793, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 112: loss=1.6201, accuracy=0.5789, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 113: loss=1.6264, accuracy=0.5800, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 114: loss=1.6325, accuracy=0.5763, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 115: loss=1.6342, accuracy=0.5760, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 116: loss=1.6969, accuracy=0.5715, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 117: loss=1.7103, accuracy=0.5722, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 118: loss=1.7032, accuracy=0.5729, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 119: loss=1.6936, accuracy=0.5736, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 120: loss=1.6862, accuracy=0.5730, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 121: loss=1.7170, accuracy=0.5688, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 122: loss=1.7101, accuracy=0.5726, 
[2025-09-19 15:02:06,465][__main__][INFO] - Test, Round 123: loss=1.7381, accuracy=0.5713, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 124: loss=1.7690, accuracy=0.5721, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 125: loss=1.7701, accuracy=0.5716, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 126: loss=1.7676, accuracy=0.5726, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 127: loss=1.8255, accuracy=0.5720, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 128: loss=1.8439, accuracy=0.5708, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 129: loss=1.7899, accuracy=0.5755, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 130: loss=1.7749, accuracy=0.5760, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 131: loss=1.7666, accuracy=0.5765, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 132: loss=1.7676, accuracy=0.5762, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 133: loss=1.7382, accuracy=0.5765, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 134: loss=1.7258, accuracy=0.5739, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 135: loss=1.6723, accuracy=0.5823, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 136: loss=1.6519, accuracy=0.5831, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 137: loss=1.6765, accuracy=0.5797, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 138: loss=1.6751, accuracy=0.5815, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 139: loss=1.6736, accuracy=0.5785, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 140: loss=1.6725, accuracy=0.5799, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 141: loss=1.6578, accuracy=0.5822, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 142: loss=1.6570, accuracy=0.5827, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 143: loss=1.6526, accuracy=0.5835, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 144: loss=1.6579, accuracy=0.5809, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 145: loss=1.6747, accuracy=0.5808, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 146: loss=1.6768, accuracy=0.5810, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 147: loss=1.6773, accuracy=0.5824, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 148: loss=1.6908, accuracy=0.5807, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 149: loss=1.6864, accuracy=0.5830, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 150: loss=1.6386, accuracy=0.5887, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 151: loss=1.7134, accuracy=0.5831, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 152: loss=1.6424, accuracy=0.5879, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 153: loss=1.6505, accuracy=0.5888, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 154: loss=1.6351, accuracy=0.5908, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 155: loss=1.6521, accuracy=0.5912, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 156: loss=1.6688, accuracy=0.5880, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 157: loss=1.8042, accuracy=0.5815, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 158: loss=1.7765, accuracy=0.5854, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 159: loss=1.6955, accuracy=0.5858, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 160: loss=1.6951, accuracy=0.5843, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 161: loss=1.6978, accuracy=0.5857, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 162: loss=1.6788, accuracy=0.5885, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 163: loss=1.6812, accuracy=0.5869, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 164: loss=1.7526, accuracy=0.5831, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 165: loss=1.7534, accuracy=0.5838, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 166: loss=1.7304, accuracy=0.5866, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 167: loss=1.7298, accuracy=0.5846, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 168: loss=1.7437, accuracy=0.5828, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 169: loss=1.7472, accuracy=0.5825, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 170: loss=1.7008, accuracy=0.5832, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 171: loss=1.6988, accuracy=0.5833, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 172: loss=1.6976, accuracy=0.5839, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 173: loss=1.6927, accuracy=0.5843, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 174: loss=1.6974, accuracy=0.5833, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 175: loss=1.6910, accuracy=0.5847, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 176: loss=1.6365, accuracy=0.5912, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 177: loss=1.6372, accuracy=0.5924, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 178: loss=1.6447, accuracy=0.5934, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 179: loss=1.7770, accuracy=0.5905, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 180: loss=1.6500, accuracy=0.5914, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 181: loss=1.6427, accuracy=0.5916, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 182: loss=1.6553, accuracy=0.5908, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 183: loss=1.6534, accuracy=0.5887, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 184: loss=1.6448, accuracy=0.5912, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 185: loss=1.6440, accuracy=0.5917, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 186: loss=1.6517, accuracy=0.5912, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 187: loss=1.6514, accuracy=0.5905, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 188: loss=1.6459, accuracy=0.5904, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 189: loss=1.6375, accuracy=0.5924, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 190: loss=1.6875, accuracy=0.5925, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 191: loss=1.7110, accuracy=0.5900, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 192: loss=1.7124, accuracy=0.5903, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 193: loss=1.7126, accuracy=0.5903, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 194: loss=1.7113, accuracy=0.5906, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 195: loss=1.7094, accuracy=0.5912, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 196: loss=1.7114, accuracy=0.5898, 
[2025-09-19 15:02:06,466][__main__][INFO] - Test, Round 197: loss=1.6838, accuracy=0.5903, 
[2025-09-19 15:02:06,467][__main__][INFO] - Test, Round 198: loss=1.6839, accuracy=0.5900, 
[2025-09-19 15:02:06,467][__main__][INFO] - Test, Round 199: loss=1.6723, accuracy=0.5912, 
[2025-09-19 15:02:06,467][__main__][INFO] - Test, Round 200: loss=1.6778, accuracy=0.5889, 

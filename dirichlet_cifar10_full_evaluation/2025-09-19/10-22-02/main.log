[2025-09-19 10:22:07,278][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.10434098008866,  accuracy: 0.3180055055055055, gradient_norm : 0.5266244152023662
[2025-09-19 10:22:11,337][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.1640885596542603,  accuracy: 0.2165
[2025-09-19 10:22:13,506][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.144692922560022,  accuracy: 0.28195577628000473, gradient_norm : 0.4678468265665253
[2025-09-19 10:22:17,571][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.0983551972018724,  accuracy: 0.27
[2025-09-19 10:22:19,858][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 1.9144918196715373,  accuracy: 0.3689795069177156, gradient_norm : 0.42756775156049903
[2025-09-19 10:22:23,936][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.033318290401205,  accuracy: 0.2897
[2025-09-19 10:22:26,373][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.9077355247225365,  accuracy: 0.34813647777066614, gradient_norm : 0.4502747459259481
[2025-09-19 10:22:30,460][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 1.9555618567600228,  accuracy: 0.3256
[2025-09-19 10:22:32,313][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.8725427890275943,  accuracy: 0.3313746826260428, gradient_norm : 0.3994096226923185
[2025-09-19 10:22:36,433][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 1.9102465395647665,  accuracy: 0.3234
[2025-09-19 10:22:38,882][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 1.7113669771135214,  accuracy: 0.40808129687878053, gradient_norm : 0.33949623982365434
[2025-09-19 10:22:42,954][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 1.855638480777026,  accuracy: 0.3298
[2025-09-19 10:22:45,439][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.902663674815729,  accuracy: 0.3374561081704313, gradient_norm : 0.35574001491758345
[2025-09-19 10:22:49,496][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.818589061063907,  accuracy: 0.343
[2025-09-19 10:22:52,011][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 1.707266132580013,  accuracy: 0.3921181767592452, gradient_norm : 0.2971766198755942
[2025-09-19 10:22:56,123][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.7859163786228451,  accuracy: 0.3453
[2025-09-19 10:22:58,584][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.8335478459483256,  accuracy: 0.3533949100913825, gradient_norm : 0.3452714060054619
[2025-09-19 10:23:02,703][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 1.7444133762585785,  accuracy: 0.3724
[2025-09-19 10:23:05,110][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 1.7129156403252714,  accuracy: 0.3875334315812456, gradient_norm : 0.3052629330537175
[2025-09-19 10:23:09,247][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.7231019826237033,  accuracy: 0.379
[2025-09-19 10:23:11,745][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 1.5864784625281103,  accuracy: 0.44996044303797467, gradient_norm : 0.32266078468802384
[2025-09-19 10:23:15,823][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.7001101497381925,  accuracy: 0.379
[2025-09-19 10:23:18,319][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 1.6344851105778817,  accuracy: 0.4122126572698893, gradient_norm : 0.2960517798535986
[2025-09-19 10:23:22,441][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.6809992810546028,  accuracy: 0.3879
[2025-09-19 10:23:24,801][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 1.709787154646006,  accuracy: 0.39151325379258217, gradient_norm : 0.34057992766535594
[2025-09-19 10:23:28,883][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.660662044612136,  accuracy: 0.3951
[2025-09-19 10:23:31,209][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 1.6596185879158374,  accuracy: 0.3948784161824833, gradient_norm : 0.27330722512279537
[2025-09-19 10:23:35,295][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.6361822191623514,  accuracy: 0.4125
[2025-09-19 10:23:37,363][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 1.596393139864975,  accuracy: 0.42080213225028557, gradient_norm : 0.28076055075938733
[2025-09-19 10:23:41,472][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.6267037052556965,  accuracy: 0.4135
[2025-09-19 10:23:43,906][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 1.6464472190344677,  accuracy: 0.40988544075727423, gradient_norm : 0.2875473818699516
[2025-09-19 10:23:47,989][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.609687645199954,  accuracy: 0.42
[2025-09-19 10:23:50,277][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 1.6481413049246652,  accuracy: 0.4143455615942029, gradient_norm : 0.30991274662257656
[2025-09-19 10:23:54,436][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.5869828762181697,  accuracy: 0.4233
[2025-09-19 10:23:56,744][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 1.629627927837903,  accuracy: 0.41773111694371534, gradient_norm : 0.33468156651040654
[2025-09-19 10:24:00,884][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.5686428533049022,  accuracy: 0.4286
[2025-09-19 10:24:03,192][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 1.6175482549953644,  accuracy: 0.4250470058686115, gradient_norm : 0.2959408205595858
[2025-09-19 10:24:07,278][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.5506428560892838,  accuracy: 0.4331
[2025-09-19 10:24:09,110][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 1.5209232071439627,  accuracy: 0.4521699613724154, gradient_norm : 0.34542408410299685
[2025-09-19 10:24:13,215][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.5452443378671354,  accuracy: 0.4332
[2025-09-19 10:24:15,592][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 1.4331062276683169,  accuracy: 0.48959660297239915, gradient_norm : 0.3090631755635921
[2025-09-19 10:24:19,785][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.5364257753877848,  accuracy: 0.4368
[2025-09-19 10:24:22,089][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 1.402004356027358,  accuracy: 0.5108289325342669, gradient_norm : 0.3139231952002049
[2025-09-19 10:24:26,218][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.5230062598089638,  accuracy: 0.4415
[2025-09-19 10:24:28,700][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 1.5290230251944352,  accuracy: 0.4582460184409053, gradient_norm : 0.30239895535328415
[2025-09-19 10:24:32,765][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.507318011925048,  accuracy: 0.4468
[2025-09-19 10:24:34,943][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 1.3754765651328045,  accuracy: 0.5098987876765655, gradient_norm : 0.3025306490193917
[2025-09-19 10:24:39,068][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.501023700960768,  accuracy: 0.4475
[2025-09-19 10:24:41,360][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 1.4069416298129709,  accuracy: 0.5023346099365196, gradient_norm : 0.2977401756054169
[2025-09-19 10:24:45,467][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.5054710787080983,  accuracy: 0.4488
[2025-09-19 10:24:48,103][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 1.415816116761819,  accuracy: 0.48604025600593637, gradient_norm : 0.28978565973988085
[2025-09-19 10:24:52,239][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.4900820007068178,  accuracy: 0.4633
[2025-09-19 10:24:54,761][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 1.402299982149043,  accuracy: 0.4929015285526375, gradient_norm : 0.30356456407338483
[2025-09-19 10:24:58,873][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.4693939426001832,  accuracy: 0.467
[2025-09-19 10:25:01,327][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 1.4115489297069967,  accuracy: 0.4969172049324721, gradient_norm : 0.2795364844598091
[2025-09-19 10:25:05,457][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.4534871429619403,  accuracy: 0.4763
[2025-09-19 10:25:08,063][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 1.410853046908327,  accuracy: 0.4963219385547382, gradient_norm : 0.3051353962231666
[2025-09-19 10:25:12,172][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.448425091472256,  accuracy: 0.4791
[2025-09-19 10:25:14,756][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 1.4235637379805797,  accuracy: 0.4965944901900986, gradient_norm : 0.3074178518072085
[2025-09-19 10:25:18,815][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.4381171938038746,  accuracy: 0.483
[2025-09-19 10:25:21,137][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 1.3229988853672348,  accuracy: 0.5237942466046412, gradient_norm : 0.3284591809989053
[2025-09-19 10:25:25,264][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.4425658371229186,  accuracy: 0.487
[2025-09-19 10:25:28,023][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 1.4302475074578032,  accuracy: 0.48142179246127675, gradient_norm : 0.3103342485683873
[2025-09-19 10:25:32,134][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.4337219180760568,  accuracy: 0.487
[2025-09-19 10:25:34,051][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 1.4145073640218675,  accuracy: 0.48017902813299235, gradient_norm : 0.276622789050251
[2025-09-19 10:25:38,196][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.4257872426458555,  accuracy: 0.4954
[2025-09-19 10:25:39,920][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 1.350356242802615,  accuracy: 0.5026844608068722, gradient_norm : 0.272443936981765
[2025-09-19 10:25:44,088][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.4265902960806447,  accuracy: 0.4964
[2025-09-19 10:25:46,173][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 1.3031732756736307,  accuracy: 0.5404084996173995, gradient_norm : 0.3652972130543014
[2025-09-19 10:25:50,289][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.40995262319267,  accuracy: 0.4993
[2025-09-19 10:25:52,387][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 1.3648664665428811,  accuracy: 0.5150403040828364, gradient_norm : 0.3740828223161011
[2025-09-19 10:25:56,487][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.403259658557837,  accuracy: 0.4998
[2025-09-19 10:25:58,794][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 1.3824625324870923,  accuracy: 0.5060573618076295, gradient_norm : 0.30048181313565425
[2025-09-19 10:26:02,894][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.3880567074917405,  accuracy: 0.5024
[2025-09-19 10:26:05,445][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 1.317179479213241,  accuracy: 0.5285445730681706, gradient_norm : 0.3094305618652139
[2025-09-19 10:26:09,567][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.387781562069508,  accuracy: 0.5029
[2025-09-19 10:26:11,964][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 1.383615476643344,  accuracy: 0.5045349648473139, gradient_norm : 0.31208208041001345
[2025-09-19 10:26:16,139][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.3860844166575395,  accuracy: 0.5064
[2025-09-19 10:26:18,348][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 1.2549364478868612,  accuracy: 0.5541526699872582, gradient_norm : 0.36083595332188806
[2025-09-19 10:26:22,459][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.378965548675311,  accuracy: 0.5094
[2025-09-19 10:26:24,855][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 1.211713049500592,  accuracy: 0.5827870142130382, gradient_norm : 0.3881850549433408
[2025-09-19 10:26:28,948][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.37938891458245,  accuracy: 0.5068
[2025-09-19 10:26:31,628][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 1.2356355597730218,  accuracy: 0.5572362685265911, gradient_norm : 0.3286721005429415
[2025-09-19 10:26:35,681][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.3580214174437382,  accuracy: 0.5173
[2025-09-19 10:26:38,056][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 1.3435033708694248,  accuracy: 0.5161152842150125, gradient_norm : 0.32258377671913896
[2025-09-19 10:26:42,166][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.3498121751325185,  accuracy: 0.5209
[2025-09-19 10:26:44,471][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 1.3176959763619134,  accuracy: 0.5280695400217312, gradient_norm : 0.3432472541498138
[2025-09-19 10:26:48,559][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.3471983108253707,  accuracy: 0.5187
[2025-09-19 10:26:50,990][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 1.1545310059373695,  accuracy: 0.595300681293922, gradient_norm : 0.3608517322791497
[2025-09-19 10:26:55,094][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.3583161106118653,  accuracy: 0.5177
[2025-09-19 10:26:57,651][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 1.1757658672183255,  accuracy: 0.5857770906807093, gradient_norm : 0.3603460063825715
[2025-09-19 10:27:01,752][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.3547828252502871,  accuracy: 0.5214
[2025-09-19 10:27:04,438][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 1.2462851606530059,  accuracy: 0.5574863707165109, gradient_norm : 0.3785306466376179
[2025-09-19 10:27:08,557][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.3456419260599806,  accuracy: 0.5212
[2025-09-19 10:27:10,798][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 1.2447481215848955,  accuracy: 0.5593043669080535, gradient_norm : 0.34658844721312465
[2025-09-19 10:27:14,898][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.3389046502953363,  accuracy: 0.5215
[2025-09-19 10:27:17,030][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 1.232060937704715,  accuracy: 0.5666476516447994, gradient_norm : 0.35349609825772776
[2025-09-19 10:27:21,125][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.3422818382305992,  accuracy: 0.5223
[2025-09-19 10:27:23,259][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 1.264115859351425,  accuracy: 0.5495222835440033, gradient_norm : 0.34389444958356125
[2025-09-19 10:27:27,399][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.3291730827402166,  accuracy: 0.529
[2025-09-19 10:27:29,560][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 1.1583465147474596,  accuracy: 0.5915144703568418, gradient_norm : 0.3616356260174211
[2025-09-19 10:27:33,693][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.325254677854587,  accuracy: 0.5302
[2025-09-19 10:27:36,023][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 1.000956387292194,  accuracy: 0.6471221362308441, gradient_norm : 0.3561185928076232
[2025-09-19 10:27:40,140][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.3099018569057939,  accuracy: 0.5337
[2025-09-19 10:27:42,650][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 1.171394577607466,  accuracy: 0.58182261208577, gradient_norm : 0.3711144519315312
[2025-09-19 10:27:46,757][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.3103600479324917,  accuracy: 0.5356
[2025-09-19 10:27:49,229][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 1.1535344111260004,  accuracy: 0.588515015247842, gradient_norm : 0.38240374219998524
[2025-09-19 10:27:53,347][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.329785606930282,  accuracy: 0.5325
[2025-09-19 10:27:55,119][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 1.0742262053781315,  accuracy: 0.6253455241335318, gradient_norm : 0.41371811613695303
[2025-09-19 10:27:59,200][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.3364639683380484,  accuracy: 0.5321
[2025-09-19 10:28:01,849][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 1.0680864207983425,  accuracy: 0.6164239259869928, gradient_norm : 0.39254849466592207
[2025-09-19 10:28:05,994][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.3329041482850008,  accuracy: 0.5355
[2025-09-19 10:28:08,242][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 1.1002037973532375,  accuracy: 0.6070504891487687, gradient_norm : 0.3994842466274847
[2025-09-19 10:28:12,357][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.3084693182983094,  accuracy: 0.5407
[2025-09-19 10:28:14,590][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.997423325016915,  accuracy: 0.6473538860395649, gradient_norm : 0.38714594463076424
[2025-09-19 10:28:18,694][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.3115065532591375,  accuracy: 0.5408
[2025-09-19 10:28:20,736][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.934647403447322,  accuracy: 0.6662451792375292, gradient_norm : 0.40285804599784275
[2025-09-19 10:28:24,857][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.322283783533417,  accuracy: 0.5399
[2025-09-19 10:28:27,404][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 1.0822356104587652,  accuracy: 0.6204997882253283, gradient_norm : 0.3961643994512562
[2025-09-19 10:28:31,468][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.3142960942388253,  accuracy: 0.548
[2025-09-19 10:28:33,919][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.9450428021780345,  accuracy: 0.6613611951957816, gradient_norm : 0.38429779070006875
[2025-09-19 10:28:38,033][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.3133572784029126,  accuracy: 0.5447
[2025-09-19 10:28:40,530][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 1.0590782283723588,  accuracy: 0.6202486858067124, gradient_norm : 0.44928656806618894
[2025-09-19 10:28:44,635][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.319673651043698,  accuracy: 0.5421
[2025-09-19 10:28:46,876][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 1.0498973323234984,  accuracy: 0.6260353639194032, gradient_norm : 0.3765841691508431
[2025-09-19 10:28:51,027][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.3224462794075658,  accuracy: 0.5404
[2025-09-19 10:28:53,123][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.9864121444277429,  accuracy: 0.6544641778422133, gradient_norm : 0.41297780257315325
[2025-09-19 10:28:57,237][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.3050080702321978,  accuracy: 0.55
[2025-09-19 10:28:59,347][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 1.0038076657546506,  accuracy: 0.6475741687130816, gradient_norm : 0.4015470757184613
[2025-09-19 10:29:03,471][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.3176089807538813,  accuracy: 0.5488
[2025-09-19 10:29:05,543][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.9973756439927259,  accuracy: 0.6453691436830061, gradient_norm : 0.4320160394434209
[2025-09-19 10:29:09,620][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.309634638573192,  accuracy: 0.5459
[2025-09-19 10:29:11,992][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.9608568705883302,  accuracy: 0.661283086585913, gradient_norm : 0.4471549882311347
[2025-09-19 10:29:16,157][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.2999670369096596,  accuracy: 0.5477
[2025-09-19 10:29:18,835][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 1.0428068486398188,  accuracy: 0.6352026118686384, gradient_norm : 0.4341029370186451
[2025-09-19 10:29:22,967][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.3300150433511657,  accuracy: 0.545
[2025-09-19 10:29:25,358][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.8458680353600603,  accuracy: 0.7064774111540703, gradient_norm : 0.4406151849928074
[2025-09-19 10:29:29,459][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.3355975776601294,  accuracy: 0.5481
[2025-09-19 10:29:31,928][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 1.018949971100405,  accuracy: 0.6377603103307472, gradient_norm : 0.4538664382055578
[2025-09-19 10:29:36,048][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.3101560473810094,  accuracy: 0.5546
[2025-09-19 10:29:38,264][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 1.0053855815775188,  accuracy: 0.6482900054285542, gradient_norm : 0.43865816549427095
[2025-09-19 10:29:42,412][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.3072001247040883,  accuracy: 0.5571
[2025-09-19 10:29:44,912][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.9696668119522712,  accuracy: 0.6587360594795539, gradient_norm : 0.4289509290278863
[2025-09-19 10:29:49,060][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.3122849641435799,  accuracy: 0.5528
[2025-09-19 10:29:51,675][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.8819990107569449,  accuracy: 0.6821694853609748, gradient_norm : 0.42784994496570344
[2025-09-19 10:29:55,810][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.303287308386113,  accuracy: 0.5586
[2025-09-19 10:29:57,970][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.738031948753056,  accuracy: 0.7479307750188111, gradient_norm : 0.4018864011135821
[2025-09-19 10:30:02,103][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.327730072079367,  accuracy: 0.5529
[2025-09-19 10:30:04,580][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.9093492440772387,  accuracy: 0.6837404301859278, gradient_norm : 0.447405555000371
[2025-09-19 10:30:08,716][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.327414660955535,  accuracy: 0.5542
[2025-09-19 10:30:10,929][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.8395692701703398,  accuracy: 0.7065948040937443, gradient_norm : 0.4835994942181372
[2025-09-19 10:30:15,027][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.3436404990286794,  accuracy: 0.5544
[2025-09-19 10:30:17,423][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.8797449771136312,  accuracy: 0.6933094994892748, gradient_norm : 0.4232763810119022
[2025-09-19 10:30:21,517][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.3280235056540368,  accuracy: 0.5616
[2025-09-19 10:30:23,678][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.9245429868758371,  accuracy: 0.672227335480902, gradient_norm : 0.4963616863434348
[2025-09-19 10:30:27,778][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.3379978072090943,  accuracy: 0.5566
[2025-09-19 10:30:29,874][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.7979838055223608,  accuracy: 0.720129240710824, gradient_norm : 0.5053422704534503
[2025-09-19 10:30:34,024][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.3304821565786502,  accuracy: 0.5634
[2025-09-19 10:30:36,242][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.7882328427828416,  accuracy: 0.727550397067807, gradient_norm : 0.4971661518884486
[2025-09-19 10:30:40,340][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.3395036109859497,  accuracy: 0.5617
[2025-09-19 10:30:42,880][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.7724373486159356,  accuracy: 0.7352884243128146, gradient_norm : 0.569088807480153
[2025-09-19 10:30:47,060][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.383515501871109,  accuracy: 0.559
[2025-09-19 10:30:49,458][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.7657955150800811,  accuracy: 0.7335124315212811, gradient_norm : 0.48321967235251984
[2025-09-19 10:30:53,599][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.3766585858977836,  accuracy: 0.5602
[2025-09-19 10:30:55,915][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.8834540066295997,  accuracy: 0.694064183123878, gradient_norm : 0.5462650687500881
[2025-09-19 10:31:00,062][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.4004346786511939,  accuracy: 0.5544
[2025-09-19 10:31:02,331][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.7794064582083488,  accuracy: 0.7292312995518787, gradient_norm : 0.437273295284226
[2025-09-19 10:31:06,486][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.3959605896220604,  accuracy: 0.5582
[2025-09-19 10:31:08,600][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.7980985148161351,  accuracy: 0.7214614499424626, gradient_norm : 0.45796175384630294
[2025-09-19 10:31:12,727][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.3962745462517938,  accuracy: 0.5602
[2025-09-19 10:31:15,203][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.7140017298833123,  accuracy: 0.7463162471616986, gradient_norm : 0.5090855262631542
[2025-09-19 10:31:19,367][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.3923842951417538,  accuracy: 0.5581
[2025-09-19 10:31:21,847][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.6918324093166571,  accuracy: 0.7617685994175272, gradient_norm : 0.4746371085348131
[2025-09-19 10:31:25,933][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.4059092404126075,  accuracy: 0.5583
[2025-09-19 10:31:28,036][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.6993857266385816,  accuracy: 0.7594352248394004, gradient_norm : 0.6253235400576708
[2025-09-19 10:31:32,156][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.4103877169555372,  accuracy: 0.5606
[2025-09-19 10:31:34,511][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.7027597284172306,  accuracy: 0.7558874836458788, gradient_norm : 0.5675886541810702
[2025-09-19 10:31:38,641][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.3821587643136406,  accuracy: 0.5659
[2025-09-19 10:31:40,889][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.7243786045648776,  accuracy: 0.7414414414414414, gradient_norm : 0.5449141730173094
[2025-09-19 10:31:45,003][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.4105706014167503,  accuracy: 0.5644
[2025-09-19 10:31:47,338][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.8419434065075176,  accuracy: 0.7016115725207634, gradient_norm : 0.5623346233668747
[2025-09-19 10:31:51,447][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.3991007487210863,  accuracy: 0.5706
[2025-09-19 10:31:53,970][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.6500481444165925,  accuracy: 0.7754152217557948, gradient_norm : 0.4617209252691751
[2025-09-19 10:31:58,161][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.4036757145988883,  accuracy: 0.5657
[2025-09-19 10:32:00,706][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.7050758228083228,  accuracy: 0.7526808599675682, gradient_norm : 0.5947767875826446
[2025-09-19 10:32:04,848][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.4105528135763177,  accuracy: 0.5703
[2025-09-19 10:32:06,867][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.6410727820243918,  accuracy: 0.7779336138382422, gradient_norm : 0.6388731291623846
[2025-09-19 10:32:10,982][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.440428140550511,  accuracy: 0.5683
[2025-09-19 10:32:13,450][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.593431031752287,  accuracy: 0.795889612282577, gradient_norm : 0.5215567712371068
[2025-09-19 10:32:17,560][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.4445244094860898,  accuracy: 0.5719
[2025-09-19 10:32:19,919][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.6353869302667069,  accuracy: 0.7814031120443655, gradient_norm : 0.49859106376240936
[2025-09-19 10:32:24,008][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.446856214984426,  accuracy: 0.5725
[2025-09-19 10:32:26,249][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.46815733961796274,  accuracy: 0.8366746859128575, gradient_norm : 0.49046885815906094
[2025-09-19 10:32:30,397][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.507461096964514,  accuracy: 0.5677
[2025-09-19 10:32:32,573][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.6740722199349335,  accuracy: 0.7658040883847336, gradient_norm : 0.43858722892979685
[2025-09-19 10:32:36,684][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.4926034788914875,  accuracy: 0.5706
[2025-09-19 10:32:39,178][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.5930123871507447,  accuracy: 0.7961277424106908, gradient_norm : 0.4677982312340066
[2025-09-19 10:32:43,317][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.5262329721890993,  accuracy: 0.5672
[2025-09-19 10:32:45,572][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.5045404477783609,  accuracy: 0.8264977336027525, gradient_norm : 0.3927763768065403
[2025-09-19 10:32:49,698][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.5050705520835226,  accuracy: 0.5735
[2025-09-19 10:32:51,789][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.5385465755200121,  accuracy: 0.8148609381486094, gradient_norm : 0.46224082261613414
[2025-09-19 10:32:55,966][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.5103516740449972,  accuracy: 0.5734
[2025-09-19 10:32:58,298][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.5939847334519568,  accuracy: 0.7990377084032673, gradient_norm : 0.4931230729400048
[2025-09-19 10:33:02,445][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.5385423162769922,  accuracy: 0.571
[2025-09-19 10:33:05,143][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.6065503438769365,  accuracy: 0.7925925925925926, gradient_norm : 0.5529667301978379
[2025-09-19 10:33:09,285][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.5338455340012749,  accuracy: 0.5722
[2025-09-19 10:33:11,958][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.532490456078207,  accuracy: 0.8147478498827209, gradient_norm : 0.5080759644671048
[2025-09-19 10:33:16,108][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.5417359355579852,  accuracy: 0.5739
[2025-09-19 10:33:18,535][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.4722333772826033,  accuracy: 0.8389015308233347, gradient_norm : 0.5834734175746826
[2025-09-19 10:33:22,657][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.5302798703359268,  accuracy: 0.5765
[2025-09-19 10:33:25,021][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.521389998156253,  accuracy: 0.8215242397184727, gradient_norm : 0.5840387313387949
[2025-09-19 10:33:29,144][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.5681758925886684,  accuracy: 0.5761
[2025-09-19 10:33:31,580][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.42409660374987024,  accuracy: 0.8540034591514905, gradient_norm : 0.5679450874386573
[2025-09-19 10:33:35,708][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.578168345157812,  accuracy: 0.5779
[2025-09-19 10:33:38,020][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.5670860813161571,  accuracy: 0.8039032915817069, gradient_norm : 0.5392538486587479
[2025-09-19 10:33:42,234][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.6020274944715376,  accuracy: 0.5733
[2025-09-19 10:33:44,527][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.46564123094773563,  accuracy: 0.8392301608225678, gradient_norm : 0.5062794257053916
[2025-09-19 10:33:48,650][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.6266587948978288,  accuracy: 0.5722
[2025-09-19 10:33:51,090][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.3308303397492485,  accuracy: 0.8934502522902072, gradient_norm : 0.3676005515107158
[2025-09-19 10:33:55,240][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.6487541129837497,  accuracy: 0.5745
[2025-09-19 10:33:57,822][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.37983184340401,  accuracy: 0.8727962085308056, gradient_norm : 0.3817979214170347
[2025-09-19 10:34:01,923][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.6478321925286712,  accuracy: 0.5725
[2025-09-19 10:34:03,750][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.4681295230252681,  accuracy: 0.8357891851141115, gradient_norm : 0.521210876234726
[2025-09-19 10:34:07,846][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.6474041399687245,  accuracy: 0.5737
[2025-09-19 10:34:10,049][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.3718328016459873,  accuracy: 0.8748913987836664, gradient_norm : 0.5303162657597459
[2025-09-19 10:34:14,130][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.693061229549241,  accuracy: 0.574
[2025-09-19 10:34:16,422][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.44901801044648093,  accuracy: 0.8444431507248065, gradient_norm : 0.4768727158079159
[2025-09-19 10:34:20,572][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.7194911157813588,  accuracy: 0.5727
[2025-09-19 10:34:22,923][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.431862139303315,  accuracy: 0.847735368956743, gradient_norm : 0.4031801033231512
[2025-09-19 10:34:27,056][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.7028242981897457,  accuracy: 0.5718
[2025-09-19 10:34:29,878][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.4795930298987205,  accuracy: 0.8329983922829582, gradient_norm : 0.36403011989767137
[2025-09-19 10:34:34,016][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.6867816338770116,  accuracy: 0.5775
[2025-09-19 10:34:36,424][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.4487251982050575,  accuracy: 0.8454814966264568, gradient_norm : 0.43100371994688497
[2025-09-19 10:34:40,541][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.7187776739604135,  accuracy: 0.5777
[2025-09-19 10:34:43,126][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.33727066853177656,  accuracy: 0.8877921323849616, gradient_norm : 0.46081854917840237
[2025-09-19 10:34:47,220][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.7413041545496908,  accuracy: 0.5783
[2025-09-19 10:34:49,546][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.4122816506113057,  accuracy: 0.8630761142590104, gradient_norm : 0.5147414642939794
[2025-09-19 10:34:53,635][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 1.7580031931390891,  accuracy: 0.5766
[2025-09-19 10:34:56,246][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.4627348219165091,  accuracy: 0.8425694546523592, gradient_norm : 0.4911626902194906
[2025-09-19 10:35:00,350][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.7592688037832376,  accuracy: 0.5797
[2025-09-19 10:35:02,766][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.47929392310720764,  accuracy: 0.834529359384003, gradient_norm : 0.3689016611342669
[2025-09-19 10:35:06,898][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.7886894225610093,  accuracy: 0.576
[2025-09-19 10:35:09,135][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.4055284300973567,  accuracy: 0.8661646522812124, gradient_norm : 0.5621764949430509
[2025-09-19 10:35:13,286][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.8277084421394065,  accuracy: 0.5741
[2025-09-19 10:35:15,651][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.331480678158144,  accuracy: 0.8877728309262678, gradient_norm : 0.5375961693501055
[2025-09-19 10:35:19,819][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.8067171672784417,  accuracy: 0.5722
[2025-09-19 10:35:22,090][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.518016273661465,  accuracy: 0.8224082106420674, gradient_norm : 0.5535240455493747
[2025-09-19 10:35:26,240][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.834869365920934,  accuracy: 0.5685
[2025-09-19 10:35:28,722][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.2624534597211882,  accuracy: 0.9132168628940373, gradient_norm : 0.449608651471313
[2025-09-19 10:35:32,888][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 1.8105145000738423,  accuracy: 0.5718
[2025-09-19 10:35:35,193][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.33424695511794106,  accuracy: 0.8866680729880815, gradient_norm : 0.5170142906281305
[2025-09-19 10:35:39,371][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.8369525882431814,  accuracy: 0.5739
[2025-09-19 10:35:41,855][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.4216138759802242,  accuracy: 0.8501620287022272, gradient_norm : 0.5038752629884052
[2025-09-19 10:35:46,007][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.8265524954031636,  accuracy: 0.5808
[2025-09-19 10:35:48,324][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.26941926674009403,  accuracy: 0.9090800833581423, gradient_norm : 0.5753557158616673
[2025-09-19 10:35:52,412][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.8608914666554062,  accuracy: 0.5847
[2025-09-19 10:35:55,013][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.27921556241512674,  accuracy: 0.9082546598886468, gradient_norm : 0.4763013260504704
[2025-09-19 10:35:59,112][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.8930270282996091,  accuracy: 0.5862
[2025-09-19 10:36:01,727][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.26057724965634604,  accuracy: 0.91364018298945, gradient_norm : 0.32538817005235604
[2025-09-19 10:36:05,882][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.8832980578996135,  accuracy: 0.5881
[2025-09-19 10:36:08,419][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.2299591140016897,  accuracy: 0.9229516539440203, gradient_norm : 0.4827815812537056
[2025-09-19 10:36:12,513][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 1.9123246055922063,  accuracy: 0.5863
[2025-09-19 10:36:14,644][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.20219033054955374,  accuracy: 0.9358612343686971, gradient_norm : 0.32673039480249283
[2025-09-19 10:36:18,803][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.9168715451547658,  accuracy: 0.5866
[2025-09-19 10:36:21,369][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.300116690281689,  accuracy: 0.8963836031430464, gradient_norm : 0.3995889435111313
[2025-09-19 10:36:25,546][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.9281962673529225,  accuracy: 0.5819
[2025-09-19 10:36:27,981][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.42493308935752455,  accuracy: 0.8520814880425155, gradient_norm : 0.38679691323765
[2025-09-19 10:36:32,079][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.9428225273496147,  accuracy: 0.5827
[2025-09-19 10:36:34,597][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.423420368324933,  accuracy: 0.8531327308527288, gradient_norm : 0.3381082628775083
[2025-09-19 10:36:38,748][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.960949395050634,  accuracy: 0.5802
[2025-09-19 10:36:41,219][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.21897205911084944,  accuracy: 0.9283208290602903, gradient_norm : 0.4367961377435242
[2025-09-19 10:36:45,347][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.9994900645082114,  accuracy: 0.5815
[2025-09-19 10:36:48,236][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.21555258314581943,  accuracy: 0.9287035046226618, gradient_norm : 0.4663575405806204
[2025-09-19 10:36:52,377][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 2.016766506920614,  accuracy: 0.5822
[2025-09-19 10:36:54,498][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.40785933026595633,  accuracy: 0.8556086659631262, gradient_norm : 0.4694267651354228
[2025-09-19 10:36:58,616][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 2.036678326837504,  accuracy: 0.5812
[2025-09-19 10:37:01,034][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.32770067616438403,  accuracy: 0.8848175714360069, gradient_norm : 0.3323969565843822
[2025-09-19 10:37:05,581][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 2.0471068128729133,  accuracy: 0.5795
[2025-09-19 10:37:10,615][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.2224000338528131,  accuracy: 0.9255374934452019, gradient_norm : 0.4370915457632929
[2025-09-19 10:37:14,747][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 2.034671100672774,  accuracy: 0.5837
[2025-09-19 10:37:16,949][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.27515036250454417,  accuracy: 0.9076505205975555, gradient_norm : 0.32254535611578833
[2025-09-19 10:37:21,098][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 2.0472509035476967,  accuracy: 0.5822
[2025-09-19 10:37:23,473][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.31680341218525987,  accuracy: 0.8884407869638672, gradient_norm : 0.5516646911429425
[2025-09-19 10:37:27,602][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 2.0472763131766443,  accuracy: 0.5843
[2025-09-19 10:37:30,203][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.4208504826448699,  accuracy: 0.8523956345127979, gradient_norm : 0.4601230456804022
[2025-09-19 10:37:34,384][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 2.0764974348514222,  accuracy: 0.5877
[2025-09-19 10:37:36,711][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.17752909856873567,  accuracy: 0.9414235441026223, gradient_norm : 0.3833563536329739
[2025-09-19 10:37:40,903][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 2.09578172992499,  accuracy: 0.5875
[2025-09-19 10:37:43,180][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.37527691464915885,  accuracy: 0.8682980816527299, gradient_norm : 0.5090006792015043
[2025-09-19 10:37:47,386][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 2.10741346377033,  accuracy: 0.5851
[2025-09-19 10:37:50,083][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.18981359078155288,  accuracy: 0.9351999672520365, gradient_norm : 0.207892173363754
[2025-09-19 10:37:54,238][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 2.0998244719591534,  accuracy: 0.5814
[2025-09-19 10:37:57,005][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.33169036812128727,  accuracy: 0.8855783444198079, gradient_norm : 0.2976807473319446
[2025-09-19 10:38:01,213][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 2.1076053191920976,  accuracy: 0.582
[2025-09-19 10:38:03,310][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.3058315789537672,  accuracy: 0.8911737824781303, gradient_norm : 0.4471476783220434
[2025-09-19 10:38:07,477][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 2.1137370220894014,  accuracy: 0.5809
[2025-09-19 10:38:09,943][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.27964281555338927,  accuracy: 0.9069014369560817, gradient_norm : 0.42311516969315327
[2025-09-19 10:38:14,082][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 2.101768960782892,  accuracy: 0.5851
[2025-09-19 10:38:16,461][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.24196200337728302,  accuracy: 0.9184149184149184, gradient_norm : 0.4369036323592147
[2025-09-19 10:38:20,622][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 2.12579052670954,  accuracy: 0.5824
[2025-09-19 10:38:22,628][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.18927025626589974,  accuracy: 0.9376162082451753, gradient_norm : 0.31044886436752817
[2025-09-19 10:38:26,768][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 2.138848015837454,  accuracy: 0.5873
[2025-09-19 10:38:28,959][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.3992859612245904,  accuracy: 0.8571265873241842, gradient_norm : 0.520659058109358
[2025-09-19 10:38:33,105][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 2.141014359027193,  accuracy: 0.5908
[2025-09-19 10:38:35,477][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.14614027476618022,  accuracy: 0.9555826788367651, gradient_norm : 0.25577495264869504
[2025-09-19 10:38:39,667][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 2.1678722960998575,  accuracy: 0.5875
[2025-09-19 10:38:42,076][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.2178144627557459,  accuracy: 0.929065208419315, gradient_norm : 0.3030347511043183
[2025-09-19 10:38:46,219][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 2.170389995235101,  accuracy: 0.5898
[2025-09-19 10:38:48,509][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.3035363930933629,  accuracy: 0.8934966494562232, gradient_norm : 0.29968250317203826
[2025-09-19 10:38:52,690][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 2.202384593689551,  accuracy: 0.5937
[2025-09-19 10:38:54,878][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.20931837195626232,  accuracy: 0.9338582677165355, gradient_norm : 0.27721313301810596
[2025-09-19 10:38:59,099][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 2.2184228402000774,  accuracy: 0.5879
[2025-09-19 10:39:01,681][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.21406888141772204,  accuracy: 0.9277893277893278, gradient_norm : 0.48977491658302325
[2025-09-19 10:39:05,824][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 2.2269380130988754,  accuracy: 0.5889
[2025-09-19 10:39:07,923][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.23579878325457232,  accuracy: 0.9216406673492742, gradient_norm : 0.2799181052743197
[2025-09-19 10:39:12,093][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 2.2500309131670666,  accuracy: 0.5848
[2025-09-19 10:39:14,632][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.2407770600191838,  accuracy: 0.9177752553916004, gradient_norm : 0.30044689754934156
[2025-09-19 10:39:18,797][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 2.2852962721014585,  accuracy: 0.5839
[2025-09-19 10:39:20,904][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.25582351338810766,  accuracy: 0.9119869192602617, gradient_norm : 0.5249538822376383
[2025-09-19 10:39:25,067][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 2.2907269908202395,  accuracy: 0.5864
[2025-09-19 10:39:27,460][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.2411193200743431,  accuracy: 0.9191486866791745, gradient_norm : 0.3226399786114465
[2025-09-19 10:39:31,669][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 2.29209618936146,  accuracy: 0.5877
[2025-09-19 10:39:33,927][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.2137234781740312,  accuracy: 0.9288670766319773, gradient_norm : 0.5427617012586888
[2025-09-19 10:39:38,069][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 2.2908264931695252,  accuracy: 0.5871
[2025-09-19 10:39:40,339][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.14802635865403777,  accuracy: 0.9514100504183057, gradient_norm : 0.28585901862417945
[2025-09-19 10:39:44,485][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 2.3035810228096034,  accuracy: 0.5876
[2025-09-19 10:39:47,018][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.2059475960548601,  accuracy: 0.9320017623733294, gradient_norm : 0.28642215259488557
[2025-09-19 10:39:51,129][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 2.322093028016695,  accuracy: 0.5872
[2025-09-19 10:39:53,822][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.06814796802915837,  accuracy: 0.979223939789986, gradient_norm : 0.2721669944656821
[2025-09-19 10:39:57,896][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 2.3389185811870377,  accuracy: 0.5849
[2025-09-19 10:40:00,458][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.1602092790302727,  accuracy: 0.9482767270355692, gradient_norm : 0.328520087449202
[2025-09-19 10:40:04,630][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 2.3342726049985627,  accuracy: 0.5874
[2025-09-19 10:40:06,947][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.13477895170052606,  accuracy: 0.9559255079006772, gradient_norm : 0.2548475647482635
[2025-09-19 10:40:11,050][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 2.3428532176048997,  accuracy: 0.5887
[2025-09-19 10:40:13,523][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.25097954483333196,  accuracy: 0.9141794602841613, gradient_norm : 0.3336599065030415
[2025-09-19 10:40:17,653][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 2.3453326150998905,  accuracy: 0.5892
[2025-09-19 10:40:19,984][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.12939227893491057,  accuracy: 0.9592519469123615, gradient_norm : 0.3185660667229298
[2025-09-19 10:40:24,092][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 2.3750483704554974,  accuracy: 0.59
[2025-09-19 10:40:26,312][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.22247844975401238,  accuracy: 0.9234397469082543, gradient_norm : 0.3894688901256554
[2025-09-19 10:40:30,431][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 2.3838550650450774,  accuracy: 0.5878
[2025-09-19 10:40:33,156][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.23062620498168251,  accuracy: 0.9195231711987745, gradient_norm : 0.42092181608479723
[2025-09-19 10:40:37,325][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 2.3969797844757528,  accuracy: 0.5897
[2025-09-19 10:40:39,744][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.13751058978204114,  accuracy: 0.953764258555133, gradient_norm : 0.3186001142438734
[2025-09-19 10:40:43,862][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 2.416376607768963,  accuracy: 0.5895
[2025-09-19 10:40:46,262][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.15977868573191234,  accuracy: 0.9455930887206367, gradient_norm : 0.1653209706733189
[2025-09-19 10:40:50,392][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 2.4193583624000263,  accuracy: 0.589
[2025-09-19 10:40:52,709][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.11941499715615515,  accuracy: 0.9617606891480197, gradient_norm : 0.24498623563768912
[2025-09-19 10:40:56,850][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 2.4158561483704464,  accuracy: 0.5912
[2025-09-19 10:40:59,403][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.14389106108367586,  accuracy: 0.9546714579055442, gradient_norm : 0.4520575621423026
[2025-09-19 10:41:03,515][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 2.4102588021761977,  accuracy: 0.5901
[2025-09-19 10:41:05,770][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.21207755813598522,  accuracy: 0.9298090718463746, gradient_norm : 0.29705411334033655
[2025-09-19 10:41:09,926][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 2.422415363955776,  accuracy: 0.5914
[2025-09-19 10:41:12,421][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.11409001806890849,  accuracy: 0.9607909169633407, gradient_norm : 0.22364945567123237
[2025-09-19 10:41:16,553][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 2.431023111913085,  accuracy: 0.5903
[2025-09-19 10:41:19,003][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.13463698618559522,  accuracy: 0.9547538154559672, gradient_norm : 0.30020971019661347
[2025-09-19 10:41:23,000][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 2.4414620517652774,  accuracy: 0.59
[2025-09-19 10:41:25,142][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.06981678917020077,  accuracy: 0.9783687125057683, gradient_norm : 0.19525234104398465
[2025-09-19 10:41:29,153][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 2.4544274881889874,  accuracy: 0.5901
[2025-09-19 10:41:31,377][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.052869612939948074,  accuracy: 0.9846589961647491, gradient_norm : 0.34008981627243934
[2025-09-19 10:41:35,402][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 2.468068383632944,  accuracy: 0.5905
[2025-09-19 10:41:37,863][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.2066755406338534,  accuracy: 0.9282074567378034, gradient_norm : 0.461910216486513
[2025-09-19 10:41:41,900][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 2.4963719562893396,  accuracy: 0.5887
[2025-09-19 10:41:44,227][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.10470349655350655,  accuracy: 0.9663237139272272, gradient_norm : 0.15523795646725924
[2025-09-19 10:41:48,292][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 2.5018646199811783,  accuracy: 0.5922
[2025-09-19 10:41:50,806][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.1334117685888615,  accuracy: 0.9554956169925826, gradient_norm : 0.21235699591589668
[2025-09-19 10:41:54,847][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 2.4945276293971568,  accuracy: 0.592
[2025-09-19 10:41:56,985][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.0899133995894658,  accuracy: 0.9733779098563645, gradient_norm : 0.2773781609785908
[2025-09-19 10:42:01,027][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 2.504368865476045,  accuracy: 0.5872
[2025-09-19 10:42:03,324][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.1051330985871423,  accuracy: 0.9655584415584415, gradient_norm : 0.2986397451166763
[2025-09-19 10:42:07,414][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 2.5172195146522847,  accuracy: 0.5884
[2025-09-19 10:42:09,635][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.13638251660595496,  accuracy: 0.9583622484385843, gradient_norm : 0.382353228170595
[2025-09-19 10:42:13,681][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 2.548824706007774,  accuracy: 0.5889
[2025-09-19 10:42:16,093][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.11440096415320374,  accuracy: 0.9647236778131921, gradient_norm : 0.38768251453406594
[2025-09-19 10:42:20,120][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 2.56349421451628,  accuracy: 0.5903
[2025-09-19 10:42:22,596][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.10049893329129887,  accuracy: 0.9687468392839081, gradient_norm : 0.22266718002369204
[2025-09-19 10:42:26,568][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 2.560945058194522,  accuracy: 0.589
[2025-09-19 10:42:28,791][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.1729179859359301,  accuracy: 0.9407054012608621, gradient_norm : 0.4174964030824302
[2025-09-19 10:42:32,847][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 2.5964106231222277,  accuracy: 0.5849
[2025-09-19 10:42:35,107][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.16095316976154264,  accuracy: 0.9475720066650798, gradient_norm : 0.43470332043278664
[2025-09-19 10:42:39,186][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 2.603898518864589,  accuracy: 0.5823
[2025-09-19 10:42:41,804][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.19418955257604054,  accuracy: 0.9361485627066904, gradient_norm : 0.5029632443224797
[2025-09-19 10:42:45,836][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 2.6165907212602466,  accuracy: 0.5826
[2025-09-19 10:42:48,075][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.11316830713944037,  accuracy: 0.9638573484727331, gradient_norm : 0.1900098325656953
[2025-09-19 10:42:52,050][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 2.6269278218462104,  accuracy: 0.5822
[2025-09-19 10:42:53,966][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.03767132955509276,  accuracy: 0.9899468154105591, gradient_norm : 0.38759223884767086
[2025-09-19 10:42:58,005][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 2.6390828181317953,  accuracy: 0.5813
[2025-09-19 10:43:00,186][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.11331062765612113,  accuracy: 0.9628530670470756, gradient_norm : 0.5600093534876248
[2025-09-19 10:43:04,169][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 2.66443613136333,  accuracy: 0.5789
[2025-09-19 10:43:06,249][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.14824598749956325,  accuracy: 0.9493445335369733, gradient_norm : 0.21620992998576782
[2025-09-19 10:43:10,312][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 2.66481920113628,  accuracy: 0.58
[2025-09-19 10:43:13,154][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.10641630264945162,  accuracy: 0.9648444142152696, gradient_norm : 0.42747101483140737
[2025-09-19 10:43:17,069][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 2.6616466556335765,  accuracy: 0.5805
[2025-09-19 10:43:19,066][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.1791177587643827,  accuracy: 0.9388667391566993, gradient_norm : 0.32224594682885627
[2025-09-19 10:43:22,620][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 2.6570767524382535,  accuracy: 0.5827
[2025-09-19 10:43:24,582][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.05761653406173482,  accuracy: 0.9832954137229074, gradient_norm : 0.31371413429334216
[2025-09-19 10:43:28,128][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 2.675903328816642,  accuracy: 0.5833
[2025-09-19 10:43:30,171][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.16775950753255808,  accuracy: 0.9466270430906389, gradient_norm : 0.5516122737881276
[2025-09-19 10:43:33,756][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 2.7061664748664622,  accuracy: 0.5816
[2025-09-19 10:43:35,903][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.058308079858042115,  accuracy: 0.9817629179331308, gradient_norm : 0.18587520581354744
[2025-09-19 10:43:39,395][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 2.7215334728246185,  accuracy: 0.5835
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 001: loss=2.1043, accuracy=0.3180, gradient_norm=0.5266, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 002: loss=2.1447, accuracy=0.2820, gradient_norm=0.4678, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 003: loss=1.9145, accuracy=0.3690, gradient_norm=0.4276, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 004: loss=1.9077, accuracy=0.3481, gradient_norm=0.4503, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 005: loss=1.8725, accuracy=0.3314, gradient_norm=0.3994, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 006: loss=1.7114, accuracy=0.4081, gradient_norm=0.3395, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 007: loss=1.9027, accuracy=0.3375, gradient_norm=0.3557, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 008: loss=1.7073, accuracy=0.3921, gradient_norm=0.2972, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 009: loss=1.8335, accuracy=0.3534, gradient_norm=0.3453, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 010: loss=1.7129, accuracy=0.3875, gradient_norm=0.3053, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 011: loss=1.5865, accuracy=0.4500, gradient_norm=0.3227, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 012: loss=1.6345, accuracy=0.4122, gradient_norm=0.2961, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 013: loss=1.7098, accuracy=0.3915, gradient_norm=0.3406, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 014: loss=1.6596, accuracy=0.3949, gradient_norm=0.2733, 
[2025-09-19 10:43:39,396][__main__][INFO] - Train, Round 015: loss=1.5964, accuracy=0.4208, gradient_norm=0.2808, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 016: loss=1.6464, accuracy=0.4099, gradient_norm=0.2875, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 017: loss=1.6481, accuracy=0.4143, gradient_norm=0.3099, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 018: loss=1.6296, accuracy=0.4177, gradient_norm=0.3347, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 019: loss=1.6175, accuracy=0.4250, gradient_norm=0.2959, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 020: loss=1.5209, accuracy=0.4522, gradient_norm=0.3454, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 021: loss=1.4331, accuracy=0.4896, gradient_norm=0.3091, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 022: loss=1.4020, accuracy=0.5108, gradient_norm=0.3139, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 023: loss=1.5290, accuracy=0.4582, gradient_norm=0.3024, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 024: loss=1.3755, accuracy=0.5099, gradient_norm=0.3025, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 025: loss=1.4069, accuracy=0.5023, gradient_norm=0.2977, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 026: loss=1.4158, accuracy=0.4860, gradient_norm=0.2898, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 027: loss=1.4023, accuracy=0.4929, gradient_norm=0.3036, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 028: loss=1.4115, accuracy=0.4969, gradient_norm=0.2795, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 029: loss=1.4109, accuracy=0.4963, gradient_norm=0.3051, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 030: loss=1.4236, accuracy=0.4966, gradient_norm=0.3074, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 031: loss=1.3230, accuracy=0.5238, gradient_norm=0.3285, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 032: loss=1.4302, accuracy=0.4814, gradient_norm=0.3103, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 033: loss=1.4145, accuracy=0.4802, gradient_norm=0.2766, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 034: loss=1.3504, accuracy=0.5027, gradient_norm=0.2724, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 035: loss=1.3032, accuracy=0.5404, gradient_norm=0.3653, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 036: loss=1.3649, accuracy=0.5150, gradient_norm=0.3741, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 037: loss=1.3825, accuracy=0.5061, gradient_norm=0.3005, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 038: loss=1.3172, accuracy=0.5285, gradient_norm=0.3094, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 039: loss=1.3836, accuracy=0.5045, gradient_norm=0.3121, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 040: loss=1.2549, accuracy=0.5542, gradient_norm=0.3608, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 041: loss=1.2117, accuracy=0.5828, gradient_norm=0.3882, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 042: loss=1.2356, accuracy=0.5572, gradient_norm=0.3287, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 043: loss=1.3435, accuracy=0.5161, gradient_norm=0.3226, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 044: loss=1.3177, accuracy=0.5281, gradient_norm=0.3432, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 045: loss=1.1545, accuracy=0.5953, gradient_norm=0.3609, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 046: loss=1.1758, accuracy=0.5858, gradient_norm=0.3603, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 047: loss=1.2463, accuracy=0.5575, gradient_norm=0.3785, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 048: loss=1.2447, accuracy=0.5593, gradient_norm=0.3466, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 049: loss=1.2321, accuracy=0.5666, gradient_norm=0.3535, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 050: loss=1.2641, accuracy=0.5495, gradient_norm=0.3439, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 051: loss=1.1583, accuracy=0.5915, gradient_norm=0.3616, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 052: loss=1.0010, accuracy=0.6471, gradient_norm=0.3561, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 053: loss=1.1714, accuracy=0.5818, gradient_norm=0.3711, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 054: loss=1.1535, accuracy=0.5885, gradient_norm=0.3824, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 055: loss=1.0742, accuracy=0.6253, gradient_norm=0.4137, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 056: loss=1.0681, accuracy=0.6164, gradient_norm=0.3925, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 057: loss=1.1002, accuracy=0.6071, gradient_norm=0.3995, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 058: loss=0.9974, accuracy=0.6474, gradient_norm=0.3871, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 059: loss=0.9346, accuracy=0.6662, gradient_norm=0.4029, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 060: loss=1.0822, accuracy=0.6205, gradient_norm=0.3962, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 061: loss=0.9450, accuracy=0.6614, gradient_norm=0.3843, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 062: loss=1.0591, accuracy=0.6202, gradient_norm=0.4493, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 063: loss=1.0499, accuracy=0.6260, gradient_norm=0.3766, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 064: loss=0.9864, accuracy=0.6545, gradient_norm=0.4130, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 065: loss=1.0038, accuracy=0.6476, gradient_norm=0.4015, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 066: loss=0.9974, accuracy=0.6454, gradient_norm=0.4320, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 067: loss=0.9609, accuracy=0.6613, gradient_norm=0.4472, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 068: loss=1.0428, accuracy=0.6352, gradient_norm=0.4341, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 069: loss=0.8459, accuracy=0.7065, gradient_norm=0.4406, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 070: loss=1.0189, accuracy=0.6378, gradient_norm=0.4539, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 071: loss=1.0054, accuracy=0.6483, gradient_norm=0.4387, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 072: loss=0.9697, accuracy=0.6587, gradient_norm=0.4290, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 073: loss=0.8820, accuracy=0.6822, gradient_norm=0.4278, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 074: loss=0.7380, accuracy=0.7479, gradient_norm=0.4019, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 075: loss=0.9093, accuracy=0.6837, gradient_norm=0.4474, 
[2025-09-19 10:43:39,397][__main__][INFO] - Train, Round 076: loss=0.8396, accuracy=0.7066, gradient_norm=0.4836, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 077: loss=0.8797, accuracy=0.6933, gradient_norm=0.4233, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 078: loss=0.9245, accuracy=0.6722, gradient_norm=0.4964, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 079: loss=0.7980, accuracy=0.7201, gradient_norm=0.5053, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 080: loss=0.7882, accuracy=0.7276, gradient_norm=0.4972, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 081: loss=0.7724, accuracy=0.7353, gradient_norm=0.5691, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 082: loss=0.7658, accuracy=0.7335, gradient_norm=0.4832, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 083: loss=0.8835, accuracy=0.6941, gradient_norm=0.5463, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 084: loss=0.7794, accuracy=0.7292, gradient_norm=0.4373, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 085: loss=0.7981, accuracy=0.7215, gradient_norm=0.4580, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 086: loss=0.7140, accuracy=0.7463, gradient_norm=0.5091, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 087: loss=0.6918, accuracy=0.7618, gradient_norm=0.4746, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 088: loss=0.6994, accuracy=0.7594, gradient_norm=0.6253, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 089: loss=0.7028, accuracy=0.7559, gradient_norm=0.5676, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 090: loss=0.7244, accuracy=0.7414, gradient_norm=0.5449, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 091: loss=0.8419, accuracy=0.7016, gradient_norm=0.5623, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 092: loss=0.6500, accuracy=0.7754, gradient_norm=0.4617, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 093: loss=0.7051, accuracy=0.7527, gradient_norm=0.5948, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 094: loss=0.6411, accuracy=0.7779, gradient_norm=0.6389, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 095: loss=0.5934, accuracy=0.7959, gradient_norm=0.5216, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 096: loss=0.6354, accuracy=0.7814, gradient_norm=0.4986, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 097: loss=0.4682, accuracy=0.8367, gradient_norm=0.4905, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 098: loss=0.6741, accuracy=0.7658, gradient_norm=0.4386, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 099: loss=0.5930, accuracy=0.7961, gradient_norm=0.4678, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 100: loss=0.5045, accuracy=0.8265, gradient_norm=0.3928, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 101: loss=0.5385, accuracy=0.8149, gradient_norm=0.4622, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 102: loss=0.5940, accuracy=0.7990, gradient_norm=0.4931, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 103: loss=0.6066, accuracy=0.7926, gradient_norm=0.5530, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 104: loss=0.5325, accuracy=0.8147, gradient_norm=0.5081, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 105: loss=0.4722, accuracy=0.8389, gradient_norm=0.5835, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 106: loss=0.5214, accuracy=0.8215, gradient_norm=0.5840, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 107: loss=0.4241, accuracy=0.8540, gradient_norm=0.5679, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 108: loss=0.5671, accuracy=0.8039, gradient_norm=0.5393, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 109: loss=0.4656, accuracy=0.8392, gradient_norm=0.5063, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 110: loss=0.3308, accuracy=0.8935, gradient_norm=0.3676, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 111: loss=0.3798, accuracy=0.8728, gradient_norm=0.3818, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 112: loss=0.4681, accuracy=0.8358, gradient_norm=0.5212, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 113: loss=0.3718, accuracy=0.8749, gradient_norm=0.5303, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 114: loss=0.4490, accuracy=0.8444, gradient_norm=0.4769, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 115: loss=0.4319, accuracy=0.8477, gradient_norm=0.4032, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 116: loss=0.4796, accuracy=0.8330, gradient_norm=0.3640, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 117: loss=0.4487, accuracy=0.8455, gradient_norm=0.4310, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 118: loss=0.3373, accuracy=0.8878, gradient_norm=0.4608, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 119: loss=0.4123, accuracy=0.8631, gradient_norm=0.5147, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 120: loss=0.4627, accuracy=0.8426, gradient_norm=0.4912, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 121: loss=0.4793, accuracy=0.8345, gradient_norm=0.3689, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 122: loss=0.4055, accuracy=0.8662, gradient_norm=0.5622, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 123: loss=0.3315, accuracy=0.8878, gradient_norm=0.5376, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 124: loss=0.5180, accuracy=0.8224, gradient_norm=0.5535, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 125: loss=0.2625, accuracy=0.9132, gradient_norm=0.4496, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 126: loss=0.3342, accuracy=0.8867, gradient_norm=0.5170, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 127: loss=0.4216, accuracy=0.8502, gradient_norm=0.5039, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 128: loss=0.2694, accuracy=0.9091, gradient_norm=0.5754, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 129: loss=0.2792, accuracy=0.9083, gradient_norm=0.4763, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 130: loss=0.2606, accuracy=0.9136, gradient_norm=0.3254, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 131: loss=0.2300, accuracy=0.9230, gradient_norm=0.4828, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 132: loss=0.2022, accuracy=0.9359, gradient_norm=0.3267, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 133: loss=0.3001, accuracy=0.8964, gradient_norm=0.3996, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 134: loss=0.4249, accuracy=0.8521, gradient_norm=0.3868, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 135: loss=0.4234, accuracy=0.8531, gradient_norm=0.3381, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 136: loss=0.2190, accuracy=0.9283, gradient_norm=0.4368, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 137: loss=0.2156, accuracy=0.9287, gradient_norm=0.4664, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 138: loss=0.4079, accuracy=0.8556, gradient_norm=0.4694, 
[2025-09-19 10:43:39,398][__main__][INFO] - Train, Round 139: loss=0.3277, accuracy=0.8848, gradient_norm=0.3324, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 140: loss=0.2224, accuracy=0.9255, gradient_norm=0.4371, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 141: loss=0.2752, accuracy=0.9077, gradient_norm=0.3225, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 142: loss=0.3168, accuracy=0.8884, gradient_norm=0.5517, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 143: loss=0.4209, accuracy=0.8524, gradient_norm=0.4601, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 144: loss=0.1775, accuracy=0.9414, gradient_norm=0.3834, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 145: loss=0.3753, accuracy=0.8683, gradient_norm=0.5090, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 146: loss=0.1898, accuracy=0.9352, gradient_norm=0.2079, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 147: loss=0.3317, accuracy=0.8856, gradient_norm=0.2977, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 148: loss=0.3058, accuracy=0.8912, gradient_norm=0.4471, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 149: loss=0.2796, accuracy=0.9069, gradient_norm=0.4231, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 150: loss=0.2420, accuracy=0.9184, gradient_norm=0.4369, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 151: loss=0.1893, accuracy=0.9376, gradient_norm=0.3104, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 152: loss=0.3993, accuracy=0.8571, gradient_norm=0.5207, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 153: loss=0.1461, accuracy=0.9556, gradient_norm=0.2558, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 154: loss=0.2178, accuracy=0.9291, gradient_norm=0.3030, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 155: loss=0.3035, accuracy=0.8935, gradient_norm=0.2997, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 156: loss=0.2093, accuracy=0.9339, gradient_norm=0.2772, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 157: loss=0.2141, accuracy=0.9278, gradient_norm=0.4898, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 158: loss=0.2358, accuracy=0.9216, gradient_norm=0.2799, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 159: loss=0.2408, accuracy=0.9178, gradient_norm=0.3004, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 160: loss=0.2558, accuracy=0.9120, gradient_norm=0.5250, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 161: loss=0.2411, accuracy=0.9191, gradient_norm=0.3226, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 162: loss=0.2137, accuracy=0.9289, gradient_norm=0.5428, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 163: loss=0.1480, accuracy=0.9514, gradient_norm=0.2859, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 164: loss=0.2059, accuracy=0.9320, gradient_norm=0.2864, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 165: loss=0.0681, accuracy=0.9792, gradient_norm=0.2722, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 166: loss=0.1602, accuracy=0.9483, gradient_norm=0.3285, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 167: loss=0.1348, accuracy=0.9559, gradient_norm=0.2548, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 168: loss=0.2510, accuracy=0.9142, gradient_norm=0.3337, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 169: loss=0.1294, accuracy=0.9593, gradient_norm=0.3186, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 170: loss=0.2225, accuracy=0.9234, gradient_norm=0.3895, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 171: loss=0.2306, accuracy=0.9195, gradient_norm=0.4209, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 172: loss=0.1375, accuracy=0.9538, gradient_norm=0.3186, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 173: loss=0.1598, accuracy=0.9456, gradient_norm=0.1653, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 174: loss=0.1194, accuracy=0.9618, gradient_norm=0.2450, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 175: loss=0.1439, accuracy=0.9547, gradient_norm=0.4521, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 176: loss=0.2121, accuracy=0.9298, gradient_norm=0.2971, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 177: loss=0.1141, accuracy=0.9608, gradient_norm=0.2236, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 178: loss=0.1346, accuracy=0.9548, gradient_norm=0.3002, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 179: loss=0.0698, accuracy=0.9784, gradient_norm=0.1953, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 180: loss=0.0529, accuracy=0.9847, gradient_norm=0.3401, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 181: loss=0.2067, accuracy=0.9282, gradient_norm=0.4619, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 182: loss=0.1047, accuracy=0.9663, gradient_norm=0.1552, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 183: loss=0.1334, accuracy=0.9555, gradient_norm=0.2124, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 184: loss=0.0899, accuracy=0.9734, gradient_norm=0.2774, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 185: loss=0.1051, accuracy=0.9656, gradient_norm=0.2986, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 186: loss=0.1364, accuracy=0.9584, gradient_norm=0.3824, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 187: loss=0.1144, accuracy=0.9647, gradient_norm=0.3877, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 188: loss=0.1005, accuracy=0.9687, gradient_norm=0.2227, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 189: loss=0.1729, accuracy=0.9407, gradient_norm=0.4175, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 190: loss=0.1610, accuracy=0.9476, gradient_norm=0.4347, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 191: loss=0.1942, accuracy=0.9361, gradient_norm=0.5030, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 192: loss=0.1132, accuracy=0.9639, gradient_norm=0.1900, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 193: loss=0.0377, accuracy=0.9899, gradient_norm=0.3876, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 194: loss=0.1133, accuracy=0.9629, gradient_norm=0.5600, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 195: loss=0.1482, accuracy=0.9493, gradient_norm=0.2162, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 196: loss=0.1064, accuracy=0.9648, gradient_norm=0.4275, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 197: loss=0.1791, accuracy=0.9389, gradient_norm=0.3222, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 198: loss=0.0576, accuracy=0.9833, gradient_norm=0.3137, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 199: loss=0.1678, accuracy=0.9466, gradient_norm=0.5516, 
[2025-09-19 10:43:39,399][__main__][INFO] - Train, Round 200: loss=0.0583, accuracy=0.9818, gradient_norm=0.1859, 
[2025-09-19 10:43:39,399][__main__][INFO] - Test, Round 001: loss=2.1641, accuracy=0.2165, 
[2025-09-19 10:43:39,399][__main__][INFO] - Test, Round 002: loss=2.0984, accuracy=0.2700, 
[2025-09-19 10:43:39,399][__main__][INFO] - Test, Round 003: loss=2.0333, accuracy=0.2897, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 004: loss=1.9556, accuracy=0.3256, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 005: loss=1.9102, accuracy=0.3234, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 006: loss=1.8556, accuracy=0.3298, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 007: loss=1.8186, accuracy=0.3430, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 008: loss=1.7859, accuracy=0.3453, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 009: loss=1.7444, accuracy=0.3724, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 010: loss=1.7231, accuracy=0.3790, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 011: loss=1.7001, accuracy=0.3790, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 012: loss=1.6810, accuracy=0.3879, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 013: loss=1.6607, accuracy=0.3951, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 014: loss=1.6362, accuracy=0.4125, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 015: loss=1.6267, accuracy=0.4135, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 016: loss=1.6097, accuracy=0.4200, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 017: loss=1.5870, accuracy=0.4233, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 018: loss=1.5686, accuracy=0.4286, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 019: loss=1.5506, accuracy=0.4331, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 020: loss=1.5452, accuracy=0.4332, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 021: loss=1.5364, accuracy=0.4368, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 022: loss=1.5230, accuracy=0.4415, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 023: loss=1.5073, accuracy=0.4468, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 024: loss=1.5010, accuracy=0.4475, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 025: loss=1.5055, accuracy=0.4488, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 026: loss=1.4901, accuracy=0.4633, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 027: loss=1.4694, accuracy=0.4670, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 028: loss=1.4535, accuracy=0.4763, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 029: loss=1.4484, accuracy=0.4791, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 030: loss=1.4381, accuracy=0.4830, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 031: loss=1.4426, accuracy=0.4870, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 032: loss=1.4337, accuracy=0.4870, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 033: loss=1.4258, accuracy=0.4954, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 034: loss=1.4266, accuracy=0.4964, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 035: loss=1.4100, accuracy=0.4993, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 036: loss=1.4033, accuracy=0.4998, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 037: loss=1.3881, accuracy=0.5024, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 038: loss=1.3878, accuracy=0.5029, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 039: loss=1.3861, accuracy=0.5064, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 040: loss=1.3790, accuracy=0.5094, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 041: loss=1.3794, accuracy=0.5068, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 042: loss=1.3580, accuracy=0.5173, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 043: loss=1.3498, accuracy=0.5209, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 044: loss=1.3472, accuracy=0.5187, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 045: loss=1.3583, accuracy=0.5177, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 046: loss=1.3548, accuracy=0.5214, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 047: loss=1.3456, accuracy=0.5212, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 048: loss=1.3389, accuracy=0.5215, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 049: loss=1.3423, accuracy=0.5223, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 050: loss=1.3292, accuracy=0.5290, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 051: loss=1.3253, accuracy=0.5302, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 052: loss=1.3099, accuracy=0.5337, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 053: loss=1.3104, accuracy=0.5356, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 054: loss=1.3298, accuracy=0.5325, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 055: loss=1.3365, accuracy=0.5321, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 056: loss=1.3329, accuracy=0.5355, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 057: loss=1.3085, accuracy=0.5407, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 058: loss=1.3115, accuracy=0.5408, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 059: loss=1.3223, accuracy=0.5399, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 060: loss=1.3143, accuracy=0.5480, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 061: loss=1.3134, accuracy=0.5447, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 062: loss=1.3197, accuracy=0.5421, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 063: loss=1.3224, accuracy=0.5404, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 064: loss=1.3050, accuracy=0.5500, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 065: loss=1.3176, accuracy=0.5488, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 066: loss=1.3096, accuracy=0.5459, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 067: loss=1.3000, accuracy=0.5477, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 068: loss=1.3300, accuracy=0.5450, 
[2025-09-19 10:43:39,400][__main__][INFO] - Test, Round 069: loss=1.3356, accuracy=0.5481, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 070: loss=1.3102, accuracy=0.5546, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 071: loss=1.3072, accuracy=0.5571, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 072: loss=1.3123, accuracy=0.5528, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 073: loss=1.3033, accuracy=0.5586, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 074: loss=1.3277, accuracy=0.5529, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 075: loss=1.3274, accuracy=0.5542, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 076: loss=1.3436, accuracy=0.5544, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 077: loss=1.3280, accuracy=0.5616, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 078: loss=1.3380, accuracy=0.5566, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 079: loss=1.3305, accuracy=0.5634, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 080: loss=1.3395, accuracy=0.5617, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 081: loss=1.3835, accuracy=0.5590, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 082: loss=1.3767, accuracy=0.5602, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 083: loss=1.4004, accuracy=0.5544, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 084: loss=1.3960, accuracy=0.5582, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 085: loss=1.3963, accuracy=0.5602, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 086: loss=1.3924, accuracy=0.5581, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 087: loss=1.4059, accuracy=0.5583, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 088: loss=1.4104, accuracy=0.5606, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 089: loss=1.3822, accuracy=0.5659, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 090: loss=1.4106, accuracy=0.5644, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 091: loss=1.3991, accuracy=0.5706, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 092: loss=1.4037, accuracy=0.5657, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 093: loss=1.4106, accuracy=0.5703, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 094: loss=1.4404, accuracy=0.5683, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 095: loss=1.4445, accuracy=0.5719, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 096: loss=1.4469, accuracy=0.5725, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 097: loss=1.5075, accuracy=0.5677, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 098: loss=1.4926, accuracy=0.5706, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 099: loss=1.5262, accuracy=0.5672, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 100: loss=1.5051, accuracy=0.5735, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 101: loss=1.5104, accuracy=0.5734, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 102: loss=1.5385, accuracy=0.5710, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 103: loss=1.5338, accuracy=0.5722, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 104: loss=1.5417, accuracy=0.5739, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 105: loss=1.5303, accuracy=0.5765, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 106: loss=1.5682, accuracy=0.5761, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 107: loss=1.5782, accuracy=0.5779, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 108: loss=1.6020, accuracy=0.5733, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 109: loss=1.6267, accuracy=0.5722, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 110: loss=1.6488, accuracy=0.5745, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 111: loss=1.6478, accuracy=0.5725, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 112: loss=1.6474, accuracy=0.5737, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 113: loss=1.6931, accuracy=0.5740, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 114: loss=1.7195, accuracy=0.5727, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 115: loss=1.7028, accuracy=0.5718, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 116: loss=1.6868, accuracy=0.5775, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 117: loss=1.7188, accuracy=0.5777, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 118: loss=1.7413, accuracy=0.5783, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 119: loss=1.7580, accuracy=0.5766, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 120: loss=1.7593, accuracy=0.5797, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 121: loss=1.7887, accuracy=0.5760, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 122: loss=1.8277, accuracy=0.5741, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 123: loss=1.8067, accuracy=0.5722, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 124: loss=1.8349, accuracy=0.5685, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 125: loss=1.8105, accuracy=0.5718, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 126: loss=1.8370, accuracy=0.5739, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 127: loss=1.8266, accuracy=0.5808, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 128: loss=1.8609, accuracy=0.5847, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 129: loss=1.8930, accuracy=0.5862, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 130: loss=1.8833, accuracy=0.5881, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 131: loss=1.9123, accuracy=0.5863, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 132: loss=1.9169, accuracy=0.5866, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 133: loss=1.9282, accuracy=0.5819, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 134: loss=1.9428, accuracy=0.5827, 
[2025-09-19 10:43:39,401][__main__][INFO] - Test, Round 135: loss=1.9609, accuracy=0.5802, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 136: loss=1.9995, accuracy=0.5815, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 137: loss=2.0168, accuracy=0.5822, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 138: loss=2.0367, accuracy=0.5812, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 139: loss=2.0471, accuracy=0.5795, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 140: loss=2.0347, accuracy=0.5837, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 141: loss=2.0473, accuracy=0.5822, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 142: loss=2.0473, accuracy=0.5843, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 143: loss=2.0765, accuracy=0.5877, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 144: loss=2.0958, accuracy=0.5875, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 145: loss=2.1074, accuracy=0.5851, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 146: loss=2.0998, accuracy=0.5814, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 147: loss=2.1076, accuracy=0.5820, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 148: loss=2.1137, accuracy=0.5809, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 149: loss=2.1018, accuracy=0.5851, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 150: loss=2.1258, accuracy=0.5824, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 151: loss=2.1388, accuracy=0.5873, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 152: loss=2.1410, accuracy=0.5908, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 153: loss=2.1679, accuracy=0.5875, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 154: loss=2.1704, accuracy=0.5898, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 155: loss=2.2024, accuracy=0.5937, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 156: loss=2.2184, accuracy=0.5879, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 157: loss=2.2269, accuracy=0.5889, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 158: loss=2.2500, accuracy=0.5848, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 159: loss=2.2853, accuracy=0.5839, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 160: loss=2.2907, accuracy=0.5864, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 161: loss=2.2921, accuracy=0.5877, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 162: loss=2.2908, accuracy=0.5871, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 163: loss=2.3036, accuracy=0.5876, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 164: loss=2.3221, accuracy=0.5872, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 165: loss=2.3389, accuracy=0.5849, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 166: loss=2.3343, accuracy=0.5874, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 167: loss=2.3429, accuracy=0.5887, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 168: loss=2.3453, accuracy=0.5892, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 169: loss=2.3750, accuracy=0.5900, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 170: loss=2.3839, accuracy=0.5878, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 171: loss=2.3970, accuracy=0.5897, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 172: loss=2.4164, accuracy=0.5895, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 173: loss=2.4194, accuracy=0.5890, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 174: loss=2.4159, accuracy=0.5912, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 175: loss=2.4103, accuracy=0.5901, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 176: loss=2.4224, accuracy=0.5914, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 177: loss=2.4310, accuracy=0.5903, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 178: loss=2.4415, accuracy=0.5900, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 179: loss=2.4544, accuracy=0.5901, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 180: loss=2.4681, accuracy=0.5905, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 181: loss=2.4964, accuracy=0.5887, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 182: loss=2.5019, accuracy=0.5922, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 183: loss=2.4945, accuracy=0.5920, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 184: loss=2.5044, accuracy=0.5872, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 185: loss=2.5172, accuracy=0.5884, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 186: loss=2.5488, accuracy=0.5889, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 187: loss=2.5635, accuracy=0.5903, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 188: loss=2.5609, accuracy=0.5890, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 189: loss=2.5964, accuracy=0.5849, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 190: loss=2.6039, accuracy=0.5823, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 191: loss=2.6166, accuracy=0.5826, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 192: loss=2.6269, accuracy=0.5822, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 193: loss=2.6391, accuracy=0.5813, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 194: loss=2.6644, accuracy=0.5789, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 195: loss=2.6648, accuracy=0.5800, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 196: loss=2.6616, accuracy=0.5805, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 197: loss=2.6571, accuracy=0.5827, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 198: loss=2.6759, accuracy=0.5833, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 199: loss=2.7062, accuracy=0.5816, 
[2025-09-19 10:43:39,402][__main__][INFO] - Test, Round 200: loss=2.7215, accuracy=0.5835, 

[2025-09-19 11:50:07,728][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 1.7043352158835818,  accuracy: 0.4336836836836837, gradient_norm : 1.7930406678541655
[2025-09-19 11:50:11,953][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.098031471379579,  accuracy: 0.2118
[2025-09-19 11:50:15,398][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 1.718957719408206,  accuracy: 0.39990540380749673, gradient_norm : 1.316496801722327
[2025-09-19 11:50:19,840][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 1.9629442091279292,  accuracy: 0.2714
[2025-09-19 11:50:23,929][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 1.5082890810375458,  accuracy: 0.4688962862789972, gradient_norm : 1.2810692178537526
[2025-09-19 11:50:28,706][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 1.883152331386786,  accuracy: 0.3245
[2025-09-19 11:50:33,093][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.3746922222497169,  accuracy: 0.5258234454236621, gradient_norm : 1.2159044645054322
[2025-09-19 11:50:37,951][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 1.8367434209079023,  accuracy: 0.3501
[2025-09-19 11:50:41,192][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.324428622391882,  accuracy: 0.5245556764599202, gradient_norm : 1.3538963918401492
[2025-09-19 11:50:45,997][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 1.7563737515499669,  accuracy: 0.3815
[2025-09-19 11:50:50,612][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 1.1549328830483196,  accuracy: 0.6015001209774982, gradient_norm : 1.3858410717039766
[2025-09-19 11:50:55,421][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 1.8107177536364136,  accuracy: 0.3815
[2025-09-19 11:50:59,949][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.3817121687478116,  accuracy: 0.5225617106021697, gradient_norm : 1.555279047864622
[2025-09-19 11:51:04,802][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.7490382196058036,  accuracy: 0.4137
[2025-09-19 11:51:09,657][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 0.9923072790344479,  accuracy: 0.662973642940254, gradient_norm : 1.2893943983393508
[2025-09-19 11:51:14,520][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.7496606164491322,  accuracy: 0.4239
[2025-09-19 11:51:19,464][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.0431320189109652,  accuracy: 0.6455242212832858, gradient_norm : 1.3369441215488895
[2025-09-19 11:51:24,335][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 1.6857316372164242,  accuracy: 0.4442
[2025-09-19 11:51:29,085][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 0.9968775673736696,  accuracy: 0.6630642432181649, gradient_norm : 1.4620299075551393
[2025-09-19 11:51:33,906][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.7228572106304914,  accuracy: 0.4504
[2025-09-19 11:51:39,135][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 0.7720116226726109,  accuracy: 0.7425336234177216, gradient_norm : 1.2914254442872524
[2025-09-19 11:51:43,947][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.7042071054795387,  accuracy: 0.4601
[2025-09-19 11:51:49,329][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 0.710463442997058,  accuracy: 0.7698420206224577, gradient_norm : 1.3406004659602262
[2025-09-19 11:51:54,077][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.7455881661675994,  accuracy: 0.4785
[2025-09-19 11:51:58,717][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 0.7755880402590705,  accuracy: 0.751660098256222, gradient_norm : 1.3095497836632997
[2025-09-19 11:52:03,513][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.7259316360427561,  accuracy: 0.4896
[2025-09-19 11:52:08,271][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 0.6956687721653234,  accuracy: 0.7816871099634173, gradient_norm : 1.3598742545000433
[2025-09-19 11:52:13,096][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.6352533447056619,  accuracy: 0.5023
[2025-09-19 11:52:17,130][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 0.6048290370481606,  accuracy: 0.8138723188221856, gradient_norm : 1.4853782905251018
[2025-09-19 11:52:21,924][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.6125104465038615,  accuracy: 0.505
[2025-09-19 11:52:26,619][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 0.4477394911030628,  accuracy: 0.8730705104071425, gradient_norm : 1.1927702052104465
[2025-09-19 11:52:31,443][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.6008536987089959,  accuracy: 0.5152
[2025-09-19 11:52:35,701][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 0.47683315282826,  accuracy: 0.8666779891304348, gradient_norm : 1.3074674126634598
[2025-09-19 11:52:40,529][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.6749738192162325,  accuracy: 0.5095
[2025-09-19 11:52:44,860][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 0.5344118386419994,  accuracy: 0.836570428696413, gradient_norm : 1.4430219246660454
[2025-09-19 11:52:49,671][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.6759052179291445,  accuracy: 0.5119
[2025-09-19 11:52:53,920][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 0.25742297816825,  accuracy: 0.9368127172240898, gradient_norm : 0.9555786268953156
[2025-09-19 11:52:58,790][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.6542152842405973,  accuracy: 0.5108
[2025-09-19 11:53:01,982][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 0.19166505690884558,  accuracy: 0.9587215026887829, gradient_norm : 1.1837947430227902
[2025-09-19 11:53:06,808][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.6766898591645716,  accuracy: 0.5164
[2025-09-19 11:53:11,080][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 0.2889368876304326,  accuracy: 0.9196921443736731, gradient_norm : 1.0865093922274787
[2025-09-19 11:53:15,940][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.6356571090913639,  accuracy: 0.5244
[2025-09-19 11:53:19,970][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 0.31115430099079683,  accuracy: 0.9212009731205126, gradient_norm : 1.41998061926015
[2025-09-19 11:53:24,827][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.619979404692338,  accuracy: 0.5345
[2025-09-19 11:53:29,449][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 0.3169795634293385,  accuracy: 0.9115150880134115, gradient_norm : 0.9517258484215102
[2025-09-19 11:53:34,318][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.6010969259044388,  accuracy: 0.5378
[2025-09-19 11:53:38,640][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 0.11373365340748604,  accuracy: 0.9774774774774775, gradient_norm : 0.7824625813580385
[2025-09-19 11:53:43,557][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.587224727168897,  accuracy: 0.5433
[2025-09-19 11:53:48,154][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 0.20448560894150633,  accuracy: 0.942867635486071, gradient_norm : 0.736025915338254
[2025-09-19 11:53:53,005][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.623174596555484,  accuracy: 0.5479
[2025-09-19 11:53:58,143][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 0.2438353392126832,  accuracy: 0.9301549021426584, gradient_norm : 0.8141596249383096
[2025-09-19 11:54:02,960][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.6905428832211462,  accuracy: 0.5437
[2025-09-19 11:54:08,116][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 0.11662771441049839,  accuracy: 0.970200027214587, gradient_norm : 0.6174986674053959
[2025-09-19 11:54:12,931][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.6547059932760104,  accuracy: 0.5492
[2025-09-19 11:54:18,075][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 0.1830409143885111,  accuracy: 0.9485222156977882, gradient_norm : 0.6592975307033868
[2025-09-19 11:54:22,925][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.696408014011648,  accuracy: 0.5447
[2025-09-19 11:54:28,115][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 0.16539310711064215,  accuracy: 0.957546035867109, gradient_norm : 0.8590648932553371
[2025-09-19 11:54:32,901][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.617455598787268,  accuracy: 0.5533
[2025-09-19 11:54:37,976][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 0.0901466138682718,  accuracy: 0.9850055911355088, gradient_norm : 0.8397927112253414
[2025-09-19 11:54:42,802][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.594337445605596,  accuracy: 0.5596
[2025-09-19 11:54:47,274][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 0.09776682561854762,  accuracy: 0.9769008662175168, gradient_norm : 0.7313536822338463
[2025-09-19 11:54:52,135][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.5684171798081201,  accuracy: 0.5683
[2025-09-19 11:54:57,647][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 0.1413659137547976,  accuracy: 0.9693347658698183, gradient_norm : 0.820391179284016
[2025-09-19 11:55:02,471][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.592864836083239,  accuracy: 0.5626
[2025-09-19 11:55:06,188][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 0.14642402207857683,  accuracy: 0.9608811904208323, gradient_norm : 0.7847611809676037
[2025-09-19 11:55:10,973][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.6829447247997777,  accuracy: 0.5605
[2025-09-19 11:55:13,992][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 0.08629324074623136,  accuracy: 0.9822825586746433, gradient_norm : 0.551631101434061
[2025-09-19 11:55:18,896][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.7228684377375103,  accuracy: 0.557
[2025-09-19 11:55:22,535][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 0.03852620971601511,  accuracy: 0.9971746424156808, gradient_norm : 0.5953128924003022
[2025-09-19 11:55:27,407][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.7775891158305461,  accuracy: 0.5528
[2025-09-19 11:55:31,332][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 0.05810678292458658,  accuracy: 0.9912838324922997, gradient_norm : 0.6719679277305332
[2025-09-19 11:55:36,158][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.7619628355142085,  accuracy: 0.5561
[2025-09-19 11:55:40,154][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 0.05522376625217338,  accuracy: 0.9889558798670198, gradient_norm : 0.41242481760974836
[2025-09-19 11:55:45,106][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.7745364605008176,  accuracy: 0.5581
[2025-09-19 11:55:49,653][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 0.08093350826420546,  accuracy: 0.980013851785891, gradient_norm : 0.48129524671058743
[2025-09-19 11:55:54,468][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.6914742547781196,  accuracy: 0.566
[2025-09-19 11:55:58,804][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 0.056619200649851244,  accuracy: 0.9909300703053722, gradient_norm : 0.5919790064624296
[2025-09-19 11:56:03,706][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.8064369091708388,  accuracy: 0.5652
[2025-09-19 11:56:07,637][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 0.052035142507067755,  accuracy: 0.9904436464728368, gradient_norm : 0.4715716405436846
[2025-09-19 11:56:12,499][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.7160234314391274,  accuracy: 0.5682
[2025-09-19 11:56:16,758][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 0.050530250938597435,  accuracy: 0.9917658782189123, gradient_norm : 0.6825793254016752
[2025-09-19 11:56:21,657][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.7161794092217344,  accuracy: 0.5658
[2025-09-19 11:56:26,609][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 0.03860109738804721,  accuracy: 0.9957279860505667, gradient_norm : 0.697695535831583
[2025-09-19 11:56:31,500][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.7270977620481047,  accuracy: 0.5653
[2025-09-19 11:56:36,019][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 0.042502095600488475,  accuracy: 0.9922753183101592, gradient_norm : 0.3919659815654203
[2025-09-19 11:56:40,922][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.7253454109816142,  accuracy: 0.5676
[2025-09-19 11:56:45,409][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 0.04216183274311972,  accuracy: 0.9918249081595695, gradient_norm : 0.45313847713311367
[2025-09-19 11:56:50,311][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.702019271829848,  accuracy: 0.5701
[2025-09-19 11:56:54,673][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 0.04285791006041944,  accuracy: 0.9931334155892925, gradient_norm : 0.7104930214469187
[2025-09-19 11:56:59,613][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.6553143928182035,  accuracy: 0.5695
[2025-09-19 11:57:04,432][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 0.026335421915869624,  accuracy: 0.9971496207546259, gradient_norm : 0.41615947120003255
[2025-09-19 11:57:09,304][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.6422997621874673,  accuracy: 0.5739
[2025-09-19 11:57:14,148][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 0.02802653453123086,  accuracy: 0.998393691588785, gradient_norm : 0.43466557983072607
[2025-09-19 11:57:19,038][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.6422255661316383,  accuracy: 0.5771
[2025-09-19 11:57:23,287][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 0.03639203087500568,  accuracy: 0.9929229756418696, gradient_norm : 0.34163003600433045
[2025-09-19 11:57:28,097][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.6498138381137115,  accuracy: 0.5769
[2025-09-19 11:57:31,857][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 0.04114705115153024,  accuracy: 0.995943462001648, gradient_norm : 0.5405495724684226
[2025-09-19 11:57:36,816][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.5896474329005532,  accuracy: 0.5816
[2025-09-19 11:57:40,526][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 0.015109487735018868,  accuracy: 0.9988131268173995, gradient_norm : 0.3335635758465286
[2025-09-19 11:57:45,355][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.5920740985537425,  accuracy: 0.5802
[2025-09-19 11:57:49,203][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 0.023089596329309885,  accuracy: 0.9964596796853049, gradient_norm : 0.27141087100722266
[2025-09-19 11:57:54,089][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.5942988993431482,  accuracy: 0.58
[2025-09-19 11:57:58,217][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 0.01621092442644584,  accuracy: 0.9993337091896879, gradient_norm : 0.5529764479928545
[2025-09-19 11:58:03,091][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.7108606886566369,  accuracy: 0.5732
[2025-09-19 11:58:07,544][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 0.016972695174434334,  accuracy: 0.9979044834307992, gradient_norm : 0.37447143475927436
[2025-09-19 11:58:12,487][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.6503440809828667,  accuracy: 0.5757
[2025-09-19 11:58:16,800][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 0.02262498381463182,  accuracy: 0.9985527471959477, gradient_norm : 0.5621943577174761
[2025-09-19 11:58:21,658][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.6002061457272618,  accuracy: 0.5809
[2025-09-19 11:58:24,829][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 0.02073946732499603,  accuracy: 0.9991494790559218, gradient_norm : 0.8130944154407317
[2025-09-19 11:58:29,774][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.6697286348765408,  accuracy: 0.5728
[2025-09-19 11:58:34,470][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 0.01752918623085835,  accuracy: 0.9985801960245488, gradient_norm : 0.4844444034449564
[2025-09-19 11:58:39,372][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.6804245911889912,  accuracy: 0.5709
[2025-09-19 11:58:43,303][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 0.034549048298860116,  accuracy: 0.9948836163274486, gradient_norm : 0.7095438215912852
[2025-09-19 11:58:48,200][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.7538105313525245,  accuracy: 0.5756
[2025-09-19 11:58:52,085][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.014573846843082775,  accuracy: 0.9976328693005693, gradient_norm : 0.25090934198603704
[2025-09-19 11:58:57,023][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.7000396143793042,  accuracy: 0.5778
[2025-09-19 11:59:00,556][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.0294107571071646,  accuracy: 0.9967756211670987, gradient_norm : 0.5896985268533999
[2025-09-19 11:59:05,444][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.6173741975109754,  accuracy: 0.5813
[2025-09-19 11:59:10,051][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 0.03068642857183993,  accuracy: 0.9973175208245094, gradient_norm : 0.6579614711253858
[2025-09-19 11:59:14,964][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.6736480382614063,  accuracy: 0.5765
[2025-09-19 11:59:19,325][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.012979510460067551,  accuracy: 0.9987305927155551, gradient_norm : 0.4284828478627788
[2025-09-19 11:59:24,206][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.6988520131197966,  accuracy: 0.5722
[2025-09-19 11:59:28,663][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.014597262755421702,  accuracy: 0.9978770723817226, gradient_norm : 0.22321444643420504
[2025-09-19 11:59:33,531][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.7053655610596536,  accuracy: 0.5748
[2025-09-19 11:59:37,357][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 0.010037975507670376,  accuracy: 0.9995887916348469, gradient_norm : 0.2308443017883267
[2025-09-19 11:59:42,237][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.6995572348419223,  accuracy: 0.5766
[2025-09-19 11:59:45,947][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.014781835433892875,  accuracy: 0.9981877491844872, gradient_norm : 0.2615152193813205
[2025-09-19 11:59:50,823][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.7085064594963588,  accuracy: 0.5778
[2025-09-19 11:59:54,428][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.02799104870709684,  accuracy: 0.9969469701997743, gradient_norm : 0.6680703352385111
[2025-09-19 11:59:59,296][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.714360399614034,  accuracy: 0.5792
[2025-09-19 12:00:03,256][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.018847352032358836,  accuracy: 0.9983740816572323, gradient_norm : 0.4732569198279769
[2025-09-19 12:00:08,113][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.7283439295938194,  accuracy: 0.5752
[2025-09-19 12:00:12,402][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.016971870629799112,  accuracy: 0.9980372364288919, gradient_norm : 0.496356251033977
[2025-09-19 12:00:17,148][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.7169758853143504,  accuracy: 0.5809
[2025-09-19 12:00:21,907][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.019156742444516355,  accuracy: 0.9978874591895526, gradient_norm : 0.3992268231362093
[2025-09-19 12:00:26,682][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.6807204662226438,  accuracy: 0.5835
[2025-09-19 12:00:30,806][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.01118378395632151,  accuracy: 0.9994174037392087, gradient_norm : 0.2637615153061529
[2025-09-19 12:00:35,695][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.6662834145351386,  accuracy: 0.5856
[2025-09-19 12:00:40,033][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 0.028669481110023765,  accuracy: 0.9992854226214781, gradient_norm : 0.5345510455801136
[2025-09-19 12:00:44,946][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.6733537774901721,  accuracy: 0.5857
[2025-09-19 12:00:48,739][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 0.00902888774361323,  accuracy: 0.9994571445804934, gradient_norm : 0.21171820683376832
[2025-09-19 12:00:53,584][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.6789388014506432,  accuracy: 0.5869
[2025-09-19 12:00:58,201][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.00807074775802015,  accuracy: 0.9997521685254027, gradient_norm : 0.3559750093507674
[2025-09-19 12:01:03,072][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.6745503827735913,  accuracy: 0.5854
[2025-09-19 12:01:07,836][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.021483532778131708,  accuracy: 0.997363156937625, gradient_norm : 0.4970898901441827
[2025-09-19 12:01:12,705][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.6355161249949244,  accuracy: 0.583
[2025-09-19 12:01:16,498][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.007894170202607888,  accuracy: 0.9998842391618915, gradient_norm : 0.30045313929842343
[2025-09-19 12:01:21,489][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.7010883777972172,  accuracy: 0.5805
[2025-09-19 12:01:26,142][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.011400119417205146,  accuracy: 0.9984961720743711, gradient_norm : 0.24906802921038632
[2025-09-19 12:01:30,998][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.6406233494174713,  accuracy: 0.5854
[2025-09-19 12:01:35,000][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.008137285862679566,  accuracy: 0.9998788833040635, gradient_norm : 0.37179442044094646
[2025-09-19 12:01:39,876][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.644581611874042,  accuracy: 0.5829
[2025-09-19 12:01:44,306][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.006455378698701179,  accuracy: 0.9997446373850868, gradient_norm : 0.17017696791502976
[2025-09-19 12:01:49,186][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.6247532215862088,  accuracy: 0.5854
[2025-09-19 12:01:53,397][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.013167849100885977,  accuracy: 0.9989070409572021, gradient_norm : 0.2969225209085475
[2025-09-19 12:01:58,252][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.620621813295238,  accuracy: 0.5849
[2025-09-19 12:02:02,147][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.006759838572314456,  accuracy: 0.9997415185783521, gradient_norm : 0.3269282847209903
[2025-09-19 12:02:07,000][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.625427539121114,  accuracy: 0.5845
[2025-09-19 12:02:11,285][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.006858330684124493,  accuracy: 0.9998778252901649, gradient_norm : 0.20143100869161157
[2025-09-19 12:02:16,139][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.6214376661519236,  accuracy: 0.5875
[2025-09-19 12:02:20,968][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.005740437990827701,  accuracy: 0.9996612466124661, gradient_norm : 0.15055442835122843
[2025-09-19 12:02:25,767][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.6227585398045334,  accuracy: 0.588
[2025-09-19 12:02:30,077][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.0040321639615180154,  accuracy: 0.9998419721871049, gradient_norm : 0.16871637066083794
[2025-09-19 12:02:34,921][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.6198443664110855,  accuracy: 0.5892
[2025-09-19 12:02:39,272][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.006460609078012136,  accuracy: 0.999382854578097, gradient_norm : 0.14805954649390424
[2025-09-19 12:02:44,202][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.6157829695779238,  accuracy: 0.5911
[2025-09-19 12:02:48,311][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.0069407875925136505,  accuracy: 0.999770194185913, gradient_norm : 0.1987772623476717
[2025-09-19 12:02:53,224][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.6158828312030369,  accuracy: 0.5902
[2025-09-19 12:02:57,336][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.007855382365542595,  accuracy: 0.9996547756041427, gradient_norm : 0.3169320875928587
[2025-09-19 12:03:02,159][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.674313966792418,  accuracy: 0.5873
[2025-09-19 12:03:06,960][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.010047503816198835,  accuracy: 0.9989371467220639, gradient_norm : 0.32879462707123636
[2025-09-19 12:03:11,764][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.6198607412710533,  accuracy: 0.5931
[2025-09-19 12:03:16,477][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.004776278334320019,  accuracy: 0.9999470479216309, gradient_norm : 0.16724836235385565
[2025-09-19 12:03:21,280][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.6230961965797528,  accuracy: 0.594
[2025-09-19 12:03:25,040][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.008157981072383266,  accuracy: 0.9998661670235546, gradient_norm : 0.4219186181340323
[2025-09-19 12:03:29,906][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.6341906567027351,  accuracy: 0.5927
[2025-09-19 12:03:34,488][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.006775629147850533,  accuracy: 0.9991822939380723, gradient_norm : 0.14733733007301658
[2025-09-19 12:03:39,261][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.6188880847515055,  accuracy: 0.5934
[2025-09-19 12:03:43,595][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.0046302745124830605,  accuracy: 0.9999399399399399, gradient_norm : 0.09691450921584918
[2025-09-19 12:03:48,356][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.6195757149404153,  accuracy: 0.5923
[2025-09-19 12:03:52,975][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.004981787576098724,  accuracy: 0.9999449975248886, gradient_norm : 0.1861033793236921
[2025-09-19 12:03:57,852][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.6176836505131784,  accuracy: 0.5939
[2025-09-19 12:04:02,784][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.006372052030675631,  accuracy: 0.9998631137068809, gradient_norm : 0.3873133912392521
[2025-09-19 12:04:07,684][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.6331004181689563,  accuracy: 0.5883
[2025-09-19 12:04:12,321][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.006594147996121665,  accuracy: 0.9998430716116545, gradient_norm : 0.3264074567194286
[2025-09-19 12:04:17,239][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.6457036092650403,  accuracy: 0.5867
[2025-09-19 12:04:20,788][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.005099696710460953,  accuracy: 0.9999332131169438, gradient_norm : 0.3451053348248086
[2025-09-19 12:04:25,651][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.644273046170822,  accuracy: 0.5878
[2025-09-19 12:04:30,530][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.01160031447503126,  accuracy: 0.9998056554270722, gradient_norm : 0.41606960622855366
[2025-09-19 12:04:35,340][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.6457650065970535,  accuracy: 0.5886
[2025-09-19 12:04:40,024][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.003102488705485979,  accuracy: 0.9998923168039627, gradient_norm : 0.07347825392872219
[2025-09-19 12:04:44,877][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.6424266112503265,  accuracy: 0.5891
[2025-09-19 12:04:49,281][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.01474630118275225,  accuracy: 0.9997326917936381, gradient_norm : 0.5118540459525084
[2025-09-19 12:04:54,138][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.6575206084396295,  accuracy: 0.5872
[2025-09-19 12:04:58,480][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.019486331819258837,  accuracy: 0.999350112253338, gradient_norm : 0.43940913577615787
[2025-09-19 12:05:03,325][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.6731998285554,  accuracy: 0.5877
[2025-09-19 12:05:08,434][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.0032742156556514385,  accuracy: 1.0, gradient_norm : 0.106716564243543
[2025-09-19 12:05:13,298][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.6702189024259544,  accuracy: 0.5872
[2025-09-19 12:05:17,810][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.017241637288780153,  accuracy: 0.9997815520725247, gradient_norm : 0.5382436049818762
[2025-09-19 12:05:22,618][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.7313798055822538,  accuracy: 0.5827
[2025-09-19 12:05:26,847][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.003859918762167036,  accuracy: 0.9998220957125067, gradient_norm : 0.14587753845880422
[2025-09-19 12:05:31,595][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.735005921992748,  accuracy: 0.5821
[2025-09-19 12:05:36,286][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.02032480770622062,  accuracy: 0.9984334787960165, gradient_norm : 0.5726970565672856
[2025-09-19 12:05:41,057][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.7253399226537607,  accuracy: 0.5842
[2025-09-19 12:05:46,412][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.003685065161616993,  accuracy: 0.9999012345679013, gradient_norm : 0.18359153153668836
[2025-09-19 12:05:51,223][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.716427856964428,  accuracy: 0.584
[2025-09-19 12:05:56,315][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.022981326729213807,  accuracy: 0.9969702892885066, gradient_norm : 0.3653961568751328
[2025-09-19 12:06:01,188][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.660175056151943,  accuracy: 0.5885
[2025-09-19 12:06:05,696][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.009698308593178436,  accuracy: 0.9988105088953247, gradient_norm : 0.5239312415561981
[2025-09-19 12:06:10,604][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.8120945394028851,  accuracy: 0.5828
[2025-09-19 12:06:15,171][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.003593671744980408,  accuracy: 0.9997899049319817, gradient_norm : 0.12829397558444028
[2025-09-19 12:06:20,049][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.8030331036462994,  accuracy: 0.5838
[2025-09-19 12:06:24,743][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.0023569969625035435,  accuracy: 1.0, gradient_norm : 0.10651219430880061
[2025-09-19 12:06:29,562][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.8003540389952564,  accuracy: 0.5833
[2025-09-19 12:06:34,075][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.0214655176246556,  accuracy: 0.9963297407515292, gradient_norm : 0.49130892291113293
[2025-09-19 12:06:38,860][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.751581561017187,  accuracy: 0.5885
[2025-09-19 12:06:43,683][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.0034042748596138364,  accuracy: 0.999947271289217, gradient_norm : 0.18994790772359052
[2025-09-19 12:06:48,494][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.7489657849247109,  accuracy: 0.5887
[2025-09-19 12:06:53,493][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.01323087233906208,  accuracy: 0.9985303483074511, gradient_norm : 0.30507932315402125
[2025-09-19 12:06:58,252][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.8495212971503325,  accuracy: 0.5793
[2025-09-19 12:07:03,525][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.007746137082502846,  accuracy: 0.9997630331753554, gradient_norm : 0.2498318385059196
[2025-09-19 12:07:08,324][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.8727945786713136,  accuracy: 0.5799
[2025-09-19 12:07:12,046][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.01494985224000046,  accuracy: 0.9993831814131999, gradient_norm : 0.6483365911569821
[2025-09-19 12:07:16,770][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.8682562196064967,  accuracy: 0.5806
[2025-09-19 12:07:21,481][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.004255050842089068,  accuracy: 0.9999420793512888, gradient_norm : 0.3043735251920152
[2025-09-19 12:07:26,230][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.849930156533241,  accuracy: 0.5797
[2025-09-19 12:07:31,341][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.007354040523920808,  accuracy: 0.9998253478488677, gradient_norm : 0.347533817504342
[2025-09-19 12:07:35,979][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.8642506905951302,  accuracy: 0.5777
[2025-09-19 12:07:41,238][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.002130893958295497,  accuracy: 1.0, gradient_norm : 0.08451735664843758
[2025-09-19 12:07:46,008][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.8641731694446115,  accuracy: 0.5775
[2025-09-19 12:07:52,102][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.01110989719537187,  accuracy: 0.9995578778135048, gradient_norm : 0.48152390625243674
[2025-09-19 12:07:56,909][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.8781753454276506,  accuracy: 0.5783
[2025-09-19 12:08:01,527][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.002772584405897179,  accuracy: 1.0, gradient_norm : 0.1527142721920378
[2025-09-19 12:08:06,341][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.881611656554896,  accuracy: 0.5776
[2025-09-19 12:08:11,540][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.009024537040152178,  accuracy: 0.9990322736730053, gradient_norm : 0.4551998192280855
[2025-09-19 12:08:16,390][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.892668396933368,  accuracy: 0.5762
[2025-09-19 12:08:20,883][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.03327873161061707,  accuracy: 0.9959109761084175, gradient_norm : 0.4425615308882341
[2025-09-19 12:08:25,658][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 1.78918725166618,  accuracy: 0.5819
[2025-09-19 12:08:30,866][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.026615166908510037,  accuracy: 0.994365231025528, gradient_norm : 0.3845475473825724
[2025-09-19 12:08:35,745][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.6794078305996576,  accuracy: 0.5888
[2025-09-19 12:08:40,664][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.020126447535944187,  accuracy: 0.9989523859410193, gradient_norm : 0.3106771058014796
[2025-09-19 12:08:45,463][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.6868540375096717,  accuracy: 0.5874
[2025-09-19 12:08:49,856][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.004147547695858711,  accuracy: 0.9998734417515661, gradient_norm : 0.2252584751972217
[2025-09-19 12:08:54,641][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.678235886010043,  accuracy: 0.588
[2025-09-19 12:08:59,725][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.014798800886485214,  accuracy: 0.9988055163427082, gradient_norm : 0.4855517733487316
[2025-09-19 12:09:04,482][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.732682527788307,  accuracy: 0.5858
[2025-09-19 12:09:09,204][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.015103493040870601,  accuracy: 0.9970065367462887, gradient_norm : 0.28519819654446155
[2025-09-19 12:09:13,948][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.6859846800389147,  accuracy: 0.5873
[2025-09-19 12:09:19,151][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.0018963135271282423,  accuracy: 1.0, gradient_norm : 0.09631755776955678
[2025-09-19 12:09:23,946][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 1.6807090425174844,  accuracy: 0.59
[2025-09-19 12:09:28,956][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.0034386946838807853,  accuracy: 0.999894525893893, gradient_norm : 0.2569848154348402
[2025-09-19 12:09:33,723][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.6849618673438147,  accuracy: 0.5889
[2025-09-19 12:09:38,778][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.017293664519654337,  accuracy: 0.9992798724345455, gradient_norm : 0.5698954784246439
[2025-09-19 12:09:43,573][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.710948236162159,  accuracy: 0.5903
[2025-09-19 12:09:48,438][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.0036353790329615243,  accuracy: 0.9999404584697826, gradient_norm : 0.2677616708916935
[2025-09-19 12:09:53,130][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.708549357052538,  accuracy: 0.591
[2025-09-19 12:09:58,686][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.004343558526703021,  accuracy: 0.9998547567175018, gradient_norm : 0.3334797987444348
[2025-09-19 12:10:03,478][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.716932205319464,  accuracy: 0.5878
[2025-09-19 12:10:09,233][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.00298037968868653,  accuracy: 0.9998599570534964, gradient_norm : 0.23640132850893944
[2025-09-19 12:10:14,064][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.725905109710885,  accuracy: 0.5878
[2025-09-19 12:10:18,913][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.00917778277695503,  accuracy: 0.9989821882951654, gradient_norm : 0.38520497484319105
[2025-09-19 12:10:23,675][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 1.7201763238582843,  accuracy: 0.5881
[2025-09-19 12:10:28,231][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.005684412684759882,  accuracy: 0.9993661038437158, gradient_norm : 0.18954988750695706
[2025-09-19 12:10:32,992][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.7118180699644323,  accuracy: 0.59
[2025-09-19 12:10:38,440][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.01757599725086585,  accuracy: 0.9979172583546341, gradient_norm : 0.42461622612699024
[2025-09-19 12:10:43,155][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.7089217111978017,  accuracy: 0.5901
[2025-09-19 12:10:48,339][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.01553315922704175,  accuracy: 0.9973948835512948, gradient_norm : 0.48289222047490277
[2025-09-19 12:10:53,055][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.7125300736672762,  accuracy: 0.5866
[2025-09-19 12:10:58,359][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.007364397076239753,  accuracy: 0.9997980511940223, gradient_norm : 0.41732099645602994
[2025-09-19 12:11:03,174][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.7320748247974043,  accuracy: 0.5856
[2025-09-19 12:11:08,410][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.003776725514359938,  accuracy: 0.9994602472067793, gradient_norm : 0.10657586194959492
[2025-09-19 12:11:13,190][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.707808335962431,  accuracy: 0.5897
[2025-09-19 12:11:19,416][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.027055842404045266,  accuracy: 0.9990969683938938, gradient_norm : 0.5285150898207501
[2025-09-19 12:11:24,181][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 1.718574136698216,  accuracy: 0.586
[2025-09-19 12:11:28,503][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.0020703620094333773,  accuracy: 1.0, gradient_norm : 0.0641352308981007
[2025-09-19 12:11:33,249][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 1.7203197836627275,  accuracy: 0.5859
[2025-09-19 12:11:38,459][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.005862526556959984,  accuracy: 0.9993233747983137, gradient_norm : 0.23046794378226934
[2025-09-19 12:11:43,171][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 1.7154301079852674,  accuracy: 0.5861
[2025-09-19 12:11:49,011][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.004862599700978776,  accuracy: 0.9995709586690185, gradient_norm : 0.2894719783997494
[2025-09-19 12:11:53,841][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 1.7027260081428417,  accuracy: 0.5849
[2025-09-19 12:11:58,513][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.02453742922776175,  accuracy: 0.9965482118605704, gradient_norm : 0.429502375858444
[2025-09-19 12:12:03,369][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 1.7699541156820586,  accuracy: 0.5817
[2025-09-19 12:12:08,587][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.02677210576803377,  accuracy: 0.994386615074391, gradient_norm : 0.5203732664845508
[2025-09-19 12:12:13,341][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 1.7339179595179488,  accuracy: 0.5862
[2025-09-19 12:12:18,615][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.01566058868956535,  accuracy: 0.9991680125287525, gradient_norm : 0.28309338337210904
[2025-09-19 12:12:23,437][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 1.7253686071656198,  accuracy: 0.5861
[2025-09-19 12:12:28,346][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.020168922417699513,  accuracy: 0.9992621182881144, gradient_norm : 0.5306209177883175
[2025-09-19 12:12:33,110][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 1.7482343078142468,  accuracy: 0.5837
[2025-09-19 12:12:37,829][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.012109212532046769,  accuracy: 0.999139203148057, gradient_norm : 0.5280525410667557
[2025-09-19 12:12:42,614][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 1.7481705597823922,  accuracy: 0.5871
[2025-09-19 12:12:48,562][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.003369235898069216,  accuracy: 0.9997953252282124, gradient_norm : 0.18672098542266788
[2025-09-19 12:12:53,357][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 1.8255379805053338,  accuracy: 0.5828
[2025-09-19 12:12:59,029][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.01722450560721059,  accuracy: 0.9959349593495935, gradient_norm : 0.3913879132901717
[2025-09-19 12:13:03,786][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 1.8278880432955205,  accuracy: 0.5775
[2025-09-19 12:13:08,199][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.00892901010682419,  accuracy: 0.9988249118683902, gradient_norm : 0.31976737592149074
[2025-09-19 12:13:12,940][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 1.8275229461885254,  accuracy: 0.5768
[2025-09-19 12:13:18,182][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.012778541962266755,  accuracy: 0.9998482088646024, gradient_norm : 0.29675356550907944
[2025-09-19 12:13:22,987][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 1.8315421595068866,  accuracy: 0.5772
[2025-09-19 12:13:27,919][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.01715702161676151,  accuracy: 0.9975063695993929, gradient_norm : 0.3264806767949515
[2025-09-19 12:13:32,765][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 1.8471030009763363,  accuracy: 0.5785
[2025-09-19 12:13:36,616][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.02938158486824886,  accuracy: 0.9934602808232352, gradient_norm : 0.349235093339154
[2025-09-19 12:13:41,431][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 1.825128101387314,  accuracy: 0.5817
[2025-09-19 12:13:45,677][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.011779135756952339,  accuracy: 0.9995444450771596, gradient_norm : 0.5346199768078335
[2025-09-19 12:13:50,428][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 1.8061595802052606,  accuracy: 0.5833
[2025-09-19 12:13:54,850][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.01809856196895208,  accuracy: 0.9990447887921885, gradient_norm : 0.5310451654909815
[2025-09-19 12:13:59,741][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 1.833378298558472,  accuracy: 0.5822
[2025-09-19 12:14:04,377][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.009782512962405355,  accuracy: 0.9987102765167148, gradient_norm : 0.29298036123856697
[2025-09-19 12:14:09,224][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 1.8370146312425317,  accuracy: 0.5796
[2025-09-19 12:14:13,900][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.012895743251214859,  accuracy: 0.9990662418982753, gradient_norm : 0.5709504588189158
[2025-09-19 12:14:18,652][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 1.8783839061691936,  accuracy: 0.5788
[2025-09-19 12:14:22,921][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.02370643328740473,  accuracy: 0.9973003374578178, gradient_norm : 0.8117036543720508
[2025-09-19 12:14:27,709][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 1.7385382201395012,  accuracy: 0.5817
[2025-09-19 12:14:32,788][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.021661458471598387,  accuracy: 0.9981057981057981, gradient_norm : 0.3994432881617229
[2025-09-19 12:14:37,619][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 1.7397879717193194,  accuracy: 0.5865
[2025-09-19 12:14:41,538][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.01614713701256405,  accuracy: 0.9969282659760285, gradient_norm : 0.4793786132479075
[2025-09-19 12:14:46,403][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 1.7081609790898866,  accuracy: 0.5864
[2025-09-19 12:14:51,593][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.02190114490147112,  accuracy: 0.9988649262202043, gradient_norm : 0.6045271156785932
[2025-09-19 12:14:56,433][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 1.692318088116822,  accuracy: 0.5886
[2025-09-19 12:15:00,693][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.0058858944412806605,  accuracy: 1.0, gradient_norm : 0.23355869801329815
[2025-09-19 12:15:05,559][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 1.6806198696877437,  accuracy: 0.5911
[2025-09-19 12:15:09,871][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.0038411004151552384,  accuracy: 0.9995895872420263, gradient_norm : 0.19558340665671492
[2025-09-19 12:15:14,671][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 1.689003842062306,  accuracy: 0.5914
[2025-09-19 12:15:18,870][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.013997152557987938,  accuracy: 0.9998226111636708, gradient_norm : 0.48221576997851245
[2025-09-19 12:15:23,719][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 1.68203982220129,  accuracy: 0.5896
[2025-09-19 12:15:27,825][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.016362595387004686,  accuracy: 0.9998337858053078, gradient_norm : 0.5050947383885872
[2025-09-19 12:15:32,714][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 1.6891935616004055,  accuracy: 0.5888
[2025-09-19 12:15:37,461][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.021850928274770604,  accuracy: 0.9990698585205855, gradient_norm : 0.43857695970989896
[2025-09-19 12:15:42,309][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 1.7092111239900774,  accuracy: 0.5864
[2025-09-19 12:15:47,577][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.0013486299621008454,  accuracy: 1.0, gradient_norm : 0.06445175750153284
[2025-09-19 12:15:52,332][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 1.7133607975849097,  accuracy: 0.5879
[2025-09-19 12:15:57,631][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.0014872800823238189,  accuracy: 1.0, gradient_norm : 0.05485295617531183
[2025-09-19 12:16:02,369][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 1.7122475016927645,  accuracy: 0.5874
[2025-09-19 12:16:07,162][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.0021396107707269342,  accuracy: 1.0, gradient_norm : 0.13372531716336966
[2025-09-19 12:16:12,011][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 1.7167026529929172,  accuracy: 0.5897
[2025-09-19 12:16:17,110][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.0065966010739340365,  accuracy: 0.9994278630685611, gradient_norm : 0.30924454833591214
[2025-09-19 12:16:21,936][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 1.6958081956665272,  accuracy: 0.5935
[2025-09-19 12:16:26,724][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.011124329295444057,  accuracy: 0.9980805089393441, gradient_norm : 0.26389723714275043
[2025-09-19 12:16:31,503][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 1.7330565913291331,  accuracy: 0.5921
[2025-09-19 12:16:35,658][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.0026189815057450928,  accuracy: 1.0, gradient_norm : 0.15566598816534927
[2025-09-19 12:16:40,521][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 1.7220153690588036,  accuracy: 0.5919
[2025-09-19 12:16:45,766][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.0025163762465650074,  accuracy: 0.9999521256223669, gradient_norm : 0.1596155599859071
[2025-09-19 12:16:50,589][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 1.7237734277705712,  accuracy: 0.5934
[2025-09-19 12:16:55,336][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.0011487170428018858,  accuracy: 1.0, gradient_norm : 0.026227128936145365
[2025-09-19 12:17:00,133][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 1.7215035063595467,  accuracy: 0.593
[2025-09-19 12:17:04,986][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.03436087399919931,  accuracy: 0.9971850126189089, gradient_norm : 0.4689547600053277
[2025-09-19 12:17:09,836][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 1.708924442439717,  accuracy: 0.5921
[2025-09-19 12:17:14,503][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.005580653959217163,  accuracy: 0.9991070490597752, gradient_norm : 0.23795413164790666
[2025-09-19 12:17:19,335][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 1.7071345058813443,  accuracy: 0.591
[2025-09-19 12:17:24,568][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.006186101466554922,  accuracy: 0.9991273100616016, gradient_norm : 0.21954416273143423
[2025-09-19 12:17:29,430][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 1.7018547632314796,  accuracy: 0.5904
[2025-09-19 12:17:33,533][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.024169374261299923,  accuracy: 0.9992274583379318, gradient_norm : 0.6730927592032806
[2025-09-19 12:17:38,350][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 1.7538407576843131,  accuracy: 0.5869
[2025-09-19 12:17:42,820][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.007943945292190066,  accuracy: 0.9999037813913211, gradient_norm : 0.3935014638833342
[2025-09-19 12:17:47,700][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 1.7673001809385753,  accuracy: 0.5852
[2025-09-19 12:17:52,199][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.016183205024388584,  accuracy: 0.9969260637437308, gradient_norm : 0.4015382177342503
[2025-09-19 12:17:57,011][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 1.7129794629942523,  accuracy: 0.5896
[2025-09-19 12:18:00,805][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.0013302915688804813,  accuracy: 0.9998846331333641, gradient_norm : 0.0372249583651501
[2025-09-19 12:18:05,715][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 1.7118268543159254,  accuracy: 0.5889
[2025-09-19 12:18:09,647][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.008356652936624909,  accuracy: 0.9991106664443333, gradient_norm : 0.36606095539010536
[2025-09-19 12:18:14,554][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 1.7102055213008316,  accuracy: 0.589
[2025-09-19 12:18:18,885][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.007389606785539607,  accuracy: 0.9996468392109379, gradient_norm : 0.31759117389865554
[2025-09-19 12:18:23,795][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 1.736089773050505,  accuracy: 0.5897
[2025-09-19 12:18:28,044][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.009138395383769841,  accuracy: 0.9982434127979924, gradient_norm : 0.22700722228495884
[2025-09-19 12:18:32,959][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 1.7443534521881323,  accuracy: 0.5895
[2025-09-19 12:18:37,534][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.013705152603115917,  accuracy: 0.9999036701666506, gradient_norm : 0.4268841578019881
[2025-09-19 12:18:42,446][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 1.7620475075331339,  accuracy: 0.5872
[2025-09-19 12:18:46,245][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.00617066295390254,  accuracy: 0.9996904408122833, gradient_norm : 0.30040909219863837
[2025-09-19 12:18:51,174][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 1.7562165365744637,  accuracy: 0.5896
[2025-09-19 12:18:55,305][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.021649341011808872,  accuracy: 0.9996883116883117, gradient_norm : 0.5770445968037601
[2025-09-19 12:19:00,217][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 1.7462814021308894,  accuracy: 0.5875
[2025-09-19 12:19:04,076][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.0019285508665563677,  accuracy: 1.0, gradient_norm : 0.0839099936417516
[2025-09-19 12:19:09,014][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 1.7409629636096489,  accuracy: 0.5883
[2025-09-19 12:19:13,267][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.0017777840351936645,  accuracy: 1.0, gradient_norm : 0.10167755262453242
[2025-09-19 12:19:18,178][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 1.743262555423739,  accuracy: 0.5886
[2025-09-19 12:19:22,530][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.00557109874218512,  accuracy: 0.9994942854253059, gradient_norm : 0.1481855294864798
[2025-09-19 12:19:27,347][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 1.7288052738733533,  accuracy: 0.5909
[2025-09-19 12:19:31,313][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.017913698423525328,  accuracy: 0.9973306071448855, gradient_norm : 0.3783800747249284
[2025-09-19 12:19:36,189][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 1.711260319979109,  accuracy: 0.5922
[2025-09-19 12:19:40,101][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.014475666046926114,  accuracy: 0.9997619614377529, gradient_norm : 0.431191611705279
[2025-09-19 12:19:44,976][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 1.719037056715464,  accuracy: 0.5911
[2025-09-19 12:19:49,573][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.004677709102791019,  accuracy: 0.999898244721445, gradient_norm : 0.28205289422986174
[2025-09-19 12:19:54,474][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 1.7253145029034285,  accuracy: 0.5912
[2025-09-19 12:19:58,469][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.009643869460439953,  accuracy: 0.9998400767631537, gradient_norm : 0.29010180184472995
[2025-09-19 12:20:03,315][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 1.730744406392051,  accuracy: 0.5927
[2025-09-19 12:20:06,644][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.0015586516145299925,  accuracy: 1.0, gradient_norm : 0.11208237590315973
[2025-09-19 12:20:11,516][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 1.732482786421018,  accuracy: 0.5929
[2025-09-19 12:20:15,493][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.012441495313781664,  accuracy: 0.999885877318117, gradient_norm : 0.43040130597281806
[2025-09-19 12:20:20,380][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 1.7360938812013174,  accuracy: 0.5914
[2025-09-19 12:20:24,237][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.018774211408148403,  accuracy: 0.9998727249586357, gradient_norm : 0.44995952980465354
[2025-09-19 12:20:29,076][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 1.732782470044727,  accuracy: 0.5906
[2025-09-19 12:20:34,512][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.017405842646434414,  accuracy: 0.9992348240095222, gradient_norm : 0.6165315160962233
[2025-09-19 12:20:39,374][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 1.9005187325473643,  accuracy: 0.5805
[2025-09-19 12:20:43,157][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.016902927832556116,  accuracy: 0.9983085659055213, gradient_norm : 0.715839568726175
[2025-09-19 12:20:47,968][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 1.818202397867063,  accuracy: 0.5856
[2025-09-19 12:20:51,807][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.0039412655199884085,  accuracy: 0.9996407615854389, gradient_norm : 0.27082176353361304
[2025-09-19 12:20:56,673][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 1.8204171139668068,  accuracy: 0.5863
[2025-09-19 12:21:00,645][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.015256858286598146,  accuracy: 0.9995245170876672, gradient_norm : 0.3300994443462597
[2025-09-19 12:21:05,498][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 1.8160124029856421,  accuracy: 0.5847
[2025-09-19 12:21:09,923][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.003388870267872711,  accuracy: 0.9996267263904441, gradient_norm : 0.17672294569642624
[2025-09-19 12:21:14,741][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 1.7618362428560024,  accuracy: 0.5875
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 001: loss=1.7043, accuracy=0.4337, gradient_norm=1.7930, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 002: loss=1.7190, accuracy=0.3999, gradient_norm=1.3165, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 003: loss=1.5083, accuracy=0.4689, gradient_norm=1.2811, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 004: loss=1.3747, accuracy=0.5258, gradient_norm=1.2159, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 005: loss=1.3244, accuracy=0.5246, gradient_norm=1.3539, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 006: loss=1.1549, accuracy=0.6015, gradient_norm=1.3858, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 007: loss=1.3817, accuracy=0.5226, gradient_norm=1.5553, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 008: loss=0.9923, accuracy=0.6630, gradient_norm=1.2894, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 009: loss=1.0431, accuracy=0.6455, gradient_norm=1.3369, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 010: loss=0.9969, accuracy=0.6631, gradient_norm=1.4620, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 011: loss=0.7720, accuracy=0.7425, gradient_norm=1.2914, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 012: loss=0.7105, accuracy=0.7698, gradient_norm=1.3406, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 013: loss=0.7756, accuracy=0.7517, gradient_norm=1.3095, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 014: loss=0.6957, accuracy=0.7817, gradient_norm=1.3599, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 015: loss=0.6048, accuracy=0.8139, gradient_norm=1.4854, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 016: loss=0.4477, accuracy=0.8731, gradient_norm=1.1928, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 017: loss=0.4768, accuracy=0.8667, gradient_norm=1.3075, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 018: loss=0.5344, accuracy=0.8366, gradient_norm=1.4430, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 019: loss=0.2574, accuracy=0.9368, gradient_norm=0.9556, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 020: loss=0.1917, accuracy=0.9587, gradient_norm=1.1838, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 021: loss=0.2889, accuracy=0.9197, gradient_norm=1.0865, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 022: loss=0.3112, accuracy=0.9212, gradient_norm=1.4200, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 023: loss=0.3170, accuracy=0.9115, gradient_norm=0.9517, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 024: loss=0.1137, accuracy=0.9775, gradient_norm=0.7825, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 025: loss=0.2045, accuracy=0.9429, gradient_norm=0.7360, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 026: loss=0.2438, accuracy=0.9302, gradient_norm=0.8142, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 027: loss=0.1166, accuracy=0.9702, gradient_norm=0.6175, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 028: loss=0.1830, accuracy=0.9485, gradient_norm=0.6593, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 029: loss=0.1654, accuracy=0.9575, gradient_norm=0.8591, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 030: loss=0.0901, accuracy=0.9850, gradient_norm=0.8398, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 031: loss=0.0978, accuracy=0.9769, gradient_norm=0.7314, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 032: loss=0.1414, accuracy=0.9693, gradient_norm=0.8204, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 033: loss=0.1464, accuracy=0.9609, gradient_norm=0.7848, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 034: loss=0.0863, accuracy=0.9823, gradient_norm=0.5516, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 035: loss=0.0385, accuracy=0.9972, gradient_norm=0.5953, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 036: loss=0.0581, accuracy=0.9913, gradient_norm=0.6720, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 037: loss=0.0552, accuracy=0.9890, gradient_norm=0.4124, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 038: loss=0.0809, accuracy=0.9800, gradient_norm=0.4813, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 039: loss=0.0566, accuracy=0.9909, gradient_norm=0.5920, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 040: loss=0.0520, accuracy=0.9904, gradient_norm=0.4716, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 041: loss=0.0505, accuracy=0.9918, gradient_norm=0.6826, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 042: loss=0.0386, accuracy=0.9957, gradient_norm=0.6977, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 043: loss=0.0425, accuracy=0.9923, gradient_norm=0.3920, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 044: loss=0.0422, accuracy=0.9918, gradient_norm=0.4531, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 045: loss=0.0429, accuracy=0.9931, gradient_norm=0.7105, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 046: loss=0.0263, accuracy=0.9971, gradient_norm=0.4162, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 047: loss=0.0280, accuracy=0.9984, gradient_norm=0.4347, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 048: loss=0.0364, accuracy=0.9929, gradient_norm=0.3416, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 049: loss=0.0411, accuracy=0.9959, gradient_norm=0.5405, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 050: loss=0.0151, accuracy=0.9988, gradient_norm=0.3336, 
[2025-09-19 12:21:14,742][__main__][INFO] - Train, Round 051: loss=0.0231, accuracy=0.9965, gradient_norm=0.2714, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 052: loss=0.0162, accuracy=0.9993, gradient_norm=0.5530, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 053: loss=0.0170, accuracy=0.9979, gradient_norm=0.3745, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 054: loss=0.0226, accuracy=0.9986, gradient_norm=0.5622, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 055: loss=0.0207, accuracy=0.9991, gradient_norm=0.8131, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 056: loss=0.0175, accuracy=0.9986, gradient_norm=0.4844, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 057: loss=0.0345, accuracy=0.9949, gradient_norm=0.7095, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 058: loss=0.0146, accuracy=0.9976, gradient_norm=0.2509, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 059: loss=0.0294, accuracy=0.9968, gradient_norm=0.5897, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 060: loss=0.0307, accuracy=0.9973, gradient_norm=0.6580, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 061: loss=0.0130, accuracy=0.9987, gradient_norm=0.4285, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 062: loss=0.0146, accuracy=0.9979, gradient_norm=0.2232, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 063: loss=0.0100, accuracy=0.9996, gradient_norm=0.2308, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 064: loss=0.0148, accuracy=0.9982, gradient_norm=0.2615, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 065: loss=0.0280, accuracy=0.9969, gradient_norm=0.6681, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 066: loss=0.0188, accuracy=0.9984, gradient_norm=0.4733, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 067: loss=0.0170, accuracy=0.9980, gradient_norm=0.4964, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 068: loss=0.0192, accuracy=0.9979, gradient_norm=0.3992, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 069: loss=0.0112, accuracy=0.9994, gradient_norm=0.2638, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 070: loss=0.0287, accuracy=0.9993, gradient_norm=0.5346, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 071: loss=0.0090, accuracy=0.9995, gradient_norm=0.2117, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 072: loss=0.0081, accuracy=0.9998, gradient_norm=0.3560, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 073: loss=0.0215, accuracy=0.9974, gradient_norm=0.4971, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 074: loss=0.0079, accuracy=0.9999, gradient_norm=0.3005, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 075: loss=0.0114, accuracy=0.9985, gradient_norm=0.2491, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 076: loss=0.0081, accuracy=0.9999, gradient_norm=0.3718, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 077: loss=0.0065, accuracy=0.9997, gradient_norm=0.1702, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 078: loss=0.0132, accuracy=0.9989, gradient_norm=0.2969, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 079: loss=0.0068, accuracy=0.9997, gradient_norm=0.3269, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 080: loss=0.0069, accuracy=0.9999, gradient_norm=0.2014, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 081: loss=0.0057, accuracy=0.9997, gradient_norm=0.1506, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 082: loss=0.0040, accuracy=0.9998, gradient_norm=0.1687, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 083: loss=0.0065, accuracy=0.9994, gradient_norm=0.1481, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 084: loss=0.0069, accuracy=0.9998, gradient_norm=0.1988, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 085: loss=0.0079, accuracy=0.9997, gradient_norm=0.3169, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 086: loss=0.0100, accuracy=0.9989, gradient_norm=0.3288, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 087: loss=0.0048, accuracy=0.9999, gradient_norm=0.1672, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 088: loss=0.0082, accuracy=0.9999, gradient_norm=0.4219, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 089: loss=0.0068, accuracy=0.9992, gradient_norm=0.1473, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 090: loss=0.0046, accuracy=0.9999, gradient_norm=0.0969, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 091: loss=0.0050, accuracy=0.9999, gradient_norm=0.1861, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 092: loss=0.0064, accuracy=0.9999, gradient_norm=0.3873, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 093: loss=0.0066, accuracy=0.9998, gradient_norm=0.3264, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 094: loss=0.0051, accuracy=0.9999, gradient_norm=0.3451, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 095: loss=0.0116, accuracy=0.9998, gradient_norm=0.4161, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 096: loss=0.0031, accuracy=0.9999, gradient_norm=0.0735, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 097: loss=0.0147, accuracy=0.9997, gradient_norm=0.5119, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 098: loss=0.0195, accuracy=0.9994, gradient_norm=0.4394, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 099: loss=0.0033, accuracy=1.0000, gradient_norm=0.1067, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 100: loss=0.0172, accuracy=0.9998, gradient_norm=0.5382, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 101: loss=0.0039, accuracy=0.9998, gradient_norm=0.1459, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 102: loss=0.0203, accuracy=0.9984, gradient_norm=0.5727, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 103: loss=0.0037, accuracy=0.9999, gradient_norm=0.1836, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 104: loss=0.0230, accuracy=0.9970, gradient_norm=0.3654, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 105: loss=0.0097, accuracy=0.9988, gradient_norm=0.5239, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 106: loss=0.0036, accuracy=0.9998, gradient_norm=0.1283, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 107: loss=0.0024, accuracy=1.0000, gradient_norm=0.1065, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 108: loss=0.0215, accuracy=0.9963, gradient_norm=0.4913, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 109: loss=0.0034, accuracy=0.9999, gradient_norm=0.1899, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 110: loss=0.0132, accuracy=0.9985, gradient_norm=0.3051, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 111: loss=0.0077, accuracy=0.9998, gradient_norm=0.2498, 
[2025-09-19 12:21:14,743][__main__][INFO] - Train, Round 112: loss=0.0149, accuracy=0.9994, gradient_norm=0.6483, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 113: loss=0.0043, accuracy=0.9999, gradient_norm=0.3044, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 114: loss=0.0074, accuracy=0.9998, gradient_norm=0.3475, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 115: loss=0.0021, accuracy=1.0000, gradient_norm=0.0845, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 116: loss=0.0111, accuracy=0.9996, gradient_norm=0.4815, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 117: loss=0.0028, accuracy=1.0000, gradient_norm=0.1527, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 118: loss=0.0090, accuracy=0.9990, gradient_norm=0.4552, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 119: loss=0.0333, accuracy=0.9959, gradient_norm=0.4426, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 120: loss=0.0266, accuracy=0.9944, gradient_norm=0.3845, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 121: loss=0.0201, accuracy=0.9990, gradient_norm=0.3107, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 122: loss=0.0041, accuracy=0.9999, gradient_norm=0.2253, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 123: loss=0.0148, accuracy=0.9988, gradient_norm=0.4856, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 124: loss=0.0151, accuracy=0.9970, gradient_norm=0.2852, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 125: loss=0.0019, accuracy=1.0000, gradient_norm=0.0963, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 126: loss=0.0034, accuracy=0.9999, gradient_norm=0.2570, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 127: loss=0.0173, accuracy=0.9993, gradient_norm=0.5699, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 128: loss=0.0036, accuracy=0.9999, gradient_norm=0.2678, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 129: loss=0.0043, accuracy=0.9999, gradient_norm=0.3335, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 130: loss=0.0030, accuracy=0.9999, gradient_norm=0.2364, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 131: loss=0.0092, accuracy=0.9990, gradient_norm=0.3852, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 132: loss=0.0057, accuracy=0.9994, gradient_norm=0.1895, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 133: loss=0.0176, accuracy=0.9979, gradient_norm=0.4246, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 134: loss=0.0155, accuracy=0.9974, gradient_norm=0.4829, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 135: loss=0.0074, accuracy=0.9998, gradient_norm=0.4173, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 136: loss=0.0038, accuracy=0.9995, gradient_norm=0.1066, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 137: loss=0.0271, accuracy=0.9991, gradient_norm=0.5285, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 138: loss=0.0021, accuracy=1.0000, gradient_norm=0.0641, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 139: loss=0.0059, accuracy=0.9993, gradient_norm=0.2305, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 140: loss=0.0049, accuracy=0.9996, gradient_norm=0.2895, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 141: loss=0.0245, accuracy=0.9965, gradient_norm=0.4295, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 142: loss=0.0268, accuracy=0.9944, gradient_norm=0.5204, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 143: loss=0.0157, accuracy=0.9992, gradient_norm=0.2831, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 144: loss=0.0202, accuracy=0.9993, gradient_norm=0.5306, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 145: loss=0.0121, accuracy=0.9991, gradient_norm=0.5281, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 146: loss=0.0034, accuracy=0.9998, gradient_norm=0.1867, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 147: loss=0.0172, accuracy=0.9959, gradient_norm=0.3914, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 148: loss=0.0089, accuracy=0.9988, gradient_norm=0.3198, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 149: loss=0.0128, accuracy=0.9998, gradient_norm=0.2968, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 150: loss=0.0172, accuracy=0.9975, gradient_norm=0.3265, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 151: loss=0.0294, accuracy=0.9935, gradient_norm=0.3492, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 152: loss=0.0118, accuracy=0.9995, gradient_norm=0.5346, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 153: loss=0.0181, accuracy=0.9990, gradient_norm=0.5310, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 154: loss=0.0098, accuracy=0.9987, gradient_norm=0.2930, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 155: loss=0.0129, accuracy=0.9991, gradient_norm=0.5710, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 156: loss=0.0237, accuracy=0.9973, gradient_norm=0.8117, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 157: loss=0.0217, accuracy=0.9981, gradient_norm=0.3994, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 158: loss=0.0161, accuracy=0.9969, gradient_norm=0.4794, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 159: loss=0.0219, accuracy=0.9989, gradient_norm=0.6045, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 160: loss=0.0059, accuracy=1.0000, gradient_norm=0.2336, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 161: loss=0.0038, accuracy=0.9996, gradient_norm=0.1956, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 162: loss=0.0140, accuracy=0.9998, gradient_norm=0.4822, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 163: loss=0.0164, accuracy=0.9998, gradient_norm=0.5051, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 164: loss=0.0219, accuracy=0.9991, gradient_norm=0.4386, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 165: loss=0.0013, accuracy=1.0000, gradient_norm=0.0645, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 166: loss=0.0015, accuracy=1.0000, gradient_norm=0.0549, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 167: loss=0.0021, accuracy=1.0000, gradient_norm=0.1337, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 168: loss=0.0066, accuracy=0.9994, gradient_norm=0.3092, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 169: loss=0.0111, accuracy=0.9981, gradient_norm=0.2639, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 170: loss=0.0026, accuracy=1.0000, gradient_norm=0.1557, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 171: loss=0.0025, accuracy=1.0000, gradient_norm=0.1596, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 172: loss=0.0011, accuracy=1.0000, gradient_norm=0.0262, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 173: loss=0.0344, accuracy=0.9972, gradient_norm=0.4690, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 174: loss=0.0056, accuracy=0.9991, gradient_norm=0.2380, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 175: loss=0.0062, accuracy=0.9991, gradient_norm=0.2195, 
[2025-09-19 12:21:14,744][__main__][INFO] - Train, Round 176: loss=0.0242, accuracy=0.9992, gradient_norm=0.6731, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 177: loss=0.0079, accuracy=0.9999, gradient_norm=0.3935, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 178: loss=0.0162, accuracy=0.9969, gradient_norm=0.4015, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 179: loss=0.0013, accuracy=0.9999, gradient_norm=0.0372, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 180: loss=0.0084, accuracy=0.9991, gradient_norm=0.3661, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 181: loss=0.0074, accuracy=0.9996, gradient_norm=0.3176, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 182: loss=0.0091, accuracy=0.9982, gradient_norm=0.2270, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 183: loss=0.0137, accuracy=0.9999, gradient_norm=0.4269, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 184: loss=0.0062, accuracy=0.9997, gradient_norm=0.3004, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 185: loss=0.0216, accuracy=0.9997, gradient_norm=0.5770, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 186: loss=0.0019, accuracy=1.0000, gradient_norm=0.0839, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 187: loss=0.0018, accuracy=1.0000, gradient_norm=0.1017, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 188: loss=0.0056, accuracy=0.9995, gradient_norm=0.1482, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 189: loss=0.0179, accuracy=0.9973, gradient_norm=0.3784, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 190: loss=0.0145, accuracy=0.9998, gradient_norm=0.4312, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 191: loss=0.0047, accuracy=0.9999, gradient_norm=0.2821, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 192: loss=0.0096, accuracy=0.9998, gradient_norm=0.2901, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 193: loss=0.0016, accuracy=1.0000, gradient_norm=0.1121, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 194: loss=0.0124, accuracy=0.9999, gradient_norm=0.4304, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 195: loss=0.0188, accuracy=0.9999, gradient_norm=0.4500, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 196: loss=0.0174, accuracy=0.9992, gradient_norm=0.6165, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 197: loss=0.0169, accuracy=0.9983, gradient_norm=0.7158, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 198: loss=0.0039, accuracy=0.9996, gradient_norm=0.2708, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 199: loss=0.0153, accuracy=0.9995, gradient_norm=0.3301, 
[2025-09-19 12:21:14,745][__main__][INFO] - Train, Round 200: loss=0.0034, accuracy=0.9996, gradient_norm=0.1767, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 001: loss=2.0980, accuracy=0.2118, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 002: loss=1.9629, accuracy=0.2714, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 003: loss=1.8832, accuracy=0.3245, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 004: loss=1.8367, accuracy=0.3501, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 005: loss=1.7564, accuracy=0.3815, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 006: loss=1.8107, accuracy=0.3815, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 007: loss=1.7490, accuracy=0.4137, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 008: loss=1.7497, accuracy=0.4239, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 009: loss=1.6857, accuracy=0.4442, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 010: loss=1.7229, accuracy=0.4504, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 011: loss=1.7042, accuracy=0.4601, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 012: loss=1.7456, accuracy=0.4785, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 013: loss=1.7259, accuracy=0.4896, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 014: loss=1.6353, accuracy=0.5023, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 015: loss=1.6125, accuracy=0.5050, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 016: loss=1.6009, accuracy=0.5152, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 017: loss=1.6750, accuracy=0.5095, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 018: loss=1.6759, accuracy=0.5119, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 019: loss=1.6542, accuracy=0.5108, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 020: loss=1.6767, accuracy=0.5164, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 021: loss=1.6357, accuracy=0.5244, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 022: loss=1.6200, accuracy=0.5345, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 023: loss=1.6011, accuracy=0.5378, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 024: loss=1.5872, accuracy=0.5433, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 025: loss=1.6232, accuracy=0.5479, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 026: loss=1.6905, accuracy=0.5437, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 027: loss=1.6547, accuracy=0.5492, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 028: loss=1.6964, accuracy=0.5447, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 029: loss=1.6175, accuracy=0.5533, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 030: loss=1.5943, accuracy=0.5596, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 031: loss=1.5684, accuracy=0.5683, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 032: loss=1.5929, accuracy=0.5626, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 033: loss=1.6829, accuracy=0.5605, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 034: loss=1.7229, accuracy=0.5570, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 035: loss=1.7776, accuracy=0.5528, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 036: loss=1.7620, accuracy=0.5561, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 037: loss=1.7745, accuracy=0.5581, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 038: loss=1.6915, accuracy=0.5660, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 039: loss=1.8064, accuracy=0.5652, 
[2025-09-19 12:21:14,745][__main__][INFO] - Test, Round 040: loss=1.7160, accuracy=0.5682, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 041: loss=1.7162, accuracy=0.5658, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 042: loss=1.7271, accuracy=0.5653, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 043: loss=1.7253, accuracy=0.5676, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 044: loss=1.7020, accuracy=0.5701, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 045: loss=1.6553, accuracy=0.5695, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 046: loss=1.6423, accuracy=0.5739, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 047: loss=1.6422, accuracy=0.5771, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 048: loss=1.6498, accuracy=0.5769, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 049: loss=1.5896, accuracy=0.5816, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 050: loss=1.5921, accuracy=0.5802, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 051: loss=1.5943, accuracy=0.5800, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 052: loss=1.7109, accuracy=0.5732, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 053: loss=1.6503, accuracy=0.5757, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 054: loss=1.6002, accuracy=0.5809, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 055: loss=1.6697, accuracy=0.5728, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 056: loss=1.6804, accuracy=0.5709, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 057: loss=1.7538, accuracy=0.5756, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 058: loss=1.7000, accuracy=0.5778, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 059: loss=1.6174, accuracy=0.5813, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 060: loss=1.6736, accuracy=0.5765, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 061: loss=1.6989, accuracy=0.5722, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 062: loss=1.7054, accuracy=0.5748, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 063: loss=1.6996, accuracy=0.5766, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 064: loss=1.7085, accuracy=0.5778, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 065: loss=1.7144, accuracy=0.5792, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 066: loss=1.7283, accuracy=0.5752, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 067: loss=1.7170, accuracy=0.5809, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 068: loss=1.6807, accuracy=0.5835, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 069: loss=1.6663, accuracy=0.5856, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 070: loss=1.6734, accuracy=0.5857, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 071: loss=1.6789, accuracy=0.5869, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 072: loss=1.6746, accuracy=0.5854, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 073: loss=1.6355, accuracy=0.5830, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 074: loss=1.7011, accuracy=0.5805, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 075: loss=1.6406, accuracy=0.5854, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 076: loss=1.6446, accuracy=0.5829, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 077: loss=1.6248, accuracy=0.5854, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 078: loss=1.6206, accuracy=0.5849, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 079: loss=1.6254, accuracy=0.5845, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 080: loss=1.6214, accuracy=0.5875, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 081: loss=1.6228, accuracy=0.5880, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 082: loss=1.6198, accuracy=0.5892, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 083: loss=1.6158, accuracy=0.5911, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 084: loss=1.6159, accuracy=0.5902, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 085: loss=1.6743, accuracy=0.5873, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 086: loss=1.6199, accuracy=0.5931, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 087: loss=1.6231, accuracy=0.5940, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 088: loss=1.6342, accuracy=0.5927, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 089: loss=1.6189, accuracy=0.5934, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 090: loss=1.6196, accuracy=0.5923, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 091: loss=1.6177, accuracy=0.5939, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 092: loss=1.6331, accuracy=0.5883, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 093: loss=1.6457, accuracy=0.5867, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 094: loss=1.6443, accuracy=0.5878, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 095: loss=1.6458, accuracy=0.5886, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 096: loss=1.6424, accuracy=0.5891, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 097: loss=1.6575, accuracy=0.5872, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 098: loss=1.6732, accuracy=0.5877, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 099: loss=1.6702, accuracy=0.5872, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 100: loss=1.7314, accuracy=0.5827, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 101: loss=1.7350, accuracy=0.5821, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 102: loss=1.7253, accuracy=0.5842, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 103: loss=1.7164, accuracy=0.5840, 
[2025-09-19 12:21:14,746][__main__][INFO] - Test, Round 104: loss=1.6602, accuracy=0.5885, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 105: loss=1.8121, accuracy=0.5828, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 106: loss=1.8030, accuracy=0.5838, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 107: loss=1.8004, accuracy=0.5833, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 108: loss=1.7516, accuracy=0.5885, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 109: loss=1.7490, accuracy=0.5887, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 110: loss=1.8495, accuracy=0.5793, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 111: loss=1.8728, accuracy=0.5799, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 112: loss=1.8683, accuracy=0.5806, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 113: loss=1.8499, accuracy=0.5797, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 114: loss=1.8643, accuracy=0.5777, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 115: loss=1.8642, accuracy=0.5775, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 116: loss=1.8782, accuracy=0.5783, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 117: loss=1.8816, accuracy=0.5776, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 118: loss=1.8927, accuracy=0.5762, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 119: loss=1.7892, accuracy=0.5819, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 120: loss=1.6794, accuracy=0.5888, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 121: loss=1.6869, accuracy=0.5874, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 122: loss=1.6782, accuracy=0.5880, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 123: loss=1.7327, accuracy=0.5858, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 124: loss=1.6860, accuracy=0.5873, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 125: loss=1.6807, accuracy=0.5900, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 126: loss=1.6850, accuracy=0.5889, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 127: loss=1.7109, accuracy=0.5903, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 128: loss=1.7085, accuracy=0.5910, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 129: loss=1.7169, accuracy=0.5878, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 130: loss=1.7259, accuracy=0.5878, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 131: loss=1.7202, accuracy=0.5881, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 132: loss=1.7118, accuracy=0.5900, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 133: loss=1.7089, accuracy=0.5901, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 134: loss=1.7125, accuracy=0.5866, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 135: loss=1.7321, accuracy=0.5856, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 136: loss=1.7078, accuracy=0.5897, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 137: loss=1.7186, accuracy=0.5860, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 138: loss=1.7203, accuracy=0.5859, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 139: loss=1.7154, accuracy=0.5861, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 140: loss=1.7027, accuracy=0.5849, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 141: loss=1.7700, accuracy=0.5817, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 142: loss=1.7339, accuracy=0.5862, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 143: loss=1.7254, accuracy=0.5861, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 144: loss=1.7482, accuracy=0.5837, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 145: loss=1.7482, accuracy=0.5871, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 146: loss=1.8255, accuracy=0.5828, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 147: loss=1.8279, accuracy=0.5775, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 148: loss=1.8275, accuracy=0.5768, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 149: loss=1.8315, accuracy=0.5772, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 150: loss=1.8471, accuracy=0.5785, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 151: loss=1.8251, accuracy=0.5817, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 152: loss=1.8062, accuracy=0.5833, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 153: loss=1.8334, accuracy=0.5822, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 154: loss=1.8370, accuracy=0.5796, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 155: loss=1.8784, accuracy=0.5788, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 156: loss=1.7385, accuracy=0.5817, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 157: loss=1.7398, accuracy=0.5865, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 158: loss=1.7082, accuracy=0.5864, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 159: loss=1.6923, accuracy=0.5886, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 160: loss=1.6806, accuracy=0.5911, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 161: loss=1.6890, accuracy=0.5914, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 162: loss=1.6820, accuracy=0.5896, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 163: loss=1.6892, accuracy=0.5888, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 164: loss=1.7092, accuracy=0.5864, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 165: loss=1.7134, accuracy=0.5879, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 166: loss=1.7122, accuracy=0.5874, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 167: loss=1.7167, accuracy=0.5897, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 168: loss=1.6958, accuracy=0.5935, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 169: loss=1.7331, accuracy=0.5921, 
[2025-09-19 12:21:14,747][__main__][INFO] - Test, Round 170: loss=1.7220, accuracy=0.5919, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 171: loss=1.7238, accuracy=0.5934, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 172: loss=1.7215, accuracy=0.5930, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 173: loss=1.7089, accuracy=0.5921, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 174: loss=1.7071, accuracy=0.5910, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 175: loss=1.7019, accuracy=0.5904, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 176: loss=1.7538, accuracy=0.5869, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 177: loss=1.7673, accuracy=0.5852, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 178: loss=1.7130, accuracy=0.5896, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 179: loss=1.7118, accuracy=0.5889, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 180: loss=1.7102, accuracy=0.5890, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 181: loss=1.7361, accuracy=0.5897, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 182: loss=1.7444, accuracy=0.5895, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 183: loss=1.7620, accuracy=0.5872, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 184: loss=1.7562, accuracy=0.5896, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 185: loss=1.7463, accuracy=0.5875, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 186: loss=1.7410, accuracy=0.5883, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 187: loss=1.7433, accuracy=0.5886, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 188: loss=1.7288, accuracy=0.5909, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 189: loss=1.7113, accuracy=0.5922, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 190: loss=1.7190, accuracy=0.5911, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 191: loss=1.7253, accuracy=0.5912, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 192: loss=1.7307, accuracy=0.5927, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 193: loss=1.7325, accuracy=0.5929, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 194: loss=1.7361, accuracy=0.5914, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 195: loss=1.7328, accuracy=0.5906, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 196: loss=1.9005, accuracy=0.5805, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 197: loss=1.8182, accuracy=0.5856, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 198: loss=1.8204, accuracy=0.5863, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 199: loss=1.8160, accuracy=0.5847, 
[2025-09-19 12:21:14,748][__main__][INFO] - Test, Round 200: loss=1.7618, accuracy=0.5875, 

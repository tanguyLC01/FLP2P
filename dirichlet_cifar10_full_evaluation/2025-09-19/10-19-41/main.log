[2025-09-19 10:19:46,801][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.263142627745645,  accuracy: 0.19871734414788267, gradient_norm : 0.3258692897290801
[2025-09-19 10:19:50,774][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.2554448091518875,  accuracy: 0.1669
[2025-09-19 10:19:53,674][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.204268927213685,  accuracy: 0.22006304616735167, gradient_norm : 0.32623600052956664
[2025-09-19 10:19:57,649][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.196433851661881,  accuracy: 0.2197
[2025-09-19 10:20:00,174][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 2.156865119547162,  accuracy: 0.23648936674087057, gradient_norm : 0.31386582666482205
[2025-09-19 10:20:04,105][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.1577060164262845,  accuracy: 0.2362
[2025-09-19 10:20:06,390][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 2.127161589896676,  accuracy: 0.2525534379277667, gradient_norm : 0.3289513772801517
[2025-09-19 10:20:10,297][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 2.1210567071129875,  accuracy: 0.2577
[2025-09-19 10:20:12,418][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 2.114106755854146,  accuracy: 0.25937805806241165, gradient_norm : 0.2780657112587466
[2025-09-19 10:20:16,331][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 2.0928072905989485,  accuracy: 0.265
[2025-09-19 10:20:18,703][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 2.0912740653777786,  accuracy: 0.26913122039361237, gradient_norm : 0.3025018189475712
[2025-09-19 10:20:22,622][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 2.0649157104082905,  accuracy: 0.273
[2025-09-19 10:20:24,824][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 2.021289209599125,  accuracy: 0.27892561983471076, gradient_norm : 0.312985896477949
[2025-09-19 10:20:28,753][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 2.0399259571077426,  accuracy: 0.2838
[2025-09-19 10:20:31,239][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 2.0459355110302337,  accuracy: 0.28125460891794896, gradient_norm : 0.24550369871996142
[2025-09-19 10:20:35,200][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 2.0212767620197933,  accuracy: 0.2908
[2025-09-19 10:20:37,517][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.9900998619385462,  accuracy: 0.30155612630306694, gradient_norm : 0.2805410185399103
[2025-09-19 10:20:41,431][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 2.006346670538585,  accuracy: 0.2906
[2025-09-19 10:20:43,944][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 1.972392118132176,  accuracy: 0.3000674612098044, gradient_norm : 0.24252344869690304
[2025-09-19 10:20:47,877][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.986258719943762,  accuracy: 0.296
[2025-09-19 10:20:50,387][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 1.9470025125093153,  accuracy: 0.30569482546589727, gradient_norm : 0.28559927500241816
[2025-09-19 10:20:54,320][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.9727508661176762,  accuracy: 0.2973
[2025-09-19 10:20:56,445][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 1.860399173562771,  accuracy: 0.34563551976737683, gradient_norm : 0.23403394567360097
[2025-09-19 10:21:00,385][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.9624632355086014,  accuracy: 0.3021
[2025-09-19 10:21:02,991][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 1.9202803111446651,  accuracy: 0.3199495937079042, gradient_norm : 0.26512522214706946
[2025-09-19 10:21:06,951][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.949744006038507,  accuracy: 0.3071
[2025-09-19 10:21:09,536][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 1.9063360480073466,  accuracy: 0.3236764574591554, gradient_norm : 0.24635902598707365
[2025-09-19 10:21:13,431][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.935861170501709,  accuracy: 0.3096
[2025-09-19 10:21:15,593][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 1.8275079885731436,  accuracy: 0.35845753991407203, gradient_norm : 0.25756644519529076
[2025-09-19 10:21:19,499][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.9209824320924282,  accuracy: 0.3136
[2025-09-19 10:21:21,846][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 1.8838680603728246,  accuracy: 0.32738125347766706, gradient_norm : 0.2362028674100169
[2025-09-19 10:21:25,775][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.9069416537400088,  accuracy: 0.3154
[2025-09-19 10:21:28,202][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 1.876629082838151,  accuracy: 0.32462152966122587, gradient_norm : 0.2878022394216819
[2025-09-19 10:21:32,134][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.8955923987662795,  accuracy: 0.319
[2025-09-19 10:21:34,055][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 1.8617410065026145,  accuracy: 0.34159462055715656, gradient_norm : 0.2721533787759537
[2025-09-19 10:21:38,037][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.886733696651558,  accuracy: 0.3203
[2025-09-19 10:21:40,330][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 1.8024183127756084,  accuracy: 0.3643246517262265, gradient_norm : 0.3026016551304928
[2025-09-19 10:21:44,423][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.8780453017486136,  accuracy: 0.3237
[2025-09-19 10:21:46,467][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 1.7454876954931746,  accuracy: 0.37874612469858765, gradient_norm : 0.3053515070048847
[2025-09-19 10:21:50,509][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.8660065672808888,  accuracy: 0.3294
[2025-09-19 10:21:52,927][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 1.7451497875647277,  accuracy: 0.3836442166215767, gradient_norm : 0.27407071821439416
[2025-09-19 10:21:56,888][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.8466097183205683,  accuracy: 0.3384
[2025-09-19 10:21:59,298][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 1.7797298799268657,  accuracy: 0.370104031832782, gradient_norm : 0.2723226070274773
[2025-09-19 10:22:03,415][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.8368669026301305,  accuracy: 0.3421
[2025-09-19 10:22:06,226][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 1.7742741547175975,  accuracy: 0.362420188507145, gradient_norm : 0.29306377289309204
[2025-09-19 10:22:10,283][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.8214050522704914,  accuracy: 0.3483
[2025-09-19 10:22:12,426][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 1.6731341785469178,  accuracy: 0.4125227066303361, gradient_norm : 0.27475661825178976
[2025-09-19 10:22:16,496][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.8097543853802978,  accuracy: 0.3535
[2025-09-19 10:22:19,069][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 1.756666846496436,  accuracy: 0.37085546803443853, gradient_norm : 0.2922836689701504
[2025-09-19 10:22:23,152][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.7979308563482264,  accuracy: 0.3594
[2025-09-19 10:22:25,679][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 1.6568098204393131,  accuracy: 0.4146966941763417, gradient_norm : 0.34206659953000484
[2025-09-19 10:22:29,734][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.7880103934979437,  accuracy: 0.3633
[2025-09-19 10:22:32,163][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 1.685337219243351,  accuracy: 0.4028854647168515, gradient_norm : 0.3137904172735297
[2025-09-19 10:22:36,257][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.7746566678573688,  accuracy: 0.3692
[2025-09-19 10:22:38,603][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 1.6522211754825438,  accuracy: 0.4148027452723053, gradient_norm : 0.322810303291377
[2025-09-19 10:22:42,718][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.7675848665212595,  accuracy: 0.3717
[2025-09-19 10:22:45,081][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 1.6160887820201415,  accuracy: 0.43712144543681347, gradient_norm : 0.3297328909685294
[2025-09-19 10:22:49,185][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.753285494106511,  accuracy: 0.3789
[2025-09-19 10:22:51,767][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 1.598343463255059,  accuracy: 0.44224708837634163, gradient_norm : 0.28600075521877
[2025-09-19 10:22:55,816][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.7359167369726303,  accuracy: 0.3837
[2025-09-19 10:22:58,592][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 1.6396074362450332,  accuracy: 0.42262396245274, gradient_norm : 0.31251894139181713
[2025-09-19 10:23:02,625][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.7261322940496107,  accuracy: 0.3878
[2025-09-19 10:23:04,453][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 1.7061008831639757,  accuracy: 0.39344262295081966, gradient_norm : 0.27840805796299756
[2025-09-19 10:23:08,528][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.7189506937562924,  accuracy: 0.3895
[2025-09-19 10:23:10,257][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 1.688284618282431,  accuracy: 0.40611868779948396, gradient_norm : 0.3469610985951452
[2025-09-19 10:23:14,336][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.714553114548773,  accuracy: 0.3933
[2025-09-19 10:23:16,335][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 1.5746304804523101,  accuracy: 0.44755369928400957, gradient_norm : 0.2849832430163836
[2025-09-19 10:23:20,377][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.7071499446435765,  accuracy: 0.397
[2025-09-19 10:23:22,599][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 1.5757296872228357,  accuracy: 0.4431883302943475, gradient_norm : 0.36980256167867104
[2025-09-19 10:23:26,701][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.7044265897224344,  accuracy: 0.4005
[2025-09-19 10:23:28,906][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 1.5788002168827553,  accuracy: 0.4464660988828669, gradient_norm : 0.3215985662250026
[2025-09-19 10:23:32,946][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.695545252936582,  accuracy: 0.4036
[2025-09-19 10:23:35,428][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 1.6048145460244907,  accuracy: 0.43491110598014315, gradient_norm : 0.28800535153668194
[2025-09-19 10:23:39,510][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.6892624482216436,  accuracy: 0.406
[2025-09-19 10:23:41,837][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 1.6327305900922757,  accuracy: 0.4200337588353202, gradient_norm : 0.31623396655393204
[2025-09-19 10:23:45,919][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.6769761715563138,  accuracy: 0.4107
[2025-09-19 10:23:48,147][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 1.536347907378782,  accuracy: 0.45315171549071015, gradient_norm : 0.35492967633281336
[2025-09-19 10:23:52,198][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.672951369034449,  accuracy: 0.4083
[2025-09-19 10:23:54,612][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 1.46220654462187,  accuracy: 0.4855706482331899, gradient_norm : 0.3524731144144862
[2025-09-19 10:23:58,628][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.671585094595154,  accuracy: 0.408
[2025-09-19 10:24:01,282][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 1.4875035434544341,  accuracy: 0.4742687245857199, gradient_norm : 0.31216398655611594
[2025-09-19 10:24:05,351][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.6560272830721734,  accuracy: 0.4141
[2025-09-19 10:24:07,719][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 1.559229205397345,  accuracy: 0.4532240606154322, gradient_norm : 0.3301587602280857
[2025-09-19 10:24:11,786][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.6525258306635415,  accuracy: 0.4142
[2025-09-19 10:24:14,052][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 1.4719827453438312,  accuracy: 0.483804415102125, gradient_norm : 0.3110579328631126
[2025-09-19 10:24:18,103][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.651693763712545,  accuracy: 0.417
[2025-09-19 10:24:20,601][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 1.43273161105178,  accuracy: 0.4919720438231961, gradient_norm : 0.39711515921097285
[2025-09-19 10:24:24,648][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.6585215152538815,  accuracy: 0.4175
[2025-09-19 10:24:27,198][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 1.454226751102872,  accuracy: 0.4897703362134575, gradient_norm : 0.3197979556515965
[2025-09-19 10:24:31,231][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.6355403647676108,  accuracy: 0.4205
[2025-09-19 10:24:33,933][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 1.4534682525127132,  accuracy: 0.4820233740744045, gradient_norm : 0.3712869166744647
[2025-09-19 10:24:37,998][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.6383873535324136,  accuracy: 0.421
[2025-09-19 10:24:40,243][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 1.495287090652077,  accuracy: 0.47360161416881513, gradient_norm : 0.36613742950793576
[2025-09-19 10:24:44,335][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.6244877379408973,  accuracy: 0.4247
[2025-09-19 10:24:46,607][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 1.4984059492104655,  accuracy: 0.4653982968632101, gradient_norm : 0.3199318892576251
[2025-09-19 10:24:50,684][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.6169351770395042,  accuracy: 0.4311
[2025-09-19 10:24:52,851][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 1.4190100751071284,  accuracy: 0.5056198718669215, gradient_norm : 0.4067870102412057
[2025-09-19 10:24:56,906][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.6176603261832396,  accuracy: 0.4359
[2025-09-19 10:24:59,098][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 1.4291085161598984,  accuracy: 0.49567193248214675, gradient_norm : 0.3292648791126974
[2025-09-19 10:25:03,172][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.6234332288875182,  accuracy: 0.432
[2025-09-19 10:25:05,490][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 1.312238642626457,  accuracy: 0.5366683857658587, gradient_norm : 0.3823452802060872
[2025-09-19 10:25:09,536][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.633405881300966,  accuracy: 0.4296
[2025-09-19 10:25:12,137][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 1.3364586453266145,  accuracy: 0.5315721361952787, gradient_norm : 0.36742862526854003
[2025-09-19 10:25:16,223][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.6059471476775407,  accuracy: 0.4392
[2025-09-19 10:25:18,666][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 1.4102827628567254,  accuracy: 0.5031827515400411, gradient_norm : 0.38808281923771226
[2025-09-19 10:25:22,741][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.6123834399787584,  accuracy: 0.4422
[2025-09-19 10:25:24,559][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 1.2557609757573402,  accuracy: 0.5582232148396302, gradient_norm : 0.3767138155777789
[2025-09-19 10:25:28,608][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.5998503198937575,  accuracy: 0.4428
[2025-09-19 10:25:31,249][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 1.34196097065511,  accuracy: 0.5260174688719569, gradient_norm : 0.4134971140548847
[2025-09-19 10:25:35,289][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.6102215406155587,  accuracy: 0.4424
[2025-09-19 10:25:37,580][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 1.2698865675208415,  accuracy: 0.5557391907021378, gradient_norm : 0.37669492094182244
[2025-09-19 10:25:41,661][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.6052565383410453,  accuracy: 0.446
[2025-09-19 10:25:43,895][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 1.3458311676263741,  accuracy: 0.5267658818302976, gradient_norm : 0.44584237174861024
[2025-09-19 10:25:47,987][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.5982538081468145,  accuracy: 0.4465
[2025-09-19 10:25:50,055][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 1.2157579605918492,  accuracy: 0.5736111891254283, gradient_norm : 0.46163687749345667
[2025-09-19 10:25:54,108][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.5917315319455665,  accuracy: 0.4463
[2025-09-19 10:25:56,662][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 1.3377562242445982,  accuracy: 0.5237034680241808, gradient_norm : 0.37466896591815996
[2025-09-19 10:26:00,701][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.5925491565806666,  accuracy: 0.4491
[2025-09-19 10:26:03,090][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 1.2511230436661436,  accuracy: 0.557315383092457, gradient_norm : 0.3370531380580401
[2025-09-19 10:26:07,181][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.5998662727559603,  accuracy: 0.4507
[2025-09-19 10:26:09,781][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 1.1628662834582344,  accuracy: 0.5920456075773219, gradient_norm : 0.3744368693585328
[2025-09-19 10:26:13,877][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.6096651725857456,  accuracy: 0.4488
[2025-09-19 10:26:16,145][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 1.2603455401242036,  accuracy: 0.5605025806787968, gradient_norm : 0.3651072815138424
[2025-09-19 10:26:20,208][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.595982413694213,  accuracy: 0.4536
[2025-09-19 10:26:22,306][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 1.213286375512764,  accuracy: 0.5746713047579741, gradient_norm : 0.42184922761925386
[2025-09-19 10:26:26,339][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.6036936150709293,  accuracy: 0.4565
[2025-09-19 10:26:28,531][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 1.1931248148675109,  accuracy: 0.5799231052825617, gradient_norm : 0.40176452306550114
[2025-09-19 10:26:32,591][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.6071755651229622,  accuracy: 0.4507
[2025-09-19 10:26:34,661][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 1.1071562253506013,  accuracy: 0.6130308318789994, gradient_norm : 0.3671890371435701
[2025-09-19 10:26:38,727][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.6151667562430105,  accuracy: 0.4566
[2025-09-19 10:26:41,067][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 1.1537815990962823,  accuracy: 0.5950832672482157, gradient_norm : 0.4463386112995483
[2025-09-19 10:26:45,161][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.630196465890507,  accuracy: 0.4555
[2025-09-19 10:26:47,756][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 1.3547464490031538,  accuracy: 0.5219351240821638, gradient_norm : 0.37287468618257724
[2025-09-19 10:26:51,812][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.630473391623,  accuracy: 0.4531
[2025-09-19 10:26:54,166][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 1.1873885773476607,  accuracy: 0.5853327979118562, gradient_norm : 0.37870066723328527
[2025-09-19 10:26:58,223][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.6058893489775061,  accuracy: 0.4584
[2025-09-19 10:27:00,774][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 1.1482699658399693,  accuracy: 0.5924136044497128, gradient_norm : 0.43060610892861134
[2025-09-19 10:27:04,842][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.5915490248865884,  accuracy: 0.4658
[2025-09-19 10:27:07,102][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 1.1521519745975066,  accuracy: 0.5938802426800317, gradient_norm : 0.4237615697635373
[2025-09-19 10:27:11,151][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.603893727158606,  accuracy: 0.4638
[2025-09-19 10:27:13,573][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 1.2244835448212086,  accuracy: 0.5704745883672325, gradient_norm : 0.4405760143143024
[2025-09-19 10:27:17,620][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.591364113700986,  accuracy: 0.4676
[2025-09-19 10:27:20,153][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 1.1851437412697567,  accuracy: 0.5822279275424334, gradient_norm : 0.3949796365706092
[2025-09-19 10:27:24,231][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.5922482094498476,  accuracy: 0.4657
[2025-09-19 10:27:26,415][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 1.0666509835854938,  accuracy: 0.625533544927219, gradient_norm : 0.3951977732534098
[2025-09-19 10:27:30,495][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.5916726448863745,  accuracy: 0.4703
[2025-09-19 10:27:32,850][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 1.231481421945133,  accuracy: 0.5702083333333333, gradient_norm : 0.4122690812147199
[2025-09-19 10:27:36,926][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.5887761578547954,  accuracy: 0.4743
[2025-09-19 10:27:39,310][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.9355327891397983,  accuracy: 0.6744689869542693, gradient_norm : 0.42224734035945244
[2025-09-19 10:27:43,416][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.6022169117661318,  accuracy: 0.4707
[2025-09-19 10:27:45,855][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 1.0475748301262746,  accuracy: 0.6326369177795356, gradient_norm : 0.40124178217140205
[2025-09-19 10:27:49,911][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.5928504427969457,  accuracy: 0.4746
[2025-09-19 10:27:52,067][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 1.2373077481289545,  accuracy: 0.5644141419695387, gradient_norm : 0.536166958720345
[2025-09-19 10:27:56,061][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.602650924067497,  accuracy: 0.471
[2025-09-19 10:27:58,243][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.9360004012357043,  accuracy: 0.6683932173818221, gradient_norm : 0.437171322727238
[2025-09-19 10:28:02,338][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.5976126330679656,  accuracy: 0.4744
[2025-09-19 10:28:04,599][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.968675110688192,  accuracy: 0.6611128412747846, gradient_norm : 0.4436565961797877
[2025-09-19 10:28:08,667][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.6302122623936832,  accuracy: 0.4721
[2025-09-19 10:28:11,169][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 1.0633738185200805,  accuracy: 0.625048076923077, gradient_norm : 0.4474377215351521
[2025-09-19 10:28:15,216][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.6337285462801159,  accuracy: 0.473
[2025-09-19 10:28:17,580][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.9385287380943367,  accuracy: 0.6671849865951742, gradient_norm : 0.45106408273365994
[2025-09-19 10:28:21,619][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.6500904668924217,  accuracy: 0.4694
[2025-09-19 10:28:24,050][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.955041202920923,  accuracy: 0.6650078833267639, gradient_norm : 0.48463872601173213
[2025-09-19 10:28:28,122][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.6426005629480878,  accuracy: 0.4741
[2025-09-19 10:28:30,408][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 1.0239680437950065,  accuracy: 0.6420082718182294, gradient_norm : 0.4389188301776763
[2025-09-19 10:28:34,423][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.650315533022384,  accuracy: 0.4717
[2025-09-19 10:28:36,403][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.9648852262166383,  accuracy: 0.6647333249274997, gradient_norm : 0.43422832390392085
[2025-09-19 10:28:40,473][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.6446696921162807,  accuracy: 0.4766
[2025-09-19 10:28:42,815][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 1.0439914703140007,  accuracy: 0.6322276323797931, gradient_norm : 0.45464034603624565
[2025-09-19 10:28:46,889][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.6697549053383876,  accuracy: 0.4764
[2025-09-19 10:28:49,407][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.9647755320056558,  accuracy: 0.66026643910302, gradient_norm : 0.4392238548467181
[2025-09-19 10:28:53,448][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.6639773623755574,  accuracy: 0.4818
[2025-09-19 10:28:55,630][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.7685856857209388,  accuracy: 0.7344823764132121, gradient_norm : 0.43793594834461885
[2025-09-19 10:28:59,670][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.6693986198237536,  accuracy: 0.4797
[2025-09-19 10:29:02,084][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.8505703476365718,  accuracy: 0.7052163164400495, gradient_norm : 0.4387842701098597
[2025-09-19 10:29:06,142][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.6763026120689513,  accuracy: 0.4812
[2025-09-19 10:29:08,447][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.8639765461958847,  accuracy: 0.6963609172482552, gradient_norm : 0.45166249929876956
[2025-09-19 10:29:12,534][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.6674854286913077,  accuracy: 0.4838
[2025-09-19 10:29:14,863][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.9502269859263395,  accuracy: 0.6665278500780843, gradient_norm : 0.39632983461957544
[2025-09-19 10:29:18,924][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.701925224703153,  accuracy: 0.4829
[2025-09-19 10:29:21,344][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.9074378090490859,  accuracy: 0.6826623087208439, gradient_norm : 0.40873617618668623
[2025-09-19 10:29:25,361][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.697977203484376,  accuracy: 0.4833
[2025-09-19 10:29:28,029][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.7224608093124264,  accuracy: 0.7541119860017498, gradient_norm : 0.5693827270920798
[2025-09-19 10:29:32,089][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.7204119262792665,  accuracy: 0.4852
[2025-09-19 10:29:34,166][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.7135799533500036,  accuracy: 0.7516221858601817, gradient_norm : 0.4640566220454765
[2025-09-19 10:29:38,235][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.7306821419656278,  accuracy: 0.4837
[2025-09-19 10:29:40,596][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.8270095219289093,  accuracy: 0.718523095936969, gradient_norm : 0.5762273845777826
[2025-09-19 10:29:44,621][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.7353942067543664,  accuracy: 0.4844
[2025-09-19 10:29:47,095][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.7193543117738219,  accuracy: 0.7489968174899682, gradient_norm : 0.45856143105744807
[2025-09-19 10:29:51,175][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.7480806804734468,  accuracy: 0.4825
[2025-09-19 10:29:53,377][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.6595430451117628,  accuracy: 0.7697849520611018, gradient_norm : 0.5445430759034161
[2025-09-19 10:29:57,420][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.7497655068508786,  accuracy: 0.4841
[2025-09-19 10:29:59,589][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.7753407257467602,  accuracy: 0.7293588176464052, gradient_norm : 0.47062503328538363
[2025-09-19 10:30:03,642][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.7503254816290736,  accuracy: 0.4859
[2025-09-19 10:30:06,206][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.6759996374520809,  accuracy: 0.769074442235476, gradient_norm : 0.4951205719337832
[2025-09-19 10:30:10,239][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.7886566491441924,  accuracy: 0.4837
[2025-09-19 10:30:12,426][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.7154527072924572,  accuracy: 0.748659410671622, gradient_norm : 0.4651840433639813
[2025-09-19 10:30:16,502][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.8169837912757196,  accuracy: 0.4838
[2025-09-19 10:30:18,519][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.7631835786145081,  accuracy: 0.7300531914893617, gradient_norm : 0.3890820856839988
[2025-09-19 10:30:22,547][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.818775283414821,  accuracy: 0.4857
[2025-09-19 10:30:25,009][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.7763755127622272,  accuracy: 0.734403276502524, gradient_norm : 0.5568942282085336
[2025-09-19 10:30:29,059][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.8369723482503497,  accuracy: 0.4853
[2025-09-19 10:30:31,761][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.6202472819050895,  accuracy: 0.7878004191376465, gradient_norm : 0.514507318599433
[2025-09-19 10:30:35,779][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.8644491502816232,  accuracy: 0.4822
[2025-09-19 10:30:38,517][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.6792767107220464,  accuracy: 0.767112810707457, gradient_norm : 0.4828588103283319
[2025-09-19 10:30:42,555][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.897331311370333,  accuracy: 0.4867
[2025-09-19 10:30:44,961][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.5910099616093698,  accuracy: 0.8014348307573788, gradient_norm : 0.4869606876814446
[2025-09-19 10:30:49,044][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.8858920118382823,  accuracy: 0.4844
[2025-09-19 10:30:51,471][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.680127990489206,  accuracy: 0.7661931956850686, gradient_norm : 0.3918198215348398
[2025-09-19 10:30:55,540][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.869559036820258,  accuracy: 0.4868
[2025-09-19 10:30:57,944][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.5510101538761534,  accuracy: 0.8104247288710525, gradient_norm : 0.40755435217963737
[2025-09-19 10:31:01,992][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.8823191501598802,  accuracy: 0.4899
[2025-09-19 10:31:04,392][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.6341137743824944,  accuracy: 0.7832244551937366, gradient_norm : 0.4311164308685921
[2025-09-19 10:31:08,416][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.904700406790202,  accuracy: 0.4864
[2025-09-19 10:31:10,621][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.8229322679585725,  accuracy: 0.7191914415745612, gradient_norm : 0.5514033664232437
[2025-09-19 10:31:14,674][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.9158457763844978,  accuracy: 0.4895
[2025-09-19 10:31:17,080][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.51612352859585,  accuracy: 0.8269129287598944, gradient_norm : 0.3818662541781689
[2025-09-19 10:31:21,133][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.9376945534970365,  accuracy: 0.4898
[2025-09-19 10:31:23,648][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.6485709570423257,  accuracy: 0.7744676877101233, gradient_norm : 0.43684487657728654
[2025-09-19 10:31:27,730][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.9619845481228828,  accuracy: 0.4906
[2025-09-19 10:31:29,558][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.6254733870982446,  accuracy: 0.7892940782870526, gradient_norm : 0.5126609843761403
[2025-09-19 10:31:33,586][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.97090358394146,  accuracy: 0.489
[2025-09-19 10:31:35,937][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.38750485231222687,  accuracy: 0.8704910908300739, gradient_norm : 0.36161661563683545
[2025-09-19 10:31:39,980][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.9927631044981375,  accuracy: 0.4904
[2025-09-19 10:31:42,313][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.5758230154656897,  accuracy: 0.7993539910215701, gradient_norm : 0.4547528552208395
[2025-09-19 10:31:46,377][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.9913168558853365,  accuracy: 0.4951
[2025-09-19 10:31:48,656][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.5457494311628123,  accuracy: 0.8111572392319668, gradient_norm : 0.4078849195731817
[2025-09-19 10:31:52,781][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 2.00210574207147,  accuracy: 0.4905
[2025-09-19 10:31:55,429][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.7051666458175199,  accuracy: 0.7542255472430036, gradient_norm : 0.4471688810993213
[2025-09-19 10:31:59,515][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 2.0190722837824624,  accuracy: 0.49
[2025-09-19 10:32:01,891][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.6367757198334408,  accuracy: 0.7837166270155961, gradient_norm : 0.5192096553431865
[2025-09-19 10:32:06,000][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 2.036731227103273,  accuracy: 0.4884
[2025-09-19 10:32:08,680][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.5011645219641638,  accuracy: 0.8319531758075005, gradient_norm : 0.47298625859735294
[2025-09-19 10:32:12,738][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 2.0316377866632243,  accuracy: 0.4883
[2025-09-19 10:32:15,127][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.5152299686310893,  accuracy: 0.8281662939621874, gradient_norm : 0.5307592319892536
[2025-09-19 10:32:19,185][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 2.0558829922878745,  accuracy: 0.4921
[2025-09-19 10:32:21,874][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.5400024153637364,  accuracy: 0.8128899943273552, gradient_norm : 0.36067633730282833
[2025-09-19 10:32:25,951][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 2.0741856694561496,  accuracy: 0.4884
[2025-09-19 10:32:28,273][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.6859647225447117,  accuracy: 0.7655402138290442, gradient_norm : 0.5378843140845933
[2025-09-19 10:32:32,332][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 2.066918979137962,  accuracy: 0.4914
[2025-09-19 10:32:34,770][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.39688577719154944,  accuracy: 0.8702001081665766, gradient_norm : 0.5720241327258412
[2025-09-19 10:32:38,919][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 2.1057456390745193,  accuracy: 0.4892
[2025-09-19 10:32:41,340][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.4837179139992477,  accuracy: 0.8383207224798633, gradient_norm : 0.5381704294850644
[2025-09-19 10:32:45,381][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 2.108569854378974,  accuracy: 0.4878
[2025-09-19 10:32:47,747][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.5875093346724343,  accuracy: 0.7990793666852142, gradient_norm : 0.478064517118644
[2025-09-19 10:32:51,784][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 2.1309691770544408,  accuracy: 0.4899
[2025-09-19 10:32:54,241][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.40787408522132185,  accuracy: 0.8635076095827933, gradient_norm : 0.3954180288499007
[2025-09-19 10:32:58,308][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 2.1369244364430755,  accuracy: 0.4898
[2025-09-19 10:33:00,662][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.4304412626482824,  accuracy: 0.8533767053454386, gradient_norm : 0.3294789544410763
[2025-09-19 10:33:04,724][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 2.1424806994855654,  accuracy: 0.4914
[2025-09-19 10:33:07,128][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.47224799379137533,  accuracy: 0.8398121075588362, gradient_norm : 0.38522916833889925
[2025-09-19 10:33:11,141][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 2.1636037528144825,  accuracy: 0.4914
[2025-09-19 10:33:13,482][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.41106921937419566,  accuracy: 0.8647186147186147, gradient_norm : 0.4888486963186701
[2025-09-19 10:33:17,524][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 2.190630149979021,  accuracy: 0.495
[2025-09-19 10:33:20,057][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.40382876090359104,  accuracy: 0.8675215667987876, gradient_norm : 0.42514294161852256
[2025-09-19 10:33:24,080][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 2.2342422669165583,  accuracy: 0.4907
[2025-09-19 10:33:26,622][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.4262990693183627,  accuracy: 0.8551717620375183, gradient_norm : 0.42909632639814044
[2025-09-19 10:33:30,742][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 2.217912787667737,  accuracy: 0.4938
[2025-09-19 10:33:33,289][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.3446194705964544,  accuracy: 0.8818233510235026, gradient_norm : 0.39706118468240004
[2025-09-19 10:33:37,354][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 2.2200247862866025,  accuracy: 0.4931
[2025-09-19 10:33:39,479][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.38114886673976367,  accuracy: 0.8707189316755886, gradient_norm : 0.5193428398260684
[2025-09-19 10:33:43,491][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 2.2160892335417373,  accuracy: 0.4937
[2025-09-19 10:33:46,005][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.4735695392406373,  accuracy: 0.840280109357763, gradient_norm : 0.3916611251889906
[2025-09-19 10:33:50,101][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 2.230096452614516,  accuracy: 0.4979
[2025-09-19 10:33:52,447][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.5750333393018777,  accuracy: 0.8052037884431201, gradient_norm : 0.48397613395189054
[2025-09-19 10:33:56,512][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 2.2257625493485236,  accuracy: 0.4975
[2025-09-19 10:33:59,009][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.4654845988720388,  accuracy: 0.8394283121597096, gradient_norm : 0.416117714594193
[2025-09-19 10:34:03,056][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 2.243306942683831,  accuracy: 0.5007
[2025-09-19 10:34:05,549][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.2992450388504267,  accuracy: 0.9008464927478838, gradient_norm : 0.387624202969193
[2025-09-19 10:34:09,622][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 2.267909895342265,  accuracy: 0.5015
[2025-09-19 10:34:12,477][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.4156291855590505,  accuracy: 0.8609309508052063, gradient_norm : 0.5099013615963933
[2025-09-19 10:34:16,597][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 2.2819798012909045,  accuracy: 0.5057
[2025-09-19 10:34:18,851][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.37768848716440395,  accuracy: 0.8709790384711591, gradient_norm : 0.347294917210025
[2025-09-19 10:34:22,925][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 2.298051700784638,  accuracy: 0.5027
[2025-09-19 10:34:25,285][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.3965978183195445,  accuracy: 0.8658808868580923, gradient_norm : 0.3875833210885079
[2025-09-19 10:34:29,313][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 2.3150573446445413,  accuracy: 0.5035
[2025-09-19 10:34:31,823][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.31973152098899205,  accuracy: 0.8927325720292417, gradient_norm : 0.30509558754993965
[2025-09-19 10:34:35,932][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 2.310570767721807,  accuracy: 0.501
[2025-09-19 10:34:38,073][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.3787562126776094,  accuracy: 0.8725479330599579, gradient_norm : 0.40522610252352526
[2025-09-19 10:34:42,145][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 2.316559590099131,  accuracy: 0.5011
[2025-09-19 10:34:44,429][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.4610672491783588,  accuracy: 0.8445736434108527, gradient_norm : 0.626345525855014
[2025-09-19 10:34:48,504][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 2.350629664595797,  accuracy: 0.4994
[2025-09-19 10:34:51,104][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.480927617338304,  accuracy: 0.8386764637057145, gradient_norm : 0.46841320348352544
[2025-09-19 10:34:55,176][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 2.3800494606432068,  accuracy: 0.4968
[2025-09-19 10:34:57,553][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.22721928787343953,  accuracy: 0.927420998980632, gradient_norm : 0.4003187079533057
[2025-09-19 10:35:01,663][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 2.3912563381374623,  accuracy: 0.4985
[2025-09-19 10:35:04,024][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.4186392005764127,  accuracy: 0.8605134601392787, gradient_norm : 0.523586408032752
[2025-09-19 10:35:08,086][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 2.400854941115056,  accuracy: 0.501
[2025-09-19 10:35:10,583][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.3911668060120726,  accuracy: 0.871000680735194, gradient_norm : 0.376443368957263
[2025-09-19 10:35:14,663][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 2.4409847291035196,  accuracy: 0.499
[2025-09-19 10:35:17,466][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.3632685151579379,  accuracy: 0.8754934962390392, gradient_norm : 0.42234325009812074
[2025-09-19 10:35:21,545][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 2.433286000078618,  accuracy: 0.4948
[2025-09-19 10:35:23,717][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.23851435365718626,  accuracy: 0.9189970563498738, gradient_norm : 0.2849601884769353
[2025-09-19 10:35:27,747][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 2.433155592571522,  accuracy: 0.4963
[2025-09-19 10:35:30,110][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.4225819935022086,  accuracy: 0.8564397046759639, gradient_norm : 0.444709641033315
[2025-09-19 10:35:34,187][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 2.4387889621156704,  accuracy: 0.4978
[2025-09-19 10:35:36,594][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.3069770210309661,  accuracy: 0.8975903614457831, gradient_norm : 0.3630378799686657
[2025-09-19 10:35:40,664][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 2.450897212472285,  accuracy: 0.4948
[2025-09-19 10:35:42,655][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.2728935231881547,  accuracy: 0.9131241878596621, gradient_norm : 0.3723797923128729
[2025-09-19 10:35:46,654][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 2.473612757813533,  accuracy: 0.4962
[2025-09-19 10:35:48,886][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.3571043708722942,  accuracy: 0.8796520306789519, gradient_norm : 0.33290952432481963
[2025-09-19 10:35:52,970][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 2.496090635602076,  accuracy: 0.4945
[2025-09-19 10:35:55,462][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.19470317051035319,  accuracy: 0.9372996417122383, gradient_norm : 0.2569782026461862
[2025-09-19 10:35:59,505][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 2.4921153496515998,  accuracy: 0.4956
[2025-09-19 10:36:01,904][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.3256506054101161,  accuracy: 0.8917152624170521, gradient_norm : 0.32190435748024454
[2025-09-19 10:36:06,021][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 2.494921328095179,  accuracy: 0.5008
[2025-09-19 10:36:08,370][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.2956789035410643,  accuracy: 0.9030667057329818, gradient_norm : 0.4194691356791205
[2025-09-19 10:36:12,401][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 2.5151545227978445,  accuracy: 0.5002
[2025-09-19 10:36:14,626][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.2318767231965941,  accuracy: 0.9244548286604362, gradient_norm : 0.25537687548617855
[2025-09-19 10:36:18,721][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 2.537556286042283,  accuracy: 0.5006
[2025-09-19 10:36:21,309][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.2983312599226089,  accuracy: 0.899851798625769, gradient_norm : 0.371812772191082
[2025-09-19 10:36:25,328][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 2.5511845294201123,  accuracy: 0.498
[2025-09-19 10:36:27,328][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.3992097369169466,  accuracy: 0.8651085990092722, gradient_norm : 0.4335565961651805
[2025-09-19 10:36:31,448][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 2.5351966953321052,  accuracy: 0.5001
[2025-09-19 10:36:34,004][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.3470248040111702,  accuracy: 0.8846974758723088, gradient_norm : 0.3079861468308283
[2025-09-19 10:36:38,066][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 2.5496719555392118,  accuracy: 0.5022
[2025-09-19 10:36:40,157][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.2709201563399685,  accuracy: 0.9090959054685354, gradient_norm : 0.2558092450801899
[2025-09-19 10:36:44,207][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 2.5509542745081335,  accuracy: 0.5059
[2025-09-19 10:36:46,730][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.23727778365734964,  accuracy: 0.9211952679455154, gradient_norm : 0.3754978468889878
[2025-09-19 10:36:50,800][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 2.5768753711227825,  accuracy: 0.5017
[2025-09-19 10:36:53,120][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.15030541843643186,  accuracy: 0.9520313507614465, gradient_norm : 0.2350439345518256
[2025-09-19 10:36:57,169][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 2.5853333375813814,  accuracy: 0.5051
[2025-09-19 10:36:59,459][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.20671835183517812,  accuracy: 0.9328549461814454, gradient_norm : 0.3219499356753443
[2025-09-19 10:37:03,497][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 2.583790895590757,  accuracy: 0.5057
[2025-09-19 10:37:05,988][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.3339557802462123,  accuracy: 0.890631937250259, gradient_norm : 0.45100921541619515
[2025-09-19 10:37:10,110][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 2.6140843036949386,  accuracy: 0.4991
[2025-09-19 10:37:12,768][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.10525960782494624,  accuracy: 0.9672814328781699, gradient_norm : 0.2423640498783189
[2025-09-19 10:37:16,844][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 2.6239523943100367,  accuracy: 0.5004
[2025-09-19 10:37:19,539][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.16119644018450424,  accuracy: 0.9483885017421603, gradient_norm : 0.23664811852449127
[2025-09-19 10:37:23,621][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 2.6373082154128697,  accuracy: 0.5005
[2025-09-19 10:37:26,029][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.17727461460146784,  accuracy: 0.9452425464921775, gradient_norm : 0.28292125693149567
[2025-09-19 10:37:30,116][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 2.634475567556222,  accuracy: 0.5027
[2025-09-19 10:37:34,789][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.3467134906467605,  accuracy: 0.8815024518477327, gradient_norm : 0.280969028518543
[2025-09-19 10:37:38,920][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 2.63471129111439,  accuracy: 0.5041
[2025-09-19 10:37:41,290][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.17605596755863875,  accuracy: 0.9455287071458075, gradient_norm : 0.3085906196099248
[2025-09-19 10:37:45,414][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 2.6577444045362872,  accuracy: 0.5034
[2025-09-19 10:37:47,686][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.3125305671338503,  accuracy: 0.8958100558659218, gradient_norm : 0.30117969466453964
[2025-09-19 10:37:51,791][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 2.6536673672077056,  accuracy: 0.5041
[2025-09-19 10:37:54,705][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.21722910116352992,  accuracy: 0.9263188429820562, gradient_norm : 0.26148773826378197
[2025-09-19 10:37:58,790][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 2.6723320709158975,  accuracy: 0.504
[2025-09-19 10:38:01,288][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.17455782354569205,  accuracy: 0.9444232784074674, gradient_norm : 0.2579327615918995
[2025-09-19 10:38:05,466][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 2.6734596463922164,  accuracy: 0.5045
[2025-09-19 10:38:07,740][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.23229631730659717,  accuracy: 0.9241390513320338, gradient_norm : 0.24612024134419297
[2025-09-19 10:38:11,910][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 2.704543030537119,  accuracy: 0.5024
[2025-09-19 10:38:14,152][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.1728382771844502,  accuracy: 0.9452342755988272, gradient_norm : 0.3366031658279354
[2025-09-19 10:38:18,252][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 2.7324105243513483,  accuracy: 0.503
[2025-09-19 10:38:20,966][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.18365048516988514,  accuracy: 0.9390507249570315, gradient_norm : 0.2700161485164199
[2025-09-19 10:38:25,053][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 2.736819642612785,  accuracy: 0.5056
[2025-09-19 10:38:27,366][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.21852524907894608,  accuracy: 0.9311781537071432, gradient_norm : 0.2733359805906687
[2025-09-19 10:38:31,499][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 2.729336483359784,  accuracy: 0.5022
[2025-09-19 10:38:33,962][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.1833228706760145,  accuracy: 0.9398970213175497, gradient_norm : 0.2512351109517659
[2025-09-19 10:38:38,081][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 2.736344354405006,  accuracy: 0.5016
[2025-09-19 10:38:40,609][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.15366639156370135,  accuracy: 0.9480569265417605, gradient_norm : 0.2413508410379616
[2025-09-19 10:38:44,724][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 2.7489477087661127,  accuracy: 0.5011
[2025-09-19 10:38:46,856][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.13255205897066813,  accuracy: 0.956453941669073, gradient_norm : 0.17382616105772375
[2025-09-19 10:38:51,000][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 2.7535123350227377,  accuracy: 0.5042
[2025-09-19 10:38:53,309][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.09249553545459625,  accuracy: 0.9735632183908046, gradient_norm : 0.1742463025091948
[2025-09-19 10:38:57,467][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 2.758538646334087,  accuracy: 0.505
[2025-09-19 10:39:00,072][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.20030326309326277,  accuracy: 0.935530474040632, gradient_norm : 0.4274972513105467
[2025-09-19 10:39:04,221][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 2.780588797104657,  accuracy: 0.5022
[2025-09-19 10:39:06,565][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.16942651135422432,  accuracy: 0.942198374329278, gradient_norm : 0.20733081276993212
[2025-09-19 10:39:10,686][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 2.7805046877704815,  accuracy: 0.502
[2025-09-19 10:39:13,259][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.17127602669359127,  accuracy: 0.9445124246987951, gradient_norm : 0.2069104349037029
[2025-09-19 10:39:17,414][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 2.790545429521427,  accuracy: 0.503
[2025-09-19 10:39:19,756][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.07802444330024332,  accuracy: 0.9768304456074386, gradient_norm : 0.16726653204102485
[2025-09-19 10:39:23,897][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 2.79924085592789,  accuracy: 0.5033
[2025-09-19 10:39:26,215][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.19407659267320992,  accuracy: 0.9353992973624875, gradient_norm : 0.30889768471760737
[2025-09-19 10:39:30,326][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 2.7936970454736305,  accuracy: 0.5059
[2025-09-19 10:39:32,587][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.21958029028949627,  accuracy: 0.9271257318093113, gradient_norm : 0.24418381467588313
[2025-09-19 10:39:36,737][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 2.7932212192755443,  accuracy: 0.5062
[2025-09-19 10:39:39,275][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.13893981725182528,  accuracy: 0.95793946338203, gradient_norm : 0.2648526208527408
[2025-09-19 10:39:43,413][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 2.8132996761649354,  accuracy: 0.5081
[2025-09-19 10:39:45,908][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.19362523676991514,  accuracy: 0.9383303589133453, gradient_norm : 0.33153964838302313
[2025-09-19 10:39:50,031][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 2.817392435360278,  accuracy: 0.5057
[2025-09-19 10:39:52,325][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.25332836604137077,  accuracy: 0.9147712139775209, gradient_norm : 0.36231530843382626
[2025-09-19 10:39:56,422][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 2.829460527458563,  accuracy: 0.5074
[2025-09-19 10:39:58,794][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.19954120715521761,  accuracy: 0.9333847736625515, gradient_norm : 0.2925184196906458
[2025-09-19 10:40:02,876][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 2.833999705615217,  accuracy: 0.5048
[2025-09-19 10:40:05,708][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.15657162545374445,  accuracy: 0.9501922112652516, gradient_norm : 0.2118406036519077
[2025-09-19 10:40:09,764][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 2.8481445683081694,  accuracy: 0.506
[2025-09-19 10:40:12,112][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.16358544832814076,  accuracy: 0.9464248488638732, gradient_norm : 0.22512445547295967
[2025-09-19 10:40:16,158][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 2.856606271160369,  accuracy: 0.5031
[2025-09-19 10:40:18,102][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.1683523410026928,  accuracy: 0.9439281876224793, gradient_norm : 0.3045005776169481
[2025-09-19 10:40:22,207][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 2.8688951917977383,  accuracy: 0.5021
[2025-09-19 10:40:24,371][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.13063966298498464,  accuracy: 0.9594381956990501, gradient_norm : 0.25814396387835875
[2025-09-19 10:40:28,543][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 2.8746798536109424,  accuracy: 0.5054
[2025-09-19 10:40:30,717][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.14094697694012728,  accuracy: 0.9536025885479864, gradient_norm : 0.25376990584630715
[2025-09-19 10:40:34,851][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 2.8689368875822425,  accuracy: 0.5038
[2025-09-19 10:40:37,639][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.16797448306905338,  accuracy: 0.9451979549583809, gradient_norm : 0.20452811526667047
[2025-09-19 10:40:41,735][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 2.9089990596505255,  accuracy: 0.4968
[2025-09-19 10:40:43,950][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.2459563150528922,  accuracy: 0.9177211810561162, gradient_norm : 0.2581299667190595
[2025-09-19 10:40:48,073][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 2.9043102703327435,  accuracy: 0.5014
[2025-09-19 10:40:50,318][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.13290165745131738,  accuracy: 0.9540749618653301, gradient_norm : 0.20972510902631936
[2025-09-19 10:40:54,391][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 2.907182708399892,  accuracy: 0.5026
[2025-09-19 10:40:56,700][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.16975527452300598,  accuracy: 0.9432960751288726, gradient_norm : 0.257696554308956
[2025-09-19 10:41:00,815][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 2.90494752033117,  accuracy: 0.505
[2025-09-19 10:41:03,039][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.12028717074176304,  accuracy: 0.9630364533136799, gradient_norm : 0.4200564509529118
[2025-09-19 10:41:07,132][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 2.9362428460321084,  accuracy: 0.5054
[2025-09-19 10:41:09,460][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.07819897916507215,  accuracy: 0.9787622281920016, gradient_norm : 0.2587393174772876
[2025-09-19 10:41:13,549][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 2.912172294240545,  accuracy: 0.5051
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 001: loss=2.2631, accuracy=0.1987, gradient_norm=0.3259, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 002: loss=2.2043, accuracy=0.2201, gradient_norm=0.3262, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 003: loss=2.1569, accuracy=0.2365, gradient_norm=0.3139, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 004: loss=2.1272, accuracy=0.2526, gradient_norm=0.3290, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 005: loss=2.1141, accuracy=0.2594, gradient_norm=0.2781, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 006: loss=2.0913, accuracy=0.2691, gradient_norm=0.3025, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 007: loss=2.0213, accuracy=0.2789, gradient_norm=0.3130, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 008: loss=2.0459, accuracy=0.2813, gradient_norm=0.2455, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 009: loss=1.9901, accuracy=0.3016, gradient_norm=0.2805, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 010: loss=1.9724, accuracy=0.3001, gradient_norm=0.2425, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 011: loss=1.9470, accuracy=0.3057, gradient_norm=0.2856, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 012: loss=1.8604, accuracy=0.3456, gradient_norm=0.2340, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 013: loss=1.9203, accuracy=0.3199, gradient_norm=0.2651, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 014: loss=1.9063, accuracy=0.3237, gradient_norm=0.2464, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 015: loss=1.8275, accuracy=0.3585, gradient_norm=0.2576, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 016: loss=1.8839, accuracy=0.3274, gradient_norm=0.2362, 
[2025-09-19 10:41:13,550][__main__][INFO] - Train, Round 017: loss=1.8766, accuracy=0.3246, gradient_norm=0.2878, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 018: loss=1.8617, accuracy=0.3416, gradient_norm=0.2722, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 019: loss=1.8024, accuracy=0.3643, gradient_norm=0.3026, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 020: loss=1.7455, accuracy=0.3787, gradient_norm=0.3054, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 021: loss=1.7451, accuracy=0.3836, gradient_norm=0.2741, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 022: loss=1.7797, accuracy=0.3701, gradient_norm=0.2723, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 023: loss=1.7743, accuracy=0.3624, gradient_norm=0.2931, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 024: loss=1.6731, accuracy=0.4125, gradient_norm=0.2748, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 025: loss=1.7567, accuracy=0.3709, gradient_norm=0.2923, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 026: loss=1.6568, accuracy=0.4147, gradient_norm=0.3421, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 027: loss=1.6853, accuracy=0.4029, gradient_norm=0.3138, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 028: loss=1.6522, accuracy=0.4148, gradient_norm=0.3228, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 029: loss=1.6161, accuracy=0.4371, gradient_norm=0.3297, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 030: loss=1.5983, accuracy=0.4422, gradient_norm=0.2860, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 031: loss=1.6396, accuracy=0.4226, gradient_norm=0.3125, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 032: loss=1.7061, accuracy=0.3934, gradient_norm=0.2784, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 033: loss=1.6883, accuracy=0.4061, gradient_norm=0.3470, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 034: loss=1.5746, accuracy=0.4476, gradient_norm=0.2850, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 035: loss=1.5757, accuracy=0.4432, gradient_norm=0.3698, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 036: loss=1.5788, accuracy=0.4465, gradient_norm=0.3216, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 037: loss=1.6048, accuracy=0.4349, gradient_norm=0.2880, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 038: loss=1.6327, accuracy=0.4200, gradient_norm=0.3162, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 039: loss=1.5363, accuracy=0.4532, gradient_norm=0.3549, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 040: loss=1.4622, accuracy=0.4856, gradient_norm=0.3525, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 041: loss=1.4875, accuracy=0.4743, gradient_norm=0.3122, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 042: loss=1.5592, accuracy=0.4532, gradient_norm=0.3302, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 043: loss=1.4720, accuracy=0.4838, gradient_norm=0.3111, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 044: loss=1.4327, accuracy=0.4920, gradient_norm=0.3971, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 045: loss=1.4542, accuracy=0.4898, gradient_norm=0.3198, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 046: loss=1.4535, accuracy=0.4820, gradient_norm=0.3713, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 047: loss=1.4953, accuracy=0.4736, gradient_norm=0.3661, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 048: loss=1.4984, accuracy=0.4654, gradient_norm=0.3199, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 049: loss=1.4190, accuracy=0.5056, gradient_norm=0.4068, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 050: loss=1.4291, accuracy=0.4957, gradient_norm=0.3293, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 051: loss=1.3122, accuracy=0.5367, gradient_norm=0.3823, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 052: loss=1.3365, accuracy=0.5316, gradient_norm=0.3674, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 053: loss=1.4103, accuracy=0.5032, gradient_norm=0.3881, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 054: loss=1.2558, accuracy=0.5582, gradient_norm=0.3767, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 055: loss=1.3420, accuracy=0.5260, gradient_norm=0.4135, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 056: loss=1.2699, accuracy=0.5557, gradient_norm=0.3767, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 057: loss=1.3458, accuracy=0.5268, gradient_norm=0.4458, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 058: loss=1.2158, accuracy=0.5736, gradient_norm=0.4616, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 059: loss=1.3378, accuracy=0.5237, gradient_norm=0.3747, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 060: loss=1.2511, accuracy=0.5573, gradient_norm=0.3371, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 061: loss=1.1629, accuracy=0.5920, gradient_norm=0.3744, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 062: loss=1.2603, accuracy=0.5605, gradient_norm=0.3651, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 063: loss=1.2133, accuracy=0.5747, gradient_norm=0.4218, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 064: loss=1.1931, accuracy=0.5799, gradient_norm=0.4018, 
[2025-09-19 10:41:13,551][__main__][INFO] - Train, Round 065: loss=1.1072, accuracy=0.6130, gradient_norm=0.3672, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 066: loss=1.1538, accuracy=0.5951, gradient_norm=0.4463, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 067: loss=1.3547, accuracy=0.5219, gradient_norm=0.3729, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 068: loss=1.1874, accuracy=0.5853, gradient_norm=0.3787, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 069: loss=1.1483, accuracy=0.5924, gradient_norm=0.4306, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 070: loss=1.1522, accuracy=0.5939, gradient_norm=0.4238, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 071: loss=1.2245, accuracy=0.5705, gradient_norm=0.4406, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 072: loss=1.1851, accuracy=0.5822, gradient_norm=0.3950, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 073: loss=1.0667, accuracy=0.6255, gradient_norm=0.3952, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 074: loss=1.2315, accuracy=0.5702, gradient_norm=0.4123, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 075: loss=0.9355, accuracy=0.6745, gradient_norm=0.4222, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 076: loss=1.0476, accuracy=0.6326, gradient_norm=0.4012, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 077: loss=1.2373, accuracy=0.5644, gradient_norm=0.5362, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 078: loss=0.9360, accuracy=0.6684, gradient_norm=0.4372, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 079: loss=0.9687, accuracy=0.6611, gradient_norm=0.4437, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 080: loss=1.0634, accuracy=0.6250, gradient_norm=0.4474, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 081: loss=0.9385, accuracy=0.6672, gradient_norm=0.4511, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 082: loss=0.9550, accuracy=0.6650, gradient_norm=0.4846, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 083: loss=1.0240, accuracy=0.6420, gradient_norm=0.4389, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 084: loss=0.9649, accuracy=0.6647, gradient_norm=0.4342, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 085: loss=1.0440, accuracy=0.6322, gradient_norm=0.4546, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 086: loss=0.9648, accuracy=0.6603, gradient_norm=0.4392, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 087: loss=0.7686, accuracy=0.7345, gradient_norm=0.4379, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 088: loss=0.8506, accuracy=0.7052, gradient_norm=0.4388, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 089: loss=0.8640, accuracy=0.6964, gradient_norm=0.4517, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 090: loss=0.9502, accuracy=0.6665, gradient_norm=0.3963, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 091: loss=0.9074, accuracy=0.6827, gradient_norm=0.4087, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 092: loss=0.7225, accuracy=0.7541, gradient_norm=0.5694, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 093: loss=0.7136, accuracy=0.7516, gradient_norm=0.4641, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 094: loss=0.8270, accuracy=0.7185, gradient_norm=0.5762, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 095: loss=0.7194, accuracy=0.7490, gradient_norm=0.4586, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 096: loss=0.6595, accuracy=0.7698, gradient_norm=0.5445, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 097: loss=0.7753, accuracy=0.7294, gradient_norm=0.4706, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 098: loss=0.6760, accuracy=0.7691, gradient_norm=0.4951, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 099: loss=0.7155, accuracy=0.7487, gradient_norm=0.4652, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 100: loss=0.7632, accuracy=0.7301, gradient_norm=0.3891, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 101: loss=0.7764, accuracy=0.7344, gradient_norm=0.5569, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 102: loss=0.6202, accuracy=0.7878, gradient_norm=0.5145, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 103: loss=0.6793, accuracy=0.7671, gradient_norm=0.4829, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 104: loss=0.5910, accuracy=0.8014, gradient_norm=0.4870, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 105: loss=0.6801, accuracy=0.7662, gradient_norm=0.3918, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 106: loss=0.5510, accuracy=0.8104, gradient_norm=0.4076, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 107: loss=0.6341, accuracy=0.7832, gradient_norm=0.4311, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 108: loss=0.8229, accuracy=0.7192, gradient_norm=0.5514, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 109: loss=0.5161, accuracy=0.8269, gradient_norm=0.3819, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 110: loss=0.6486, accuracy=0.7745, gradient_norm=0.4368, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 111: loss=0.6255, accuracy=0.7893, gradient_norm=0.5127, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 112: loss=0.3875, accuracy=0.8705, gradient_norm=0.3616, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 113: loss=0.5758, accuracy=0.7994, gradient_norm=0.4548, 
[2025-09-19 10:41:13,552][__main__][INFO] - Train, Round 114: loss=0.5457, accuracy=0.8112, gradient_norm=0.4079, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 115: loss=0.7052, accuracy=0.7542, gradient_norm=0.4472, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 116: loss=0.6368, accuracy=0.7837, gradient_norm=0.5192, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 117: loss=0.5012, accuracy=0.8320, gradient_norm=0.4730, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 118: loss=0.5152, accuracy=0.8282, gradient_norm=0.5308, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 119: loss=0.5400, accuracy=0.8129, gradient_norm=0.3607, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 120: loss=0.6860, accuracy=0.7655, gradient_norm=0.5379, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 121: loss=0.3969, accuracy=0.8702, gradient_norm=0.5720, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 122: loss=0.4837, accuracy=0.8383, gradient_norm=0.5382, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 123: loss=0.5875, accuracy=0.7991, gradient_norm=0.4781, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 124: loss=0.4079, accuracy=0.8635, gradient_norm=0.3954, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 125: loss=0.4304, accuracy=0.8534, gradient_norm=0.3295, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 126: loss=0.4722, accuracy=0.8398, gradient_norm=0.3852, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 127: loss=0.4111, accuracy=0.8647, gradient_norm=0.4888, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 128: loss=0.4038, accuracy=0.8675, gradient_norm=0.4251, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 129: loss=0.4263, accuracy=0.8552, gradient_norm=0.4291, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 130: loss=0.3446, accuracy=0.8818, gradient_norm=0.3971, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 131: loss=0.3811, accuracy=0.8707, gradient_norm=0.5193, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 132: loss=0.4736, accuracy=0.8403, gradient_norm=0.3917, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 133: loss=0.5750, accuracy=0.8052, gradient_norm=0.4840, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 134: loss=0.4655, accuracy=0.8394, gradient_norm=0.4161, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 135: loss=0.2992, accuracy=0.9008, gradient_norm=0.3876, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 136: loss=0.4156, accuracy=0.8609, gradient_norm=0.5099, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 137: loss=0.3777, accuracy=0.8710, gradient_norm=0.3473, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 138: loss=0.3966, accuracy=0.8659, gradient_norm=0.3876, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 139: loss=0.3197, accuracy=0.8927, gradient_norm=0.3051, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 140: loss=0.3788, accuracy=0.8725, gradient_norm=0.4052, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 141: loss=0.4611, accuracy=0.8446, gradient_norm=0.6263, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 142: loss=0.4809, accuracy=0.8387, gradient_norm=0.4684, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 143: loss=0.2272, accuracy=0.9274, gradient_norm=0.4003, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 144: loss=0.4186, accuracy=0.8605, gradient_norm=0.5236, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 145: loss=0.3912, accuracy=0.8710, gradient_norm=0.3764, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 146: loss=0.3633, accuracy=0.8755, gradient_norm=0.4223, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 147: loss=0.2385, accuracy=0.9190, gradient_norm=0.2850, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 148: loss=0.4226, accuracy=0.8564, gradient_norm=0.4447, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 149: loss=0.3070, accuracy=0.8976, gradient_norm=0.3630, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 150: loss=0.2729, accuracy=0.9131, gradient_norm=0.3724, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 151: loss=0.3571, accuracy=0.8797, gradient_norm=0.3329, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 152: loss=0.1947, accuracy=0.9373, gradient_norm=0.2570, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 153: loss=0.3257, accuracy=0.8917, gradient_norm=0.3219, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 154: loss=0.2957, accuracy=0.9031, gradient_norm=0.4195, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 155: loss=0.2319, accuracy=0.9245, gradient_norm=0.2554, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 156: loss=0.2983, accuracy=0.8999, gradient_norm=0.3718, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 157: loss=0.3992, accuracy=0.8651, gradient_norm=0.4336, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 158: loss=0.3470, accuracy=0.8847, gradient_norm=0.3080, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 159: loss=0.2709, accuracy=0.9091, gradient_norm=0.2558, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 160: loss=0.2373, accuracy=0.9212, gradient_norm=0.3755, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 161: loss=0.1503, accuracy=0.9520, gradient_norm=0.2350, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 162: loss=0.2067, accuracy=0.9329, gradient_norm=0.3219, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 163: loss=0.3340, accuracy=0.8906, gradient_norm=0.4510, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 164: loss=0.1053, accuracy=0.9673, gradient_norm=0.2424, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 165: loss=0.1612, accuracy=0.9484, gradient_norm=0.2366, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 166: loss=0.1773, accuracy=0.9452, gradient_norm=0.2829, 
[2025-09-19 10:41:13,553][__main__][INFO] - Train, Round 167: loss=0.3467, accuracy=0.8815, gradient_norm=0.2810, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 168: loss=0.1761, accuracy=0.9455, gradient_norm=0.3086, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 169: loss=0.3125, accuracy=0.8958, gradient_norm=0.3012, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 170: loss=0.2172, accuracy=0.9263, gradient_norm=0.2615, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 171: loss=0.1746, accuracy=0.9444, gradient_norm=0.2579, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 172: loss=0.2323, accuracy=0.9241, gradient_norm=0.2461, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 173: loss=0.1728, accuracy=0.9452, gradient_norm=0.3366, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 174: loss=0.1837, accuracy=0.9391, gradient_norm=0.2700, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 175: loss=0.2185, accuracy=0.9312, gradient_norm=0.2733, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 176: loss=0.1833, accuracy=0.9399, gradient_norm=0.2512, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 177: loss=0.1537, accuracy=0.9481, gradient_norm=0.2414, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 178: loss=0.1326, accuracy=0.9565, gradient_norm=0.1738, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 179: loss=0.0925, accuracy=0.9736, gradient_norm=0.1742, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 180: loss=0.2003, accuracy=0.9355, gradient_norm=0.4275, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 181: loss=0.1694, accuracy=0.9422, gradient_norm=0.2073, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 182: loss=0.1713, accuracy=0.9445, gradient_norm=0.2069, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 183: loss=0.0780, accuracy=0.9768, gradient_norm=0.1673, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 184: loss=0.1941, accuracy=0.9354, gradient_norm=0.3089, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 185: loss=0.2196, accuracy=0.9271, gradient_norm=0.2442, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 186: loss=0.1389, accuracy=0.9579, gradient_norm=0.2649, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 187: loss=0.1936, accuracy=0.9383, gradient_norm=0.3315, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 188: loss=0.2533, accuracy=0.9148, gradient_norm=0.3623, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 189: loss=0.1995, accuracy=0.9334, gradient_norm=0.2925, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 190: loss=0.1566, accuracy=0.9502, gradient_norm=0.2118, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 191: loss=0.1636, accuracy=0.9464, gradient_norm=0.2251, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 192: loss=0.1684, accuracy=0.9439, gradient_norm=0.3045, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 193: loss=0.1306, accuracy=0.9594, gradient_norm=0.2581, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 194: loss=0.1409, accuracy=0.9536, gradient_norm=0.2538, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 195: loss=0.1680, accuracy=0.9452, gradient_norm=0.2045, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 196: loss=0.2460, accuracy=0.9177, gradient_norm=0.2581, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 197: loss=0.1329, accuracy=0.9541, gradient_norm=0.2097, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 198: loss=0.1698, accuracy=0.9433, gradient_norm=0.2577, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 199: loss=0.1203, accuracy=0.9630, gradient_norm=0.4201, 
[2025-09-19 10:41:13,554][__main__][INFO] - Train, Round 200: loss=0.0782, accuracy=0.9788, gradient_norm=0.2587, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 001: loss=2.2554, accuracy=0.1669, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 002: loss=2.1964, accuracy=0.2197, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 003: loss=2.1577, accuracy=0.2362, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 004: loss=2.1211, accuracy=0.2577, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 005: loss=2.0928, accuracy=0.2650, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 006: loss=2.0649, accuracy=0.2730, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 007: loss=2.0399, accuracy=0.2838, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 008: loss=2.0213, accuracy=0.2908, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 009: loss=2.0063, accuracy=0.2906, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 010: loss=1.9863, accuracy=0.2960, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 011: loss=1.9728, accuracy=0.2973, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 012: loss=1.9625, accuracy=0.3021, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 013: loss=1.9497, accuracy=0.3071, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 014: loss=1.9359, accuracy=0.3096, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 015: loss=1.9210, accuracy=0.3136, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 016: loss=1.9069, accuracy=0.3154, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 017: loss=1.8956, accuracy=0.3190, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 018: loss=1.8867, accuracy=0.3203, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 019: loss=1.8780, accuracy=0.3237, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 020: loss=1.8660, accuracy=0.3294, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 021: loss=1.8466, accuracy=0.3384, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 022: loss=1.8369, accuracy=0.3421, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 023: loss=1.8214, accuracy=0.3483, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 024: loss=1.8098, accuracy=0.3535, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 025: loss=1.7979, accuracy=0.3594, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 026: loss=1.7880, accuracy=0.3633, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 027: loss=1.7747, accuracy=0.3692, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 028: loss=1.7676, accuracy=0.3717, 
[2025-09-19 10:41:13,554][__main__][INFO] - Test, Round 029: loss=1.7533, accuracy=0.3789, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 030: loss=1.7359, accuracy=0.3837, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 031: loss=1.7261, accuracy=0.3878, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 032: loss=1.7190, accuracy=0.3895, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 033: loss=1.7146, accuracy=0.3933, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 034: loss=1.7071, accuracy=0.3970, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 035: loss=1.7044, accuracy=0.4005, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 036: loss=1.6955, accuracy=0.4036, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 037: loss=1.6893, accuracy=0.4060, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 038: loss=1.6770, accuracy=0.4107, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 039: loss=1.6730, accuracy=0.4083, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 040: loss=1.6716, accuracy=0.4080, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 041: loss=1.6560, accuracy=0.4141, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 042: loss=1.6525, accuracy=0.4142, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 043: loss=1.6517, accuracy=0.4170, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 044: loss=1.6585, accuracy=0.4175, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 045: loss=1.6355, accuracy=0.4205, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 046: loss=1.6384, accuracy=0.4210, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 047: loss=1.6245, accuracy=0.4247, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 048: loss=1.6169, accuracy=0.4311, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 049: loss=1.6177, accuracy=0.4359, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 050: loss=1.6234, accuracy=0.4320, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 051: loss=1.6334, accuracy=0.4296, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 052: loss=1.6059, accuracy=0.4392, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 053: loss=1.6124, accuracy=0.4422, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 054: loss=1.5999, accuracy=0.4428, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 055: loss=1.6102, accuracy=0.4424, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 056: loss=1.6053, accuracy=0.4460, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 057: loss=1.5983, accuracy=0.4465, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 058: loss=1.5917, accuracy=0.4463, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 059: loss=1.5925, accuracy=0.4491, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 060: loss=1.5999, accuracy=0.4507, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 061: loss=1.6097, accuracy=0.4488, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 062: loss=1.5960, accuracy=0.4536, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 063: loss=1.6037, accuracy=0.4565, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 064: loss=1.6072, accuracy=0.4507, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 065: loss=1.6152, accuracy=0.4566, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 066: loss=1.6302, accuracy=0.4555, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 067: loss=1.6305, accuracy=0.4531, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 068: loss=1.6059, accuracy=0.4584, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 069: loss=1.5915, accuracy=0.4658, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 070: loss=1.6039, accuracy=0.4638, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 071: loss=1.5914, accuracy=0.4676, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 072: loss=1.5922, accuracy=0.4657, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 073: loss=1.5917, accuracy=0.4703, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 074: loss=1.5888, accuracy=0.4743, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 075: loss=1.6022, accuracy=0.4707, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 076: loss=1.5929, accuracy=0.4746, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 077: loss=1.6027, accuracy=0.4710, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 078: loss=1.5976, accuracy=0.4744, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 079: loss=1.6302, accuracy=0.4721, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 080: loss=1.6337, accuracy=0.4730, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 081: loss=1.6501, accuracy=0.4694, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 082: loss=1.6426, accuracy=0.4741, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 083: loss=1.6503, accuracy=0.4717, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 084: loss=1.6447, accuracy=0.4766, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 085: loss=1.6698, accuracy=0.4764, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 086: loss=1.6640, accuracy=0.4818, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 087: loss=1.6694, accuracy=0.4797, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 088: loss=1.6763, accuracy=0.4812, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 089: loss=1.6675, accuracy=0.4838, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 090: loss=1.7019, accuracy=0.4829, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 091: loss=1.6980, accuracy=0.4833, 
[2025-09-19 10:41:13,555][__main__][INFO] - Test, Round 092: loss=1.7204, accuracy=0.4852, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 093: loss=1.7307, accuracy=0.4837, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 094: loss=1.7354, accuracy=0.4844, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 095: loss=1.7481, accuracy=0.4825, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 096: loss=1.7498, accuracy=0.4841, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 097: loss=1.7503, accuracy=0.4859, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 098: loss=1.7887, accuracy=0.4837, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 099: loss=1.8170, accuracy=0.4838, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 100: loss=1.8188, accuracy=0.4857, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 101: loss=1.8370, accuracy=0.4853, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 102: loss=1.8644, accuracy=0.4822, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 103: loss=1.8973, accuracy=0.4867, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 104: loss=1.8859, accuracy=0.4844, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 105: loss=1.8696, accuracy=0.4868, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 106: loss=1.8823, accuracy=0.4899, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 107: loss=1.9047, accuracy=0.4864, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 108: loss=1.9158, accuracy=0.4895, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 109: loss=1.9377, accuracy=0.4898, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 110: loss=1.9620, accuracy=0.4906, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 111: loss=1.9709, accuracy=0.4890, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 112: loss=1.9928, accuracy=0.4904, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 113: loss=1.9913, accuracy=0.4951, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 114: loss=2.0021, accuracy=0.4905, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 115: loss=2.0191, accuracy=0.4900, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 116: loss=2.0367, accuracy=0.4884, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 117: loss=2.0316, accuracy=0.4883, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 118: loss=2.0559, accuracy=0.4921, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 119: loss=2.0742, accuracy=0.4884, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 120: loss=2.0669, accuracy=0.4914, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 121: loss=2.1057, accuracy=0.4892, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 122: loss=2.1086, accuracy=0.4878, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 123: loss=2.1310, accuracy=0.4899, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 124: loss=2.1369, accuracy=0.4898, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 125: loss=2.1425, accuracy=0.4914, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 126: loss=2.1636, accuracy=0.4914, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 127: loss=2.1906, accuracy=0.4950, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 128: loss=2.2342, accuracy=0.4907, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 129: loss=2.2179, accuracy=0.4938, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 130: loss=2.2200, accuracy=0.4931, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 131: loss=2.2161, accuracy=0.4937, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 132: loss=2.2301, accuracy=0.4979, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 133: loss=2.2258, accuracy=0.4975, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 134: loss=2.2433, accuracy=0.5007, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 135: loss=2.2679, accuracy=0.5015, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 136: loss=2.2820, accuracy=0.5057, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 137: loss=2.2981, accuracy=0.5027, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 138: loss=2.3151, accuracy=0.5035, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 139: loss=2.3106, accuracy=0.5010, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 140: loss=2.3166, accuracy=0.5011, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 141: loss=2.3506, accuracy=0.4994, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 142: loss=2.3800, accuracy=0.4968, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 143: loss=2.3913, accuracy=0.4985, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 144: loss=2.4009, accuracy=0.5010, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 145: loss=2.4410, accuracy=0.4990, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 146: loss=2.4333, accuracy=0.4948, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 147: loss=2.4332, accuracy=0.4963, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 148: loss=2.4388, accuracy=0.4978, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 149: loss=2.4509, accuracy=0.4948, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 150: loss=2.4736, accuracy=0.4962, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 151: loss=2.4961, accuracy=0.4945, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 152: loss=2.4921, accuracy=0.4956, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 153: loss=2.4949, accuracy=0.5008, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 154: loss=2.5152, accuracy=0.5002, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 155: loss=2.5376, accuracy=0.5006, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 156: loss=2.5512, accuracy=0.4980, 
[2025-09-19 10:41:13,556][__main__][INFO] - Test, Round 157: loss=2.5352, accuracy=0.5001, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 158: loss=2.5497, accuracy=0.5022, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 159: loss=2.5510, accuracy=0.5059, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 160: loss=2.5769, accuracy=0.5017, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 161: loss=2.5853, accuracy=0.5051, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 162: loss=2.5838, accuracy=0.5057, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 163: loss=2.6141, accuracy=0.4991, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 164: loss=2.6240, accuracy=0.5004, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 165: loss=2.6373, accuracy=0.5005, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 166: loss=2.6345, accuracy=0.5027, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 167: loss=2.6347, accuracy=0.5041, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 168: loss=2.6577, accuracy=0.5034, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 169: loss=2.6537, accuracy=0.5041, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 170: loss=2.6723, accuracy=0.5040, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 171: loss=2.6735, accuracy=0.5045, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 172: loss=2.7045, accuracy=0.5024, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 173: loss=2.7324, accuracy=0.5030, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 174: loss=2.7368, accuracy=0.5056, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 175: loss=2.7293, accuracy=0.5022, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 176: loss=2.7363, accuracy=0.5016, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 177: loss=2.7489, accuracy=0.5011, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 178: loss=2.7535, accuracy=0.5042, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 179: loss=2.7585, accuracy=0.5050, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 180: loss=2.7806, accuracy=0.5022, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 181: loss=2.7805, accuracy=0.5020, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 182: loss=2.7905, accuracy=0.5030, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 183: loss=2.7992, accuracy=0.5033, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 184: loss=2.7937, accuracy=0.5059, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 185: loss=2.7932, accuracy=0.5062, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 186: loss=2.8133, accuracy=0.5081, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 187: loss=2.8174, accuracy=0.5057, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 188: loss=2.8295, accuracy=0.5074, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 189: loss=2.8340, accuracy=0.5048, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 190: loss=2.8481, accuracy=0.5060, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 191: loss=2.8566, accuracy=0.5031, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 192: loss=2.8689, accuracy=0.5021, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 193: loss=2.8747, accuracy=0.5054, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 194: loss=2.8689, accuracy=0.5038, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 195: loss=2.9090, accuracy=0.4968, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 196: loss=2.9043, accuracy=0.5014, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 197: loss=2.9072, accuracy=0.5026, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 198: loss=2.9049, accuracy=0.5050, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 199: loss=2.9362, accuracy=0.5054, 
[2025-09-19 10:41:13,557][__main__][INFO] - Test, Round 200: loss=2.9122, accuracy=0.5051, 

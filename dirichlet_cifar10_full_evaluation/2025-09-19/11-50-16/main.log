[2025-09-19 11:50:27,067][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 1.7031967331200888,  accuracy: 0.43262012012012013, gradient_norm : 1.7906984673568833
[2025-09-19 11:50:31,814][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.094798765078333,  accuracy: 0.2158
[2025-09-19 11:50:35,613][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 1.7186001062330936,  accuracy: 0.398486460919948, gradient_norm : 1.3216139884705531
[2025-09-19 11:50:40,184][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 1.9628034482855081,  accuracy: 0.2744
[2025-09-19 11:50:44,318][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 1.510050140440892,  accuracy: 0.47082076354936025, gradient_norm : 1.288067389208863
[2025-09-19 11:50:49,143][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 1.8871406073268067,  accuracy: 0.3174
[2025-09-19 11:50:53,675][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.368785841753151,  accuracy: 0.5266604303086997, gradient_norm : 1.220285500450354
[2025-09-19 11:50:58,477][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 1.8439210095198764,  accuracy: 0.348
[2025-09-19 11:51:01,900][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.3207778551722171,  accuracy: 0.5270221254987305, gradient_norm : 1.3577733619839032
[2025-09-19 11:51:06,549][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 1.814100885540427,  accuracy: 0.3682
[2025-09-19 11:51:11,390][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 1.154392487124219,  accuracy: 0.6008710379869344, gradient_norm : 1.3790725886105075
[2025-09-19 11:51:16,195][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 1.8370384059886913,  accuracy: 0.3843
[2025-09-19 11:51:21,118][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.3841939246939317,  accuracy: 0.520360568104397, gradient_norm : 1.5457112831485251
[2025-09-19 11:51:25,983][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.7919733566681826,  accuracy: 0.4181
[2025-09-19 11:51:30,782][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 0.9939842457462906,  accuracy: 0.6610512470278748, gradient_norm : 1.3121017567237274
[2025-09-19 11:51:35,565][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.7798926538822426,  accuracy: 0.4284
[2025-09-19 11:51:40,757][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.0517756863846544,  accuracy: 0.6387933575709934, gradient_norm : 1.3741753014480598
[2025-09-19 11:51:45,628][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 1.7349004257054497,  accuracy: 0.4447
[2025-09-19 11:51:50,698][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 0.9925055593848334,  accuracy: 0.6656296053708859, gradient_norm : 1.466128769895846
[2025-09-19 11:51:55,530][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.7534658962885907,  accuracy: 0.4487
[2025-09-19 11:52:00,449][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 0.7678923567804173,  accuracy: 0.7420391613924051, gradient_norm : 1.3811460880147148
[2025-09-19 11:52:05,272][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.76832976596274,  accuracy: 0.4518
[2025-09-19 11:52:10,297][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 0.7017920844860563,  accuracy: 0.771828587645445, gradient_norm : 1.4711427921913534
[2025-09-19 11:52:15,081][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.950125125020003,  accuracy: 0.4669
[2025-09-19 11:52:19,570][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 0.7829123248558445,  accuracy: 0.7462614047400529, gradient_norm : 1.29307512210032
[2025-09-19 11:52:24,496][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.8995237065248245,  accuracy: 0.4778
[2025-09-19 11:52:29,042][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 0.7037714701777568,  accuracy: 0.7729180116204003, gradient_norm : 1.5235317738546317
[2025-09-19 11:52:33,985][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.8250292673761277,  accuracy: 0.4911
[2025-09-19 11:52:37,867][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 0.6216593209136998,  accuracy: 0.8039725853534713, gradient_norm : 1.630735251685509
[2025-09-19 11:52:42,682][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.8384815826341847,  accuracy: 0.4905
[2025-09-19 11:52:47,242][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 0.4669202080625669,  accuracy: 0.8591943204431776, gradient_norm : 1.3399583837322786
[2025-09-19 11:52:52,116][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.765349227663229,  accuracy: 0.5048
[2025-09-19 11:52:56,344][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 0.49467460047161643,  accuracy: 0.8604506340579711, gradient_norm : 1.399436702923198
[2025-09-19 11:53:01,268][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.9045483981404483,  accuracy: 0.5008
[2025-09-19 11:53:05,309][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 0.5605621690834613,  accuracy: 0.8306794983960338, gradient_norm : 1.5091799478032437
[2025-09-19 11:53:10,267][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.9036091463412457,  accuracy: 0.4966
[2025-09-19 11:53:14,339][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 0.27507706179328256,  accuracy: 0.9289499173836249, gradient_norm : 1.1030244153394737
[2025-09-19 11:53:19,340][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.8178277491743338,  accuracy: 0.5036
[2025-09-19 11:53:22,520][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 0.19166470357297663,  accuracy: 0.9537983791562523, gradient_norm : 1.2417519524929699
[2025-09-19 11:53:27,397][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.8020196823368173,  accuracy: 0.511
[2025-09-19 11:53:31,867][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 0.31102161811998047,  accuracy: 0.9138004246284501, gradient_norm : 1.143930866854498
[2025-09-19 11:53:36,802][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.7288191545918954,  accuracy: 0.5157
[2025-09-19 11:53:41,149][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 0.3485645967676428,  accuracy: 0.9099270159615499, gradient_norm : 1.442615649983767
[2025-09-19 11:53:46,062][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.7121957784394115,  accuracy: 0.5186
[2025-09-19 11:53:50,817][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 0.3326706367306505,  accuracy: 0.9042854149203688, gradient_norm : 1.0264198478895181
[2025-09-19 11:53:55,766][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.7566587126008362,  accuracy: 0.5161
[2025-09-19 11:54:00,144][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 0.12089016386802458,  accuracy: 0.9716939161383605, gradient_norm : 0.7532116470338682
[2025-09-19 11:54:05,054][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.6853020691833582,  accuracy: 0.5302
[2025-09-19 11:54:09,822][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 0.20618868572303148,  accuracy: 0.941451130580767, gradient_norm : 0.7044857087030609
[2025-09-19 11:54:14,677][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.6842745776975174,  accuracy: 0.5425
[2025-09-19 11:54:20,111][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 0.2442426262772339,  accuracy: 0.9296911232724238, gradient_norm : 0.774365426429341
[2025-09-19 11:54:25,028][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.7337694720295207,  accuracy: 0.5349
[2025-09-19 11:54:30,105][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 0.12448329654462992,  accuracy: 0.9682950061232821, gradient_norm : 0.6421791498914647
[2025-09-19 11:54:35,049][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.7217834776299337,  accuracy: 0.5411
[2025-09-19 11:54:40,059][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 0.1756395321756073,  accuracy: 0.9495498140536308, gradient_norm : 0.5978582687875086
[2025-09-19 11:54:44,956][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.6956231577005558,  accuracy: 0.5463
[2025-09-19 11:54:49,943][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 0.15687121284100858,  accuracy: 0.9585076205586807, gradient_norm : 0.7646265481582685
[2025-09-19 11:54:54,916][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.670233488642332,  accuracy: 0.5589
[2025-09-19 11:54:59,967][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 0.09298130746009851,  accuracy: 0.9808884822608519, gradient_norm : 0.7677683571796196
[2025-09-19 11:55:04,910][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.6392749260443022,  accuracy: 0.5551
[2025-09-19 11:55:09,205][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 0.09409738462585476,  accuracy: 0.9758314618757352, gradient_norm : 0.7752471763320982
[2025-09-19 11:55:14,125][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.6578718567523922,  accuracy: 0.5583
[2025-09-19 11:55:18,977][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 0.13598743717200337,  accuracy: 0.9704987017638106, gradient_norm : 0.7529134169979296
[2025-09-19 11:55:23,964][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.7753880275230323,  accuracy: 0.5475
[2025-09-19 11:55:27,459][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 0.12323083699143636,  accuracy: 0.9703557312252964, gradient_norm : 0.5961457543776103
[2025-09-19 11:55:32,440][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.8143893831519282,  accuracy: 0.5464
[2025-09-19 11:55:35,441][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 0.08352055296842327,  accuracy: 0.9812087743518945, gradient_norm : 0.4965181188617527
[2025-09-19 11:55:40,345][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.8345373177190616,  accuracy: 0.5464
[2025-09-19 11:55:43,981][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 0.03743197059139176,  accuracy: 0.996115133321561, gradient_norm : 0.48105122706730324
[2025-09-19 11:55:48,964][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.8162988012182704,  accuracy: 0.5474
[2025-09-19 11:55:52,663][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 0.049687819689776064,  accuracy: 0.9924634641850711, gradient_norm : 0.5918106178749197
[2025-09-19 11:55:57,557][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.8033171959862426,  accuracy: 0.5511
[2025-09-19 11:56:02,081][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 0.06610331692287086,  accuracy: 0.9840536428692174, gradient_norm : 0.3634517239704566
[2025-09-19 11:56:07,033][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.8748076972311056,  accuracy: 0.552
[2025-09-19 11:56:11,535][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 0.07277828419202664,  accuracy: 0.9813990303749877, gradient_norm : 0.4810076796541348
[2025-09-19 11:56:16,439][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.8186061457591087,  accuracy: 0.5536
[2025-09-19 11:56:20,656][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 0.05695603470943444,  accuracy: 0.9885150002683412, gradient_norm : 0.5061009363477469
[2025-09-19 11:56:25,652][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.8645367546815506,  accuracy: 0.5539
[2025-09-19 11:56:29,689][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 0.050490047288728364,  accuracy: 0.9896328043553805, gradient_norm : 0.3674290559775491
[2025-09-19 11:56:34,565][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.822009990120944,  accuracy: 0.5605
[2025-09-19 11:56:39,138][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 0.03602872772558125,  accuracy: 0.9941784234541354, gradient_norm : 0.5809272527299028
[2025-09-19 11:56:44,018][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.844068346136792,  accuracy: 0.5578
[2025-09-19 11:56:49,157][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 0.04501294352057384,  accuracy: 0.9908892763731474, gradient_norm : 0.5918027279066113
[2025-09-19 11:56:54,081][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.7427340936906301,  accuracy: 0.5607
[2025-09-19 11:56:58,331][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 0.04691838992712945,  accuracy: 0.9894518139683555, gradient_norm : 0.33138327840501436
[2025-09-19 11:57:03,298][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.7508755563169762,  accuracy: 0.5632
[2025-09-19 11:57:07,709][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 0.03498686612164256,  accuracy: 0.9924975422983391, gradient_norm : 0.2459329098146783
[2025-09-19 11:57:12,574][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.778279881575893,  accuracy: 0.5585
[2025-09-19 11:57:17,009][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 0.07130487549983897,  accuracy: 0.9839064427874041, gradient_norm : 0.7461926391186625
[2025-09-19 11:57:21,885][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.7867148712017704,  accuracy: 0.5585
[2025-09-19 11:57:26,629][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 0.020992305460964516,  accuracy: 0.9979226049567612, gradient_norm : 0.3345295178212689
[2025-09-19 11:57:31,634][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.771435353376031,  accuracy: 0.5652
[2025-09-19 11:57:36,288][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 0.03632130126234497,  accuracy: 0.9931366822429907, gradient_norm : 0.4579633683106853
[2025-09-19 11:57:41,279][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.7769744698001544,  accuracy: 0.5625
[2025-09-19 11:57:45,289][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 0.03992637841573688,  accuracy: 0.9904542462146149, gradient_norm : 0.45134516514661
[2025-09-19 11:57:50,279][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.9497763233735765,  accuracy: 0.5594
[2025-09-19 11:57:53,986][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 0.07445871677143073,  accuracy: 0.9870064017240286, gradient_norm : 0.5504779640731111
[2025-09-19 11:57:58,997][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.7958566312288564,  accuracy: 0.5656
[2025-09-19 11:58:02,757][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 0.01264472819170022,  accuracy: 0.9992878760904398, gradient_norm : 0.2669358166569637
[2025-09-19 11:58:07,732][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.7885286151811801,  accuracy: 0.5639
[2025-09-19 11:58:11,625][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 0.021933719911146742,  accuracy: 0.9961225063220006, gradient_norm : 0.25758725096537605
[2025-09-19 11:58:16,579][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.7872440611388607,  accuracy: 0.5646
[2025-09-19 11:58:20,773][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 0.011770504771731149,  accuracy: 0.9995899748859618, gradient_norm : 0.47387555644025714
[2025-09-19 11:58:25,671][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.9527147338440012,  accuracy: 0.5582
[2025-09-19 11:58:30,108][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 0.012656195532215319,  accuracy: 0.9980506822612085, gradient_norm : 0.18989745179813594
[2025-09-19 11:58:35,080][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.7840427859645227,  accuracy: 0.564
[2025-09-19 11:58:39,342][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 0.029080548757798638,  accuracy: 0.9955548663875536, gradient_norm : 0.46428294047306523
[2025-09-19 11:58:44,264][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.7744415906502724,  accuracy: 0.5655
[2025-09-19 11:58:47,364][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 0.03036909174543667,  accuracy: 0.9973066836770855, gradient_norm : 0.8136107909162404
[2025-09-19 11:58:52,312][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 2.0052543863051646,  accuracy: 0.5521
[2025-09-19 11:58:57,017][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 0.018394787429691258,  accuracy: 0.997068791792617, gradient_norm : 0.4052446564429809
[2025-09-19 11:59:01,954][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.9345796846849568,  accuracy: 0.5537
[2025-09-19 11:59:05,934][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 0.05666001748048227,  accuracy: 0.9863375688743956, gradient_norm : 0.5487552863358326
[2025-09-19 11:59:10,835][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.9285056638909228,  accuracy: 0.5633
[2025-09-19 11:59:14,727][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.031107751221018297,  accuracy: 0.9924477258637209, gradient_norm : 0.3198494235512343
[2025-09-19 11:59:19,701][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.7286163885018406,  accuracy: 0.5727
[2025-09-19 11:59:23,193][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.02490326737299501,  accuracy: 0.9986090914838465, gradient_norm : 0.5065176227104263
[2025-09-19 11:59:28,167][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.7267550372253695,  accuracy: 0.5724
[2025-09-19 11:59:32,751][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 0.04488509491882995,  accuracy: 0.9939291260765213, gradient_norm : 0.6691362674965793
[2025-09-19 11:59:37,650][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.7302951450270618,  accuracy: 0.5734
[2025-09-19 11:59:41,974][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.012587671523605702,  accuracy: 0.9987305927155551, gradient_norm : 0.2914207339962386
[2025-09-19 11:59:46,922][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.7711564208943855,  accuracy: 0.5657
[2025-09-19 11:59:51,445][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.017312825954226976,  accuracy: 0.9968156085725839, gradient_norm : 0.2536671913488835
[2025-09-19 11:59:56,422][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.7675732949600118,  accuracy: 0.5694
[2025-09-19 12:00:00,560][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 0.008755106402938223,  accuracy: 0.9991188392175292, gradient_norm : 0.13525155027713823
[2025-09-19 12:00:05,446][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.7801412159907315,  accuracy: 0.5724
[2025-09-19 12:00:09,367][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.016559642672517427,  accuracy: 0.9978252990213845, gradient_norm : 0.297382561627698
[2025-09-19 12:00:14,319][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.762694710489163,  accuracy: 0.5752
[2025-09-19 12:00:18,034][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.043644473827186926,  accuracy: 0.9919692042211455, gradient_norm : 0.6032448219137335
[2025-09-19 12:00:23,013][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.7899424298042148,  accuracy: 0.5758
[2025-09-19 12:00:26,629][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.020808563029812124,  accuracy: 0.9962061905335421, gradient_norm : 0.36743182336936486
[2025-09-19 12:00:31,567][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.7953957580126414,  accuracy: 0.5715
[2025-09-19 12:00:35,605][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.02003213459467632,  accuracy: 0.9965231045311799, gradient_norm : 0.42930942736712197
[2025-09-19 12:00:40,599][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.7419772467862877,  accuracy: 0.5766
[2025-09-19 12:00:45,190][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.0283027361780313,  accuracy: 0.9945265988092952, gradient_norm : 0.3756972354627722
[2025-09-19 12:00:50,166][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.7168951437965072,  accuracy: 0.5777
[2025-09-19 12:00:54,516][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.012885462462360445,  accuracy: 0.9986229542926752, gradient_norm : 0.2636117719790511
[2025-09-19 12:00:59,428][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.734159269809594,  accuracy: 0.5783
[2025-09-19 12:01:03,856][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 0.03932427995835054,  accuracy: 0.9971416904859126, gradient_norm : 0.6364624550524098
[2025-09-19 12:01:08,848][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.72463349993077,  accuracy: 0.5797
[2025-09-19 12:01:12,623][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 0.007281806704869952,  accuracy: 0.9994571445804934, gradient_norm : 0.16793598222296444
[2025-09-19 12:01:17,516][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.7242904595538682,  accuracy: 0.5774
[2025-09-19 12:01:22,078][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.007121689446470371,  accuracy: 0.9996034696406444, gradient_norm : 0.2506176592069303
[2025-09-19 12:01:27,051][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.7176259223539339,  accuracy: 0.5787
[2025-09-19 12:01:31,781][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.029577105096332792,  accuracy: 0.9951809419894526, gradient_norm : 0.48659814626011444
[2025-09-19 12:01:36,769][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.7370448243031842,  accuracy: 0.5768
[2025-09-19 12:01:40,683][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.007862156907742567,  accuracy: 0.9998263587428373, gradient_norm : 0.2897612461414864
[2025-09-19 12:01:45,595][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.8815521613902597,  accuracy: 0.5692
[2025-09-19 12:01:50,506][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.01404816332010539,  accuracy: 0.9977670433831571, gradient_norm : 0.32484203269303064
[2025-09-19 12:01:55,483][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.715473206088399,  accuracy: 0.5789
[2025-09-19 12:01:59,608][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.00900882771251387,  accuracy: 0.9993944165203174, gradient_norm : 0.4694131716571917
[2025-09-19 12:02:04,487][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.7273135523249896,  accuracy: 0.5797
[2025-09-19 12:02:09,293][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.00877313088509925,  accuracy: 0.9987742594484168, gradient_norm : 0.18170540245147204
[2025-09-19 12:02:14,157][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.6962421938364292,  accuracy: 0.5814
[2025-09-19 12:02:18,301][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.023341878286411426,  accuracy: 0.9958007363092499, gradient_norm : 0.31328935663009394
[2025-09-19 12:02:23,200][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.7243807070805408,  accuracy: 0.5794
[2025-09-19 12:02:26,944][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.006921424249128306,  accuracy: 0.9993537964458804, gradient_norm : 0.29147727003943774
[2025-09-19 12:02:31,894][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.72687094126091,  accuracy: 0.5792
[2025-09-19 12:02:35,716][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.00823666092741909,  accuracy: 0.9992058643860721, gradient_norm : 0.1985207647355512
[2025-09-19 12:02:40,588][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.7199174899244731,  accuracy: 0.5798
[2025-09-19 12:02:45,253][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.00859678553723249,  accuracy: 0.9993708865660085, gradient_norm : 0.3697568321479035
[2025-09-19 12:02:50,180][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.726403287219772,  accuracy: 0.5784
[2025-09-19 12:02:54,663][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.004122166365135924,  accuracy: 0.9998419721871049, gradient_norm : 0.19533368208371796
[2025-09-19 12:02:59,591][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.7150194537519114,  accuracy: 0.5794
[2025-09-19 12:03:04,377][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.005726895781109178,  accuracy: 0.9995511669658886, gradient_norm : 0.1503386397128787
[2025-09-19 12:03:09,339][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.7182926208264326,  accuracy: 0.5795
[2025-09-19 12:03:13,676][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.006630597324130894,  accuracy: 0.9995403883718258, gradient_norm : 0.22417143032250206
[2025-09-19 12:03:18,532][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.7170829176430547,  accuracy: 0.5816
[2025-09-19 12:03:22,493][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.009212305138940398,  accuracy: 0.9987341772151899, gradient_norm : 0.3411093294257288
[2025-09-19 12:03:27,324][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.7098438547951125,  accuracy: 0.5799
[2025-09-19 12:03:32,255][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.013330308685547722,  accuracy: 0.9973911783177931, gradient_norm : 0.26456403300604003
[2025-09-19 12:03:37,128][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.6663972711932022,  accuracy: 0.5846
[2025-09-19 12:03:41,796][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.003487378189624234,  accuracy: 0.9999470479216309, gradient_norm : 0.109969584549927
[2025-09-19 12:03:46,658][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.6666485212573112,  accuracy: 0.5851
[2025-09-19 12:03:50,612][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.0056117433520966814,  accuracy: 1.0, gradient_norm : 0.3345382397683435
[2025-09-19 12:03:55,525][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.6779002691562672,  accuracy: 0.5835
[2025-09-19 12:03:59,981][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.0035064827794633346,  accuracy: 0.9997819450501526, gradient_norm : 0.08573611239511572
[2025-09-19 12:04:04,879][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.6723470339518651,  accuracy: 0.5842
[2025-09-19 12:04:08,995][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.01012534825650991,  accuracy: 0.9983783783783784, gradient_norm : 0.1498293822131144
[2025-09-19 12:04:13,909][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.676366861917726,  accuracy: 0.584
[2025-09-19 12:04:18,137][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.0065505942458195686,  accuracy: 0.9996149826742203, gradient_norm : 0.2819913550998657
[2025-09-19 12:04:23,071][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.6760859584221761,  accuracy: 0.5828
[2025-09-19 12:04:28,142][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.011238198938658217,  accuracy: 0.9994524548275233, gradient_norm : 0.5287088439491908
[2025-09-19 12:04:33,014][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.6979681035515242,  accuracy: 0.58
[2025-09-19 12:04:37,953][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.006888553524300103,  accuracy: 0.9994769053721818, gradient_norm : 0.2987557216372296
[2025-09-19 12:04:42,898][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.7057061646887073,  accuracy: 0.5806
[2025-09-19 12:04:46,774][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.005901510915052793,  accuracy: 0.9998664262338877, gradient_norm : 0.37645083452774436
[2025-09-19 12:04:51,728][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.7075239615000442,  accuracy: 0.5799
[2025-09-19 12:04:56,741][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.013882122090344791,  accuracy: 0.998979690992129, gradient_norm : 0.5718822139819925
[2025-09-19 12:05:01,663][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.732526819541756,  accuracy: 0.5753
[2025-09-19 12:05:06,527][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.0029278605780579414,  accuracy: 0.9999461584019814, gradient_norm : 0.09836694524933787
[2025-09-19 12:05:11,404][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.7234104821610956,  accuracy: 0.5776
[2025-09-19 12:05:15,947][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.018610511211573946,  accuracy: 0.9992515370221866, gradient_norm : 0.6070133375081419
[2025-09-19 12:05:20,849][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.7158057000963232,  accuracy: 0.5812
[2025-09-19 12:05:25,072][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.021137599152321,  accuracy: 0.9983457402812241, gradient_norm : 0.49529313020284454
[2025-09-19 12:05:29,981][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.7666988357570321,  accuracy: 0.5731
[2025-09-19 12:05:34,808][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.0026310089425007665,  accuracy: 1.0, gradient_norm : 0.09134866468151472
[2025-09-19 12:05:39,706][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.7582928629848393,  accuracy: 0.5737
[2025-09-19 12:05:44,310][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.01731554790978488,  accuracy: 0.9995631041450495, gradient_norm : 0.5667721883092682
[2025-09-19 12:05:49,241][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.7938629297559787,  accuracy: 0.5688
[2025-09-19 12:05:53,430][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.004537974393691233,  accuracy: 0.9996441914250134, gradient_norm : 0.1161498531768252
[2025-09-19 12:05:58,334][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.775458809662196,  accuracy: 0.5703
[2025-09-19 12:06:02,641][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.020795827013280158,  accuracy: 0.9982096900525903, gradient_norm : 0.611866610131138
[2025-09-19 12:06:07,542][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.7387978853814854,  accuracy: 0.5797
[2025-09-19 12:06:12,521][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.003874673327189592,  accuracy: 0.9998024691358025, gradient_norm : 0.11806866394892064
[2025-09-19 12:06:17,463][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.7211654359165651,  accuracy: 0.5842
[2025-09-19 12:06:22,553][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.01645329181764413,  accuracy: 0.9985828772478499, gradient_norm : 0.32353182965678323
[2025-09-19 12:06:27,496][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.726177763511424,  accuracy: 0.5788
[2025-09-19 12:06:32,300][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.005726211028515505,  accuracy: 0.9993276789408357, gradient_norm : 0.334480150461988
[2025-09-19 12:06:37,164][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.7167156959692569,  accuracy: 0.5791
[2025-09-19 12:06:41,994][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.005048297763063495,  accuracy: 0.9993171910289406, gradient_norm : 0.16843736396612555
[2025-09-19 12:06:46,892][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.7016792668669982,  accuracy: 0.5817
[2025-09-19 12:06:51,861][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.001847132752268569,  accuracy: 1.0, gradient_norm : 0.044665275972785794
[2025-09-19 12:06:56,833][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.6999913936274287,  accuracy: 0.5816
[2025-09-19 12:07:01,487][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.009229571149521885,  accuracy: 0.9998252257500728, gradient_norm : 0.36777763248287276
[2025-09-19 12:07:06,381][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.743076954740004,  accuracy: 0.5793
[2025-09-19 12:07:11,039][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.0036465088561573474,  accuracy: 0.999947271289217, gradient_norm : 0.258014159432625
[2025-09-19 12:07:15,878][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.7442150372358658,  accuracy: 0.58
[2025-09-19 12:07:21,025][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.007261253537801109,  accuracy: 0.9996080928819869, gradient_norm : 0.30156557374167725
[2025-09-19 12:07:25,833][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.741952291361856,  accuracy: 0.5805
[2025-09-19 12:07:31,420][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.010954250914255642,  accuracy: 0.9993838862559242, gradient_norm : 0.42133410306859664
[2025-09-19 12:07:36,248][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.7792294066350098,  accuracy: 0.5793
[2025-09-19 12:07:40,400][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.02021202279914648,  accuracy: 0.9986292920293331, gradient_norm : 0.6253074939059574
[2025-09-19 12:07:45,292][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.7786609943724196,  accuracy: 0.5799
[2025-09-19 12:07:50,081][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.00368046335661804,  accuracy: 0.9999420793512888, gradient_norm : 0.2476546260268841
[2025-09-19 12:07:54,959][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.7561149171904098,  accuracy: 0.5814
[2025-09-19 12:07:59,301][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.007335845368915925,  accuracy: 0.998952087093206, gradient_norm : 0.3585140031052254
[2025-09-19 12:08:04,187][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.7488694927771262,  accuracy: 0.5826
[2025-09-19 12:08:08,877][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.0017737873778297657,  accuracy: 1.0, gradient_norm : 0.0875068123495021
[2025-09-19 12:08:13,779][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.7517396234079614,  accuracy: 0.5831
[2025-09-19 12:08:19,318][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.01977299228983963,  accuracy: 0.9989951768488746, gradient_norm : 0.5798632074095139
[2025-09-19 12:08:24,238][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.7922151251696814,  accuracy: 0.5803
[2025-09-19 12:08:29,121][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.0027739135555344234,  accuracy: 1.0, gradient_norm : 0.2205677785957345
[2025-09-19 12:08:34,045][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.805080744814146,  accuracy: 0.5782
[2025-09-19 12:08:39,278][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.01052461016345417,  accuracy: 0.9993709778874534, gradient_norm : 0.47468939339857685
[2025-09-19 12:08:44,246][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.8159090867607477,  accuracy: 0.5787
[2025-09-19 12:08:48,779][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.02861349380553356,  accuracy: 0.9969040247678018, gradient_norm : 0.5674083448273373
[2025-09-19 12:08:53,634][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 1.7844868807730265,  accuracy: 0.5813
[2025-09-19 12:08:59,056][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.013638113077759556,  accuracy: 0.9975011024547994, gradient_norm : 0.49337794573286886
[2025-09-19 12:09:03,936][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.7478644725319472,  accuracy: 0.5801
[2025-09-19 12:09:08,912][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.019996135239541427,  accuracy: 0.9994761929705097, gradient_norm : 0.30883209967241027
[2025-09-19 12:09:13,733][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.7594505720455174,  accuracy: 0.5783
[2025-09-19 12:09:18,291][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.006743561030205706,  accuracy: 0.9994937670062647, gradient_norm : 0.4311500405175379
[2025-09-19 12:09:23,106][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.7439438509581713,  accuracy: 0.5798
[2025-09-19 12:09:28,065][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.020206721454345013,  accuracy: 0.9987512216310132, gradient_norm : 0.4821808909365647
[2025-09-19 12:09:32,937][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.7302798654100162,  accuracy: 0.5809
[2025-09-19 12:09:37,640][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.012961334935181777,  accuracy: 0.9986559960901704, gradient_norm : 0.2875188601923115
[2025-09-19 12:09:42,513][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.7200334629314005,  accuracy: 0.582
[2025-09-19 12:09:47,903][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.001632735894942852,  accuracy: 0.999905051272313, gradient_norm : 0.05719875728379394
[2025-09-19 12:09:52,675][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 1.716423155320379,  accuracy: 0.5814
[2025-09-19 12:09:57,824][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.00446048877132962,  accuracy: 0.9997890517877861, gradient_norm : 0.2807826885716403
[2025-09-19 12:10:02,673][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.71634560296369,  accuracy: 0.5802
[2025-09-19 12:10:07,625][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.023250736954699557,  accuracy: 0.9990741217015585, gradient_norm : 0.6749004782618541
[2025-09-19 12:10:12,590][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.8954826500505497,  accuracy: 0.5716
[2025-09-19 12:10:17,313][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.003688638220754154,  accuracy: 0.9998809169395654, gradient_norm : 0.2284703076918632
[2025-09-19 12:10:22,239][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.8982045388189244,  accuracy: 0.5729
[2025-09-19 12:10:27,517][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.0052810726823731766,  accuracy: 0.9994674412975066, gradient_norm : 0.32614134068123624
[2025-09-19 12:10:32,393][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.923019472964004,  accuracy: 0.5711
[2025-09-19 12:10:37,918][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.0039209955024159015,  accuracy: 0.9998599570534964, gradient_norm : 0.43824713488165723
[2025-09-19 12:10:42,807][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.9371129962833677,  accuracy: 0.569
[2025-09-19 12:10:48,122][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.013592712952145897,  accuracy: 0.9985241730279898, gradient_norm : 0.40628241489618455
[2025-09-19 12:10:52,973][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 1.9491238718824582,  accuracy: 0.566
[2025-09-19 12:10:57,835][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.00680290838138689,  accuracy: 0.9990779692272229, gradient_norm : 0.27715887738373945
[2025-09-19 12:11:02,644][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.9360516664627194,  accuracy: 0.5707
[2025-09-19 12:11:08,182][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.009385611008345658,  accuracy: 0.9990059642147118, gradient_norm : 0.31362656522051885
[2025-09-19 12:11:13,013][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.932344634222014,  accuracy: 0.5747
[2025-09-19 12:11:18,353][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.028153498541061715,  accuracy: 0.9969780649195019, gradient_norm : 0.6791326827062869
[2025-09-19 12:11:23,241][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.8295761467653742,  accuracy: 0.5777
[2025-09-19 12:11:28,200][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.00779032843709006,  accuracy: 0.9994446407835613, gradient_norm : 0.42438927492852924
[2025-09-19 12:11:33,043][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.8519945951788286,  accuracy: 0.5803
[2025-09-19 12:11:38,145][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.001417967040763734,  accuracy: 0.999946024720678, gradient_norm : 0.04209572875202527
[2025-09-19 12:11:43,012][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.8421053595652228,  accuracy: 0.5797
[2025-09-19 12:11:49,412][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.032483169914428824,  accuracy: 0.9981939367877876, gradient_norm : 0.5738356871568314
[2025-09-19 12:11:54,332][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 1.8049584652370922,  accuracy: 0.5815
[2025-09-19 12:11:58,868][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.0016593621259576167,  accuracy: 1.0, gradient_norm : 0.04425589187440448
[2025-09-19 12:12:03,745][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 1.8023813204348607,  accuracy: 0.5811
[2025-09-19 12:12:09,091][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.005366290477689238,  accuracy: 0.9992192786134388, gradient_norm : 0.18402804506466094
[2025-09-19 12:12:14,021][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 1.7677134252394548,  accuracy: 0.5819
[2025-09-19 12:12:19,318][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.006119933355760747,  accuracy: 0.9987605472660533, gradient_norm : 0.15773988042314296
[2025-09-19 12:12:24,249][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 1.7703534860131485,  accuracy: 0.5824
[2025-09-19 12:12:28,998][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.014742953951504406,  accuracy: 0.9989814395654142, gradient_norm : 0.26978056548654483
[2025-09-19 12:12:33,924][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 1.761597802038227,  accuracy: 0.5851
[2025-09-19 12:12:38,812][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.006579429542757016,  accuracy: 0.9995095100550438, gradient_norm : 0.24510189028434662
[2025-09-19 12:12:43,673][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 1.7450313677705669,  accuracy: 0.5842
[2025-09-19 12:12:49,252][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.01618480048009659,  accuracy: 0.9994127147261782, gradient_norm : 0.28633473348510124
[2025-09-19 12:12:54,154][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 1.7320149312920397,  accuracy: 0.5857
[2025-09-19 12:12:59,024][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.022632779893590364,  accuracy: 0.9993188784197979, gradient_norm : 0.611519017850876
[2025-09-19 12:13:03,849][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 1.8048642396259242,  accuracy: 0.58
[2025-09-19 12:13:08,486][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.014424054384879977,  accuracy: 0.9984013772749631, gradient_norm : 0.4235384883403649
[2025-09-19 12:13:13,322][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 1.76952044927656,  accuracy: 0.583
[2025-09-19 12:13:19,224][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.002274989967916637,  accuracy: 0.9999181300912849, gradient_norm : 0.15403393732987003
[2025-09-19 12:13:23,999][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 1.862042871007416,  accuracy: 0.5795
[2025-09-19 12:13:29,505][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.0034151520074686987,  accuracy: 0.9998614190687362, gradient_norm : 0.20206199179556011
[2025-09-19 12:13:34,425][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 1.867119787799646,  accuracy: 0.5778
[2025-09-19 12:13:38,405][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.004420074352514676,  accuracy: 0.9995430212821517, gradient_norm : 0.1887295966594782
[2025-09-19 12:13:43,297][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 1.860976161472473,  accuracy: 0.5802
[2025-09-19 12:13:48,086][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.012643597851327668,  accuracy: 0.9997976118194697, gradient_norm : 0.28729163955879555
[2025-09-19 12:13:52,999][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 1.8761132736276984,  accuracy: 0.5769
[2025-09-19 12:13:57,393][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.010023905347016025,  accuracy: 0.9978316257386025, gradient_norm : 0.08876821918009362
[2025-09-19 12:14:02,255][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 1.82695131850222,  accuracy: 0.5811
[2025-09-19 12:14:06,095][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.0034687978697269632,  accuracy: 0.9998717702122203, gradient_norm : 0.09226682623386365
[2025-09-19 12:14:10,977][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 1.8370385803189797,  accuracy: 0.5801
[2025-09-19 12:14:15,430][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.013404150377760417,  accuracy: 0.9991458345196743, gradient_norm : 0.4986447067201014
[2025-09-19 12:14:20,387][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 1.818468421825211,  accuracy: 0.5826
[2025-09-19 12:14:24,987][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.013530796316398452,  accuracy: 0.9997877308427086, gradient_norm : 0.47570929785856925
[2025-09-19 12:14:29,876][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 1.8159569133952664,  accuracy: 0.5845
[2025-09-19 12:14:34,669][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.007907318329377586,  accuracy: 0.9991229880313661, gradient_norm : 0.3293923277262651
[2025-09-19 12:14:39,686][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 1.7370728662691917,  accuracy: 0.5867
[2025-09-19 12:14:44,001][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.014194067835567953,  accuracy: 0.9995056574755575, gradient_norm : 0.4340622513578989
[2025-09-19 12:14:48,968][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 1.7281959377219973,  accuracy: 0.5899
[2025-09-19 12:14:53,473][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.01020953704731995,  accuracy: 0.9987626546681665, gradient_norm : 0.6036872206130228
[2025-09-19 12:14:58,405][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 1.7983706804170407,  accuracy: 0.5808
[2025-09-19 12:15:03,495][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.010657330168290407,  accuracy: 0.9993069993069993, gradient_norm : 0.36755698077126386
[2025-09-19 12:15:08,355][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 1.7843819757733654,  accuracy: 0.5849
[2025-09-19 12:15:12,234][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.00957061596602549,  accuracy: 0.9983135577907607, gradient_norm : 0.353819025821027
[2025-09-19 12:15:17,147][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 1.7505317186681033,  accuracy: 0.584
[2025-09-19 12:15:22,014][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.02064471061239839,  accuracy: 0.9993189557321226, gradient_norm : 0.671977016574932
[2025-09-19 12:15:26,884][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 1.7588941759054275,  accuracy: 0.585
[2025-09-19 12:15:30,744][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.008700476982159052,  accuracy: 0.9993234100135318, gradient_norm : 0.2828965823793313
[2025-09-19 12:15:35,702][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 1.7419767373775459,  accuracy: 0.5854
[2025-09-19 12:15:39,940][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.004849709890977588,  accuracy: 0.9989446529080676, gradient_norm : 0.23644996103338012
[2025-09-19 12:15:44,851][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 1.7452455977123922,  accuracy: 0.5875
[2025-09-19 12:15:49,217][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.013449097623352297,  accuracy: 0.9993495742667928, gradient_norm : 0.4637172061726833
[2025-09-19 12:15:54,087][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 1.731221410216547,  accuracy: 0.5885
[2025-09-19 12:15:58,712][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.01765828452830785,  accuracy: 0.9997229763421797, gradient_norm : 0.517716551004951
[2025-09-19 12:16:03,618][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 1.7450974392443472,  accuracy: 0.5886
[2025-09-19 12:16:08,826][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.021811991734914042,  accuracy: 0.9996573162970578, gradient_norm : 0.40589570042892475
[2025-09-19 12:16:13,649][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 1.7643503819683763,  accuracy: 0.5861
[2025-09-19 12:16:19,074][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.0009648095860348494,  accuracy: 1.0, gradient_norm : 0.03439541631599467
[2025-09-19 12:16:23,989][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 1.7634676351451617,  accuracy: 0.5868
[2025-09-19 12:16:29,080][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.0011813768561441279,  accuracy: 1.0, gradient_norm : 0.05292550893961772
[2025-09-19 12:16:34,067][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 1.7618144537090643,  accuracy: 0.5858
[2025-09-19 12:16:38,365][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.0018839425251840499,  accuracy: 1.0, gradient_norm : 0.11273113719229537
[2025-09-19 12:16:43,296][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 1.7612515957538144,  accuracy: 0.5859
[2025-09-19 12:16:48,210][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.005614104992306906,  accuracy: 0.999475541146181, gradient_norm : 0.3845895731212872
[2025-09-19 12:16:53,181][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 1.8018048472378085,  accuracy: 0.5835
[2025-09-19 12:16:57,701][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.008017434914897759,  accuracy: 0.9983547219480092, gradient_norm : 0.18969384816424503
[2025-09-19 12:17:02,642][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 1.7765935143247673,  accuracy: 0.5854
[2025-09-19 12:17:07,103][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.0026880844884098714,  accuracy: 0.9998274374460742, gradient_norm : 0.18881532862976547
[2025-09-19 12:17:11,970][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 1.7723295286410983,  accuracy: 0.5845
[2025-09-19 12:17:17,336][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.0019031396500680665,  accuracy: 0.9998563768671007, gradient_norm : 0.07875355946448123
[2025-09-19 12:17:22,311][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 1.7729892458385075,  accuracy: 0.5835
[2025-09-19 12:17:27,105][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.0012251149738024434,  accuracy: 0.9999493029150823, gradient_norm : 0.03616431817616576
[2025-09-19 12:17:32,055][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 1.7723862823997962,  accuracy: 0.5859
[2025-09-19 12:17:36,969][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.026299371126718984,  accuracy: 0.9990778489613668, gradient_norm : 0.35384053515932323
[2025-09-19 12:17:41,932][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 1.7400369094812147,  accuracy: 0.5867
[2025-09-19 12:17:46,101][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.0048907844710860005,  accuracy: 0.9992121021115663, gradient_norm : 0.21848833504299398
[2025-09-19 12:17:51,080][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 1.7492319142374337,  accuracy: 0.5871
[2025-09-19 12:17:55,723][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.0031774710091165476,  accuracy: 0.999794661190965, gradient_norm : 0.19343396950836897
[2025-09-19 12:18:00,606][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 1.7616528995655618,  accuracy: 0.5859
[2025-09-19 12:18:04,652][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.0219009131034965,  accuracy: 0.9992274583379318, gradient_norm : 0.642840872032434
[2025-09-19 12:18:09,730][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 1.8097113301848022,  accuracy: 0.5837
[2025-09-19 12:18:14,133][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.004097680226943415,  accuracy: 0.9997113441739632, gradient_norm : 0.22229606919748016
[2025-09-19 12:18:19,115][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 1.8124644498931746,  accuracy: 0.5835
[2025-09-19 12:18:23,352][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.014787157211264232,  accuracy: 0.9974653508062341, gradient_norm : 0.3404388754674202
[2025-09-19 12:18:28,352][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 1.7942455475962218,  accuracy: 0.5831
[2025-09-19 12:18:32,132][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.0033433255976644126,  accuracy: 0.9990770650669127, gradient_norm : 0.11211173044751847
[2025-09-19 12:18:37,106][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 1.7822966252536352,  accuracy: 0.5857
[2025-09-19 12:18:41,153][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.005405208127180552,  accuracy: 0.9996109165693958, gradient_norm : 0.35340314381822246
[2025-09-19 12:18:46,031][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 1.7788368862252275,  accuracy: 0.5857
[2025-09-19 12:18:50,419][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.010261905756100415,  accuracy: 0.9997981938348216, gradient_norm : 0.26572394406721966
[2025-09-19 12:18:55,417][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 1.7700003862184155,  accuracy: 0.584
[2025-09-19 12:18:59,647][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.005695688385190403,  accuracy: 0.999447929736512, gradient_norm : 0.31844135525347145
[2025-09-19 12:19:04,632][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 1.8058442813925808,  accuracy: 0.5845
[2025-09-19 12:19:09,187][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.013983789502482755,  accuracy: 0.9998073403333012, gradient_norm : 0.4582753052504513
[2025-09-19 12:19:14,146][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 1.8038864388061144,  accuracy: 0.5832
[2025-09-19 12:19:17,899][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.005207113560532772,  accuracy: 0.9997523526498266, gradient_norm : 0.26249300699125305
[2025-09-19 12:19:22,899][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 1.7931918474837722,  accuracy: 0.5852
[2025-09-19 12:19:27,037][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.022367665758106694,  accuracy: 0.9996363636363637, gradient_norm : 0.33026463733174216
[2025-09-19 12:19:31,918][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 1.8114466047724664,  accuracy: 0.5837
[2025-09-19 12:19:35,845][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.0029226742562822915,  accuracy: 0.9997686791579922, gradient_norm : 0.15254207190873187
[2025-09-19 12:19:40,798][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 1.8113553124163415,  accuracy: 0.5845
[2025-09-19 12:19:45,025][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.0012759927653244205,  accuracy: 1.0, gradient_norm : 0.06815665781756235
[2025-09-19 12:19:49,984][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 1.810701879474788,  accuracy: 0.5838
[2025-09-19 12:19:54,337][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.013858100304714988,  accuracy: 0.9994942854253059, gradient_norm : 0.2460049696654664
[2025-09-19 12:19:59,305][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 1.9474861936329424,  accuracy: 0.5775
[2025-09-19 12:20:03,236][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.015624105024658528,  accuracy: 0.9984665189981258, gradient_norm : 0.3923677498925697
[2025-09-19 12:20:08,194][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 1.933563317655927,  accuracy: 0.5786
[2025-09-19 12:20:12,213][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.026904664473521724,  accuracy: 0.9994644132349441, gradient_norm : 0.5844296658295935
[2025-09-19 12:20:17,093][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 1.8178725142204715,  accuracy: 0.5807
[2025-09-19 12:20:21,832][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.006219560259768604,  accuracy: 0.9996438565250573, gradient_norm : 0.34509930113846965
[2025-09-19 12:20:26,766][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 1.7968569227964024,  accuracy: 0.5844
[2025-09-19 12:20:31,187][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.009779772952936352,  accuracy: 0.9997334612719229, gradient_norm : 0.29926960663117724
[2025-09-19 12:20:36,116][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 1.8105025155737344,  accuracy: 0.5852
[2025-09-19 12:20:39,551][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.0009179485844963116,  accuracy: 1.0, gradient_norm : 0.031102934049264522
[2025-09-19 12:20:44,526][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 1.8132581508542134,  accuracy: 0.5844
[2025-09-19 12:20:48,466][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.016462977651174215,  accuracy: 0.9998288159771754, gradient_norm : 0.3207512272200991
[2025-09-19 12:20:53,437][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 1.8334023586439792,  accuracy: 0.5829
[2025-09-19 12:20:57,091][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.018902119570993477,  accuracy: 0.9993636247931781, gradient_norm : 0.42824319794327076
[2025-09-19 12:21:01,983][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 1.878084085593101,  accuracy: 0.5823
[2025-09-19 12:21:07,382][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.017139863191395106,  accuracy: 0.998342118687298, gradient_norm : 0.5451094824232928
[2025-09-19 12:21:12,310][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 2.018083887270335,  accuracy: 0.5721
[2025-09-19 12:21:15,996][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.01463994566030661,  accuracy: 0.9977648906608675, gradient_norm : 0.4949038910899824
[2025-09-19 12:21:20,290][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 1.8418596856263274,  accuracy: 0.5814
[2025-09-19 12:21:23,736][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.0028770248763487632,  accuracy: 0.9999401269309065, gradient_norm : 0.27465509307721186
[2025-09-19 12:21:27,999][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 1.8566857240757189,  accuracy: 0.5788
[2025-09-19 12:21:31,540][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.0168464501478875,  accuracy: 0.9997622585438336, gradient_norm : 0.2626675475693366
[2025-09-19 12:21:35,854][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 1.8608803635664763,  accuracy: 0.5812
[2025-09-19 12:21:39,625][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.002496569533083681,  accuracy: 0.999573401589079, gradient_norm : 0.14687549778723547
[2025-09-19 12:21:43,967][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 1.8518245802728648,  accuracy: 0.5819
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 001: loss=1.7032, accuracy=0.4326, gradient_norm=1.7907, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 002: loss=1.7186, accuracy=0.3985, gradient_norm=1.3216, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 003: loss=1.5101, accuracy=0.4708, gradient_norm=1.2881, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 004: loss=1.3688, accuracy=0.5267, gradient_norm=1.2203, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 005: loss=1.3208, accuracy=0.5270, gradient_norm=1.3578, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 006: loss=1.1544, accuracy=0.6009, gradient_norm=1.3791, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 007: loss=1.3842, accuracy=0.5204, gradient_norm=1.5457, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 008: loss=0.9940, accuracy=0.6611, gradient_norm=1.3121, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 009: loss=1.0518, accuracy=0.6388, gradient_norm=1.3742, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 010: loss=0.9925, accuracy=0.6656, gradient_norm=1.4661, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 011: loss=0.7679, accuracy=0.7420, gradient_norm=1.3811, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 012: loss=0.7018, accuracy=0.7718, gradient_norm=1.4711, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 013: loss=0.7829, accuracy=0.7463, gradient_norm=1.2931, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 014: loss=0.7038, accuracy=0.7729, gradient_norm=1.5235, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 015: loss=0.6217, accuracy=0.8040, gradient_norm=1.6307, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 016: loss=0.4669, accuracy=0.8592, gradient_norm=1.3400, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 017: loss=0.4947, accuracy=0.8605, gradient_norm=1.3994, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 018: loss=0.5606, accuracy=0.8307, gradient_norm=1.5092, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 019: loss=0.2751, accuracy=0.9289, gradient_norm=1.1030, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 020: loss=0.1917, accuracy=0.9538, gradient_norm=1.2418, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 021: loss=0.3110, accuracy=0.9138, gradient_norm=1.1439, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 022: loss=0.3486, accuracy=0.9099, gradient_norm=1.4426, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 023: loss=0.3327, accuracy=0.9043, gradient_norm=1.0264, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 024: loss=0.1209, accuracy=0.9717, gradient_norm=0.7532, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 025: loss=0.2062, accuracy=0.9415, gradient_norm=0.7045, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 026: loss=0.2442, accuracy=0.9297, gradient_norm=0.7744, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 027: loss=0.1245, accuracy=0.9683, gradient_norm=0.6422, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 028: loss=0.1756, accuracy=0.9495, gradient_norm=0.5979, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 029: loss=0.1569, accuracy=0.9585, gradient_norm=0.7646, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 030: loss=0.0930, accuracy=0.9809, gradient_norm=0.7678, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 031: loss=0.0941, accuracy=0.9758, gradient_norm=0.7752, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 032: loss=0.1360, accuracy=0.9705, gradient_norm=0.7529, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 033: loss=0.1232, accuracy=0.9704, gradient_norm=0.5961, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 034: loss=0.0835, accuracy=0.9812, gradient_norm=0.4965, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 035: loss=0.0374, accuracy=0.9961, gradient_norm=0.4811, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 036: loss=0.0497, accuracy=0.9925, gradient_norm=0.5918, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 037: loss=0.0661, accuracy=0.9841, gradient_norm=0.3635, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 038: loss=0.0728, accuracy=0.9814, gradient_norm=0.4810, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 039: loss=0.0570, accuracy=0.9885, gradient_norm=0.5061, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 040: loss=0.0505, accuracy=0.9896, gradient_norm=0.3674, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 041: loss=0.0360, accuracy=0.9942, gradient_norm=0.5809, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 042: loss=0.0450, accuracy=0.9909, gradient_norm=0.5918, 
[2025-09-19 12:21:43,968][__main__][INFO] - Train, Round 043: loss=0.0469, accuracy=0.9895, gradient_norm=0.3314, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 044: loss=0.0350, accuracy=0.9925, gradient_norm=0.2459, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 045: loss=0.0713, accuracy=0.9839, gradient_norm=0.7462, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 046: loss=0.0210, accuracy=0.9979, gradient_norm=0.3345, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 047: loss=0.0363, accuracy=0.9931, gradient_norm=0.4580, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 048: loss=0.0399, accuracy=0.9905, gradient_norm=0.4513, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 049: loss=0.0745, accuracy=0.9870, gradient_norm=0.5505, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 050: loss=0.0126, accuracy=0.9993, gradient_norm=0.2669, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 051: loss=0.0219, accuracy=0.9961, gradient_norm=0.2576, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 052: loss=0.0118, accuracy=0.9996, gradient_norm=0.4739, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 053: loss=0.0127, accuracy=0.9981, gradient_norm=0.1899, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 054: loss=0.0291, accuracy=0.9956, gradient_norm=0.4643, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 055: loss=0.0304, accuracy=0.9973, gradient_norm=0.8136, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 056: loss=0.0184, accuracy=0.9971, gradient_norm=0.4052, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 057: loss=0.0567, accuracy=0.9863, gradient_norm=0.5488, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 058: loss=0.0311, accuracy=0.9924, gradient_norm=0.3198, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 059: loss=0.0249, accuracy=0.9986, gradient_norm=0.5065, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 060: loss=0.0449, accuracy=0.9939, gradient_norm=0.6691, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 061: loss=0.0126, accuracy=0.9987, gradient_norm=0.2914, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 062: loss=0.0173, accuracy=0.9968, gradient_norm=0.2537, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 063: loss=0.0088, accuracy=0.9991, gradient_norm=0.1353, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 064: loss=0.0166, accuracy=0.9978, gradient_norm=0.2974, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 065: loss=0.0436, accuracy=0.9920, gradient_norm=0.6032, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 066: loss=0.0208, accuracy=0.9962, gradient_norm=0.3674, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 067: loss=0.0200, accuracy=0.9965, gradient_norm=0.4293, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 068: loss=0.0283, accuracy=0.9945, gradient_norm=0.3757, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 069: loss=0.0129, accuracy=0.9986, gradient_norm=0.2636, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 070: loss=0.0393, accuracy=0.9971, gradient_norm=0.6365, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 071: loss=0.0073, accuracy=0.9995, gradient_norm=0.1679, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 072: loss=0.0071, accuracy=0.9996, gradient_norm=0.2506, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 073: loss=0.0296, accuracy=0.9952, gradient_norm=0.4866, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 074: loss=0.0079, accuracy=0.9998, gradient_norm=0.2898, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 075: loss=0.0140, accuracy=0.9978, gradient_norm=0.3248, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 076: loss=0.0090, accuracy=0.9994, gradient_norm=0.4694, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 077: loss=0.0088, accuracy=0.9988, gradient_norm=0.1817, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 078: loss=0.0233, accuracy=0.9958, gradient_norm=0.3133, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 079: loss=0.0069, accuracy=0.9994, gradient_norm=0.2915, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 080: loss=0.0082, accuracy=0.9992, gradient_norm=0.1985, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 081: loss=0.0086, accuracy=0.9994, gradient_norm=0.3698, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 082: loss=0.0041, accuracy=0.9998, gradient_norm=0.1953, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 083: loss=0.0057, accuracy=0.9996, gradient_norm=0.1503, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 084: loss=0.0066, accuracy=0.9995, gradient_norm=0.2242, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 085: loss=0.0092, accuracy=0.9987, gradient_norm=0.3411, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 086: loss=0.0133, accuracy=0.9974, gradient_norm=0.2646, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 087: loss=0.0035, accuracy=0.9999, gradient_norm=0.1100, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 088: loss=0.0056, accuracy=1.0000, gradient_norm=0.3345, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 089: loss=0.0035, accuracy=0.9998, gradient_norm=0.0857, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 090: loss=0.0101, accuracy=0.9984, gradient_norm=0.1498, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 091: loss=0.0066, accuracy=0.9996, gradient_norm=0.2820, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 092: loss=0.0112, accuracy=0.9995, gradient_norm=0.5287, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 093: loss=0.0069, accuracy=0.9995, gradient_norm=0.2988, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 094: loss=0.0059, accuracy=0.9999, gradient_norm=0.3765, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 095: loss=0.0139, accuracy=0.9990, gradient_norm=0.5719, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 096: loss=0.0029, accuracy=0.9999, gradient_norm=0.0984, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 097: loss=0.0186, accuracy=0.9993, gradient_norm=0.6070, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 098: loss=0.0211, accuracy=0.9983, gradient_norm=0.4953, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 099: loss=0.0026, accuracy=1.0000, gradient_norm=0.0913, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 100: loss=0.0173, accuracy=0.9996, gradient_norm=0.5668, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 101: loss=0.0045, accuracy=0.9996, gradient_norm=0.1161, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 102: loss=0.0208, accuracy=0.9982, gradient_norm=0.6119, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 103: loss=0.0039, accuracy=0.9998, gradient_norm=0.1181, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 104: loss=0.0165, accuracy=0.9986, gradient_norm=0.3235, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 105: loss=0.0057, accuracy=0.9993, gradient_norm=0.3345, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 106: loss=0.0050, accuracy=0.9993, gradient_norm=0.1684, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 107: loss=0.0018, accuracy=1.0000, gradient_norm=0.0447, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 108: loss=0.0092, accuracy=0.9998, gradient_norm=0.3678, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 109: loss=0.0036, accuracy=0.9999, gradient_norm=0.2580, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 110: loss=0.0073, accuracy=0.9996, gradient_norm=0.3016, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 111: loss=0.0110, accuracy=0.9994, gradient_norm=0.4213, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 112: loss=0.0202, accuracy=0.9986, gradient_norm=0.6253, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 113: loss=0.0037, accuracy=0.9999, gradient_norm=0.2477, 
[2025-09-19 12:21:43,969][__main__][INFO] - Train, Round 114: loss=0.0073, accuracy=0.9990, gradient_norm=0.3585, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 115: loss=0.0018, accuracy=1.0000, gradient_norm=0.0875, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 116: loss=0.0198, accuracy=0.9990, gradient_norm=0.5799, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 117: loss=0.0028, accuracy=1.0000, gradient_norm=0.2206, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 118: loss=0.0105, accuracy=0.9994, gradient_norm=0.4747, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 119: loss=0.0286, accuracy=0.9969, gradient_norm=0.5674, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 120: loss=0.0136, accuracy=0.9975, gradient_norm=0.4934, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 121: loss=0.0200, accuracy=0.9995, gradient_norm=0.3088, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 122: loss=0.0067, accuracy=0.9995, gradient_norm=0.4312, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 123: loss=0.0202, accuracy=0.9988, gradient_norm=0.4822, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 124: loss=0.0130, accuracy=0.9987, gradient_norm=0.2875, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 125: loss=0.0016, accuracy=0.9999, gradient_norm=0.0572, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 126: loss=0.0045, accuracy=0.9998, gradient_norm=0.2808, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 127: loss=0.0233, accuracy=0.9991, gradient_norm=0.6749, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 128: loss=0.0037, accuracy=0.9999, gradient_norm=0.2285, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 129: loss=0.0053, accuracy=0.9995, gradient_norm=0.3261, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 130: loss=0.0039, accuracy=0.9999, gradient_norm=0.4382, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 131: loss=0.0136, accuracy=0.9985, gradient_norm=0.4063, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 132: loss=0.0068, accuracy=0.9991, gradient_norm=0.2772, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 133: loss=0.0094, accuracy=0.9990, gradient_norm=0.3136, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 134: loss=0.0282, accuracy=0.9970, gradient_norm=0.6791, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 135: loss=0.0078, accuracy=0.9994, gradient_norm=0.4244, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 136: loss=0.0014, accuracy=0.9999, gradient_norm=0.0421, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 137: loss=0.0325, accuracy=0.9982, gradient_norm=0.5738, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 138: loss=0.0017, accuracy=1.0000, gradient_norm=0.0443, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 139: loss=0.0054, accuracy=0.9992, gradient_norm=0.1840, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 140: loss=0.0061, accuracy=0.9988, gradient_norm=0.1577, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 141: loss=0.0147, accuracy=0.9990, gradient_norm=0.2698, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 142: loss=0.0066, accuracy=0.9995, gradient_norm=0.2451, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 143: loss=0.0162, accuracy=0.9994, gradient_norm=0.2863, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 144: loss=0.0226, accuracy=0.9993, gradient_norm=0.6115, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 145: loss=0.0144, accuracy=0.9984, gradient_norm=0.4235, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 146: loss=0.0023, accuracy=0.9999, gradient_norm=0.1540, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 147: loss=0.0034, accuracy=0.9999, gradient_norm=0.2021, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 148: loss=0.0044, accuracy=0.9995, gradient_norm=0.1887, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 149: loss=0.0126, accuracy=0.9998, gradient_norm=0.2873, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 150: loss=0.0100, accuracy=0.9978, gradient_norm=0.0888, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 151: loss=0.0035, accuracy=0.9999, gradient_norm=0.0923, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 152: loss=0.0134, accuracy=0.9991, gradient_norm=0.4986, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 153: loss=0.0135, accuracy=0.9998, gradient_norm=0.4757, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 154: loss=0.0079, accuracy=0.9991, gradient_norm=0.3294, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 155: loss=0.0142, accuracy=0.9995, gradient_norm=0.4341, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 156: loss=0.0102, accuracy=0.9988, gradient_norm=0.6037, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 157: loss=0.0107, accuracy=0.9993, gradient_norm=0.3676, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 158: loss=0.0096, accuracy=0.9983, gradient_norm=0.3538, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 159: loss=0.0206, accuracy=0.9993, gradient_norm=0.6720, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 160: loss=0.0087, accuracy=0.9993, gradient_norm=0.2829, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 161: loss=0.0048, accuracy=0.9989, gradient_norm=0.2364, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 162: loss=0.0134, accuracy=0.9993, gradient_norm=0.4637, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 163: loss=0.0177, accuracy=0.9997, gradient_norm=0.5177, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 164: loss=0.0218, accuracy=0.9997, gradient_norm=0.4059, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 165: loss=0.0010, accuracy=1.0000, gradient_norm=0.0344, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 166: loss=0.0012, accuracy=1.0000, gradient_norm=0.0529, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 167: loss=0.0019, accuracy=1.0000, gradient_norm=0.1127, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 168: loss=0.0056, accuracy=0.9995, gradient_norm=0.3846, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 169: loss=0.0080, accuracy=0.9984, gradient_norm=0.1897, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 170: loss=0.0027, accuracy=0.9998, gradient_norm=0.1888, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 171: loss=0.0019, accuracy=0.9999, gradient_norm=0.0788, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 172: loss=0.0012, accuracy=0.9999, gradient_norm=0.0362, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 173: loss=0.0263, accuracy=0.9991, gradient_norm=0.3538, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 174: loss=0.0049, accuracy=0.9992, gradient_norm=0.2185, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 175: loss=0.0032, accuracy=0.9998, gradient_norm=0.1934, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 176: loss=0.0219, accuracy=0.9992, gradient_norm=0.6428, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 177: loss=0.0041, accuracy=0.9997, gradient_norm=0.2223, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 178: loss=0.0148, accuracy=0.9975, gradient_norm=0.3404, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 179: loss=0.0033, accuracy=0.9991, gradient_norm=0.1121, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 180: loss=0.0054, accuracy=0.9996, gradient_norm=0.3534, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 181: loss=0.0103, accuracy=0.9998, gradient_norm=0.2657, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 182: loss=0.0057, accuracy=0.9994, gradient_norm=0.3184, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 183: loss=0.0140, accuracy=0.9998, gradient_norm=0.4583, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 184: loss=0.0052, accuracy=0.9998, gradient_norm=0.2625, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 185: loss=0.0224, accuracy=0.9996, gradient_norm=0.3303, 
[2025-09-19 12:21:43,970][__main__][INFO] - Train, Round 186: loss=0.0029, accuracy=0.9998, gradient_norm=0.1525, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 187: loss=0.0013, accuracy=1.0000, gradient_norm=0.0682, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 188: loss=0.0139, accuracy=0.9995, gradient_norm=0.2460, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 189: loss=0.0156, accuracy=0.9985, gradient_norm=0.3924, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 190: loss=0.0269, accuracy=0.9995, gradient_norm=0.5844, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 191: loss=0.0062, accuracy=0.9996, gradient_norm=0.3451, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 192: loss=0.0098, accuracy=0.9997, gradient_norm=0.2993, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 193: loss=0.0009, accuracy=1.0000, gradient_norm=0.0311, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 194: loss=0.0165, accuracy=0.9998, gradient_norm=0.3208, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 195: loss=0.0189, accuracy=0.9994, gradient_norm=0.4282, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 196: loss=0.0171, accuracy=0.9983, gradient_norm=0.5451, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 197: loss=0.0146, accuracy=0.9978, gradient_norm=0.4949, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 198: loss=0.0029, accuracy=0.9999, gradient_norm=0.2747, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 199: loss=0.0168, accuracy=0.9998, gradient_norm=0.2627, 
[2025-09-19 12:21:43,971][__main__][INFO] - Train, Round 200: loss=0.0025, accuracy=0.9996, gradient_norm=0.1469, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 001: loss=2.0948, accuracy=0.2158, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 002: loss=1.9628, accuracy=0.2744, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 003: loss=1.8871, accuracy=0.3174, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 004: loss=1.8439, accuracy=0.3480, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 005: loss=1.8141, accuracy=0.3682, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 006: loss=1.8370, accuracy=0.3843, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 007: loss=1.7920, accuracy=0.4181, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 008: loss=1.7799, accuracy=0.4284, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 009: loss=1.7349, accuracy=0.4447, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 010: loss=1.7535, accuracy=0.4487, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 011: loss=1.7683, accuracy=0.4518, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 012: loss=1.9501, accuracy=0.4669, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 013: loss=1.8995, accuracy=0.4778, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 014: loss=1.8250, accuracy=0.4911, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 015: loss=1.8385, accuracy=0.4905, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 016: loss=1.7653, accuracy=0.5048, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 017: loss=1.9045, accuracy=0.5008, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 018: loss=1.9036, accuracy=0.4966, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 019: loss=1.8178, accuracy=0.5036, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 020: loss=1.8020, accuracy=0.5110, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 021: loss=1.7288, accuracy=0.5157, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 022: loss=1.7122, accuracy=0.5186, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 023: loss=1.7567, accuracy=0.5161, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 024: loss=1.6853, accuracy=0.5302, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 025: loss=1.6843, accuracy=0.5425, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 026: loss=1.7338, accuracy=0.5349, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 027: loss=1.7218, accuracy=0.5411, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 028: loss=1.6956, accuracy=0.5463, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 029: loss=1.6702, accuracy=0.5589, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 030: loss=1.6393, accuracy=0.5551, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 031: loss=1.6579, accuracy=0.5583, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 032: loss=1.7754, accuracy=0.5475, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 033: loss=1.8144, accuracy=0.5464, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 034: loss=1.8345, accuracy=0.5464, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 035: loss=1.8163, accuracy=0.5474, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 036: loss=1.8033, accuracy=0.5511, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 037: loss=1.8748, accuracy=0.5520, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 038: loss=1.8186, accuracy=0.5536, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 039: loss=1.8645, accuracy=0.5539, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 040: loss=1.8220, accuracy=0.5605, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 041: loss=1.8441, accuracy=0.5578, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 042: loss=1.7427, accuracy=0.5607, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 043: loss=1.7509, accuracy=0.5632, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 044: loss=1.7783, accuracy=0.5585, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 045: loss=1.7867, accuracy=0.5585, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 046: loss=1.7714, accuracy=0.5652, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 047: loss=1.7770, accuracy=0.5625, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 048: loss=1.9498, accuracy=0.5594, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 049: loss=1.7959, accuracy=0.5656, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 050: loss=1.7885, accuracy=0.5639, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 051: loss=1.7872, accuracy=0.5646, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 052: loss=1.9527, accuracy=0.5582, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 053: loss=1.7840, accuracy=0.5640, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 054: loss=1.7744, accuracy=0.5655, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 055: loss=2.0053, accuracy=0.5521, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 056: loss=1.9346, accuracy=0.5537, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 057: loss=1.9285, accuracy=0.5633, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 058: loss=1.7286, accuracy=0.5727, 
[2025-09-19 12:21:43,971][__main__][INFO] - Test, Round 059: loss=1.7268, accuracy=0.5724, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 060: loss=1.7303, accuracy=0.5734, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 061: loss=1.7712, accuracy=0.5657, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 062: loss=1.7676, accuracy=0.5694, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 063: loss=1.7801, accuracy=0.5724, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 064: loss=1.7627, accuracy=0.5752, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 065: loss=1.7899, accuracy=0.5758, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 066: loss=1.7954, accuracy=0.5715, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 067: loss=1.7420, accuracy=0.5766, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 068: loss=1.7169, accuracy=0.5777, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 069: loss=1.7342, accuracy=0.5783, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 070: loss=1.7246, accuracy=0.5797, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 071: loss=1.7243, accuracy=0.5774, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 072: loss=1.7176, accuracy=0.5787, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 073: loss=1.7370, accuracy=0.5768, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 074: loss=1.8816, accuracy=0.5692, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 075: loss=1.7155, accuracy=0.5789, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 076: loss=1.7273, accuracy=0.5797, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 077: loss=1.6962, accuracy=0.5814, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 078: loss=1.7244, accuracy=0.5794, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 079: loss=1.7269, accuracy=0.5792, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 080: loss=1.7199, accuracy=0.5798, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 081: loss=1.7264, accuracy=0.5784, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 082: loss=1.7150, accuracy=0.5794, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 083: loss=1.7183, accuracy=0.5795, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 084: loss=1.7171, accuracy=0.5816, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 085: loss=1.7098, accuracy=0.5799, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 086: loss=1.6664, accuracy=0.5846, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 087: loss=1.6666, accuracy=0.5851, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 088: loss=1.6779, accuracy=0.5835, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 089: loss=1.6723, accuracy=0.5842, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 090: loss=1.6764, accuracy=0.5840, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 091: loss=1.6761, accuracy=0.5828, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 092: loss=1.6980, accuracy=0.5800, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 093: loss=1.7057, accuracy=0.5806, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 094: loss=1.7075, accuracy=0.5799, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 095: loss=1.7325, accuracy=0.5753, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 096: loss=1.7234, accuracy=0.5776, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 097: loss=1.7158, accuracy=0.5812, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 098: loss=1.7667, accuracy=0.5731, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 099: loss=1.7583, accuracy=0.5737, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 100: loss=1.7939, accuracy=0.5688, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 101: loss=1.7755, accuracy=0.5703, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 102: loss=1.7388, accuracy=0.5797, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 103: loss=1.7212, accuracy=0.5842, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 104: loss=1.7262, accuracy=0.5788, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 105: loss=1.7167, accuracy=0.5791, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 106: loss=1.7017, accuracy=0.5817, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 107: loss=1.7000, accuracy=0.5816, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 108: loss=1.7431, accuracy=0.5793, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 109: loss=1.7442, accuracy=0.5800, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 110: loss=1.7420, accuracy=0.5805, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 111: loss=1.7792, accuracy=0.5793, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 112: loss=1.7787, accuracy=0.5799, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 113: loss=1.7561, accuracy=0.5814, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 114: loss=1.7489, accuracy=0.5826, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 115: loss=1.7517, accuracy=0.5831, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 116: loss=1.7922, accuracy=0.5803, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 117: loss=1.8051, accuracy=0.5782, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 118: loss=1.8159, accuracy=0.5787, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 119: loss=1.7845, accuracy=0.5813, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 120: loss=1.7479, accuracy=0.5801, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 121: loss=1.7595, accuracy=0.5783, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 122: loss=1.7439, accuracy=0.5798, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 123: loss=1.7303, accuracy=0.5809, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 124: loss=1.7200, accuracy=0.5820, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 125: loss=1.7164, accuracy=0.5814, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 126: loss=1.7163, accuracy=0.5802, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 127: loss=1.8955, accuracy=0.5716, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 128: loss=1.8982, accuracy=0.5729, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 129: loss=1.9230, accuracy=0.5711, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 130: loss=1.9371, accuracy=0.5690, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 131: loss=1.9491, accuracy=0.5660, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 132: loss=1.9361, accuracy=0.5707, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 133: loss=1.9323, accuracy=0.5747, 
[2025-09-19 12:21:43,972][__main__][INFO] - Test, Round 134: loss=1.8296, accuracy=0.5777, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 135: loss=1.8520, accuracy=0.5803, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 136: loss=1.8421, accuracy=0.5797, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 137: loss=1.8050, accuracy=0.5815, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 138: loss=1.8024, accuracy=0.5811, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 139: loss=1.7677, accuracy=0.5819, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 140: loss=1.7704, accuracy=0.5824, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 141: loss=1.7616, accuracy=0.5851, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 142: loss=1.7450, accuracy=0.5842, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 143: loss=1.7320, accuracy=0.5857, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 144: loss=1.8049, accuracy=0.5800, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 145: loss=1.7695, accuracy=0.5830, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 146: loss=1.8620, accuracy=0.5795, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 147: loss=1.8671, accuracy=0.5778, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 148: loss=1.8610, accuracy=0.5802, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 149: loss=1.8761, accuracy=0.5769, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 150: loss=1.8270, accuracy=0.5811, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 151: loss=1.8370, accuracy=0.5801, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 152: loss=1.8185, accuracy=0.5826, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 153: loss=1.8160, accuracy=0.5845, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 154: loss=1.7371, accuracy=0.5867, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 155: loss=1.7282, accuracy=0.5899, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 156: loss=1.7984, accuracy=0.5808, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 157: loss=1.7844, accuracy=0.5849, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 158: loss=1.7505, accuracy=0.5840, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 159: loss=1.7589, accuracy=0.5850, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 160: loss=1.7420, accuracy=0.5854, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 161: loss=1.7452, accuracy=0.5875, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 162: loss=1.7312, accuracy=0.5885, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 163: loss=1.7451, accuracy=0.5886, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 164: loss=1.7644, accuracy=0.5861, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 165: loss=1.7635, accuracy=0.5868, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 166: loss=1.7618, accuracy=0.5858, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 167: loss=1.7613, accuracy=0.5859, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 168: loss=1.8018, accuracy=0.5835, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 169: loss=1.7766, accuracy=0.5854, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 170: loss=1.7723, accuracy=0.5845, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 171: loss=1.7730, accuracy=0.5835, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 172: loss=1.7724, accuracy=0.5859, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 173: loss=1.7400, accuracy=0.5867, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 174: loss=1.7492, accuracy=0.5871, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 175: loss=1.7617, accuracy=0.5859, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 176: loss=1.8097, accuracy=0.5837, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 177: loss=1.8125, accuracy=0.5835, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 178: loss=1.7942, accuracy=0.5831, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 179: loss=1.7823, accuracy=0.5857, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 180: loss=1.7788, accuracy=0.5857, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 181: loss=1.7700, accuracy=0.5840, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 182: loss=1.8058, accuracy=0.5845, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 183: loss=1.8039, accuracy=0.5832, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 184: loss=1.7932, accuracy=0.5852, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 185: loss=1.8114, accuracy=0.5837, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 186: loss=1.8114, accuracy=0.5845, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 187: loss=1.8107, accuracy=0.5838, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 188: loss=1.9475, accuracy=0.5775, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 189: loss=1.9336, accuracy=0.5786, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 190: loss=1.8179, accuracy=0.5807, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 191: loss=1.7969, accuracy=0.5844, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 192: loss=1.8105, accuracy=0.5852, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 193: loss=1.8133, accuracy=0.5844, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 194: loss=1.8334, accuracy=0.5829, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 195: loss=1.8781, accuracy=0.5823, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 196: loss=2.0181, accuracy=0.5721, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 197: loss=1.8419, accuracy=0.5814, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 198: loss=1.8567, accuracy=0.5788, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 199: loss=1.8609, accuracy=0.5812, 
[2025-09-19 12:21:43,973][__main__][INFO] - Test, Round 200: loss=1.8518, accuracy=0.5819, 

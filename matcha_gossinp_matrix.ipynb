{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30609c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "def decomposition(graph, size):\n",
    "    node_degree = [[i, 0] for i in range(size)]\n",
    "    node_to_node = [[] for i in range(size)]\n",
    "    node_degree_dict = collections.defaultdict(int)\n",
    "    node_set = set()\n",
    "    for edge in graph:\n",
    "        node1, node2 = edge[0], edge[1]\n",
    "        node_degree[node1][1] += 1\n",
    "        node_degree[node2][1] += 1\n",
    "        if node1 in node_to_node[node2] or node2 in node_to_node[node1]:\n",
    "            print(\"Invalid input graph! Double edge! (\"+str(node1) +\", \"+ str(node2)+\")\")\n",
    "            exit()\n",
    "        if node1 == node2:\n",
    "            print(\"Invalid input graph! Circle! (\"+str(node1) +\", \"+ str(node2)+\")\")\n",
    "            exit()\n",
    "\n",
    "        node_to_node[node1].append(node2)\n",
    "        node_to_node[node2].append(node1)\n",
    "        node_degree_dict[node1] += 1\n",
    "        node_degree_dict[node2] += 1\n",
    "        node_set.add(node1)\n",
    "        node_set.add(node2)\n",
    "\n",
    "    node_degree = sorted(node_degree, key = lambda x: x[1])\n",
    "    node_degree[:] = node_degree[::-1]\n",
    "    subgraphs = []\n",
    "    min_num = node_degree[0][1]\n",
    "    while node_set:\n",
    "        subgraph = []\n",
    "        for i in range(size):\n",
    "            node1, node1_degree = node_degree[i]\n",
    "            if node1 not in node_set:\n",
    "                continue\n",
    "            for j in range(i+1, size):\n",
    "                node2, node2_degree = node_degree[j]\n",
    "                if node2 in node_set and node2 in node_to_node[node1]:\n",
    "                    subgraph.append((node1, node2))\n",
    "                    node_degree[j][1] -= 1\n",
    "                    node_degree[i][1] -= 1\n",
    "                    node_degree_dict[node1] -= 1\n",
    "                    node_degree_dict[node2] -= 1\n",
    "                    node_to_node[node1].remove(node2)\n",
    "                    node_to_node[node2].remove(node1)\n",
    "                    node_set.remove(node1)\n",
    "                    node_set.remove(node2)\n",
    "                    break\n",
    "        subgraphs.append(subgraph)\n",
    "        for node in node_degree_dict:\n",
    "            if node_degree_dict[node] > 0:\n",
    "                node_set.add(node)\n",
    "        node_degree = sorted(node_degree, key = lambda x: x[1])\n",
    "        node_degree[:] = node_degree[::-1]\n",
    "    return subgraphs\n",
    "\n",
    "def getSubGraphs(graph, size):\n",
    "    subgraphs = list()\n",
    "    for i in range(80-1):\n",
    "        M1 = nx.max_weight_matching(graph)\n",
    "    if nx.is_perfect_matching(graph, M1):\n",
    "        graph.remove_edges_from(list(M1))\n",
    "        subgraphs.append(list(M1))\n",
    "    else:\n",
    "        edge_list = list(graph.edges)\n",
    "        random.shuffle(edge_list)\n",
    "        graph.remove_edges_from(edge_list)\n",
    "        graph.add_edges_from(edge_list)\n",
    "\n",
    "    # use greedy algorithm to decomposes the remaining part\n",
    "    rpart = decomposition(list(graph.edges), size)\n",
    "    for sgraph in rpart:\n",
    "        subgraphs.append(sgraph)\n",
    "    return subgraphs\n",
    "\n",
    "        \n",
    "def graphToLaplacian(subGraphs, size):\n",
    "    L_matrices = list()\n",
    "    for i, subgraph in enumerate(subGraphs):\n",
    "        tmp_G = nx.Graph()\n",
    "        tmp_G.add_edges_from(subgraph)\n",
    "        tmp_G.add_nodes_from(range(size)) \n",
    "        L_matrices.append(nx.laplacian_matrix(tmp_G, nodelist=list(range(size))).todense())\n",
    "\n",
    "    return L_matrices\n",
    "    \n",
    "def getProbability(L_matrices, commBudget):\n",
    "    num_subgraphs = len(L_matrices)\n",
    "    p = cp.Variable(num_subgraphs)\n",
    "    L = p[0]*L_matrices[0]\n",
    "    for i in range(num_subgraphs-1):\n",
    "        L += p[i+1]*L_matrices[i+1]\n",
    "    eig = cp.lambda_sum_smallest(L, 2)\n",
    "    sum_p = p[0]\n",
    "    for i in range(num_subgraphs-1):\n",
    "        sum_p += p[i+1]\n",
    "\n",
    "    # cvx optimization for activation probabilities\n",
    "    obj_fn = eig\n",
    "    constraint = [sum_p <= num_subgraphs*commBudget, p>=0, p<=1]\n",
    "    problem = cp.Problem(cp.Maximize(obj_fn), constraint)\n",
    "    problem.solve(solver='CVXOPT', kktsolver=cp.ROBUST_KKTSOLVER)\n",
    "\n",
    "    # get solution\n",
    "    tmp_p = p.value\n",
    "    originActivationRatio = np.zeros((num_subgraphs))\n",
    "    for i, pval in enumerate(tmp_p):\n",
    "        originActivationRatio[i] = np.real(float(pval))\n",
    "\n",
    "    return np.minimum(originActivationRatio, 1) \n",
    "\n",
    "def getAlpha(L_matrices, probabilities, num_nodes):\n",
    "    num_subgraphs = len(L_matrices)\n",
    "    \n",
    "    # prepare matrices\n",
    "    I = np.eye(num_nodes)\n",
    "    J = np.ones((num_nodes, num_nodes))/num_nodes\n",
    "\n",
    "    mean_L = np.zeros((num_nodes,num_nodes))\n",
    "    var_L = np.zeros((num_nodes,num_nodes))\n",
    "    for i in range(num_subgraphs):\n",
    "        val = probabilities[i]\n",
    "        mean_L += L_matrices[i]*val\n",
    "        var_L += L_matrices[i]*(1-val)*val\n",
    "\n",
    "    # SDP for mixing weight\n",
    "    a = cp.Variable()\n",
    "    b = cp.Variable()\n",
    "    s = cp.Variable()\n",
    "    obj_fn = s\n",
    "    constraint = [(1-s)*I - 2*a*mean_L-J + b*(np.dot(mean_L,mean_L)+2*var_L) << 0, a>=0, s>=0, b>=0, cp.square(a) <= b]\n",
    "    problem = cp.Problem(cp.Minimize(obj_fn), constraint)\n",
    "    problem.solve(solver='CVXOPT', kktsolver=cp.ROBUST_KKTSOLVER)\n",
    "\n",
    "    return  float(a.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba25d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(5, 0)],\n",
       " [(0, 1), (5, 6)],\n",
       " [(5, 9), (0, 4)],\n",
       " [(0, 2), (5, 7)],\n",
       " [(8, 5), (3, 0)]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "G = pickle.load(open('two_clusters/2025-09-26/11-03-55/graph.pickle', 'rb'))\n",
    "subgraphs = list()\n",
    "\n",
    "# first try to get as many maximal matchings as possiblez\n",
    "for i in range(80-1):\n",
    "    M1 = nx.max_weight_matching(G)\n",
    "    if nx.is_perfect_matching(G, M1):\n",
    "        G.remove_edges_from(list(M1))\n",
    "        subgraphs.append(list(M1))\n",
    "    else:\n",
    "        edge_list = list(G.edges)\n",
    "        random.shuffle(edge_list)\n",
    "        G.remove_edges_from(edge_list)\n",
    "        G.add_edges_from(edge_list)\n",
    "\n",
    "# use greedy algorithm to decompose the remaining part\n",
    "rpart = decomposition(list(G.edges), 80)\n",
    "for sgraph in rpart:\n",
    "    subgraphs.append(sgraph)\n",
    "subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 2]\n",
      " [0 5]\n",
      " [0 3]\n",
      " [0 4]\n",
      " [5 9]\n",
      " [5 8]\n",
      " [5 7]\n",
      " [5 6]]\n",
      "[[0 1]\n",
      " [0 2]\n",
      " [0 5]\n",
      " [0 3]\n",
      " [0 4]\n",
      " [5 9]\n",
      " [5 8]\n",
      " [5 7]\n",
      " [5 6]]\n",
      "[1 2 3 4 5 9 5 8 5 7 5 6]\n"
     ]
    }
   ],
   "source": [
    "edges = list(G.edges())\n",
    "print(edges)\n",
    "#probs = [data.get('probability_selection', 0) for _, _, data in graph.edges(data=True)]\n",
    "#idxs = [idx for idx in range(len(edges)) if np.random.random() < probs[idx]]\n",
    "max_degree = sorted(max(G.degree, key=lambda x: x[1]))\n",
    "center_node_1, center_node_2 = max_degree\n",
    "active_edges = []\n",
    "if np.random.random() < 0.2:\n",
    "    active_edges.append((center_node_1, center_node_2))\n",
    "print(edges)\n",
    "print(edges[~(edges == [center_node_1, center_node_2])])\n",
    "# idxs = np.random.choice(len(edges), int(participation_rate * len(edges)), replace=False)\n",
    "# active_edges = np.concatenate((active_edges, edges[idxs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dd242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "laplacians = graphToLaplacian(subgraphs, size)\n",
    "probas = getProbability(laplacians, 2/5)\n",
    "alpha = getAlpha(laplacians, probas, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09bdbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = list()\n",
    "fraction_activated = dict()\n",
    "for _ in range(100):\n",
    "    L_k = np.sum([laplacians[i] for i in range(len(subgraphs)) if np.random.random() < probas[i]], axis=0)\n",
    "    W = np.eye(size) - alpha * L_k \n",
    "    mask =  ~np.eye(W.shape[0], dtype=bool)\n",
    "    non_zero_indices  = np.nonzero(W * mask)\n",
    "    nodes_involved = set(non_zero_indices[0]) | set(non_zero_indices[1])\n",
    "    for node in nodes_involved:\n",
    "        if not node in fraction_activated:\n",
    "            fraction_activated[node] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762edc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): 1,\n",
       " np.int64(5): 1,\n",
       " np.int64(2): 1,\n",
       " np.int64(3): 1,\n",
       " np.int64(7): 1,\n",
       " np.int64(8): 1,\n",
       " np.int64(1): 1,\n",
       " np.int64(6): 1,\n",
       " np.int64(4): 1,\n",
       " np.int64(9): 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction_activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca4535c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0), np.int64(5)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_involved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

nohup: ignoring input
data:
  name: cifar10
  root: ./data
  batch_size: 10
  num_workers: 1
model:
  name: lenet5
  latent_dimension: 1600
  num_classes: 10
  in_channels: 3
  batch_norm: false
partition:
  name: dirichlet
  num_clients: 40
  strategy: dirichlet
  dirichlet_alpha: 0.05
  min_partition_size: 1
client:
  learning_rate: 0.01
  weight_decay: 0.0001
  momentum: 0.9
train:
  rounds: 1000
  local_epochs: 3
  progress: true
  participation_rate: 0.4
  lr_decay: 0.992
graph:
  name: two_clusters
  topology: two_clusters
seed: 42
use_cuda: true
mixing_matrix: metropolis_hasting
run_name: fedavg_dirichlet
consensus_lr: 0.001
old_gradients: false
same_distrib_test_set: false

[2025-10-02 16:07:08,012][__main__][INFO] - Train, Round 0 : gradient_norm : 1.2315555184987603
[2025-10-02 16:07:33,306][__main__][INFO] - Train, Round 0 : loss => 2.3038437222464014,  accuracy: 0.10444
[2025-10-02 16:07:33,307][__main__][INFO] - Test, Round 0 : loss => 2.3036209003181205,  accuracy: 0.1071, std: 0.030907443809097185
[2025-10-02 16:07:39,913][__main__][INFO] - Train, Round 1 : gradient_norm : 1.295647247858847
[2025-10-02 16:08:05,097][__main__][INFO] - Train, Round 1 : loss => 2.3038545898908622,  accuracy: 0.10582
[2025-10-02 16:08:05,097][__main__][INFO] - Test, Round 1 : loss => 2.303624087837851,  accuracy: 0.1075, std: 0.03102287777290334
[2025-10-02 16:08:11,955][__main__][INFO] - Train, Round 2 : gradient_norm : 1.2099263134618798
[2025-10-02 16:08:37,048][__main__][INFO] - Train, Round 2 : loss => 2.3044767613522863,  accuracy: 0.09986
[2025-10-02 16:08:37,048][__main__][INFO] - Test, Round 2 : loss => 2.3042480383708965,  accuracy: 0.0999, std: 0.028829632460586452
[2025-10-02 16:08:43,277][__main__][INFO] - Train, Round 3 : gradient_norm : 1.1433970494373205
[2025-10-02 16:09:08,529][__main__][INFO] - Train, Round 3 : loss => 2.304683105791636,  accuracy: 0.09996
[2025-10-02 16:09:08,529][__main__][INFO] - Test, Round 3 : loss => 2.3044049436119725,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:09:15,326][__main__][INFO] - Train, Round 4 : gradient_norm : 0.9563533261945639
[2025-10-02 16:09:40,669][__main__][INFO] - Train, Round 4 : loss => 2.3045663642993377,  accuracy: 0.09994
[2025-10-02 16:09:40,670][__main__][INFO] - Test, Round 4 : loss => 2.3043565188243877,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:09:46,868][__main__][INFO] - Train, Round 5 : gradient_norm : 1.711930073024463
[2025-10-02 16:10:12,120][__main__][INFO] - Train, Round 5 : loss => 2.3051153879775224,  accuracy: 0.1
[2025-10-02 16:10:12,120][__main__][INFO] - Test, Round 5 : loss => 2.3048792675042615,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:10:17,242][__main__][INFO] - Train, Round 6 : gradient_norm : 1.3324925792685713
[2025-10-02 16:10:42,580][__main__][INFO] - Train, Round 6 : loss => 2.3054887248194817,  accuracy: 0.1
[2025-10-02 16:10:42,581][__main__][INFO] - Test, Round 6 : loss => 2.3053203464313667,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:10:48,193][__main__][INFO] - Train, Round 7 : gradient_norm : 1.395110361074394
[2025-10-02 16:11:13,407][__main__][INFO] - Train, Round 7 : loss => 2.3059850132699493,  accuracy: 0.1
[2025-10-02 16:11:13,408][__main__][INFO] - Test, Round 7 : loss => 2.3057969846543247,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:11:19,296][__main__][INFO] - Train, Round 8 : gradient_norm : 1.4080691776654126
[2025-10-02 16:11:44,576][__main__][INFO] - Train, Round 8 : loss => 2.3059037086112304,  accuracy: 0.1
[2025-10-02 16:11:44,576][__main__][INFO] - Test, Round 8 : loss => 2.30567501760592,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:11:50,797][__main__][INFO] - Train, Round 9 : gradient_norm : 1.0922550347323887
[2025-10-02 16:12:16,097][__main__][INFO] - Train, Round 9 : loss => 2.3058489689923256,  accuracy: 0.1
[2025-10-02 16:12:16,097][__main__][INFO] - Test, Round 9 : loss => 2.305547097685991,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:12:21,792][__main__][INFO] - Train, Round 10 : gradient_norm : 1.5544372138422466
[2025-10-02 16:12:46,992][__main__][INFO] - Train, Round 10 : loss => 2.3061782153152803,  accuracy: 0.1
[2025-10-02 16:12:46,992][__main__][INFO] - Test, Round 10 : loss => 2.3058941926166523,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:12:52,651][__main__][INFO] - Train, Round 11 : gradient_norm : 1.0961934594301623
[2025-10-02 16:13:17,918][__main__][INFO] - Train, Round 11 : loss => 2.3064113595275266,  accuracy: 0.1
[2025-10-02 16:13:17,918][__main__][INFO] - Test, Round 11 : loss => 2.305976156975815,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:13:24,265][__main__][INFO] - Train, Round 12 : gradient_norm : 1.4601847835347077
[2025-10-02 16:13:49,581][__main__][INFO] - Train, Round 12 : loss => 2.3063846816570037,  accuracy: 0.09996
[2025-10-02 16:13:49,582][__main__][INFO] - Test, Round 12 : loss => 2.3060391192223637,  accuracy: 0.0998, std: 0.028800773969634912
[2025-10-02 16:13:55,547][__main__][INFO] - Train, Round 13 : gradient_norm : 1.2787748886953192
[2025-10-02 16:14:20,731][__main__][INFO] - Train, Round 13 : loss => 2.3060523386765075,  accuracy: 0.0998
[2025-10-02 16:14:20,732][__main__][INFO] - Test, Round 13 : loss => 2.3058144286939295,  accuracy: 0.0993, std: 0.028656481514877225
[2025-10-02 16:14:27,406][__main__][INFO] - Train, Round 14 : gradient_norm : 1.3252098660778786
[2025-10-02 16:14:52,568][__main__][INFO] - Train, Round 14 : loss => 2.3065161925253803,  accuracy: 0.10044
[2025-10-02 16:14:52,568][__main__][INFO] - Test, Round 14 : loss => 2.306066710478183,  accuracy: 0.10199999999999998, std: 0.029435660770568747
[2025-10-02 16:14:59,807][__main__][INFO] - Train, Round 15 : gradient_norm : 1.3552993103964563
[2025-10-02 16:15:24,992][__main__][INFO] - Train, Round 15 : loss => 2.3069234825558973,  accuracy: 0.11534
[2025-10-02 16:15:24,992][__main__][INFO] - Test, Round 15 : loss => 2.306506844842512,  accuracy: 0.1177, std: 0.03396644384996021
[2025-10-02 16:15:31,859][__main__][INFO] - Train, Round 16 : gradient_norm : 1.2266281596875384
[2025-10-02 16:15:57,186][__main__][INFO] - Train, Round 16 : loss => 2.306750277194258,  accuracy: 0.12352
[2025-10-02 16:15:57,186][__main__][INFO] - Test, Round 16 : loss => 2.3062956940596258,  accuracy: 0.1282, std: 0.036996585399871704
[2025-10-02 16:16:03,822][__main__][INFO] - Train, Round 17 : gradient_norm : 1.3435422815551685
[2025-10-02 16:16:29,037][__main__][INFO] - Train, Round 17 : loss => 2.3075171939155723,  accuracy: 0.10782
[2025-10-02 16:16:29,038][__main__][INFO] - Test, Round 17 : loss => 2.30715036544071,  accuracy: 0.1091, std: 0.03148461362812795
[2025-10-02 16:16:35,258][__main__][INFO] - Train, Round 18 : gradient_norm : 1.1638870313616734
[2025-10-02 16:17:00,527][__main__][INFO] - Train, Round 18 : loss => 2.307466748751765,  accuracy: 0.10558
[2025-10-02 16:17:00,527][__main__][INFO] - Test, Round 18 : loss => 2.3071677654412137,  accuracy: 0.1081, std: 0.031196028718612566
[2025-10-02 16:17:06,738][__main__][INFO] - Train, Round 19 : gradient_norm : 1.2078577566755249
[2025-10-02 16:17:32,107][__main__][INFO] - Train, Round 19 : loss => 2.307303687802339,  accuracy: 0.11106
[2025-10-02 16:17:32,107][__main__][INFO] - Test, Round 19 : loss => 2.3069728286403,  accuracy: 0.1135, std: 0.032754387229995616
[2025-10-02 16:17:38,670][__main__][INFO] - Train, Round 20 : gradient_norm : 1.5336428946679865
[2025-10-02 16[2025-10-02 16:18:13,767][__main__][INFO] - Train, Round 20 : loss => 2.3044048828273835,  accuracy: 0.10506
[2025-10-02 16:18:13,768][__main__][INFO] - Test, Round 20 : loss => 2.304246875131205,  accuracy: 0.1114, std: 0.032155897519934036
[2025-10-02 16:18:23,202][__main__][INFO] - Train, Round 21 : gradient_norm : 1.5902861322972468[[2025-10-02 16:19:12,008][__main__][INFO] - Train, Round 21 : loss => 2.304791670232774,  accuracy: 0.09832
[2025-10-02 16:19:12,008][__main__][INFO] - Test, Round 21 : loss => 2.304483213242448,  accuracy: 0.1043, std: 0.03010646419505494
[2025-10-02 16:19:21,120][__main__][INFO] - Train, Round 22 : gradient_norm : 1.9360630874017013
[2025-10-02 16:20:39,089][__main__][INFO] - Train, Round 22 : loss => 2.305553820612849,  accuracy: 0.10796
[2025-10-02 16:20:39,090][__main__][INFO] - Test, Round 22 : loss => 2.305184760670755,  accuracy: 0.1079, std: 0.03114561348654293
[2025-10-02 16:20:53,072][__main__][INFO] - Train, Round 23 : gradient_norm : 1.9197407087261096
[2025-10-02 16:21:42,185][__main__][INFO] - Train, Round 23 : loss => 2.3055205581194795,  accuracy: 0.10554
[2025-10-02 16:21:42,185][__main__][INFO] - Test, Round 23 : loss => 2.3051818495343444,  accuracy: 0.105, std: 0.03030852100173316
[2025-10-02 16:21:52,143][__main__][INFO] - Train, Round 24 : gradient_norm : 1.9436299863652886
[2025-10-02 16:22:41,098][__main__][INFO] - Train, Round 24 : loss => 2.305331949220053,  accuracy: 0.086
[2025-10-02 16:22:41,098][__main__][INFO] - Test, Round 24 : loss => 2.3049531013343003,  accuracy: 0.0888, std: 0.02563234919003719
[2025-10-02 16:22:51,862][__main__][INFO] - Train, Round 25 : gradient_norm : 1.5443470441268856
[2025-10-02 16:23:40,942][__main__][INFO] - Train, Round 25 : loss => 2.304991530949701,  accuracy: 0.08154
[2025-10-02 16:23:40,942][__main__][INFO] - Test, Round 25 : loss => 2.3047027344916255,  accuracy: 0.0851, std: 0.024564334640452306
[2025-10-02 16:23:51,730][__main__][INFO] - Train, Round 26 : gradient_norm : 1.5421955183645644
[2025-10-02 16:24:40,852][__main__][INFO] - Train, Round 26 : loss => 2.3050451383644543,  accuracy: 0.10328
[2025-10-02 16:24:40,852][__main__][INFO] - Test, Round 26 : loss => 2.304773790821152,  accuracy: 0.103, std: 0.029731215839795384
[2025-10-02 16:24:50,763][__main__][INFO] - Train, Round 27 : gradient_norm : 2.159081271062241
[2025-10-02 16:25:40,016][__main__][INFO] - Train, Round 27 : loss => 2.3049171696642157,  accuracy: 0.07692
[2025-10-02 16:25:40,016][__main__][INFO] - Test, Round 27 : loss => 2.304511612387979,  accuracy: 0.0806, std: 0.02326539802609231
[2025-10-02 16:25:50,184][__main__][INFO] - Train, Round 28 : gradient_norm : 1.7454071550173083
[2025-10-02 16:26:39,350][__main__][INFO] - Train, Round 28 : loss => 2.304080686852939,  accuracy: 0.0991
[2025-10-02 16:26:39,350][__main__][INFO] - Test, Round 28 : loss => 2.3037192426669395,  accuracy: 0.1003, std: 0.02895185387117939
[2025-10-02 16:26:49,305][__main__][INFO] - Train, Round 29 : gradient_norm : 1.626289846264255
[2025-10-02 16:27:38,414][__main__][INFO] - Train, Round 29 : loss => 2.3039275193858724,  accuracy: 0.0828
[2025-10-02 16:27:38,414][__main__][INFO] - Test, Round 29 : loss => 2.3035922703469636,  accuracy: 0.0847, std: 0.024448873608064747
[2025-10-02 16:27:48,223][__main__][INFO] - Train, Round 30 : gradient_norm : 1.749604485750682
[2025-10-02 16:28:37,332][__main__][INFO] - Train, Round 30 : loss => 2.303755426442427,  accuracy: 0.08786
[2025-10-02 16:28:37,333][__main__][INFO] - Test, Round 30 : loss => 2.3036155685497683,  accuracy: 0.0892, std: 0.02574781022242474
[2025-10-02 16:28:47,560][__main__][INFO] - Train, Round 31 : gradient_norm : 1.6907136821758046
[2025-10-02 16:29:36,472][__main__][INFO] - Train, Round 31 : loss => 2.3038707003265007,  accuracy: 0.08206
[2025-10-02 16:29:36,472][__main__][INFO] - Test, Round 31 : loss => 2.3035973151018627,  accuracy: 0.0819, std: 0.023640646381351865
[2025-10-02 16:29:46,486][__main__][INFO] - Train, Round 32 : gradient_norm : 2.0860090120792885
[2025-10-02 16:30:35,589][__main__][INFO] - Train, Round 32 : loss => 2.3045113685483156,  accuracy: 0.08874
[2025-10-02 16:30:35,590][__main__][INFO] - Test, Round 32 : loss => 2.304320991418925,  accuracy: 0.08699999999999998, std: 0.025112774544293188
[2025-10-02 16:30:45,390][__main__][INFO] - Train, Round 33 : gradient_norm : 1.8115163341656249
[2025-10-02 16:31:34,538][__main__][INFO] - Train, Round 33 : loss => 2.3042547656598846,  accuracy: 0.09204
[2025-10-02 16:31:34,538][__main__][INFO] - Test, Round 33 : loss => 2.304046682491427,  accuracy: 0.0886, std: 0.02557461867384341
[2025-10-02 16:31:44,380][__main__][INFO] - Train, Round 34 : gradient_norm : 1.5937635167606112
[2025-10-02 16:32:33,574][__main__][INFO] - Train, Round 34 : loss => 2.304626422944031,  accuracy: 0.08772
[2025-10-02 16:32:33,574][__main__][INFO] - Test, Round 34 : loss => 2.3046383371778316,  accuracy: 0.0871, std: 0.02514163980239008
[2025-10-02 16:32:43,919][__main__][INFO] - Train, Round 35 : gradient_norm : 2.178405366041341
[2025-10-02 16:33:32,976][__main__][INFO] - Train, Round 35 : loss => 2.3038790720705666,  accuracy: 0.07914
[2025-10-02 16:33:32,976][__main__][INFO] - Test, Round 35 : loss => 2.3034344888796503,  accuracy: 0.0803, std: 0.023178802251801644
[2025-10-02 16:33:43,702][__main__][INFO] - Train, Round 36 : gradient_norm : 1.6273907778087573
[2025-10-02 16:34:33,171][__main__][INFO] - Train, Round 36 : loss => 2.304146218300366,  accuracy: 0.08284
[2025-10-02 16:34:33,171][__main__][INFO] - Test, Round 36 : loss => 2.3038356941976357,  accuracy: 0.0849, std: 0.02450660412425853
[2025-10-02 16:34:43,757][__main__][INFO] - Train, Round 37 : gradient_norm : 1.7236409963960702
[2025-10-02 16:35:32,953][__main__][INFO] - Train, Round 37 : loss => 2.3038487339193665,  accuracy: 0.09646
[2025-10-02 16:35:32,953][__main__][INFO] - Test, Round 37 : loss => 2.303584517946671,  accuracy: 0.0978, std: 0.02823022241875717
[2025-10-02 16:35:42,930][__main__][INFO] - Train, Round 38 : gradient_norm : 1.2534826301626254
[2025-10-02 16:36:31,897][__main__][INFO] - Train, Round 38 : loss => 2.3039952740412186,  accuracy: 0.09584
[2025-10-02 16:36:31,897][__main__][INFO] - Test, Round 38 : loss => 2.303611738666611,  accuracy: 0.09710000000000002, std: 0.028028165612078958
[2025-10-02 16:36:41,623][__main__][INFO] - Train, Round 39 : gradient_norm : 1.6809703236852915
main__][INFO] - Train, Round 39 : loss => 2.3074340422100086,  accuracy: 0.0966
[2025-10-02 16:28:03,626][__main__][INFO] - Test, Round 39 : loss => 2.3072001827750235,  accuracy: 0.097, std: 0.02799273622299185
[2025-10-02 16:28:10,410][__main__][INFO] - Train, Round 40 : gradient_norm : 1.4101139441266475
[2025-10-02 16:28:35,641][__main__][INFO] - Train, Round 40 : loss => 2.308414890877745,  accuracy: 0.09926
[2025-10-02 16:28:35,641][__main__][INFO] - Test, Round 40 : loss => 2.308211587796546,  accuracy: 0.09859999999999998, std: 0.028454472078216452
[2025-10-02 16:28:42,447][__main__][INFO] - Train, Round 41 : gradient_norm : 1.213932279714901
[2025-10-02 16:29:07,661][__main__][INFO] - Train, Round 41 : loss => 2.308620326794447,  accuracy: 0.09996
[2025-10-02 16:29:07,661][__main__][INFO] - Test, Round 41 : loss => 2.308519557782798,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:29:14,021][__main__][INFO] - Train, Round 42 : gradient_norm : 1.141378848757862
[2025-10-02 16:29:39,243][__main__][INFO] - Train, Round 42 : loss => 2.309386288623304,  accuracy: 0.1
[2025-10-02 16:29:39,243][__main__][INFO] - Test, Round 42 : loss => 2.3092647342924852,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:29:46,023][__main__][INFO] - Train, Round 43 : gradient_norm : 1.5713047024275433
[2025-10-02 16:30:11,306][__main__][INFO] - Train, Round 43 : loss => 2.3089104331532755,  accuracy: 0.1
[2025-10-02 16:30:11,306][__main__][INFO] - Test, Round 43 : loss => 2.3086328688700477,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:30:17,537][__main__][INFO] - Train, Round 44 : gradient_norm : 1.664021402387238
[2025-10-02 16:30:42,746][__main__][INFO] - Train, Round 44 : loss => 2.3078205413567576,  accuracy: 0.09996
[2025-10-02 16:30:42,747][__main__][INFO] - Test, Round 44 : loss => 2.3075928475446763,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:30:48,585][__main__][INFO] - Train, Round 45 : gradient_norm : 1.668497627614485
[2025-10-02 16:31:13,707][__main__][INFO] - Train, Round 45 : loss => 2.3084956845631264,  accuracy: 0.1
[2025-10-02 16:31:13,708][__main__][INFO] - Test, Round 45 : loss => 2.3082451243309445,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:31:19,604][__main__][INFO] - Train, Round 46 : gradient_norm : 1.7024461488799345
[2025-10-02 16:31:44,955][__main__][INFO] - Train, Round 46 : loss => 2.311446042149015,  accuracy: 0.1
[2025-10-02 16:31:44,955][__main__][INFO] - Test, Round 46 : loss => 2.311282935415861,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:31:51,025][__main__][INFO] - Train, Round 47 : gradient_norm : 1.4534397040526368
[2025-10-02 16:32:16,260][__main__][INFO] - Train, Round 47 : loss => 2.311065267749998,  accuracy: 0.1
[2025-10-02 16:32:16,261][__main__][INFO] - Test, Round 47 : loss => 2.3110642387608795,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:32:22,860][__main__][INFO] - Train, Round 48 : gradient_norm : 2.245871129493606
[2025-10-02 16:32:48,241][__main__][INFO] - Train, Round 48 : loss => 2.307410793178181,  accuracy: 0.1
[2025-10-02 16:32:48,242][__main__][INFO] - Test, Round 48 : loss => 2.3072530327329206,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:32:55,260][__main__][INFO] - Train, Round 49 : gradient_norm : 1.1921815710863677
[2025-10-02 16:33:20,431][__main__][INFO] - Train, Round 49 : loss => 2.3076536524336473,  accuracy: 0.1
[2025-10-02 16:33:20,431][__main__][INFO] - Test, Round 49 : loss => 2.3076231464458865,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:33:26,356][__main__][INFO] - Train, Round 50 : gradient_norm : 1.6258586207289183
[2025-10-02 16:33:51,699][__main__][INFO] - Train, Round 50 : loss => 2.3074608007701554,  accuracy: 0.1
[2025-10-02 16:33:51,700][__main__][INFO] - Test, Round 50 : loss => 2.307495592506067,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:33:58,834][__main__][INFO] - Train, Round 51 : gradient_norm : 1.2814892358297825
[2025-10-02 16:34:24,173][__main__][INFO] - Train, Round 51 : loss => 2.3073015983605005,  accuracy: 0.1
[2025-10-02 16:34:24,173][__main__][INFO] - Test, Round 51 : loss => 2.3073286281269834,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:34:30,839][__main__][INFO] - Train, Round 52 : gradient_norm : 1.3577210771945303
[2025-10-02 16:34:56,146][__main__][INFO] - Train, Round 52 : loss => 2.307319217014971,  accuracy: 0.1
[2025-10-02 16:34:56,147][__main__][INFO] - Test, Round 52 : loss => 2.3073241923265395,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:35:01,702][__main__][INFO] - Train, Round 53 : gradient_norm : 1.3926542819386154
[2025-10-02 16:35:26,970][__main__][INFO] - Train, Round 53 : loss => 2.3093048558793203,  accuracy: 0.1
[2025-10-02 16:35:26,971][__main__][INFO] - Test, Round 53 : loss => 2.309146964625947,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:35:32,676][__main__][INFO] - Train, Round 54 : gradient_norm : 1.387017236562924
[2025-10-02 16:35:57,988][__main__][INFO] - Train, Round 54 : loss => 2.3078333760825265,  accuracy: 0.1
[2025-10-02 16:35:57,988][__main__][INFO] - Test, Round 54 : loss => 2.307825506113135,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:36:03,488][__main__][INFO] - Train, Round 55 : gradient_norm : 1.7246486953356026
[2025-10-02 16:36:28,720][__main__][INFO] - Train, Round 55 : loss => 2.3109220121533975,  accuracy: 0.1
[2025-10-02 16:36:28,721][__main__][INFO] - Test, Round 55 : loss => 2.310886492395098,  accuracy: 0.1, std: 0.028858490951537988
[2025-10-02 16:36:35,694][__main__][INFO] - Train, Round 56 : gradient_norm : 1.337270555128779

[2025-09-18 18:11:11,560][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.2563964236792318,  accuracy: 0.2520437158469945, gradient_norm : 0.8587341046633894
[2025-09-18 18:11:17,453][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.23193106944561,  accuracy: 0.3448
[2025-09-18 18:11:34,756][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.1750288330949843,  accuracy: 0.4315833333333334, gradient_norm : 0.9003482409800753
[2025-09-18 18:11:40,723][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.145958695089817,  accuracy: 0.4512
[2025-09-18 18:11:57,953][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 2.0818102611278095,  accuracy: 0.5115449735449734, gradient_norm : 1.0660688946685877
[2025-09-18 18:12:04,069][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.0198428282499314,  accuracy: 0.5105
[2025-09-18 18:12:21,355][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.894878249667171,  accuracy: 0.5383915343915343, gradient_norm : 1.357398734437556
[2025-09-18 18:12:27,355][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 1.8025592904958874,  accuracy: 0.544
[2025-09-18 18:12:45,412][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.5959323573624715,  accuracy: 0.5548181818181818, gradient_norm : 1.5516492736096232
[2025-09-18 18:12:51,573][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 1.509158907327149,  accuracy: 0.5572
[2025-09-18 18:13:09,913][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 1.3296095667874896,  accuracy: 0.5617611940298507, gradient_norm : 1.3381994252937246
[2025-09-18 18:13:16,073][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 1.2693965901136863,  accuracy: 0.5858
[2025-09-18 18:13:32,693][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.1817845402023521,  accuracy: 0.5949333333333333, gradient_norm : 1.181301229095816
[2025-09-18 18:13:38,698][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.0848343278624584,  accuracy: 0.5958
[2025-09-18 18:13:56,311][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 0.9159392448248884,  accuracy: 0.6081458333333333, gradient_norm : 0.9427376165369802
[2025-09-18 18:14:02,557][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 0.9403480218417011,  accuracy: 0.6143
[2025-09-18 18:14:21,226][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 0.8456465607544925,  accuracy: 0.6280099502487563, gradient_norm : 0.8695611958280131
[2025-09-18 18:14:27,396][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 0.7988872031670995,  accuracy: 0.6277
[2025-09-18 18:14:46,214][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 0.7283879525714961,  accuracy: 0.6398921568627451, gradient_norm : 0.6219307667069113
[2025-09-18 18:14:52,314][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 0.7235029456694727,  accuracy: 0.6457
[2025-09-18 18:15:08,713][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 0.6485583158910383,  accuracy: 0.6531299435028247, gradient_norm : 0.4421814058456678
[2025-09-18 18:15:14,865][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 0.6940928049937822,  accuracy: 0.659
[2025-09-18 18:15:32,187][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 0.6733101828354576,  accuracy: 0.655268817204301, gradient_norm : 0.431412422656322
[2025-09-18 18:15:38,331][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 0.6588309479619842,  accuracy: 0.666
[2025-09-18 18:15:55,203][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 0.6167148749379622,  accuracy: 0.6832111111111111, gradient_norm : 0.3665366190309412
[2025-09-18 18:16:01,324][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 0.641048378307221,  accuracy: 0.6739
[2025-09-18 18:16:18,180][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 0.5966448599454854,  accuracy: 0.6888555555555554, gradient_norm : 0.3425335450886411
[2025-09-18 18:16:24,314][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 0.6258429894645117,  accuracy: 0.6735
[2025-09-18 18:16:40,047][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 0.6465390350790369,  accuracy: 0.6551547619047619, gradient_norm : 0.3334366828245106
[2025-09-18 18:16:46,113][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 0.6138971780811203,  accuracy: 0.676
[2025-09-18 18:17:04,257][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 0.5895063658468492,  accuracy: 0.6816562499999999, gradient_norm : 0.27385891032185017
[2025-09-18 18:17:10,490][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 0.6061074748725513,  accuracy: 0.6841
[2025-09-18 18:17:28,712][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 0.6135229212509541,  accuracy: 0.680471794871795, gradient_norm : 0.3259485525156172
[2025-09-18 18:17:34,903][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 0.5933440447349684,  accuracy: 0.684
[2025-09-18 18:17:51,566][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 0.5889691997400935,  accuracy: 0.6899887005649717, gradient_norm : 0.3251102908527359
[2025-09-18 18:17:57,822][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 0.5788302788063651,  accuracy: 0.6945
[2025-09-18 18:18:15,308][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 0.5545660337272609,  accuracy: 0.7127407407407408, gradient_norm : 0.27653799295524706
[2025-09-18 18:18:21,410][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 0.5714609331364103,  accuracy: 0.7028
[2025-09-18 18:18:39,933][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 0.5340117370777246,  accuracy: 0.72269696969697, gradient_norm : 0.2657533620197306
[2025-09-18 18:18:46,108][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 0.5675263227733609,  accuracy: 0.7049
[2025-09-18 18:19:02,815][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 0.5187994154733488,  accuracy: 0.7308361581920906, gradient_norm : 0.27666686014490655
[2025-09-18 18:19:09,028][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 0.5552621350449335,  accuracy: 0.7003
[2025-09-18 18:19:26,794][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 0.5287082556478228,  accuracy: 0.7306349206349206, gradient_norm : 0.2793583961634358
[2025-09-18 18:19:32,967][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 0.5466297557716491,  accuracy: 0.7053
[2025-09-18 18:19:49,176][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 0.5143106409138047,  accuracy: 0.7271264367816089, gradient_norm : 0.24407500812517818
[2025-09-18 18:19:55,327][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 0.5427153423493263,  accuracy: 0.7112
[2025-09-18 18:20:13,351][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 0.5234359468841621,  accuracy: 0.7272820512820514, gradient_norm : 0.24916147357690946
[2025-09-18 18:20:19,583][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 0.5378946981661342,  accuracy: 0.7152
[2025-09-18 18:20:37,232][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 0.5201339449606609,  accuracy: 0.7292698412698413, gradient_norm : 0.2589270631126146
[2025-09-18 18:20:43,415][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 0.5344340125074785,  accuracy: 0.7164
[2025-09-18 18:21:00,542][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 0.5160526143183154,  accuracy: 0.7266885245901636, gradient_norm : 0.24404586729965874
[2025-09-18 18:21:06,644][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 0.5307330264158809,  accuracy: 0.7212
[2025-09-18 18:21:24,223][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 0.5149035233289444,  accuracy: 0.7389100529100532, gradient_norm : 0.25417379227755715
[2025-09-18 18:21:30,425][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 0.5266398766945786,  accuracy: 0.7212
[2025-09-18 18:21:46,075][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 0.5136511517871225,  accuracy: 0.7331309523809524, gradient_norm : 0.24519416781819567
[2025-09-18 18:21:52,192][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 0.5236055855932471,  accuracy: 0.7222
[2025-09-18 18:22:09,185][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 0.5049332846838545,  accuracy: 0.7412786885245903, gradient_norm : 0.2616921340643451
[2025-09-18 18:22:15,322][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 0.5221402663139044,  accuracy: 0.7232
[2025-09-18 18:22:30,634][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 0.483925734695169,  accuracy: 0.7525939393939395, gradient_norm : 0.2241188492127405
[2025-09-18 18:22:36,705][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 0.520237935271184,  accuracy: 0.7262
[2025-09-18 18:22:52,437][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 0.5212235310101645,  accuracy: 0.732233918128655, gradient_norm : 0.2490751953113855
[2025-09-18 18:22:58,487][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 0.5134318633659161,  accuracy: 0.7326
[2025-09-18 18:23:16,228][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 0.4813471706185244,  accuracy: 0.7608125, gradient_norm : 0.24687643266385742
[2025-09-18 18:23:22,341][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 0.5091166965999553,  accuracy: 0.731
[2025-09-18 18:23:40,230][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 0.4760469299811138,  accuracy: 0.7622604166666668, gradient_norm : 0.2599029952207089
[2025-09-18 18:23:46,343][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 0.5054153720165486,  accuracy: 0.7346
[2025-09-18 18:24:03,828][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 0.460299208897138,  accuracy: 0.767037037037037, gradient_norm : 0.23996578217519052
[2025-09-18 18:24:10,008][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 0.5018019560765926,  accuracy: 0.7381
[2025-09-18 18:24:26,537][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 0.5119982142369134,  accuracy: 0.7416271186440677, gradient_norm : 0.2635524492135358
[2025-09-18 18:24:32,649][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 0.4993052367455661,  accuracy: 0.7381
[2025-09-18 18:24:50,424][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 0.4677274563432738,  accuracy: 0.7632708333333331, gradient_norm : 0.24066867944259906
[2025-09-18 18:24:56,469][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 0.4922910910319886,  accuracy: 0.7463
[2025-09-18 18:25:12,948][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 0.45558630458975313,  accuracy: 0.769943502824859, gradient_norm : 0.24027810411642928
[2025-09-18 18:25:19,138][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 0.4907299721207906,  accuracy: 0.7462
[2025-09-18 18:25:37,104][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 0.4644367099353425,  accuracy: 0.7631589743589744, gradient_norm : 0.22142949963878636
[2025-09-18 18:25:43,176][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 0.488290213293492,  accuracy: 0.7441
[2025-09-18 18:25:59,187][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 0.45080113625472384,  accuracy: 0.7781754385964911, gradient_norm : 0.24073733088487648
[2025-09-18 18:26:05,348][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 0.48299729666810454,  accuracy: 0.7505
[2025-09-18 18:26:22,170][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 0.4493437939605126,  accuracy: 0.779611111111111, gradient_norm : 0.26945771758240533
[2025-09-18 18:26:28,230][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 0.4821651162055248,  accuracy: 0.7532
[2025-09-18 18:26:46,207][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 0.4562907164027478,  accuracy: 0.7793645833333329, gradient_norm : 0.2571814627969997
[2025-09-18 18:26:52,385][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 0.4805557073544056,  accuracy: 0.7521
[2025-09-18 18:27:11,307][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 0.4470531228139249,  accuracy: 0.7768756218905474, gradient_norm : 0.2581850051961952
[2025-09-18 18:27:17,491][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 0.47189812826018024,  accuracy: 0.7578
[2025-09-18 18:27:34,876][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 0.44857158527886093,  accuracy: 0.7768994708994711, gradient_norm : 0.25856442497863696
[2025-09-18 18:27:40,992][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 0.4707614821665862,  accuracy: 0.7574
[2025-09-18 18:27:56,538][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 0.4109936105338919,  accuracy: 0.8009761904761905, gradient_norm : 0.2381726902981347
[2025-09-18 18:28:02,608][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 0.46803735589907736,  accuracy: 0.7602
[2025-09-18 18:28:20,912][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 0.4290641917780308,  accuracy: 0.792225641025641, gradient_norm : 0.24410419993824586
[2025-09-18 18:28:27,142][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 0.46152394768701344,  accuracy: 0.7655
[2025-09-18 18:28:45,262][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 0.4147227076611717,  accuracy: 0.804953846153846, gradient_norm : 0.24376260345798859
[2025-09-18 18:28:51,422][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 0.4591556549843139,  accuracy: 0.7698
[2025-09-18 18:29:08,508][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 0.4380544095154102,  accuracy: 0.7830601092896174, gradient_norm : 0.24041188281607548
[2025-09-18 18:29:14,708][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 0.4567871632270398,  accuracy: 0.7681
[2025-09-18 18:29:32,491][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 0.4149789598687824,  accuracy: 0.7972698412698414, gradient_norm : 0.23850738843723043
[2025-09-18 18:29:38,600][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 0.4550812923204328,  accuracy: 0.7694
[2025-09-18 18:29:55,893][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 0.44389829468804315,  accuracy: 0.7825806451612904, gradient_norm : 0.2671976500397792
[2025-09-18 18:30:02,178][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 0.45458151992149726,  accuracy: 0.7707
[2025-09-18 18:30:19,499][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 0.42275126050787154,  accuracy: 0.7955806451612906, gradient_norm : 0.25305881214831877
[2025-09-18 18:30:25,674][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 0.4497894962890197,  accuracy: 0.7732
[2025-09-18 18:30:42,126][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 0.4317522020676523,  accuracy: 0.7917853107344632, gradient_norm : 0.25599208676387175
[2025-09-18 18:30:48,314][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 0.44670440800957223,  accuracy: 0.7743
[2025-09-18 18:31:12,713][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 0.42568754735401204,  accuracy: 0.7929354838709682, gradient_norm : 0.25178788369316735
[2025-09-18 18:31:19,027][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 0.44566938074055723,  accuracy: 0.7703
[2025-09-18 18:31:36,609][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 0.41332693560283945,  accuracy: 0.8025376344086023, gradient_norm : 0.28012097882159037
[2025-09-18 18:31:42,984][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 0.44321119356101046,  accuracy: 0.7762
[2025-09-18 18:32:01,473][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 0.40533828294736285,  accuracy: 0.802818181818182, gradient_norm : 0.25805255506092956
[2025-09-18 18:32:07,846][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 0.4391647310188651,  accuracy: 0.7791
[2025-09-18 18:32:25,491][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 0.3731961970382158,  accuracy: 0.8257460317460318, gradient_norm : 0.24984481067347608
[2025-09-18 18:32:31,828][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 0.4359507865596679,  accuracy: 0.7808
[2025-09-18 18:32:49,213][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 0.3759403721879775,  accuracy: 0.8219462365591397, gradient_norm : 0.25347153951249013
[2025-09-18 18:32:55,428][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 0.43444938920436615,  accuracy: 0.7811
[2025-09-18 18:33:12,469][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 0.38098309626211185,  accuracy: 0.8177158469945356, gradient_norm : 0.24021232066624792
[2025-09-18 18:33:18,818][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 0.4325820812544509,  accuracy: 0.784
[2025-09-18 18:33:34,198][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.38607234517298694,  accuracy: 0.8208242424242423, gradient_norm : 0.25070195634928466
[2025-09-18 18:33:40,583][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 0.42783030673172473,  accuracy: 0.7853
[2025-09-18 18:33:56,762][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.37745940009190965,  accuracy: 0.820528735632184, gradient_norm : 0.24470361320356884
[2025-09-18 18:34:03,038][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 0.4261344041003773,  accuracy: 0.7844
[2025-09-18 18:34:19,687][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 0.37967890541231253,  accuracy: 0.8190734463276836, gradient_norm : 0.2557062909295595
[2025-09-18 18:34:26,027][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 0.42357351716036573,  accuracy: 0.7892
[2025-09-18 18:34:41,879][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.3808753984564502,  accuracy: 0.8169473684210526, gradient_norm : 0.23451499182079974
[2025-09-18 18:34:48,205][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 0.4201918168659482,  accuracy: 0.7897
[2025-09-18 18:35:06,978][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.35990977880952696,  accuracy: 0.8314427860696517, gradient_norm : 0.240418973799655
[2025-09-18 18:35:13,389][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 0.4185854581574036,  accuracy: 0.7931
[2025-09-18 18:35:31,343][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 0.3688122592621616,  accuracy: 0.8304374999999997, gradient_norm : 0.25538365326540446
[2025-09-18 18:35:37,579][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 0.41782280169247243,  accuracy: 0.7956
[2025-09-18 18:35:55,215][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.34611514848022895,  accuracy: 0.8378095238095234, gradient_norm : 0.24486036992650975
[2025-09-18 18:36:01,558][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 0.4177483659925412,  accuracy: 0.7924
[2025-09-18 18:36:17,807][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.36751911945195354,  accuracy: 0.8270114942528733, gradient_norm : 0.2301508934576672
[2025-09-18 18:36:24,171][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 0.41166861454880127,  accuracy: 0.7949
[2025-09-18 18:36:41,036][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.3604577336538568,  accuracy: 0.8312444444444445, gradient_norm : 0.25159453662251313
[2025-09-18 18:36:47,302][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 0.4101130726160678,  accuracy: 0.8002
[2025-09-18 18:37:04,097][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.3556107675167014,  accuracy: 0.8327444444444447, gradient_norm : 0.2541479572736292
[2025-09-18 18:37:10,512][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 0.4092200614460984,  accuracy: 0.8017
[2025-09-18 18:37:28,679][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.3391820886934576,  accuracy: 0.8406979166666667, gradient_norm : 0.26465216915006495
[2025-09-18 18:37:35,090][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 0.4074508470720459,  accuracy: 0.8021
[2025-09-18 18:37:52,613][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.3238352288876397,  accuracy: 0.8507956989247314, gradient_norm : 0.24211102273386703
[2025-09-18 18:37:59,027][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 0.4064926467775804,  accuracy: 0.8065
[2025-09-18 18:38:16,698][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 0.3562127744115629,  accuracy: 0.832137566137566, gradient_norm : 0.24032581852172286
[2025-09-18 18:38:23,182][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 0.40363646546279636,  accuracy: 0.8034
[2025-09-18 18:38:40,276][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 0.33642083167395254,  accuracy: 0.8428666666666664, gradient_norm : 0.2493917909693488
[2025-09-18 18:38:46,632][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 0.40310030596793656,  accuracy: 0.8037
[2025-09-18 18:39:02,808][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.3238027816006021,  accuracy: 0.852528735632184, gradient_norm : 0.2588891771060806
[2025-09-18 18:39:09,108][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 0.40230618546216135,  accuracy: 0.8063
[2025-09-18 18:39:27,239][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.30959919984757,  accuracy: 0.8609948717948721, gradient_norm : 0.2742692563752659
[2025-09-18 18:39:33,610][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 0.3996509315094205,  accuracy: 0.8067
[2025-09-18 18:39:50,031][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.3130617689019983,  accuracy: 0.8578531073446327, gradient_norm : 0.22924189291029165
[2025-09-18 18:39:56,342][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 0.3966414086519988,  accuracy: 0.8087
[2025-09-18 18:40:12,921][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.3250544887126891,  accuracy: 0.8521468926553671, gradient_norm : 0.28174678334440384
[2025-09-18 18:40:19,160][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 0.3974781820897828,  accuracy: 0.8105
[2025-09-18 18:40:36,416][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.3111268569423569,  accuracy: 0.8585913978494625, gradient_norm : 0.2320306877253508
[2025-09-18 18:40:42,775][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 0.39417646110530474,  accuracy: 0.812
[2025-09-18 18:41:00,522][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.2893376727185121,  accuracy: 0.8714285714285714, gradient_norm : 0.24051227492083452
[2025-09-18 18:41:06,894][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 0.39138935768737027,  accuracy: 0.8122
[2025-09-18 18:41:24,061][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.3447372282904931,  accuracy: 0.8372043010752688, gradient_norm : 0.25435184751827355
[2025-09-18 18:41:30,407][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 0.38965577310312144,  accuracy: 0.8134
[2025-09-18 18:41:47,499][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.33733013991381183,  accuracy: 0.8439562841530054, gradient_norm : 0.2524534727508026
[2025-09-18 18:41:53,798][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 0.38803721670046726,  accuracy: 0.8122
[2025-09-18 18:42:10,390][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.30523330192987624,  accuracy: 0.8597288135593222, gradient_norm : 0.2436379393440694
[2025-09-18 18:42:16,840][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 0.38775979001799643,  accuracy: 0.8129
[2025-09-18 18:42:34,831][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.32049515548653323,  accuracy: 0.8514479166666665, gradient_norm : 0.25200570264496736
[2025-09-18 18:42:41,227][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 0.38752792094795807,  accuracy: 0.8132
[2025-09-18 18:42:57,104][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.28164542404330895,  accuracy: 0.873485380116959, gradient_norm : 0.24940624456764765
[2025-09-18 18:43:03,460][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 0.3875701924961228,  accuracy: 0.8135
[2025-09-18 18:43:21,541][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.2922607258323647,  accuracy: 0.8663282051282051, gradient_norm : 0.24234757273591082
[2025-09-18 18:43:27,812][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 0.3852706417776262,  accuracy: 0.8157
[2025-09-18 18:43:45,289][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.30036806433886654,  accuracy: 0.8635873015873016, gradient_norm : 0.236680251797534
[2025-09-18 18:43:51,579][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 0.3824447622154359,  accuracy: 0.8179
[2025-09-18 18:44:09,684][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.3168624887994677,  accuracy: 0.8539999999999999, gradient_norm : 0.23728075682913657
[2025-09-18 18:44:15,982][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 0.37899128902189005,  accuracy: 0.8199
[2025-09-18 18:44:32,571][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.25668780524024365,  accuracy: 0.886779661016949, gradient_norm : 0.2408750516024363
[2025-09-18 18:44:38,871][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 0.37745459597639563,  accuracy: 0.8222
[2025-09-18 18:44:55,743][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.2726403478677412,  accuracy: 0.8797222222222224, gradient_norm : 0.23985873571163463
[2025-09-18 18:45:02,104][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 0.37764816219466374,  accuracy: 0.8228
[2025-09-18 18:45:19,510][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.30418153978077733,  accuracy: 0.8602962962962962, gradient_norm : 0.25388270183079564
[2025-09-18 18:45:25,942][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 0.3752370529868611,  accuracy: 0.8218
[2025-09-18 18:45:43,193][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.26105620238177507,  accuracy: 0.8855806451612902, gradient_norm : 0.23704067048621347
[2025-09-18 18:45:49,415][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 0.3715417709963687,  accuracy: 0.8241
[2025-09-18 18:46:09,036][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.28873521477012865,  accuracy: 0.8701619047619048, gradient_norm : 0.23845059315605574
[2025-09-18 18:46:15,417][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 0.3756732766635301,  accuracy: 0.8228
[2025-09-18 18:46:34,394][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.25458311223079066,  accuracy: 0.8882189054726369, gradient_norm : 0.24741835970847656
[2025-09-18 18:46:40,742][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 0.37704092327696237,  accuracy: 0.8228
[2025-09-18 18:46:57,878][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.25393607648503447,  accuracy: 0.8872000000000001, gradient_norm : 0.22158716859305755
[2025-09-18 18:47:04,273][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 0.3740693518207419,  accuracy: 0.8245
[2025-09-18 18:47:21,296][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.24242375210366537,  accuracy: 0.8958000000000002, gradient_norm : 0.24520975839166229
[2025-09-18 18:47:27,677][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 0.37327478840151124,  accuracy: 0.8268
[2025-09-18 18:47:43,759][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.26878113413993404,  accuracy: 0.8818045977011494, gradient_norm : 0.23624306630265296
[2025-09-18 18:47:50,005][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 0.37386601559032095,  accuracy: 0.825
[2025-09-18 18:48:08,138][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.2743101292777652,  accuracy: 0.8779687500000002, gradient_norm : 0.2509856176337296
[2025-09-18 18:48:14,397][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 0.37661973396172616,  accuracy: 0.8237
[2025-09-18 18:48:31,997][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.22086243036889833,  accuracy: 0.905269841269841, gradient_norm : 0.2503368241731375
[2025-09-18 18:48:38,300][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 0.37205485781995157,  accuracy: 0.8255
[2025-09-18 18:48:57,021][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.2586411560663131,  accuracy: 0.8858805970149254, gradient_norm : 0.24950806856770466
[2025-09-18 18:49:03,395][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 0.37533005797995356,  accuracy: 0.8269
[2025-09-18 18:49:20,328][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.24001062797683992,  accuracy: 0.8971147540983607, gradient_norm : 0.2504293740480037
[2025-09-18 18:49:26,653][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 0.3727012856551963,  accuracy: 0.8269
[2025-09-18 18:49:43,239][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.23394112014870766,  accuracy: 0.8973898305084745, gradient_norm : 0.24140079654770003
[2025-09-18 18:49:49,551][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 0.3685031679486165,  accuracy: 0.8306
[2025-09-18 18:50:06,525][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.23119647599874615,  accuracy: 0.8988415300546451, gradient_norm : 0.24752163676078437
[2025-09-18 18:50:12,930][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 0.3679649086260255,  accuracy: 0.8309
[2025-09-18 18:50:29,603][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.25646313892537675,  accuracy: 0.8871444444444446, gradient_norm : 0.24102191247685376
[2025-09-18 18:50:35,741][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 0.3679770590319578,  accuracy: 0.8314
[2025-09-18 18:50:53,112][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.24336661963343176,  accuracy: 0.896483870967742, gradient_norm : 0.2633882862243907
[2025-09-18 18:50:59,372][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 0.3710434329518699,  accuracy: 0.8336
[2025-09-18 18:51:15,336][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.24878348921671387,  accuracy: 0.8900701754385965, gradient_norm : 0.23221520612315483
[2025-09-18 18:51:21,610][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 0.3684594673842672,  accuracy: 0.8352
[2025-09-18 18:51:37,842][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.2239234839113469,  accuracy: 0.9030804597701146, gradient_norm : 0.23422357145406672
[2025-09-18 18:51:44,122][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 0.3674745227828447,  accuracy: 0.835
[2025-09-18 18:52:00,961][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.2385615593495357,  accuracy: 0.8948777777777778, gradient_norm : 0.23904870082685123
[2025-09-18 18:52:07,309][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 0.36683093394406024,  accuracy: 0.8339
[2025-09-18 18:52:25,242][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.23711713628141204,  accuracy: 0.8969230769230768, gradient_norm : 0.2580098369033992
[2025-09-18 18:52:31,659][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 0.36602893524274843,  accuracy: 0.8345
[2025-09-18 18:52:47,528][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.22821394196969044,  accuracy: 0.8984210526315789, gradient_norm : 0.23450335625824595
[2025-09-18 18:52:53,840][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 0.3662867413522392,  accuracy: 0.8365
[2025-09-18 18:53:11,471][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.21367004192332328,  accuracy: 0.9085185185185187, gradient_norm : 0.249146049151063
[2025-09-18 18:53:17,671][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 0.3669961076514868,  accuracy: 0.8344
[2025-09-18 18:53:34,300][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.2136659641989718,  accuracy: 0.9098983050847458, gradient_norm : 0.2845944657242603
[2025-09-18 18:53:40,572][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 0.3688514551593311,  accuracy: 0.8332
[2025-09-18 18:53:58,804][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.20296814410853,  accuracy: 0.9147589743589741, gradient_norm : 0.23432002932298213
[2025-09-18 18:54:05,262][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 0.36606103720679384,  accuracy: 0.8348
[2025-09-18 18:54:22,761][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.17950674638371472,  accuracy: 0.9299354838709681, gradient_norm : 0.24915920612990652
[2025-09-18 18:54:29,089][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 0.36935963927143495,  accuracy: 0.8376
[2025-09-18 18:54:45,073][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.2056320578178138,  accuracy: 0.915029239766082, gradient_norm : 0.25052111340073163
[2025-09-18 18:54:51,391][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 0.3660512552234995,  accuracy: 0.8373
[2025-09-18 18:55:10,492][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.2076954359846111,  accuracy: 0.9107549019607841, gradient_norm : 0.23423552400005962
[2025-09-18 18:55:16,901][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 0.3637229478661138,  accuracy: 0.8395
[2025-09-18 18:55:35,094][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.21318025737699814,  accuracy: 0.9096512820512824, gradient_norm : 0.250233202493896
[2025-09-18 18:55:41,497][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 0.3630160878866696,  accuracy: 0.8408
[2025-09-18 18:55:59,987][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.21129035177199457,  accuracy: 0.910989898989899, gradient_norm : 0.23425571569700254
[2025-09-18 18:56:06,384][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 0.36391970044815863,  accuracy: 0.8376
[2025-09-18 18:56:23,237][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.20949741294425875,  accuracy: 0.909533333333333, gradient_norm : 0.23847302955581479
[2025-09-18 18:56:29,592][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 0.362319211617234,  accuracy: 0.8379
[2025-09-18 18:56:47,460][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.19689531346993294,  accuracy: 0.9177187499999999, gradient_norm : 0.2490117559935271
[2025-09-18 18:56:53,821][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 0.36963497173509424,  accuracy: 0.838
[2025-09-18 18:57:10,898][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.19802413160689866,  accuracy: 0.919103825136612, gradient_norm : 0.2311459582995788
[2025-09-18 18:57:17,284][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 0.3640658831399658,  accuracy: 0.8417
[2025-09-18 18:57:35,287][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.21961634421928974,  accuracy: 0.9045624999999999, gradient_norm : 0.2322035357030402
[2025-09-18 18:57:41,708][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 0.36385308654174003,  accuracy: 0.8403
[2025-09-18 18:57:59,907][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.19908664406868462,  accuracy: 0.9164205128205128, gradient_norm : 0.21182371748181772
[2025-09-18 18:58:06,144][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 0.36536016300896373,  accuracy: 0.8397
[2025-09-18 18:58:23,302][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.17543307204409828,  accuracy: 0.92975956284153, gradient_norm : 0.24082027649383222
[2025-09-18 18:58:29,644][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 0.36866529159768396,  accuracy: 0.841
[2025-09-18 18:58:46,132][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.2294765076559669,  accuracy: 0.9002372881355931, gradient_norm : 0.22564217588674765
[2025-09-18 18:58:52,450][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 0.36491796777539637,  accuracy: 0.8411
[2025-09-18 18:59:09,934][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.1763473700125971,  accuracy: 0.9306559139784947, gradient_norm : 0.2151282812380878
[2025-09-18 18:59:16,261][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 0.36334648296825545,  accuracy: 0.8417
[2025-09-18 18:59:33,141][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.18938922649627893,  accuracy: 0.9208555555555554, gradient_norm : 0.22764989118502846
[2025-09-18 18:59:39,366][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 0.3663538892635337,  accuracy: 0.8436
[2025-09-18 18:59:55,331][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.17856171916215507,  accuracy: 0.9257309941520468, gradient_norm : 0.2634561523786842
[2025-09-18 19:00:01,688][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 0.3705977796375577,  accuracy: 0.8399
[2025-09-18 19:00:19,320][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.1626228167889605,  accuracy: 0.9349417989417987, gradient_norm : 0.23004988096556797
[2025-09-18 19:00:25,675][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 0.37048140617030934,  accuracy: 0.8409
[2025-09-18 19:00:42,709][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.18555530198988537,  accuracy: 0.9222732240437161, gradient_norm : 0.21355567173484818
[2025-09-18 19:00:49,068][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 0.3681965322554341,  accuracy: 0.8411
[2025-09-18 19:01:06,575][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.18648555804585784,  accuracy: 0.921703703703704, gradient_norm : 0.23554694298619908
[2025-09-18 19:01:12,797][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 0.366464988015046,  accuracy: 0.8459
[2025-09-18 19:01:29,718][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.15332715148405107,  accuracy: 0.9403278688524589, gradient_norm : 0.2242362529428626
[2025-09-18 19:01:35,985][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 0.36787164973041037,  accuracy: 0.8434
[2025-09-18 19:01:52,974][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.17852442455397993,  accuracy: 0.9276284153005466, gradient_norm : 0.25172490633811817
[2025-09-18 19:01:59,290][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 0.3685258057432988,  accuracy: 0.8423
[2025-09-18 19:02:16,165][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.14811600095527458,  accuracy: 0.943311111111111, gradient_norm : 0.2275204356073949
[2025-09-18 19:02:22,365][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 0.3732573683849052,  accuracy: 0.8404
[2025-09-18 19:02:39,147][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.1463556406450809,  accuracy: 0.9409555555555553, gradient_norm : 0.21281729268610997
[2025-09-18 19:02:45,312][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 0.3749201200390799,  accuracy: 0.841
[2025-09-18 19:03:04,050][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.1556598848337027,  accuracy: 0.9378308457711444, gradient_norm : 0.23773254307089203
[2025-09-18 19:03:10,395][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 0.370320760719815,  accuracy: 0.8435
[2025-09-18 19:03:28,527][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.17184479231787722,  accuracy: 0.9288645833333334, gradient_norm : 0.2300989995500343
[2025-09-18 19:03:34,940][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 0.3747512181933207,  accuracy: 0.8451
[2025-09-18 19:03:51,943][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.15163117570143783,  accuracy: 0.9415519125683056, gradient_norm : 0.26357604368187987
[2025-09-18 19:03:58,319][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 0.37698839444596977,  accuracy: 0.8447
[2025-09-18 19:04:15,402][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.13685363015194477,  accuracy: 0.9476444444444444, gradient_norm : 0.23900757180339444
[2025-09-18 19:04:21,639][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 0.3789806041550708,  accuracy: 0.8449
[2025-09-18 19:04:39,782][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.15665567101205408,  accuracy: 0.9385846153846155, gradient_norm : 0.24129240190301202
[2025-09-18 19:04:46,095][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 0.3789343557522154,  accuracy: 0.8452
[2025-09-18 19:05:02,744][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.13509013582620485,  accuracy: 0.9491525423728815, gradient_norm : 0.2176464067277512
[2025-09-18 19:05:09,075][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 0.38373716354073495,  accuracy: 0.8431
[2025-09-18 19:05:27,942][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.14671217008673526,  accuracy: 0.9426766169154229, gradient_norm : 0.22622717382331975
[2025-09-18 19:05:34,258][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 0.3854236773084029,  accuracy: 0.8445
[2025-09-18 19:05:52,098][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.1514411670254609,  accuracy: 0.9406031746031744, gradient_norm : 0.22909611296733448
[2025-09-18 19:05:58,537][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 0.3841622401803648,  accuracy: 0.8461
[2025-09-18 19:06:15,810][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.13528433297956646,  accuracy: 0.9493989071038251, gradient_norm : 0.22612236093575055
[2025-09-18 19:06:22,103][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 0.3832385994796041,  accuracy: 0.8451
[2025-09-18 19:06:40,075][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.15744032648011108,  accuracy: 0.9376666666666666, gradient_norm : 0.23357890331001127
[2025-09-18 19:06:46,336][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 0.38206115870592877,  accuracy: 0.8455
[2025-09-18 19:07:03,013][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.14487680913465634,  accuracy: 0.9398666666666664, gradient_norm : 0.22075769675087029
[2025-09-18 19:07:09,327][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 0.3811245258825602,  accuracy: 0.8433
[2025-09-18 19:07:32,910][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.14889820803117415,  accuracy: 0.9401481481481482, gradient_norm : 0.2510859847798567
[2025-09-18 19:07:39,219][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 0.3876646676622915,  accuracy: 0.8406
[2025-09-18 19:07:56,823][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.14093441000978915,  accuracy: 0.9455268817204302, gradient_norm : 0.21372966334417004
[2025-09-18 19:08:03,247][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 0.3868162893495655,  accuracy: 0.8424
[2025-09-18 19:08:19,687][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.1273763326333873,  accuracy: 0.9505197740112994, gradient_norm : 0.234730911993423
[2025-09-18 19:08:26,030][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 0.38563937977661755,  accuracy: 0.8457
[2025-09-18 19:08:42,789][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.14087489606565298,  accuracy: 0.9448474576271189, gradient_norm : 0.23108471033116265
[2025-09-18 19:08:48,989][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 0.39021521601115944,  accuracy: 0.8448
[2025-09-18 19:09:05,158][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.1388910496874574,  accuracy: 0.9477126436781609, gradient_norm : 0.22260710499752412
[2025-09-18 19:09:11,423][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 0.3882127997491569,  accuracy: 0.8485
[2025-09-18 19:09:29,594][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.12468827020706953,  accuracy: 0.9528307692307689, gradient_norm : 0.21663818738433616
[2025-09-18 19:09:35,960][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 0.38301808208603927,  accuracy: 0.8517
[2025-09-18 19:09:54,809][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.12359292012363096,  accuracy: 0.9518109452736321, gradient_norm : 0.20195819834382278
[2025-09-18 19:10:01,170][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 0.39031109864816627,  accuracy: 0.8507
[2025-09-18 19:10:18,534][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.12161995355157852,  accuracy: 0.9536451612903227, gradient_norm : 0.22810117916547107
[2025-09-18 19:10:24,972][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 0.3933422836412241,  accuracy: 0.8495
[2025-09-18 19:10:42,162][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.12001309791533515,  accuracy: 0.9560109289617486, gradient_norm : 0.21235941358105598
[2025-09-18 19:10:48,488][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 0.39377309937286065,  accuracy: 0.8516
[2025-09-18 19:11:04,500][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.08971573920978547,  accuracy: 0.9685380116959065, gradient_norm : 0.19261321881951488
[2025-09-18 19:11:10,831][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 0.3878911381840524,  accuracy: 0.8516
[2025-09-18 19:11:27,811][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.13093752049826307,  accuracy: 0.9481888888888889, gradient_norm : 0.1921732278198366
[2025-09-18 19:11:34,062][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 0.39210736319187,  accuracy: 0.8494
[2025-09-18 19:11:50,984][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.13217749694762232,  accuracy: 0.9483444444444443, gradient_norm : 0.2243934337768079
[2025-09-18 19:11:57,282][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 0.3960054312254233,  accuracy: 0.8495
[2025-09-18 19:12:14,199][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.11134392539985864,  accuracy: 0.9581111111111109, gradient_norm : 0.18376165251111998
[2025-09-18 19:12:20,552][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 0.3938962724091469,  accuracy: 0.8502
[2025-09-18 19:12:38,099][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.09969687753045725,  accuracy: 0.9632365591397851, gradient_norm : 0.2005230747658757
[2025-09-18 19:12:44,440][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 0.39459265182828784,  accuracy: 0.8482
[2025-09-18 19:13:01,832][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.11699343686804706,  accuracy: 0.9565591397849462, gradient_norm : 0.21884924611369724
[2025-09-18 19:13:08,128][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 0.3979210323971249,  accuracy: 0.8506
[2025-09-18 19:13:24,279][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.10222825141993498,  accuracy: 0.9645847953216374, gradient_norm : 0.19238695822936228
[2025-09-18 19:13:30,567][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 0.3963116285131367,  accuracy: 0.8488
[2025-09-18 19:13:49,386][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.10251780239577242,  accuracy: 0.9617810945273632, gradient_norm : 0.19868383258440575
[2025-09-18 19:13:55,802][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 0.39664191762747414,  accuracy: 0.8514
[2025-09-18 19:14:14,059][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.09800666171991541,  accuracy: 0.9661875, gradient_norm : 0.20638557365746207
[2025-09-18 19:14:20,358][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 0.4019404460406806,  accuracy: 0.8494
[2025-09-18 19:14:37,662][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.09597769801196769,  accuracy: 0.9655698924731182, gradient_norm : 0.19421516649909096
[2025-09-18 19:14:44,004][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 0.40083787705670637,  accuracy: 0.8499
[2025-09-18 19:15:00,369][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.10041189573151355,  accuracy: 0.9666206896551723, gradient_norm : 0.20823962260855913
[2025-09-18 19:15:06,803][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 0.4022963389957573,  accuracy: 0.8513
[2025-09-18 19:15:22,475][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.08449766336147625,  accuracy: 0.9725833333333335, gradient_norm : 0.21105775198783502
[2025-09-18 19:15:28,738][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 0.4068838650440928,  accuracy: 0.849
[2025-09-18 19:15:45,620][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.1073203399658079,  accuracy: 0.9619111111111112, gradient_norm : 0.19762237234980004
[2025-09-18 19:15:51,912][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 0.4097080292366351,  accuracy: 0.8469
[2025-09-18 19:16:09,218][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.07982397791228141,  accuracy: 0.9742841530054646, gradient_norm : 0.1872268483831742
[2025-09-18 19:16:15,447][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 0.4076695699055881,  accuracy: 0.8473
[2025-09-18 19:16:31,529][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.08580982714743604,  accuracy: 0.971103448275862, gradient_norm : 0.18476304980911007
[2025-09-18 19:16:37,828][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 0.4081947810904207,  accuracy: 0.8496
[2025-09-18 19:16:55,948][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.0768266331252351,  accuracy: 0.9754895833333332, gradient_norm : 0.1791986670076765
[2025-09-18 19:17:02,293][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 0.4116454147429784,  accuracy: 0.8488
[2025-09-18 19:17:19,625][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.09333864905382935,  accuracy: 0.9683225806451613, gradient_norm : 0.19332505642701853
[2025-09-18 19:17:25,791][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 0.4143749282653618,  accuracy: 0.8505
[2025-09-18 19:17:43,195][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.08693540515695893,  accuracy: 0.97052688172043, gradient_norm : 0.18760276878482382
[2025-09-18 19:17:49,502][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 0.418709640524138,  accuracy: 0.8506
[2025-09-18 19:18:08,029][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.09480814079750789,  accuracy: 0.966577114427861, gradient_norm : 0.18596039988983393
[2025-09-18 19:18:14,319][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 0.4155591509609261,  accuracy: 0.851
[2025-09-18 19:18:30,620][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.07397911436803287,  accuracy: 0.9762183908045974, gradient_norm : 0.18124268753914888
[2025-09-18 19:18:36,937][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 0.41986448126098186,  accuracy: 0.8497
[2025-09-18 19:18:56,785][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.10133900740521162,  accuracy: 0.9633047619047619, gradient_norm : 0.18726248895743577
[2025-09-18 19:19:03,101][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 0.4264012247137081,  accuracy: 0.8491
[2025-09-18 19:19:19,572][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.078247335513635,  accuracy: 0.9720677966101692, gradient_norm : 0.18709789957435194
[2025-09-18 19:19:25,915][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 0.4300197782790914,  accuracy: 0.8499
[2025-09-18 19:19:43,381][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.0874885643809499,  accuracy: 0.9704086021505376, gradient_norm : 0.19606887995160938
[2025-09-18 19:19:49,613][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 0.42912749044084997,  accuracy: 0.848
[2025-09-18 19:20:06,552][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.09582851788383003,  accuracy: 0.9666229508196719, gradient_norm : 0.19190738876514432
[2025-09-18 19:20:12,808][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 0.42947540975323173,  accuracy: 0.849
[2025-09-18 19:20:29,166][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.07375229127857458,  accuracy: 0.9760919540229884, gradient_norm : 0.16728877937388714
[2025-09-18 19:20:35,399][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 0.42940323869287783,  accuracy: 0.851
[2025-09-18 19:20:52,961][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.06966623538274358,  accuracy: 0.9785820105820107, gradient_norm : 0.17094487111159654
[2025-09-18 19:20:59,254][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 0.4356957641243327,  accuracy: 0.8498
[2025-09-18 19:21:16,409][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.08822031949284544,  accuracy: 0.9687431693989073, gradient_norm : 0.17581720375497548
[2025-09-18 19:21:22,771][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 0.43597400245319295,  accuracy: 0.8494
[2025-09-18 19:21:40,011][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.07195022439975061,  accuracy: 0.9763655913978496, gradient_norm : 0.16433279406294252
[2025-09-18 19:21:46,283][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 0.4317335281956937,  accuracy: 0.8532
[2025-09-18 19:22:03,467][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.05439646306101286,  accuracy: 0.9850601092896178, gradient_norm : 0.15076724197426516
[2025-09-18 19:22:09,667][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 0.43151093730142165,  accuracy: 0.8531
[2025-09-18 19:22:27,414][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.05497865550320891,  accuracy: 0.9853015873015875, gradient_norm : 0.14359284465206498
[2025-09-18 19:22:33,798][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 0.4346487122067492,  accuracy: 0.8534
[2025-09-18 19:22:51,354][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.07117007062130576,  accuracy: 0.9759247311827958, gradient_norm : 0.1445762742631141
[2025-09-18 19:22:57,572][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 0.4362895784132306,  accuracy: 0.8548
[2025-09-18 19:23:14,162][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.06720538590924259,  accuracy: 0.9782033898305086, gradient_norm : 0.1676984217994711
[2025-09-18 19:23:20,394][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 0.4342602619624535,  accuracy: 0.8539
[2025-09-18 19:23:37,574][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.06928920539994055,  accuracy: 0.9775519125683061, gradient_norm : 0.14579246086859798
[2025-09-18 19:23:43,974][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 0.4380361192168153,  accuracy: 0.8538
[2025-09-18 19:24:01,033][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.054723915289569144,  accuracy: 0.9835956284153006, gradient_norm : 0.14419926509887981
[2025-09-18 19:24:07,344][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 0.44254115797709875,  accuracy: 0.8527
[2025-09-18 19:24:24,721][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.07319083864580464,  accuracy: 0.9756129032258064, gradient_norm : 0.14675849897673754
[2025-09-18 19:24:31,003][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 0.44592098735519686,  accuracy: 0.8521
[2025-09-18 19:24:48,433][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.054967365371800685,  accuracy: 0.9844301075268818, gradient_norm : 0.13642768538346448
[2025-09-18 19:24:54,669][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 0.4460200254682628,  accuracy: 0.8546
[2025-09-18 19:25:11,182][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.06738157208006812,  accuracy: 0.9787005649717512, gradient_norm : 0.17167772816983762
[2025-09-18 19:25:17,554][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 0.4487602459660617,  accuracy: 0.851
[2025-09-18 19:25:35,524][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.04887185372475617,  accuracy: 0.9878437499999999, gradient_norm : 0.1437439347654274
[2025-09-18 19:25:41,973][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 0.447883828365672,  accuracy: 0.8552
[2025-09-18 19:26:00,617][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.05788318593779262,  accuracy: 0.9822626262626263, gradient_norm : 0.14317616578238385
[2025-09-18 19:26:06,892][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 0.45233138061510125,  accuracy: 0.8566
[2025-09-18 19:26:24,284][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.06038045626248904,  accuracy: 0.980720430107527, gradient_norm : 0.14241123451928003
[2025-09-18 19:26:30,608][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 0.4511889710336085,  accuracy: 0.8551
[2025-09-18 19:26:46,303][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.034520529096988904,  accuracy: 0.9926904761904762, gradient_norm : 0.12337857601620149
[2025-09-18 19:26:52,637][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 0.4531250984170274,  accuracy: 0.8534
[2025-09-18 19:27:11,118][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.07330608345166112,  accuracy: 0.9744615384615385, gradient_norm : 0.16829074011908618
[2025-09-18 19:27:17,484][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 0.4563445421894157,  accuracy: 0.8524
[2025-09-18 19:27:35,107][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.04919554800011689,  accuracy: 0.9863333333333333, gradient_norm : 0.14963192861606237
[2025-09-18 19:27:41,373][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 0.46384562283600245,  accuracy: 0.8507
[2025-09-18 19:27:58,124][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.040025368745156845,  accuracy: 0.9903728813559322, gradient_norm : 0.12393541632007822
[2025-09-18 19:28:04,512][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 0.46624576467442713,  accuracy: 0.851
[2025-09-18 19:28:22,257][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.05286506424804599,  accuracy: 0.9847301587301589, gradient_norm : 0.16394976625954602
[2025-09-18 19:28:28,600][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 0.4659634065451146,  accuracy: 0.8494
[2025-09-18 19:28:44,886][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.04814781629259404,  accuracy: 0.9861494252873562, gradient_norm : 0.12513255166322118
[2025-09-18 19:28:51,210][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 0.46615954982676566,  accuracy: 0.8522
[2025-09-18 19:29:07,704][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.042804359297126296,  accuracy: 0.9892090395480228, gradient_norm : 0.1401279286188866
[2025-09-18 19:29:13,948][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 0.46620809630746834,  accuracy: 0.8539
[2025-09-18 19:29:31,613][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.048947448532333994,  accuracy: 0.9864656084656086, gradient_norm : 0.13156849607669518
[2025-09-18 19:29:37,906][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 0.4656608223746618,  accuracy: 0.8544
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 001: loss=2.2564, accuracy=0.2520, gradient_norm=0.8587, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 002: loss=2.1750, accuracy=0.4316, gradient_norm=0.9003, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 003: loss=2.0818, accuracy=0.5115, gradient_norm=1.0661, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 004: loss=1.8949, accuracy=0.5384, gradient_norm=1.3574, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 005: loss=1.5959, accuracy=0.5548, gradient_norm=1.5516, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 006: loss=1.3296, accuracy=0.5618, gradient_norm=1.3382, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 007: loss=1.1818, accuracy=0.5949, gradient_norm=1.1813, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 008: loss=0.9159, accuracy=0.6081, gradient_norm=0.9427, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 009: loss=0.8456, accuracy=0.6280, gradient_norm=0.8696, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 010: loss=0.7284, accuracy=0.6399, gradient_norm=0.6219, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 011: loss=0.6486, accuracy=0.6531, gradient_norm=0.4422, 
[2025-09-18 19:29:37,906][__main__][INFO] - Train, Round 012: loss=0.6733, accuracy=0.6553, gradient_norm=0.4314, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 013: loss=0.6167, accuracy=0.6832, gradient_norm=0.3665, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 014: loss=0.5966, accuracy=0.6889, gradient_norm=0.3425, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 015: loss=0.6465, accuracy=0.6552, gradient_norm=0.3334, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 016: loss=0.5895, accuracy=0.6817, gradient_norm=0.2739, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 017: loss=0.6135, accuracy=0.6805, gradient_norm=0.3259, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 018: loss=0.5890, accuracy=0.6900, gradient_norm=0.3251, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 019: loss=0.5546, accuracy=0.7127, gradient_norm=0.2765, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 020: loss=0.5340, accuracy=0.7227, gradient_norm=0.2658, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 021: loss=0.5188, accuracy=0.7308, gradient_norm=0.2767, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 022: loss=0.5287, accuracy=0.7306, gradient_norm=0.2794, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 023: loss=0.5143, accuracy=0.7271, gradient_norm=0.2441, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 024: loss=0.5234, accuracy=0.7273, gradient_norm=0.2492, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 025: loss=0.5201, accuracy=0.7293, gradient_norm=0.2589, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 026: loss=0.5161, accuracy=0.7267, gradient_norm=0.2440, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 027: loss=0.5149, accuracy=0.7389, gradient_norm=0.2542, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 028: loss=0.5137, accuracy=0.7331, gradient_norm=0.2452, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 029: loss=0.5049, accuracy=0.7413, gradient_norm=0.2617, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 030: loss=0.4839, accuracy=0.7526, gradient_norm=0.2241, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 031: loss=0.5212, accuracy=0.7322, gradient_norm=0.2491, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 032: loss=0.4813, accuracy=0.7608, gradient_norm=0.2469, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 033: loss=0.4760, accuracy=0.7623, gradient_norm=0.2599, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 034: loss=0.4603, accuracy=0.7670, gradient_norm=0.2400, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 035: loss=0.5120, accuracy=0.7416, gradient_norm=0.2636, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 036: loss=0.4677, accuracy=0.7633, gradient_norm=0.2407, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 037: loss=0.4556, accuracy=0.7699, gradient_norm=0.2403, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 038: loss=0.4644, accuracy=0.7632, gradient_norm=0.2214, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 039: loss=0.4508, accuracy=0.7782, gradient_norm=0.2407, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 040: loss=0.4493, accuracy=0.7796, gradient_norm=0.2695, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 041: loss=0.4563, accuracy=0.7794, gradient_norm=0.2572, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 042: loss=0.4471, accuracy=0.7769, gradient_norm=0.2582, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 043: loss=0.4486, accuracy=0.7769, gradient_norm=0.2586, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 044: loss=0.4110, accuracy=0.8010, gradient_norm=0.2382, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 045: loss=0.4291, accuracy=0.7922, gradient_norm=0.2441, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 046: loss=0.4147, accuracy=0.8050, gradient_norm=0.2438, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 047: loss=0.4381, accuracy=0.7831, gradient_norm=0.2404, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 048: loss=0.4150, accuracy=0.7973, gradient_norm=0.2385, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 049: loss=0.4439, accuracy=0.7826, gradient_norm=0.2672, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 050: loss=0.4228, accuracy=0.7956, gradient_norm=0.2531, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 051: loss=0.4318, accuracy=0.7918, gradient_norm=0.2560, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 052: loss=0.4257, accuracy=0.7929, gradient_norm=0.2518, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 053: loss=0.4133, accuracy=0.8025, gradient_norm=0.2801, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 054: loss=0.4053, accuracy=0.8028, gradient_norm=0.2581, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 055: loss=0.3732, accuracy=0.8257, gradient_norm=0.2498, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 056: loss=0.3759, accuracy=0.8219, gradient_norm=0.2535, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 057: loss=0.3810, accuracy=0.8177, gradient_norm=0.2402, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 058: loss=0.3861, accuracy=0.8208, gradient_norm=0.2507, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 059: loss=0.3775, accuracy=0.8205, gradient_norm=0.2447, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 060: loss=0.3797, accuracy=0.8191, gradient_norm=0.2557, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 061: loss=0.3809, accuracy=0.8169, gradient_norm=0.2345, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 062: loss=0.3599, accuracy=0.8314, gradient_norm=0.2404, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 063: loss=0.3688, accuracy=0.8304, gradient_norm=0.2554, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 064: loss=0.3461, accuracy=0.8378, gradient_norm=0.2449, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 065: loss=0.3675, accuracy=0.8270, gradient_norm=0.2302, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 066: loss=0.3605, accuracy=0.8312, gradient_norm=0.2516, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 067: loss=0.3556, accuracy=0.8327, gradient_norm=0.2541, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 068: loss=0.3392, accuracy=0.8407, gradient_norm=0.2647, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 069: loss=0.3238, accuracy=0.8508, gradient_norm=0.2421, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 070: loss=0.3562, accuracy=0.8321, gradient_norm=0.2403, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 071: loss=0.3364, accuracy=0.8429, gradient_norm=0.2494, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 072: loss=0.3238, accuracy=0.8525, gradient_norm=0.2589, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 073: loss=0.3096, accuracy=0.8610, gradient_norm=0.2743, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 074: loss=0.3131, accuracy=0.8579, gradient_norm=0.2292, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 075: loss=0.3251, accuracy=0.8521, gradient_norm=0.2817, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 076: loss=0.3111, accuracy=0.8586, gradient_norm=0.2320, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 077: loss=0.2893, accuracy=0.8714, gradient_norm=0.2405, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 078: loss=0.3447, accuracy=0.8372, gradient_norm=0.2544, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 079: loss=0.3373, accuracy=0.8440, gradient_norm=0.2525, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 080: loss=0.3052, accuracy=0.8597, gradient_norm=0.2436, 
[2025-09-18 19:29:37,907][__main__][INFO] - Train, Round 081: loss=0.3205, accuracy=0.8514, gradient_norm=0.2520, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 082: loss=0.2816, accuracy=0.8735, gradient_norm=0.2494, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 083: loss=0.2923, accuracy=0.8663, gradient_norm=0.2423, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 084: loss=0.3004, accuracy=0.8636, gradient_norm=0.2367, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 085: loss=0.3169, accuracy=0.8540, gradient_norm=0.2373, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 086: loss=0.2567, accuracy=0.8868, gradient_norm=0.2409, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 087: loss=0.2726, accuracy=0.8797, gradient_norm=0.2399, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 088: loss=0.3042, accuracy=0.8603, gradient_norm=0.2539, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 089: loss=0.2611, accuracy=0.8856, gradient_norm=0.2370, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 090: loss=0.2887, accuracy=0.8702, gradient_norm=0.2385, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 091: loss=0.2546, accuracy=0.8882, gradient_norm=0.2474, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 092: loss=0.2539, accuracy=0.8872, gradient_norm=0.2216, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 093: loss=0.2424, accuracy=0.8958, gradient_norm=0.2452, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 094: loss=0.2688, accuracy=0.8818, gradient_norm=0.2362, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 095: loss=0.2743, accuracy=0.8780, gradient_norm=0.2510, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 096: loss=0.2209, accuracy=0.9053, gradient_norm=0.2503, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 097: loss=0.2586, accuracy=0.8859, gradient_norm=0.2495, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 098: loss=0.2400, accuracy=0.8971, gradient_norm=0.2504, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 099: loss=0.2339, accuracy=0.8974, gradient_norm=0.2414, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 100: loss=0.2312, accuracy=0.8988, gradient_norm=0.2475, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 101: loss=0.2565, accuracy=0.8871, gradient_norm=0.2410, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 102: loss=0.2434, accuracy=0.8965, gradient_norm=0.2634, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 103: loss=0.2488, accuracy=0.8901, gradient_norm=0.2322, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 104: loss=0.2239, accuracy=0.9031, gradient_norm=0.2342, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 105: loss=0.2386, accuracy=0.8949, gradient_norm=0.2390, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 106: loss=0.2371, accuracy=0.8969, gradient_norm=0.2580, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 107: loss=0.2282, accuracy=0.8984, gradient_norm=0.2345, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 108: loss=0.2137, accuracy=0.9085, gradient_norm=0.2491, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 109: loss=0.2137, accuracy=0.9099, gradient_norm=0.2846, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 110: loss=0.2030, accuracy=0.9148, gradient_norm=0.2343, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 111: loss=0.1795, accuracy=0.9299, gradient_norm=0.2492, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 112: loss=0.2056, accuracy=0.9150, gradient_norm=0.2505, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 113: loss=0.2077, accuracy=0.9108, gradient_norm=0.2342, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 114: loss=0.2132, accuracy=0.9097, gradient_norm=0.2502, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 115: loss=0.2113, accuracy=0.9110, gradient_norm=0.2343, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 116: loss=0.2095, accuracy=0.9095, gradient_norm=0.2385, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 117: loss=0.1969, accuracy=0.9177, gradient_norm=0.2490, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 118: loss=0.1980, accuracy=0.9191, gradient_norm=0.2311, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 119: loss=0.2196, accuracy=0.9046, gradient_norm=0.2322, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 120: loss=0.1991, accuracy=0.9164, gradient_norm=0.2118, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 121: loss=0.1754, accuracy=0.9298, gradient_norm=0.2408, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 122: loss=0.2295, accuracy=0.9002, gradient_norm=0.2256, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 123: loss=0.1763, accuracy=0.9307, gradient_norm=0.2151, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 124: loss=0.1894, accuracy=0.9209, gradient_norm=0.2276, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 125: loss=0.1786, accuracy=0.9257, gradient_norm=0.2635, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 126: loss=0.1626, accuracy=0.9349, gradient_norm=0.2300, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 127: loss=0.1856, accuracy=0.9223, gradient_norm=0.2136, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 128: loss=0.1865, accuracy=0.9217, gradient_norm=0.2355, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 129: loss=0.1533, accuracy=0.9403, gradient_norm=0.2242, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 130: loss=0.1785, accuracy=0.9276, gradient_norm=0.2517, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 131: loss=0.1481, accuracy=0.9433, gradient_norm=0.2275, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 132: loss=0.1464, accuracy=0.9410, gradient_norm=0.2128, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 133: loss=0.1557, accuracy=0.9378, gradient_norm=0.2377, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 134: loss=0.1718, accuracy=0.9289, gradient_norm=0.2301, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 135: loss=0.1516, accuracy=0.9416, gradient_norm=0.2636, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 136: loss=0.1369, accuracy=0.9476, gradient_norm=0.2390, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 137: loss=0.1567, accuracy=0.9386, gradient_norm=0.2413, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 138: loss=0.1351, accuracy=0.9492, gradient_norm=0.2176, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 139: loss=0.1467, accuracy=0.9427, gradient_norm=0.2262, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 140: loss=0.1514, accuracy=0.9406, gradient_norm=0.2291, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 141: loss=0.1353, accuracy=0.9494, gradient_norm=0.2261, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 142: loss=0.1574, accuracy=0.9377, gradient_norm=0.2336, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 143: loss=0.1449, accuracy=0.9399, gradient_norm=0.2208, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 144: loss=0.1489, accuracy=0.9401, gradient_norm=0.2511, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 145: loss=0.1409, accuracy=0.9455, gradient_norm=0.2137, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 146: loss=0.1274, accuracy=0.9505, gradient_norm=0.2347, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 147: loss=0.1409, accuracy=0.9448, gradient_norm=0.2311, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 148: loss=0.1389, accuracy=0.9477, gradient_norm=0.2226, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 149: loss=0.1247, accuracy=0.9528, gradient_norm=0.2166, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 150: loss=0.1236, accuracy=0.9518, gradient_norm=0.2020, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 151: loss=0.1216, accuracy=0.9536, gradient_norm=0.2281, 
[2025-09-18 19:29:37,908][__main__][INFO] - Train, Round 152: loss=0.1200, accuracy=0.9560, gradient_norm=0.2124, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 153: loss=0.0897, accuracy=0.9685, gradient_norm=0.1926, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 154: loss=0.1309, accuracy=0.9482, gradient_norm=0.1922, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 155: loss=0.1322, accuracy=0.9483, gradient_norm=0.2244, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 156: loss=0.1113, accuracy=0.9581, gradient_norm=0.1838, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 157: loss=0.0997, accuracy=0.9632, gradient_norm=0.2005, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 158: loss=0.1170, accuracy=0.9566, gradient_norm=0.2188, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 159: loss=0.1022, accuracy=0.9646, gradient_norm=0.1924, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 160: loss=0.1025, accuracy=0.9618, gradient_norm=0.1987, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 161: loss=0.0980, accuracy=0.9662, gradient_norm=0.2064, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 162: loss=0.0960, accuracy=0.9656, gradient_norm=0.1942, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 163: loss=0.1004, accuracy=0.9666, gradient_norm=0.2082, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 164: loss=0.0845, accuracy=0.9726, gradient_norm=0.2111, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 165: loss=0.1073, accuracy=0.9619, gradient_norm=0.1976, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 166: loss=0.0798, accuracy=0.9743, gradient_norm=0.1872, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 167: loss=0.0858, accuracy=0.9711, gradient_norm=0.1848, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 168: loss=0.0768, accuracy=0.9755, gradient_norm=0.1792, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 169: loss=0.0933, accuracy=0.9683, gradient_norm=0.1933, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 170: loss=0.0869, accuracy=0.9705, gradient_norm=0.1876, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 171: loss=0.0948, accuracy=0.9666, gradient_norm=0.1860, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 172: loss=0.0740, accuracy=0.9762, gradient_norm=0.1812, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 173: loss=0.1013, accuracy=0.9633, gradient_norm=0.1873, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 174: loss=0.0782, accuracy=0.9721, gradient_norm=0.1871, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 175: loss=0.0875, accuracy=0.9704, gradient_norm=0.1961, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 176: loss=0.0958, accuracy=0.9666, gradient_norm=0.1919, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 177: loss=0.0738, accuracy=0.9761, gradient_norm=0.1673, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 178: loss=0.0697, accuracy=0.9786, gradient_norm=0.1709, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 179: loss=0.0882, accuracy=0.9687, gradient_norm=0.1758, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 180: loss=0.0720, accuracy=0.9764, gradient_norm=0.1643, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 181: loss=0.0544, accuracy=0.9851, gradient_norm=0.1508, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 182: loss=0.0550, accuracy=0.9853, gradient_norm=0.1436, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 183: loss=0.0712, accuracy=0.9759, gradient_norm=0.1446, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 184: loss=0.0672, accuracy=0.9782, gradient_norm=0.1677, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 185: loss=0.0693, accuracy=0.9776, gradient_norm=0.1458, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 186: loss=0.0547, accuracy=0.9836, gradient_norm=0.1442, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 187: loss=0.0732, accuracy=0.9756, gradient_norm=0.1468, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 188: loss=0.0550, accuracy=0.9844, gradient_norm=0.1364, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 189: loss=0.0674, accuracy=0.9787, gradient_norm=0.1717, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 190: loss=0.0489, accuracy=0.9878, gradient_norm=0.1437, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 191: loss=0.0579, accuracy=0.9823, gradient_norm=0.1432, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 192: loss=0.0604, accuracy=0.9807, gradient_norm=0.1424, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 193: loss=0.0345, accuracy=0.9927, gradient_norm=0.1234, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 194: loss=0.0733, accuracy=0.9745, gradient_norm=0.1683, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 195: loss=0.0492, accuracy=0.9863, gradient_norm=0.1496, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 196: loss=0.0400, accuracy=0.9904, gradient_norm=0.1239, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 197: loss=0.0529, accuracy=0.9847, gradient_norm=0.1639, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 198: loss=0.0481, accuracy=0.9861, gradient_norm=0.1251, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 199: loss=0.0428, accuracy=0.9892, gradient_norm=0.1401, 
[2025-09-18 19:29:37,909][__main__][INFO] - Train, Round 200: loss=0.0489, accuracy=0.9865, gradient_norm=0.1316, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 001: loss=2.2319, accuracy=0.3448, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 002: loss=2.1460, accuracy=0.4512, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 003: loss=2.0198, accuracy=0.5105, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 004: loss=1.8026, accuracy=0.5440, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 005: loss=1.5092, accuracy=0.5572, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 006: loss=1.2694, accuracy=0.5858, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 007: loss=1.0848, accuracy=0.5958, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 008: loss=0.9403, accuracy=0.6143, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 009: loss=0.7989, accuracy=0.6277, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 010: loss=0.7235, accuracy=0.6457, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 011: loss=0.6941, accuracy=0.6590, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 012: loss=0.6588, accuracy=0.6660, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 013: loss=0.6410, accuracy=0.6739, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 014: loss=0.6258, accuracy=0.6735, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 015: loss=0.6139, accuracy=0.6760, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 016: loss=0.6061, accuracy=0.6841, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 017: loss=0.5933, accuracy=0.6840, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 018: loss=0.5788, accuracy=0.6945, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 019: loss=0.5715, accuracy=0.7028, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 020: loss=0.5675, accuracy=0.7049, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 021: loss=0.5553, accuracy=0.7003, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 022: loss=0.5466, accuracy=0.7053, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 023: loss=0.5427, accuracy=0.7112, 
[2025-09-18 19:29:37,909][__main__][INFO] - Test, Round 024: loss=0.5379, accuracy=0.7152, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 025: loss=0.5344, accuracy=0.7164, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 026: loss=0.5307, accuracy=0.7212, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 027: loss=0.5266, accuracy=0.7212, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 028: loss=0.5236, accuracy=0.7222, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 029: loss=0.5221, accuracy=0.7232, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 030: loss=0.5202, accuracy=0.7262, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 031: loss=0.5134, accuracy=0.7326, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 032: loss=0.5091, accuracy=0.7310, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 033: loss=0.5054, accuracy=0.7346, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 034: loss=0.5018, accuracy=0.7381, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 035: loss=0.4993, accuracy=0.7381, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 036: loss=0.4923, accuracy=0.7463, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 037: loss=0.4907, accuracy=0.7462, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 038: loss=0.4883, accuracy=0.7441, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 039: loss=0.4830, accuracy=0.7505, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 040: loss=0.4822, accuracy=0.7532, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 041: loss=0.4806, accuracy=0.7521, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 042: loss=0.4719, accuracy=0.7578, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 043: loss=0.4708, accuracy=0.7574, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 044: loss=0.4680, accuracy=0.7602, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 045: loss=0.4615, accuracy=0.7655, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 046: loss=0.4592, accuracy=0.7698, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 047: loss=0.4568, accuracy=0.7681, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 048: loss=0.4551, accuracy=0.7694, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 049: loss=0.4546, accuracy=0.7707, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 050: loss=0.4498, accuracy=0.7732, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 051: loss=0.4467, accuracy=0.7743, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 052: loss=0.4457, accuracy=0.7703, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 053: loss=0.4432, accuracy=0.7762, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 054: loss=0.4392, accuracy=0.7791, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 055: loss=0.4360, accuracy=0.7808, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 056: loss=0.4344, accuracy=0.7811, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 057: loss=0.4326, accuracy=0.7840, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 058: loss=0.4278, accuracy=0.7853, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 059: loss=0.4261, accuracy=0.7844, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 060: loss=0.4236, accuracy=0.7892, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 061: loss=0.4202, accuracy=0.7897, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 062: loss=0.4186, accuracy=0.7931, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 063: loss=0.4178, accuracy=0.7956, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 064: loss=0.4177, accuracy=0.7924, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 065: loss=0.4117, accuracy=0.7949, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 066: loss=0.4101, accuracy=0.8002, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 067: loss=0.4092, accuracy=0.8017, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 068: loss=0.4075, accuracy=0.8021, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 069: loss=0.4065, accuracy=0.8065, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 070: loss=0.4036, accuracy=0.8034, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 071: loss=0.4031, accuracy=0.8037, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 072: loss=0.4023, accuracy=0.8063, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 073: loss=0.3997, accuracy=0.8067, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 074: loss=0.3966, accuracy=0.8087, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 075: loss=0.3975, accuracy=0.8105, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 076: loss=0.3942, accuracy=0.8120, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 077: loss=0.3914, accuracy=0.8122, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 078: loss=0.3897, accuracy=0.8134, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 079: loss=0.3880, accuracy=0.8122, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 080: loss=0.3878, accuracy=0.8129, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 081: loss=0.3875, accuracy=0.8132, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 082: loss=0.3876, accuracy=0.8135, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 083: loss=0.3853, accuracy=0.8157, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 084: loss=0.3824, accuracy=0.8179, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 085: loss=0.3790, accuracy=0.8199, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 086: loss=0.3775, accuracy=0.8222, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 087: loss=0.3776, accuracy=0.8228, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 088: loss=0.3752, accuracy=0.8218, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 089: loss=0.3715, accuracy=0.8241, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 090: loss=0.3757, accuracy=0.8228, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 091: loss=0.3770, accuracy=0.8228, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 092: loss=0.3741, accuracy=0.8245, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 093: loss=0.3733, accuracy=0.8268, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 094: loss=0.3739, accuracy=0.8250, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 095: loss=0.3766, accuracy=0.8237, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 096: loss=0.3721, accuracy=0.8255, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 097: loss=0.3753, accuracy=0.8269, 
[2025-09-18 19:29:37,910][__main__][INFO] - Test, Round 098: loss=0.3727, accuracy=0.8269, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 099: loss=0.3685, accuracy=0.8306, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 100: loss=0.3680, accuracy=0.8309, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 101: loss=0.3680, accuracy=0.8314, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 102: loss=0.3710, accuracy=0.8336, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 103: loss=0.3685, accuracy=0.8352, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 104: loss=0.3675, accuracy=0.8350, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 105: loss=0.3668, accuracy=0.8339, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 106: loss=0.3660, accuracy=0.8345, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 107: loss=0.3663, accuracy=0.8365, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 108: loss=0.3670, accuracy=0.8344, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 109: loss=0.3689, accuracy=0.8332, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 110: loss=0.3661, accuracy=0.8348, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 111: loss=0.3694, accuracy=0.8376, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 112: loss=0.3661, accuracy=0.8373, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 113: loss=0.3637, accuracy=0.8395, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 114: loss=0.3630, accuracy=0.8408, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 115: loss=0.3639, accuracy=0.8376, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 116: loss=0.3623, accuracy=0.8379, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 117: loss=0.3696, accuracy=0.8380, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 118: loss=0.3641, accuracy=0.8417, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 119: loss=0.3639, accuracy=0.8403, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 120: loss=0.3654, accuracy=0.8397, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 121: loss=0.3687, accuracy=0.8410, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 122: loss=0.3649, accuracy=0.8411, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 123: loss=0.3633, accuracy=0.8417, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 124: loss=0.3664, accuracy=0.8436, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 125: loss=0.3706, accuracy=0.8399, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 126: loss=0.3705, accuracy=0.8409, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 127: loss=0.3682, accuracy=0.8411, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 128: loss=0.3665, accuracy=0.8459, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 129: loss=0.3679, accuracy=0.8434, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 130: loss=0.3685, accuracy=0.8423, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 131: loss=0.3733, accuracy=0.8404, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 132: loss=0.3749, accuracy=0.8410, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 133: loss=0.3703, accuracy=0.8435, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 134: loss=0.3748, accuracy=0.8451, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 135: loss=0.3770, accuracy=0.8447, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 136: loss=0.3790, accuracy=0.8449, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 137: loss=0.3789, accuracy=0.8452, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 138: loss=0.3837, accuracy=0.8431, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 139: loss=0.3854, accuracy=0.8445, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 140: loss=0.3842, accuracy=0.8461, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 141: loss=0.3832, accuracy=0.8451, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 142: loss=0.3821, accuracy=0.8455, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 143: loss=0.3811, accuracy=0.8433, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 144: loss=0.3877, accuracy=0.8406, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 145: loss=0.3868, accuracy=0.8424, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 146: loss=0.3856, accuracy=0.8457, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 147: loss=0.3902, accuracy=0.8448, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 148: loss=0.3882, accuracy=0.8485, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 149: loss=0.3830, accuracy=0.8517, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 150: loss=0.3903, accuracy=0.8507, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 151: loss=0.3933, accuracy=0.8495, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 152: loss=0.3938, accuracy=0.8516, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 153: loss=0.3879, accuracy=0.8516, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 154: loss=0.3921, accuracy=0.8494, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 155: loss=0.3960, accuracy=0.8495, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 156: loss=0.3939, accuracy=0.8502, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 157: loss=0.3946, accuracy=0.8482, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 158: loss=0.3979, accuracy=0.8506, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 159: loss=0.3963, accuracy=0.8488, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 160: loss=0.3966, accuracy=0.8514, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 161: loss=0.4019, accuracy=0.8494, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 162: loss=0.4008, accuracy=0.8499, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 163: loss=0.4023, accuracy=0.8513, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 164: loss=0.4069, accuracy=0.8490, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 165: loss=0.4097, accuracy=0.8469, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 166: loss=0.4077, accuracy=0.8473, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 167: loss=0.4082, accuracy=0.8496, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 168: loss=0.4116, accuracy=0.8488, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 169: loss=0.4144, accuracy=0.8505, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 170: loss=0.4187, accuracy=0.8506, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 171: loss=0.4156, accuracy=0.8510, 
[2025-09-18 19:29:37,911][__main__][INFO] - Test, Round 172: loss=0.4199, accuracy=0.8497, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 173: loss=0.4264, accuracy=0.8491, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 174: loss=0.4300, accuracy=0.8499, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 175: loss=0.4291, accuracy=0.8480, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 176: loss=0.4295, accuracy=0.8490, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 177: loss=0.4294, accuracy=0.8510, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 178: loss=0.4357, accuracy=0.8498, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 179: loss=0.4360, accuracy=0.8494, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 180: loss=0.4317, accuracy=0.8532, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 181: loss=0.4315, accuracy=0.8531, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 182: loss=0.4346, accuracy=0.8534, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 183: loss=0.4363, accuracy=0.8548, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 184: loss=0.4343, accuracy=0.8539, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 185: loss=0.4380, accuracy=0.8538, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 186: loss=0.4425, accuracy=0.8527, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 187: loss=0.4459, accuracy=0.8521, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 188: loss=0.4460, accuracy=0.8546, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 189: loss=0.4488, accuracy=0.8510, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 190: loss=0.4479, accuracy=0.8552, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 191: loss=0.4523, accuracy=0.8566, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 192: loss=0.4512, accuracy=0.8551, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 193: loss=0.4531, accuracy=0.8534, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 194: loss=0.4563, accuracy=0.8524, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 195: loss=0.4638, accuracy=0.8507, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 196: loss=0.4662, accuracy=0.8510, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 197: loss=0.4660, accuracy=0.8494, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 198: loss=0.4662, accuracy=0.8522, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 199: loss=0.4662, accuracy=0.8539, 
[2025-09-18 19:29:37,912][__main__][INFO] - Test, Round 200: loss=0.4657, accuracy=0.8544, 

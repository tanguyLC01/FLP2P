[2025-09-15 09:51:05,111][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.309844796359539,  accuracy: 0.10492, gradient_norm : 0.7361420699085218
[2025-09-15 09:51:15,635][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.304917322039604,  accuracy: 0.0988
[2025-09-15 09:51:25,401][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.303200606405735,  accuracy: 0.10922, gradient_norm : 0.7082880478234366
[2025-09-15 09:51:35,838][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.302730763375759,  accuracy: 0.105
[2025-09-15 09:51:45,854][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 2.2974347537755966,  accuracy: 0.11446, gradient_norm : 0.7032288342302647
[2025-09-15 09:51:57,747][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.2991531492352486,  accuracy: 0.1161
[2025-09-15 09:52:07,723][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 2.292629137635231,  accuracy: 0.12392, gradient_norm : 0.6924724836152764
[2025-09-15 09:52:18,259][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 2.294439847588539,  accuracy: 0.1266
[2025-09-15 09:52:28,161][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 2.288365100324154,  accuracy: 0.13102, gradient_norm : 0.7104259239171563
[2025-09-15 09:52:38,650][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 2.289109628760815,  accuracy: 0.1387
[2025-09-15 09:52:48,503][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 2.283758541941643,  accuracy: 0.13864, gradient_norm : 0.7002938857226585
[2025-09-15 09:52:59,013][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 2.2840472656488418,  accuracy: 0.1453
[2025-09-15 09:53:08,871][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 2.2792873960733413,  accuracy: 0.1486, gradient_norm : 0.7084543875248004
[2025-09-15 09:53:19,512][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 2.2788452066540716,  accuracy: 0.1536
[2025-09-15 09:53:29,296][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 2.2745819026231766,  accuracy: 0.15774, gradient_norm : 0.7269886215163629
[2025-09-15 09:53:39,727][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 2.273857901120186,  accuracy: 0.1646
[2025-09-15 09:53:49,571][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 2.2696794110536573,  accuracy: 0.17088, gradient_norm : 0.7238064777381921
[2025-09-15 09:54:00,198][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 2.268388538515568,  accuracy: 0.1753
[2025-09-15 09:54:10,095][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 2.264427410662174,  accuracy: 0.18154, gradient_norm : 0.7424425003934567
[2025-09-15 09:54:20,621][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 2.2630656340122224,  accuracy: 0.1839
[2025-09-15 09:54:30,440][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 2.258890665769577,  accuracy: 0.18908, gradient_norm : 0.7562216842695731
[2025-09-15 09:54:41,003][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 2.2570324518203737,  accuracy: 0.1897
[2025-09-15 09:54:50,730][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 2.252754758298397,  accuracy: 0.198, gradient_norm : 0.7651949558199915
[2025-09-15 09:55:01,240][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 2.250317586195469,  accuracy: 0.1969
[2025-09-15 09:55:11,051][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 2.2459597998857497,  accuracy: 0.20754, gradient_norm : 0.7972122288407132
[2025-09-15 09:55:21,744][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 2.2432048302412033,  accuracy: 0.2042
[2025-09-15 09:55:31,612][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 2.2385733419656755,  accuracy: 0.2164, gradient_norm : 0.8018179983776054
[2025-09-15 09:55:42,037][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 2.2352738643407823,  accuracy: 0.2173
[2025-09-15 09:55:51,880][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 2.2305865159630773,  accuracy: 0.22668, gradient_norm : 0.8316972501188531
[2025-09-15 09:56:02,486][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 2.226126721954346,  accuracy: 0.2276
[2025-09-15 09:56:12,292][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 2.221314564347267,  accuracy: 0.2375, gradient_norm : 0.8616565905254732
[2025-09-15 09:56:22,768][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 2.215387904417515,  accuracy: 0.2363
[2025-09-15 09:56:32,555][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 2.210926094353199,  accuracy: 0.24754, gradient_norm : 0.8898597874314247
[2025-09-15 09:56:43,198][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 2.2041114532470703,  accuracy: 0.2538
[2025-09-15 09:56:53,095][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 2.1994267371296883,  accuracy: 0.2579, gradient_norm : 0.9291498727282536
[2025-09-15 09:57:03,567][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 2.1922092071533203,  accuracy: 0.2586
[2025-09-15 09:57:13,434][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 2.1876782512664796,  accuracy: 0.26404, gradient_norm : 0.9528627212506616
[2025-09-15 09:57:24,084][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 2.178493694746494,  accuracy: 0.2671
[2025-09-15 09:57:34,044][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 2.1749897077679634,  accuracy: 0.2692, gradient_norm : 1.0156770111621873
[2025-09-15 09:57:44,689][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 2.167115734255314,  accuracy: 0.2618
[2025-09-15 09:57:54,918][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 2.1610275027155876,  accuracy: 0.27292, gradient_norm : 1.0265550918282664
[2025-09-15 09:58:06,689][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 2.149746350777149,  accuracy: 0.2646
[2025-09-15 09:58:16,723][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 2.1459287723898886,  accuracy: 0.27288, gradient_norm : 1.0728917684758743
[2025-09-15 09:58:27,661][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 2.136006469261646,  accuracy: 0.2673
[2025-09-15 09:58:37,716][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 2.13084331035614,  accuracy: 0.2779, gradient_norm : 1.1184034926965318
[2025-09-15 09:58:48,946][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 2.119030685865879,  accuracy: 0.2687
[2025-09-15 09:58:59,337][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 2.115244225561619,  accuracy: 0.27568, gradient_norm : 1.1831325446103262
[2025-09-15 09:59:09,940][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 2.1090825971364975,  accuracy: 0.2613
[2025-09-15 09:59:19,963][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 2.1006550380587576,  accuracy: 0.27998, gradient_norm : 1.300818033344525
[2025-09-15 09:59:30,577][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 2.104123957747221,  accuracy: 0.2397
[2025-09-15 09:59:40,611][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 2.1026207306981086,  accuracy: 0.26244, gradient_norm : 1.6330509473125598
[2025-09-15 09:59:51,375][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 2.185043850553036,  accuracy: 0.1904
[2025-09-15 10:00:01,240][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 2.115760229229927,  accuracy: 0.25658, gradient_norm : 1.617939347944067
[2025-09-15 10:00:12,420][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 2.099442378932238,  accuracy: 0.2298
[2025-09-15 10:00:22,321][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 2.08910454839468,  accuracy: 0.27066, gradient_norm : 1.2658254827777058
[2025-09-15 10:00:32,818][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 2.0781739690542222,  accuracy: 0.2615
[2025-09-15 10:00:42,697][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 2.0541911706328393,  accuracy: 0.2817, gradient_norm : 1.3359081148741092
[2025-09-15 10:00:53,231][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 2.0558194940447807,  accuracy: 0.2804
[2025-09-15 10:01:03,387][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 2.030278708934784,  accuracy: 0.29088, gradient_norm : 1.4513772304219938
[2025-09-15 10:01:14,024][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 2.0459457073926925,  accuracy: 0.2745
[2025-09-15 10:01:24,026][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 2.0145828127861023,  accuracy: 0.29154, gradient_norm : 1.5456471269723853
[2025-09-15 10:01:34,663][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 2.05229255374074,  accuracy: 0.2521
[2025-09-15 10:01:44,567][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 2.041181361824274,  accuracy: 0.27064, gradient_norm : 1.8638771083523915
[2025-09-15 10:01:55,064][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 2.1746126065790654,  accuracy: 0.2155
[2025-09-15 10:02:04,870][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 2.0549670961499213,  accuracy: 0.26654, gradient_norm : 2.017888407227833
[2025-09-15 10:02:15,472][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 2.127764541107416,  accuracy: 0.2159
[2025-09-15 10:02:25,319][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 2.0033475306630133,  accuracy: 0.28932, gradient_norm : 1.569449476355602
[2025-09-15 10:02:35,719][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 2.021387968736887,  accuracy: 0.2667
[2025-09-15 10:02:45,519][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 1.977123005092144,  accuracy: 0.29772, gradient_norm : 1.928931968282064
[2025-09-15 10:02:56,080][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 2.176773923045397,  accuracy: 0.22
[2025-09-15 10:03:05,968][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 2.001977928876877,  accuracy: 0.29806, gradient_norm : 1.668828083181377
[2025-09-15 10:03:16,353][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.9837954379200935,  accuracy: 0.284
[2025-09-15 10:03:26,157][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 1.9611663933098316,  accuracy: 0.2992, gradient_norm : 1.6505150476199113
[2025-09-15 10:03:36,787][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.9404622470140458,  accuracy: 0.3038
[2025-09-15 10:03:46,681][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 1.926686049103737,  accuracy: 0.31092, gradient_norm : 1.7681408528730682
[2025-09-15 10:03:57,183][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.9490952083170414,  accuracy: 0.2895
[2025-09-15 10:04:06,982][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 1.9248019818961621,  accuracy: 0.306, gradient_norm : 2.3774456408562505
[2025-09-15 10:04:17,688][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 2.4474721578061582,  accuracy: 0.2044
[2025-09-15 10:04:27,514][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 1.9851198971271515,  accuracy: 0.29636, gradient_norm : 2.1369302553724867
[2025-09-15 10:04:38,018][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 2.040639593744278,  accuracy: 0.2467
[2025-09-15 10:04:47,860][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 1.9406781652569771,  accuracy: 0.30612, gradient_norm : 1.8100134593816437
[2025-09-15 10:04:58,617][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.9224719552099705,  accuracy: 0.3108
[2025-09-15 10:05:08,374][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 1.903055541664362,  accuracy: 0.3202, gradient_norm : 1.7169629358681646
[2025-09-15 10:05:18,768][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.9167528356671333,  accuracy: 0.3072
[2025-09-15 10:05:28,885][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 1.878632221966982,  accuracy: 0.32916, gradient_norm : 1.9161300068217457
[2025-09-15 10:05:39,398][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.8699767360568047,  accuracy: 0.3179
[2025-09-15 10:05:49,115][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 1.8484020641446113,  accuracy: 0.332, gradient_norm : 1.9879045861896822
[2025-09-15 10:05:59,577][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.8646350015997886,  accuracy: 0.3194
[2025-09-15 10:06:09,420][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 1.8272372978925704,  accuracy: 0.34444, gradient_norm : 2.215849920714662
[2025-09-15 10:06:20,068][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.834549467110634,  accuracy: 0.3335
[2025-09-15 10:06:29,788][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 1.8163360720872879,  accuracy: 0.34384, gradient_norm : 2.2623381864566943
[2025-09-15 10:06:40,237][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.9278203932642937,  accuracy: 0.2853
[2025-09-15 10:06:50,072][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 1.8902376878261566,  accuracy: 0.30912, gradient_norm : 3.120577268974119
[2025-09-15 10:07:00,602][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 2.7626572795152664,  accuracy: 0.1763
[2025-09-15 10:07:10,386][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 2.1129530696570873,  accuracy: 0.24472, gradient_norm : 4.252911205649636
[2025-09-15 10:07:20,851][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 2.2052499990582466,  accuracy: 0.2595
[2025-09-15 10:07:30,779][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 1.9548972828686237,  accuracy: 0.293, gradient_norm : 1.9628686744833608
[2025-09-15 10:07:41,284][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.941782229834795,  accuracy: 0.3023
[2025-09-15 10:07:51,353][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 1.8864798176288604,  accuracy: 0.32882, gradient_norm : 2.0303278010461976
[2025-09-15 10:08:03,091][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.9526566805303096,  accuracy: 0.2655
[2025-09-15 10:08:13,266][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 1.849520090073347,  accuracy: 0.33114, gradient_norm : 2.136002979638343
[2025-09-15 10:08:23,911][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.8450386051774026,  accuracy: 0.3419
[2025-09-15 10:08:33,824][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 1.8115751813352108,  accuracy: 0.35188, gradient_norm : 2.1489085354492663
[2025-09-15 10:08:44,293][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.9010542480826378,  accuracy: 0.2915
[2025-09-15 10:08:54,197][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 1.819163685888052,  accuracy: 0.33336, gradient_norm : 2.5823382425177788
[2025-09-15 10:09:04,885][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 2.2255663466751576,  accuracy: 0.2586
[2025-09-15 10:09:14,718][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 1.8701935206353664,  accuracy: 0.32948, gradient_norm : 2.6297901225277203
[2025-09-15 10:09:25,287][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 2.1526521914064882,  accuracy: 0.2381
[2025-09-15 10:09:35,222][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 1.8129473567008971,  accuracy: 0.34266, gradient_norm : 2.2859621444626925
[2025-09-15 10:09:45,977][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.830206605052948,  accuracy: 0.3276
[2025-09-15 10:09:56,198][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 1.7906239247322082,  accuracy: 0.34854, gradient_norm : 2.132290615771837
[2025-09-15 10:10:08,438][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.8800178634762763,  accuracy: 0.2936
[2025-09-15 10:10:18,923][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 1.7694936828315257,  accuracy: 0.34996, gradient_norm : 2.665645347420413
[2025-09-15 10:10:31,206][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 2.1106469474077225,  accuracy: 0.2769
[2025-09-15 10:10:41,731][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 1.8138878355920314,  accuracy: 0.34284, gradient_norm : 2.353865723587065
[2025-09-15 10:10:53,703][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.929463966023922,  accuracy: 0.2834
[2025-09-15 10:11:04,158][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 1.7400351698696612,  accuracy: 0.36428, gradient_norm : 2.3720804115665506
[2025-09-15 10:11:16,347][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.8156588728606702,  accuracy: 0.337
[2025-09-15 10:11:26,883][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 1.7236158490180968,  accuracy: 0.37638, gradient_norm : 2.32951776586931
[2025-09-15 10:11:38,928][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.8534364736557007,  accuracy: 0.3158
[2025-09-15 10:11:49,472][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 1.7371240912377834,  accuracy: 0.36382, gradient_norm : 2.90883690060863
[2025-09-15 10:12:01,849][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 2.6618291017174722,  accuracy: 0.2161
[2025-09-15 10:12:12,294][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 1.8848955573141575,  accuracy: 0.32246, gradient_norm : 4.003159750834903
[2025-09-15 10:12:24,565][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 2.4892674320340156,  accuracy: 0.2462
[2025-09-15 10:12:34,994][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 1.8863255015015603,  accuracy: 0.31876, gradient_norm : 2.561510056958718
[2025-09-15 10:12:47,368][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.894957244181633,  accuracy: 0.3068
[2025-09-15 10:12:57,818][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 1.8369116780161858,  accuracy: 0.32816, gradient_norm : 2.517000273677855
[2025-09-15 10:13:09,820][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 2.01140192040205,  accuracy: 0.2621
[2025-09-15 10:13:20,278][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 1.839491262435913,  accuracy: 0.32854, gradient_norm : 2.8715068135733497
[2025-09-15 10:13:32,501][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 2.155529601895809,  accuracy: 0.2558
[2025-09-15 10:13:43,039][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 1.8764472591876984,  accuracy: 0.3186, gradient_norm : 2.830418959334279
[2025-09-15 10:13:55,170][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.8880451412200927,  accuracy: 0.2912
[2025-09-15 10:14:05,692][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 1.8199346075952052,  accuracy: 0.34118, gradient_norm : 2.7771956388697823
[2025-09-15 10:14:17,817][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.836280004310608,  accuracy: 0.3193
[2025-09-15 10:14:28,296][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 1.7844113241136075,  accuracy: 0.3488, gradient_norm : 2.6315345956355385
[2025-09-15 10:14:40,364][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.7971637901961803,  accuracy: 0.3305
[2025-09-15 10:14:50,875][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 1.7406242217123509,  accuracy: 0.36286, gradient_norm : 2.50180851566998
[2025-09-15 10:15:03,046][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.7754258312940598,  accuracy: 0.3506
[2025-09-15 10:15:13,555][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 1.7119393157958984,  accuracy: 0.38044, gradient_norm : 2.5281321189174495
[2025-09-15 10:15:25,811][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.7178998874902724,  accuracy: 0.359
[2025-09-15 10:15:36,268][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 1.6980310533940792,  accuracy: 0.37536, gradient_norm : 2.4877224512750034
[2025-09-15 10:15:48,530][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.7234363855600356,  accuracy: 0.3675
[2025-09-15 10:15:59,038][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 1.6957013767957687,  accuracy: 0.38386, gradient_norm : 2.6603557303917933
[2025-09-15 10:16:11,077][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.7064875641524793,  accuracy: 0.3675
[2025-09-15 10:16:21,564][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 1.6977993416786195,  accuracy: 0.3702, gradient_norm : 2.581093146765819
[2025-09-15 10:16:33,795][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.7335818602085113,  accuracy: 0.3598
[2025-09-15 10:16:44,284][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 1.6924919053912162,  accuracy: 0.38618, gradient_norm : 2.856030346754248
[2025-09-15 10:16:56,326][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.7849212828159333,  accuracy: 0.3505
[2025-09-15 10:17:06,816][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 1.7274865107238293,  accuracy: 0.3691, gradient_norm : 2.9020390160252276
[2025-09-15 10:17:19,021][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 2.0277584296524527,  accuracy: 0.293
[2025-09-15 10:17:29,537][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 1.6992593717575073,  accuracy: 0.38568, gradient_norm : 2.5835863214202903
[2025-09-15 10:17:41,500][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.7419359701395034,  accuracy: 0.3473
[2025-09-15 10:17:52,021][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 1.667423901259899,  accuracy: 0.38972, gradient_norm : 2.574128501746113
[2025-09-15 10:18:04,217][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.7039998462736607,  accuracy: 0.3741
[2025-09-15 10:18:14,691][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 1.6438275854289532,  accuracy: 0.40122, gradient_norm : 2.4998772187162808
[2025-09-15 10:18:26,758][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.7082895497739314,  accuracy: 0.3685
[2025-09-15 10:18:37,197][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 1.625395724028349,  accuracy: 0.40104, gradient_norm : 2.4342928532809256
[2025-09-15 10:18:49,416][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.6857832269072532,  accuracy: 0.3731
[2025-09-15 10:18:59,861][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 1.6257381473481656,  accuracy: 0.40378, gradient_norm : 2.683538542648547
[2025-09-15 10:19:12,027][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.706688134032488,  accuracy: 0.3705
[2025-09-15 10:19:22,548][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 1.6332672441005707,  accuracy: 0.39832, gradient_norm : 2.52355700907305
[2025-09-15 10:19:34,683][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.7276275416195392,  accuracy: 0.3575
[2025-09-15 10:19:45,177][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 1.6064843381941318,  accuracy: 0.41314, gradient_norm : 2.51822494467314
[2025-09-15 10:19:57,372][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.6774862368643284,  accuracy: 0.3775
[2025-09-15 10:20:07,848][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 1.6001371924579144,  accuracy: 0.41142, gradient_norm : 2.5446895001541256
[2025-09-15 10:20:20,070][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.7335666384279729,  accuracy: 0.353
[2025-09-15 10:20:30,674][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 1.6079479011893272,  accuracy: 0.41144, gradient_norm : 2.810145384749158
[2025-09-15 10:20:42,914][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.858115057325363,  accuracy: 0.3413
[2025-09-15 10:20:53,419][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 1.6386346472799778,  accuracy: 0.3965, gradient_norm : 2.810445842254698
[2025-09-15 10:21:05,702][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 2.0970641639888288,  accuracy: 0.2947
[2025-09-15 10:21:16,129][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 1.6182905101776124,  accuracy: 0.4075, gradient_norm : 2.7017112390201055
[2025-09-15 10:21:28,201][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.8018417018711568,  accuracy: 0.3418
[2025-09-15 10:21:38,720][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 1.6135996793210508,  accuracy: 0.40428, gradient_norm : 2.8181445597889323
[2025-09-15 10:21:51,065][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.9908393368840218,  accuracy: 0.3108
[2025-09-15 10:22:01,502][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 1.6170431545376778,  accuracy: 0.404, gradient_norm : 3.0292504549222907
[2025-09-15 10:22:13,711][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.986612703126669,  accuracy: 0.3167
[2025-09-15 10:22:24,241][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 1.6328885905444621,  accuracy: 0.39808, gradient_norm : 3.199516818668337
[2025-09-15 10:22:36,423][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 2.5613657806754113,  accuracy: 0.2572
[2025-09-15 10:22:46,954][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 1.6664634937047957,  accuracy: 0.3909, gradient_norm : 3.246954684131497
[2025-09-15 10:22:59,035][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 2.1429204718887807,  accuracy: 0.2835
[2025-09-15 10:23:09,589][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 1.6663538175821304,  accuracy: 0.38502, gradient_norm : 3.001097225165754
[2025-09-15 10:23:21,839][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.875447733962536,  accuracy: 0.3321
[2025-09-15 10:23:32,393][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 1.6516114258766175,  accuracy: 0.39082, gradient_norm : 3.0275888575043215
[2025-09-15 10:23:44,419][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.9423292966365815,  accuracy: 0.2976
[2025-09-15 10:23:54,923][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 1.663963741660118,  accuracy: 0.38194, gradient_norm : 3.708152117969827
[2025-09-15 10:24:07,165][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 2.3052209525883196,  accuracy: 0.2807
[2025-09-15 10:24:17,662][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 1.7501117125153542,  accuracy: 0.3641, gradient_norm : 3.248987109824351
[2025-09-15 10:24:29,821][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.831519585162401,  accuracy: 0.3313
[2025-09-15 10:24:40,298][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 1.6414333526790141,  accuracy: 0.40202, gradient_norm : 3.0747862061748408
[2025-09-15 10:24:52,802][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.8221249044001102,  accuracy: 0.3367
[2025-09-15 10:25:03,242][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 1.6086408068239688,  accuracy: 0.41266, gradient_norm : 2.8759513811398794
[2025-09-15 10:25:15,388][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.7936083380043506,  accuracy: 0.3413
[2025-09-15 10:25:25,816][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 1.5943626967072486,  accuracy: 0.40978, gradient_norm : 2.9697602639496723
[2025-09-15 10:25:38,047][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 2.0400507323205472,  accuracy: 0.3085
[2025-09-15 10:25:48,533][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 1.6051386679708957,  accuracy: 0.4064, gradient_norm : 2.957320776020265
[2025-09-15 10:26:00,550][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.8643297423779965,  accuracy: 0.3416
[2025-09-15 10:26:11,041][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 1.5816990664601327,  accuracy: 0.41704, gradient_norm : 2.861661412425542
[2025-09-15 10:26:23,101][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.9650561635017394,  accuracy: 0.3237
[2025-09-15 10:26:33,605][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 1.5772691977024078,  accuracy: 0.42178, gradient_norm : 2.89989946017745
[2025-09-15 10:26:45,620][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.8594420651555061,  accuracy: 0.3383
[2025-09-15 10:26:56,127][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 1.5724567864835262,  accuracy: 0.4221, gradient_norm : 2.8550277610570243
[2025-09-15 10:27:08,315][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.8566063685953618,  accuracy: 0.3407
[2025-09-15 10:27:18,825][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 1.553337723314762,  accuracy: 0.4284, gradient_norm : 2.7806331898879715
[2025-09-15 10:27:30,776][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.722111431890726,  accuracy: 0.3719
[2025-09-15 10:27:41,319][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 1.5351172713935375,  accuracy: 0.43666, gradient_norm : 2.806196223991494
[2025-09-15 10:27:53,673][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.6759954150497913,  accuracy: 0.3886
[2025-09-15 10:28:04,050][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 1.5227711072564125,  accuracy: 0.442, gradient_norm : 2.8132410451258862
[2025-09-15 10:28:16,196][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.7493410146176815,  accuracy: 0.3743
[2025-09-15 10:28:26,576][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 1.5387320418655872,  accuracy: 0.43376, gradient_norm : 2.9993332663978443
[2025-09-15 10:28:38,803][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 2.0862023285329343,  accuracy: 0.307
[2025-09-15 10:28:49,421][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 1.5715388725697994,  accuracy: 0.42262, gradient_norm : 3.166013827225778
[2025-09-15 10:29:01,481][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.954872017633915,  accuracy: 0.329
[2025-09-15 10:29:11,971][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 1.561351405084133,  accuracy: 0.4223, gradient_norm : 2.9048919556698354
[2025-09-15 10:29:24,258][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.7761669514894485,  accuracy: 0.3614
[2025-09-15 10:29:34,752][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 1.5387031134963036,  accuracy: 0.43006, gradient_norm : 2.8807320062813346
[2025-09-15 10:29:46,853][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.7336112162053585,  accuracy: 0.3707
[2025-09-15 10:29:57,303][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 1.5237254729866982,  accuracy: 0.44102, gradient_norm : 2.935206508347944
[2025-09-15 10:30:09,455][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.9134270287036896,  accuracy: 0.3322
[2025-09-15 10:30:19,940][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 1.5420018082857132,  accuracy: 0.43208, gradient_norm : 3.078298096485714
[2025-09-15 10:30:31,935][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.829662867283821,  accuracy: 0.3505
[2025-09-15 10:30:42,475][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 1.5469991825520992,  accuracy: 0.43198, gradient_norm : 3.2561206135236307
[2025-09-15 10:30:54,725][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.8942253353834153,  accuracy: 0.341
[2025-09-15 10:31:05,276][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 1.5970788410305976,  accuracy: 0.40776, gradient_norm : 3.426902465411828
[2025-09-15 10:31:17,324][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.8532026764094829,  accuracy: 0.3469
[2025-09-15 10:31:27,812][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 1.6165641981363297,  accuracy: 0.41552, gradient_norm : 3.7797942230260695
[2025-09-15 10:31:40,117][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.837738584959507,  accuracy: 0.3577
[2025-09-15 10:31:50,599][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 1.6604159937798977,  accuracy: 0.39518, gradient_norm : 3.488384366946599
[2025-09-15 10:32:02,754][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.6169062973856927,  accuracy: 0.4049
[2025-09-15 10:32:13,221][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 1.5728976327180861,  accuracy: 0.42772, gradient_norm : 3.395394289548566
[2025-09-15 10:32:25,404][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.72133178434968,  accuracy: 0.3644
[2025-09-15 10:32:35,862][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 1.5841248606145382,  accuracy: 0.40966, gradient_norm : 3.6610966474544915
[2025-09-15 10:32:47,938][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.9083753601253033,  accuracy: 0.3423
[2025-09-15 10:32:58,424][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 1.6345993626117705,  accuracy: 0.40726, gradient_norm : 3.574271115598281
[2025-09-15 10:33:10,581][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.7512847142100334,  accuracy: 0.3443
[2025-09-15 10:33:21,072][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 1.6092048475146294,  accuracy: 0.40146, gradient_norm : 3.541858550740398
[2025-09-15 10:33:33,099][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.7824254614412784,  accuracy: 0.369
[2025-09-15 10:33:43,535][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 1.6063765373826027,  accuracy: 0.4157, gradient_norm : 3.4787869618194844
[2025-09-15 10:33:55,816][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 2.08508241468668,  accuracy: 0.2766
[2025-09-15 10:34:06,371][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 1.6123056277632712,  accuracy: 0.40646, gradient_norm : 3.5213914580686043
[2025-09-15 10:34:18,485][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.8346527302742004,  accuracy: 0.3448
[2025-09-15 10:34:29,035][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 1.600942860096693,  accuracy: 0.4116, gradient_norm : 3.04996494187106
[2025-09-15 10:34:41,280][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.6353901223123073,  accuracy: 0.3922
[2025-09-15 10:34:51,872][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 1.5227835023403167,  accuracy: 0.43828, gradient_norm : 2.80614845671909
[2025-09-15 10:35:04,067][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.6303989868462085,  accuracy: 0.3883
[2025-09-15 10:35:14,659][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 1.4822447836399077,  accuracy: 0.45502, gradient_norm : 2.6820165435691474
[2025-09-15 10:35:26,887][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.7075524733066558,  accuracy: 0.3711
[2025-09-15 10:35:37,323][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 1.4867132042348385,  accuracy: 0.45278, gradient_norm : 2.965292365391864
[2025-09-15 10:35:49,448][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.742875902056694,  accuracy: 0.3681
[2025-09-15 10:35:59,843][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 1.5059874519705772,  accuracy: 0.44584, gradient_norm : 3.1239068798160634
[2025-09-15 10:36:12,115][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 2.134114922565222,  accuracy: 0.2892
[2025-09-15 10:36:22,575][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 1.5370829486846924,  accuracy: 0.43574, gradient_norm : 3.255813538402026
[2025-09-15 10:36:34,709][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.8445738412141799,  accuracy: 0.3436
[2025-09-15 10:36:45,227][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 1.5343822227418422,  accuracy: 0.4305, gradient_norm : 2.984013002288664
[2025-09-15 10:36:57,417][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.6609569819450378,  accuracy: 0.3813
[2025-09-15 10:37:07,946][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 1.4940367810428143,  accuracy: 0.44254, gradient_norm : 3.0062042006746985
[2025-09-15 10:37:20,045][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.7471484753370286,  accuracy: 0.3626
[2025-09-15 10:37:30,536][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 1.495997871607542,  accuracy: 0.44656, gradient_norm : 3.071530608281472
[2025-09-15 10:37:42,742][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.78508107188344,  accuracy: 0.3568
[2025-09-15 10:37:53,291][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 1.501467865407467,  accuracy: 0.43634, gradient_norm : 3.152731332287026
[2025-09-15 10:38:05,302][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.7537728046059609,  accuracy: 0.3636
[2025-09-15 10:38:15,853][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 1.4945116543769836,  accuracy: 0.44144, gradient_norm : 3.252187131687
[2025-09-15 10:38:28,070][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 2.01340656542778,  accuracy: 0.3023
[2025-09-15 10:38:38,591][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 1.531792143434286,  accuracy: 0.42492, gradient_norm : 3.4730222997794
[2025-09-15 10:38:50,690][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.8810905242919922,  accuracy: 0.3417
[2025-09-15 10:39:01,155][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 1.52737990796566,  accuracy: 0.42452, gradient_norm : 3.1410023998257532
[2025-09-15 10:39:13,395][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.686637820506096,  accuracy: 0.3752
[2025-09-15 10:39:23,825][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 1.4776580925285816,  accuracy: 0.44678, gradient_norm : 2.9987059060057675
[2025-09-15 10:39:35,947][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.7310576279222964,  accuracy: 0.3736
[2025-09-15 10:39:46,419][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 1.4646252128481865,  accuracy: 0.45988, gradient_norm : 3.07185400420862
[2025-09-15 10:39:58,671][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.776009219110012,  accuracy: 0.3564
[2025-09-15 10:40:09,112][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 1.464338714182377,  accuracy: 0.45038, gradient_norm : 3.22057933251739
[2025-09-15 10:40:21,201][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.7562978425860405,  accuracy: 0.3642
[2025-09-15 10:40:31,615][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 1.4968554908037186,  accuracy: 0.44126, gradient_norm : 3.334328344429285
[2025-09-15 10:40:43,866][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 1.9382343631207943,  accuracy: 0.3217
[2025-09-15 10:40:54,370][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 1.4959079712629317,  accuracy: 0.43668, gradient_norm : 3.396311304843621
[2025-09-15 10:41:06,510][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 1.7818724391043186,  accuracy: 0.3636
[2025-09-15 10:41:17,004][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 1.5013746447861194,  accuracy: 0.44322, gradient_norm : 3.124729877936377
[2025-09-15 10:41:29,227][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 1.6094618884921075,  accuracy: 0.4006
[2025-09-15 10:41:39,858][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 1.4483404703438283,  accuracy: 0.45666, gradient_norm : 3.048868897401891
[2025-09-15 10:41:51,912][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 1.619493156903982,  accuracy: 0.3903
[2025-09-15 10:42:02,447][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 1.441557396799326,  accuracy: 0.46048, gradient_norm : 3.0320224424510176
[2025-09-15 10:42:14,730][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 1.6154554498136044,  accuracy: 0.3919
[2025-09-15 10:42:25,214][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 1.4340956668555735,  accuracy: 0.4613, gradient_norm : 3.1768683224891827
[2025-09-15 10:42:37,294][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 1.6447771031975746,  accuracy: 0.3883
[2025-09-15 10:42:47,803][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 1.4577025465667248,  accuracy: 0.45264, gradient_norm : 3.1826527527253274
[2025-09-15 10:43:00,038][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 1.723488893198967,  accuracy: 0.3691
[2025-09-15 10:43:10,565][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 1.4466844254732132,  accuracy: 0.46354, gradient_norm : 3.340501139513524
[2025-09-15 10:43:22,636][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 1.7636762768626213,  accuracy: 0.3738
[2025-09-15 10:43:33,056][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 1.48526248306036,  accuracy: 0.45294, gradient_norm : 3.2860436111357574
[2025-09-15 10:43:45,304][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 1.65845132920146,  accuracy: 0.3853
[2025-09-15 10:43:55,803][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 1.4463441097736358,  accuracy: 0.46514, gradient_norm : 3.270159030514585
[2025-09-15 10:44:07,893][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 1.600322534018755,  accuracy: 0.4044
[2025-09-15 10:44:18,373][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 1.4424788604676724,  accuracy: 0.47364, gradient_norm : 3.2650605505270063
[2025-09-15 10:44:30,667][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 1.6724519419431687,  accuracy: 0.3799
[2025-09-15 10:44:41,101][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 1.4756691655516625,  accuracy: 0.4639, gradient_norm : 3.668419042030127
[2025-09-15 10:44:53,254][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 1.9742535227119922,  accuracy: 0.3312
[2025-09-15 10:45:03,719][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 1.5465122294425964,  accuracy: 0.43678, gradient_norm : 3.7975890261732754
[2025-09-15 10:45:15,816][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 1.6950186569690704,  accuracy: 0.3712
[2025-09-15 10:45:26,402][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 1.5102864469587802,  accuracy: 0.44984, gradient_norm : 3.728273797922822
[2025-09-15 10:45:38,486][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 1.684068681204319,  accuracy: 0.3865
[2025-09-15 10:45:48,975][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 1.5042614027857781,  accuracy: 0.4556, gradient_norm : 3.7040615316593657
[2025-09-15 10:46:01,178][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 1.735561702030897,  accuracy: 0.364
[2025-09-15 10:46:11,649][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 1.4777634751796722,  accuracy: 0.46646, gradient_norm : 3.6500675342318107
[2025-09-15 10:46:23,621][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 1.7656665872216224,  accuracy: 0.3797
[2025-09-15 10:46:34,170][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 1.4724852760136127,  accuracy: 0.46378, gradient_norm : 3.339011436827639
[2025-09-15 10:46:46,378][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 1.846038369733095,  accuracy: 0.3512
[2025-09-15 10:46:56,834][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 1.4471749365329742,  accuracy: 0.47692, gradient_norm : 3.4707227544197967
[2025-09-15 10:47:08,984][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 2.5009005081772804,  accuracy: 0.2945
[2025-09-15 10:47:19,402][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 1.4789228527247906,  accuracy: 0.46564, gradient_norm : 3.4208201970822456
[2025-09-15 10:47:31,660][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 2.0347052287817,  accuracy: 0.3326
[2025-09-15 10:47:42,141][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 1.4508711460232735,  accuracy: 0.4745, gradient_norm : 3.192402325067814
[2025-09-15 10:47:54,325][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 1.789692240178585,  accuracy: 0.3643
[2025-09-15 10:48:04,772][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 1.384040361493826,  accuracy: 0.4933, gradient_norm : 3.0896101379068717
[2025-09-15 10:48:17,042][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 1.7662432468891143,  accuracy: 0.3836
[2025-09-15 10:48:27,524][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 1.397730239033699,  accuracy: 0.49416, gradient_norm : 3.1905894374746917
[2025-09-15 10:48:39,634][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 1.890639981585741,  accuracy: 0.3515
[2025-09-15 10:48:50,122][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 1.4050479939579963,  accuracy: 0.48896, gradient_norm : 3.400032938536571
[2025-09-15 10:49:02,333][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 1.8941393745720387,  accuracy: 0.3527
[2025-09-15 10:49:12,872][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 1.4204048082232474,  accuracy: 0.47972, gradient_norm : 3.4794073564708334
[2025-09-15 10:49:24,929][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 1.9120229093790055,  accuracy: 0.3438
[2025-09-15 10:49:35,396][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 1.4334098203480243,  accuracy: 0.47046, gradient_norm : 3.478379654345419
[2025-09-15 10:49:47,556][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 1.880528601682186,  accuracy: 0.3639
[2025-09-15 10:49:58,004][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 1.4486944577097893,  accuracy: 0.46762, gradient_norm : 3.670341950275396
[2025-09-15 10:50:10,165][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 1.9371569811046123,  accuracy: 0.3379
[2025-09-15 10:50:20,712][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 1.4798532895743848,  accuracy: 0.45266, gradient_norm : 3.828818561961256
[2025-09-15 10:50:32,904][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 1.8777928693056107,  accuracy: 0.3487
[2025-09-15 10:50:43,420][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 1.5178823801875114,  accuracy: 0.44466, gradient_norm : 3.8987985237901537
[2025-09-15 10:50:55,479][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 1.6730322147727013,  accuracy: 0.3949
[2025-09-15 10:51:05,918][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 1.4848190316557883,  accuracy: 0.4506, gradient_norm : 3.792902962862618
[2025-09-15 10:51:18,262][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 1.7704362991690636,  accuracy: 0.367
[2025-09-15 10:51:28,715][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 1.4940758827328682,  accuracy: 0.45646, gradient_norm : 3.619499486003057
[2025-09-15 10:51:40,827][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 1.6029755133092403,  accuracy: 0.4159
[2025-09-15 10:51:51,349][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 1.4062799283862113,  accuracy: 0.48534, gradient_norm : 3.2575670093527807
[2025-09-15 10:52:03,635][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 1.5438443980872631,  accuracy: 0.4355
[2025-09-15 10:52:14,154][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 1.378075235337019,  accuracy: 0.49832, gradient_norm : 3.143828004172643
[2025-09-15 10:52:26,298][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 1.5085724901497364,  accuracy: 0.4509
[2025-09-15 10:52:36,729][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 1.3617221820354461,  accuracy: 0.50752, gradient_norm : 3.141106572178539
[2025-09-15 10:52:48,855][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 1.5562100175082683,  accuracy: 0.4381
[2025-09-15 10:52:59,281][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 1.3577785110473632,  accuracy: 0.50604, gradient_norm : 3.109705853984073
[2025-09-15 10:53:11,307][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 1.5584263482153415,  accuracy: 0.4283
[2025-09-15 10:53:21,737][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 1.3506097482144832,  accuracy: 0.5107, gradient_norm : 3.352658200992205
[2025-09-15 10:53:33,932][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 1.6273971493661403,  accuracy: 0.42
[2025-09-15 10:53:44,429][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 1.3859027168154716,  accuracy: 0.48944, gradient_norm : 3.256010894308182
[2025-09-15 10:53:56,620][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 1.579033909624815,  accuracy: 0.4161
[2025-09-15 10:54:07,175][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 1.3567938530445098,  accuracy: 0.49736, gradient_norm : 3.3924895393919456
[2025-09-15 10:54:19,361][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 1.63935915569067,  accuracy: 0.4058
[2025-09-15 10:54:29,824][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 1.3804608784615993,  accuracy: 0.49006, gradient_norm : 3.528943839905698
[2025-09-15 10:54:41,871][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 1.6862811422467232,  accuracy: 0.3872
[2025-09-15 10:54:52,423][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 1.3914461776614189,  accuracy: 0.47736, gradient_norm : 3.6516067199832265
[2025-09-15 10:55:04,511][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 1.8354629153311253,  accuracy: 0.3642
[2025-09-15 10:55:15,006][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 1.4211062623560429,  accuracy: 0.4761, gradient_norm : 3.6966303050428877
[2025-09-15 10:55:27,143][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 1.7289747167527676,  accuracy: 0.3834
[2025-09-15 10:55:37,669][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 1.4049648874998093,  accuracy: 0.4789, gradient_norm : 3.799313981212543
[2025-09-15 10:55:49,947][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 1.7777773319780827,  accuracy: 0.3738
[2025-09-15 10:56:00,494][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 1.4259019635617733,  accuracy: 0.47546, gradient_norm : 3.676086660573269
[2025-09-15 10:56:12,620][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 1.7403548253178596,  accuracy: 0.378
[2025-09-15 10:56:23,091][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 1.3769151459634303,  accuracy: 0.48966, gradient_norm : 3.5897262549667768
[2025-09-15 10:56:35,310][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 1.7907066364228725,  accuracy: 0.3776
[2025-09-15 10:56:45,811][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 1.3985479374229908,  accuracy: 0.48706, gradient_norm : 3.619288441714191
[2025-09-15 10:56:57,785][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 2.2593994174718857,  accuracy: 0.2957
[2025-09-15 10:57:08,201][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 1.4273804250359534,  accuracy: 0.48022, gradient_norm : 4.0581609898390045
[2025-09-15 10:57:20,369][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 2.610745988410711,  accuracy: 0.2772
[2025-09-15 10:57:30,820][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 1.5097898818552493,  accuracy: 0.4477, gradient_norm : 3.9475899706297444
[2025-09-15 10:57:42,896][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 2.349464684343338,  accuracy: 0.287
[2025-09-15 10:57:53,393][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 1.4280147081613541,  accuracy: 0.47866, gradient_norm : 3.5578582186946655
[2025-09-15 10:58:05,550][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 1.7457507942318917,  accuracy: 0.3866
[2025-09-15 10:58:16,124][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 1.4030166155099868,  accuracy: 0.48832, gradient_norm : 3.7145447807036414
[2025-09-15 10:58:28,198][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 1.9283932884693147,  accuracy: 0.3321
[2025-09-15 10:58:38,754][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 1.4455461716651916,  accuracy: 0.47342, gradient_norm : 3.8584058673134645
[2025-09-15 10:58:51,020][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 1.8005301256597042,  accuracy: 0.3814
[2025-09-15 10:59:01,612][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 1.4114320279657842,  accuracy: 0.49008, gradient_norm : 3.6626265387132744
[2025-09-15 10:59:13,595][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 1.668900906562805,  accuracy: 0.3972
[2025-09-15 10:59:24,086][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 1.3738736572861672,  accuracy: 0.4998, gradient_norm : 3.5401494309046355
[2025-09-15 10:59:36,245][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 1.6782022242546082,  accuracy: 0.4147
[2025-09-15 10:59:46,758][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 1.3638330656290054,  accuracy: 0.50732, gradient_norm : 3.4815347086142108
[2025-09-15 10:59:58,911][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 1.780410471957922,  accuracy: 0.376
[2025-09-15 11:00:09,359][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 1.361999168470502,  accuracy: 0.50296, gradient_norm : 3.4875135671483752
[2025-09-15 11:00:21,646][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 1.8231841615200042,  accuracy: 0.3827
[2025-09-15 11:00:32,113][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 1.3449556598812342,  accuracy: 0.50898, gradient_norm : 3.5157424535057693
[2025-09-15 11:00:44,389][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 1.8788405862033368,  accuracy: 0.3515
[2025-09-15 11:00:54,963][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 1.3623027102649212,  accuracy: 0.49496, gradient_norm : 3.606885770700391
[2025-09-15 11:01:07,224][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 1.7430299206912518,  accuracy: 0.3936
[2025-09-15 11:01:17,822][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 1.3384202383458614,  accuracy: 0.50742, gradient_norm : 3.639571071813188
[2025-09-15 11:01:29,901][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 1.8738618555903435,  accuracy: 0.351
[2025-09-15 11:01:40,359][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 1.359030601605773,  accuracy: 0.49458, gradient_norm : 3.643774513350908
[2025-09-15 11:01:52,623][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 1.761039558684826,  accuracy: 0.3924
[2025-09-15 11:02:03,152][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 1.3313719145208598,  accuracy: 0.51092, gradient_norm : 3.558231128214706
[2025-09-15 11:02:15,214][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 1.9733161149799823,  accuracy: 0.3547
[2025-09-15 11:02:25,763][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 1.350169496461749,  accuracy: 0.50562, gradient_norm : 3.5951116510761367
[2025-09-15 11:02:37,990][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 1.8504380731165408,  accuracy: 0.3623
[2025-09-15 11:02:48,674][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 1.347313657104969,  accuracy: 0.50572, gradient_norm : 3.8010060324149673
[2025-09-15 11:03:00,638][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 1.9817639327943326,  accuracy: 0.3519
[2025-09-15 11:03:11,167][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 1.378283347338438,  accuracy: 0.4875, gradient_norm : 3.7395768261022315
[2025-09-15 11:03:23,397][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 1.8990758644342423,  accuracy: 0.3485
[2025-09-15 11:03:33,871][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 1.3671752484887838,  accuracy: 0.50546, gradient_norm : 3.8390573532616226
[2025-09-15 11:03:45,937][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 1.898541110533476,  accuracy: 0.3591
[2025-09-15 11:03:56,422][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 1.3640020360052585,  accuracy: 0.49258, gradient_norm : 3.6933238282000547
[2025-09-15 11:04:08,655][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 1.731399084198475,  accuracy: 0.3831
[2025-09-15 11:04:19,204][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 1.3545971488952637,  accuracy: 0.50404, gradient_norm : 3.8075167587895624
[2025-09-15 11:04:31,422][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 1.721233330053091,  accuracy: 0.3942
[2025-09-15 11:04:41,905][flp2p.graph_runner][INFO] - Train, Round 200 : loss => 1.3719271315634252,  accuracy: 0.49428, gradient_norm : 3.782656950689564
[2025-09-15 11:04:54,127][flp2p.graph_runner][INFO] - Test, Round 200 : loss => 1.758217102277279,  accuracy: 0.3619
[2025-09-15 11:05:04,651][flp2p.graph_runner][INFO] - Train, Round 201 : loss => 1.379253140538931,  accuracy: 0.49, gradient_norm : 4.076764365616096
[2025-09-15 11:05:16,741][flp2p.graph_runner][INFO] - Test, Round 201 : loss => 1.7778941860854627,  accuracy: 0.3863
[2025-09-15 11:05:27,156][flp2p.graph_runner][INFO] - Train, Round 202 : loss => 1.399145413786173,  accuracy: 0.48234, gradient_norm : 3.657986792454058
[2025-09-15 11:05:39,407][flp2p.graph_runner][INFO] - Test, Round 202 : loss => 1.5998219329595567,  accuracy: 0.4108
[2025-09-15 11:05:49,814][flp2p.graph_runner][INFO] - Train, Round 203 : loss => 1.2819762610644103,  accuracy: 0.53302, gradient_norm : 3.4607379081270766
[2025-09-15 11:06:02,002][flp2p.graph_runner][INFO] - Test, Round 203 : loss => 1.5397080964863301,  accuracy: 0.4334
[2025-09-15 11:06:12,531][flp2p.graph_runner][INFO] - Train, Round 204 : loss => 1.2821524024009705,  accuracy: 0.5284, gradient_norm : 3.4378180490820647
[2025-09-15 11:06:24,873][flp2p.graph_runner][INFO] - Test, Round 204 : loss => 1.5680541252553464,  accuracy: 0.4221
[2025-09-15 11:06:35,377][flp2p.graph_runner][INFO] - Train, Round 205 : loss => 1.302443853393197,  accuracy: 0.51572, gradient_norm : 3.8601537261795613
[2025-09-15 11:06:47,401][flp2p.graph_runner][INFO] - Test, Round 205 : loss => 1.7314439516842366,  accuracy: 0.3809
[2025-09-15 11:06:57,878][flp2p.graph_runner][INFO] - Train, Round 206 : loss => 1.4055067762732505,  accuracy: 0.47382, gradient_norm : 4.08345784883434
[2025-09-15 11:07:10,109][flp2p.graph_runner][INFO] - Test, Round 206 : loss => 1.8840817223966122,  accuracy: 0.3622
[2025-09-15 11:07:20,694][flp2p.graph_runner][INFO] - Train, Round 207 : loss => 1.3693292184174062,  accuracy: 0.48758, gradient_norm : 3.9154561861380013
[2025-09-15 11:07:32,846][flp2p.graph_runner][INFO] - Test, Round 207 : loss => 1.6642004620611668,  accuracy: 0.3915
[2025-09-15 11:07:43,389][flp2p.graph_runner][INFO] - Train, Round 208 : loss => 1.3298549566417932,  accuracy: 0.50842, gradient_norm : 3.6648051784099236
[2025-09-15 11:07:55,574][flp2p.graph_runner][INFO] - Test, Round 208 : loss => 1.5699638960361482,  accuracy: 0.4205
[2025-09-15 11:08:06,147][flp2p.graph_runner][INFO] - Train, Round 209 : loss => 1.2864054853469133,  accuracy: 0.51842, gradient_norm : 3.561739023879142
[2025-09-15 11:08:18,181][flp2p.graph_runner][INFO] - Test, Round 209 : loss => 1.6392623130977153,  accuracy: 0.4008
[2025-09-15 11:08:28,639][flp2p.graph_runner][INFO] - Train, Round 210 : loss => 1.3057332967221738,  accuracy: 0.51726, gradient_norm : 3.7194217786145676
[2025-09-15 11:08:40,868][flp2p.graph_runner][INFO] - Test, Round 210 : loss => 1.5952564358949661,  accuracy: 0.4191
[2025-09-15 11:08:51,367][flp2p.graph_runner][INFO] - Train, Round 211 : loss => 1.2907960214465857,  accuracy: 0.51448, gradient_norm : 3.679590099310334
[2025-09-15 11:09:03,581][flp2p.graph_runner][INFO] - Test, Round 211 : loss => 1.6372556367039681,  accuracy: 0.4075
[2025-09-15 11:09:14,027][flp2p.graph_runner][INFO] - Train, Round 212 : loss => 1.3008168664574624,  accuracy: 0.52014, gradient_norm : 3.7519674227807145
[2025-09-15 11:09:26,408][flp2p.graph_runner][INFO] - Test, Round 212 : loss => 1.5722484997451305,  accuracy: 0.4327
[2025-09-15 11:09:36,860][flp2p.graph_runner][INFO] - Train, Round 213 : loss => 1.2710830634087324,  accuracy: 0.5294, gradient_norm : 3.6121636419052177
[2025-09-15 11:09:49,048][flp2p.graph_runner][INFO] - Test, Round 213 : loss => 1.6368566356420517,  accuracy: 0.4166
[2025-09-15 11:09:59,522][flp2p.graph_runner][INFO] - Train, Round 214 : loss => 1.275490114763379,  accuracy: 0.53546, gradient_norm : 3.6134114370782338
[2025-09-15 11:10:11,833][flp2p.graph_runner][INFO] - Test, Round 214 : loss => 1.642816539657116,  accuracy: 0.4154
[2025-09-15 11:10:22,229][flp2p.graph_runner][INFO] - Train, Round 215 : loss => 1.261439141780138,  accuracy: 0.53592, gradient_norm : 3.671553434068507
[2025-09-15 11:10:34,329][flp2p.graph_runner][INFO] - Test, Round 215 : loss => 1.8012726544082165,  accuracy: 0.3983
[2025-09-15 11:10:44,754][flp2p.graph_runner][INFO] - Train, Round 216 : loss => 1.298430086672306,  accuracy: 0.52726, gradient_norm : 3.8765615309247687
[2025-09-15 11:10:56,967][flp2p.graph_runner][INFO] - Test, Round 216 : loss => 2.1068094706475735,  accuracy: 0.3339
[2025-09-15 11:11:07,504][flp2p.graph_runner][INFO] - Train, Round 217 : loss => 1.3213040855526925,  accuracy: 0.51716, gradient_norm : 4.309633113188254
[2025-09-15 11:11:19,521][flp2p.graph_runner][INFO] - Test, Round 217 : loss => 2.881219622015953,  accuracy: 0.2792
[2025-09-15 11:11:30,023][flp2p.graph_runner][INFO] - Train, Round 218 : loss => 1.4451902650296689,  accuracy: 0.48152, gradient_norm : 4.177306975638735
[2025-09-15 11:11:42,168][flp2p.graph_runner][INFO] - Test, Round 218 : loss => 2.4019293757081033,  accuracy: 0.2973
[2025-09-15 11:11:52,744][flp2p.graph_runner][INFO] - Train, Round 219 : loss => 1.3144410740584136,  accuracy: 0.52236, gradient_norm : 3.9174866254983045
[2025-09-15 11:12:04,751][flp2p.graph_runner][INFO] - Test, Round 219 : loss => 1.951553919696808,  accuracy: 0.3595
[2025-09-15 11:12:15,338][flp2p.graph_runner][INFO] - Train, Round 220 : loss => 1.3421410517394543,  accuracy: 0.51674, gradient_norm : 4.256293543897809
[2025-09-15 11:12:27,528][flp2p.graph_runner][INFO] - Test, Round 220 : loss => 2.091744564014673,  accuracy: 0.3234
[2025-09-15 11:12:38,122][flp2p.graph_runner][INFO] - Train, Round 221 : loss => 1.3720489573478698,  accuracy: 0.48496, gradient_norm : 4.0894625687614035
[2025-09-15 11:12:50,227][flp2p.graph_runner][INFO] - Test, Round 221 : loss => 1.8065388084352016,  accuracy: 0.3862
[2025-09-15 11:13:00,714][flp2p.graph_runner][INFO] - Train, Round 222 : loss => 1.358193734139204,  accuracy: 0.50376, gradient_norm : 3.9354176836201504
[2025-09-15 11:13:12,930][flp2p.graph_runner][INFO] - Test, Round 222 : loss => 1.714303096997738,  accuracy: 0.3938
[2025-09-15 11:13:23,402][flp2p.graph_runner][INFO] - Train, Round 223 : loss => 1.285591897368431,  accuracy: 0.52854, gradient_norm : 3.8773188618287877
[2025-09-15 11:13:35,535][flp2p.graph_runner][INFO] - Test, Round 223 : loss => 1.8093569410979748,  accuracy: 0.3721
[2025-09-15 11:13:46,044][flp2p.graph_runner][INFO] - Train, Round 224 : loss => 1.2961413933336734,  accuracy: 0.52406, gradient_norm : 3.7534662248170916
[2025-09-15 11:13:58,342][flp2p.graph_runner][INFO] - Test, Round 224 : loss => 1.7160063151478768,  accuracy: 0.3945
[2025-09-15 11:14:08,908][flp2p.graph_runner][INFO] - Train, Round 225 : loss => 1.2747075421363114,  accuracy: 0.52622, gradient_norm : 3.724564589894829
[2025-09-15 11:14:21,015][flp2p.graph_runner][INFO] - Test, Round 225 : loss => 1.8011741531193257,  accuracy: 0.3662
[2025-09-15 11:14:31,517][flp2p.graph_runner][INFO] - Train, Round 226 : loss => 1.2631105484068395,  accuracy: 0.53198, gradient_norm : 3.592691312541364
[2025-09-15 11:14:43,693][flp2p.graph_runner][INFO] - Test, Round 226 : loss => 1.6191826056718825,  accuracy: 0.4153
[2025-09-15 11:14:54,100][flp2p.graph_runner][INFO] - Train, Round 227 : loss => 1.2498659201711417,  accuracy: 0.5343, gradient_norm : 3.7141882649733717
[2025-09-15 11:15:06,196][flp2p.graph_runner][INFO] - Test, Round 227 : loss => 1.6008995445489884,  accuracy: 0.4136
[2025-09-15 11:15:16,623][flp2p.graph_runner][INFO] - Train, Round 228 : loss => 1.251349029019475,  accuracy: 0.5343, gradient_norm : 3.6518964895873114
[2025-09-15 11:15:28,828][flp2p.graph_runner][INFO] - Test, Round 228 : loss => 1.6357659540176392,  accuracy: 0.4107
[2025-09-15 11:15:39,318][flp2p.graph_runner][INFO] - Train, Round 229 : loss => 1.2355966654419899,  accuracy: 0.53978, gradient_norm : 3.7833139162174074
[2025-09-15 11:15:51,343][flp2p.graph_runner][INFO] - Test, Round 229 : loss => 1.7390323935270309,  accuracy: 0.3868
[2025-09-15 11:16:01,858][flp2p.graph_runner][INFO] - Train, Round 230 : loss => 1.2574897041171789,  accuracy: 0.53134, gradient_norm : 3.5893373155898742
[2025-09-15 11:16:13,979][flp2p.graph_runner][INFO] - Test, Round 230 : loss => 1.6422447693228721,  accuracy: 0.4113
[2025-09-15 11:16:24,495][flp2p.graph_runner][INFO] - Train, Round 231 : loss => 1.216961956769228,  accuracy: 0.55232, gradient_norm : 3.615162842156819
[2025-09-15 11:16:36,607][flp2p.graph_runner][INFO] - Test, Round 231 : loss => 1.641853517192602,  accuracy: 0.4138
[2025-09-15 11:16:47,186][flp2p.graph_runner][INFO] - Train, Round 232 : loss => 1.2146637443453074,  accuracy: 0.5564, gradient_norm : 3.5807294259125837
[2025-09-15 11:16:59,462][flp2p.graph_runner][INFO] - Test, Round 232 : loss => 1.7362264635920523,  accuracy: 0.3978
[2025-09-15 11:17:09,993][flp2p.graph_runner][INFO] - Train, Round 233 : loss => 1.239795096218586,  accuracy: 0.54928, gradient_norm : 3.956355447849087
[2025-09-15 11:17:21,901][flp2p.graph_runner][INFO] - Test, Round 233 : loss => 1.8312351928055286,  accuracy: 0.3878
[2025-09-15 11:17:32,351][flp2p.graph_runner][INFO] - Train, Round 234 : loss => 1.3145399974286556,  accuracy: 0.52586, gradient_norm : 4.320071222927635
[2025-09-15 11:17:44,582][flp2p.graph_runner][INFO] - Test, Round 234 : loss => 2.6336384196996687,  accuracy: 0.2838
[2025-09-15 11:17:55,082][flp2p.graph_runner][INFO] - Train, Round 235 : loss => 1.3646967201679945,  accuracy: 0.51264, gradient_norm : 4.547398196914591
[2025-09-15 11:18:07,224][flp2p.graph_runner][INFO] - Test, Round 235 : loss => 2.3560115808844566,  accuracy: 0.3049
[2025-09-15 11:18:17,676][flp2p.graph_runner][INFO] - Train, Round 236 : loss => 1.4080335228145122,  accuracy: 0.49126, gradient_norm : 4.640870759564745
[2025-09-15 11:18:29,979][flp2p.graph_runner][INFO] - Test, Round 236 : loss => 2.43245732909441,  accuracy: 0.2848
[2025-09-15 11:18:40,436][flp2p.graph_runner][INFO] - Train, Round 237 : loss => 1.3655539387464524,  accuracy: 0.50926, gradient_norm : 4.420746335674868
[2025-09-15 11:18:52,470][flp2p.graph_runner][INFO] - Test, Round 237 : loss => 1.9814717571556568,  accuracy: 0.362
[2025-09-15 11:19:02,507][flp2p.graph_runner][INFO] - Train, Round 238 : loss => 1.3321236718446017,  accuracy: 0.5244, gradient_norm : 4.176381975065503
[2025-09-15 11:19:13,069][flp2p.graph_runner][INFO] - Test, Round 238 : loss => 2.150806555992365,  accuracy: 0.3252
[2025-09-15 11:19:23,009][flp2p.graph_runner][INFO] - Train, Round 239 : loss => 1.293403452411294,  accuracy: 0.53396, gradient_norm : 3.837881145575242
[2025-09-15 11:19:33,450][flp2p.graph_runner][INFO] - Test, Round 239 : loss => 1.8132579448461532,  accuracy: 0.3812
[2025-09-15 11:19:43,184][flp2p.graph_runner][INFO] - Train, Round 240 : loss => 1.227111128345132,  accuracy: 0.55932, gradient_norm : 3.568631663987512
[2025-09-15 11:19:53,912][flp2p.graph_runner][INFO] - Test, Round 240 : loss => 1.614751774674654,  accuracy: 0.4202
[2025-09-15 11:20:03,717][flp2p.graph_runner][INFO] - Train, Round 241 : loss => 1.1616180977225303,  accuracy: 0.58552, gradient_norm : 3.3694579374806737
[2025-09-15 11:20:14,259][flp2p.graph_runner][INFO] - Test, Round 241 : loss => 1.5987324500858784,  accuracy: 0.4266
[2025-09-15 11:20:24,095][flp2p.graph_runner][INFO] - Train, Round 242 : loss => 1.1633932719379663,  accuracy: 0.5813, gradient_norm : 3.5369147715719307
[2025-09-15 11:20:34,703][flp2p.graph_runner][INFO] - Test, Round 242 : loss => 1.7019565785050392,  accuracy: 0.3923
[2025-09-15 11:20:44,493][flp2p.graph_runner][INFO] - Train, Round 243 : loss => 1.191751651838422,  accuracy: 0.56728, gradient_norm : 3.8354323439066023
[2025-09-15 11:20:54,903][flp2p.graph_runner][INFO] - Test, Round 243 : loss => 1.8185031242489815,  accuracy: 0.3667
[2025-09-15 11:21:04,664][flp2p.graph_runner][INFO] - Train, Round 244 : loss => 1.2476477539539337,  accuracy: 0.53272, gradient_norm : 4.1768590815551585
[2025-09-15 11:21:15,255][flp2p.graph_runner][INFO] - Test, Round 244 : loss => 1.965110855960846,  accuracy: 0.3509
[2025-09-15 11:21:25,010][flp2p.graph_runner][INFO] - Train, Round 245 : loss => 1.2993108290433883,  accuracy: 0.52338, gradient_norm : 4.188581553762789
[2025-09-15 11:21:35,446][flp2p.graph_runner][INFO] - Test, Round 245 : loss => 1.8530124000072479,  accuracy: 0.3595
[2025-09-15 11:21:45,230][flp2p.graph_runner][INFO] - Train, Round 246 : loss => 1.25191180922091,  accuracy: 0.53162, gradient_norm : 4.1745758642190784
[2025-09-15 11:21:55,712][flp2p.graph_runner][INFO] - Test, Round 246 : loss => 1.8525642065346242,  accuracy: 0.3718
[2025-09-15 11:22:05,563][flp2p.graph_runner][INFO] - Train, Round 247 : loss => 1.2821444303542375,  accuracy: 0.53722, gradient_norm : 4.261773516118417
[2025-09-15 11:22:16,055][flp2p.graph_runner][INFO] - Test, Round 247 : loss => 1.9089697488367559,  accuracy: 0.3514
[2025-09-15 11:22:25,870][flp2p.graph_runner][INFO] - Train, Round 248 : loss => 1.2606720917671919,  accuracy: 0.54024, gradient_norm : 4.135489466407673
[2025-09-15 11:22:36,418][flp2p.graph_runner][INFO] - Test, Round 248 : loss => 1.848366472607851,  accuracy: 0.3798
[2025-09-15 11:22:46,295][flp2p.graph_runner][INFO] - Train, Round 249 : loss => 1.2372644214332105,  accuracy: 0.5591, gradient_norm : 3.8869662139211694
[2025-09-15 11:22:56,660][flp2p.graph_runner][INFO] - Test, Round 249 : loss => 1.7870117157399654,  accuracy: 0.378
[2025-09-15 11:23:06,572][flp2p.graph_runner][INFO] - Train, Round 250 : loss => 1.2038597241044044,  accuracy: 0.56586, gradient_norm : 3.944722112512586
[2025-09-15 11:23:17,184][flp2p.graph_runner][INFO] - Test, Round 250 : loss => 1.7050709816932679,  accuracy: 0.4064
[2025-09-15 11:23:27,044][flp2p.graph_runner][INFO] - Train, Round 251 : loss => 1.208160710260272,  accuracy: 0.55972, gradient_norm : 3.99880392830417
[2025-09-15 11:23:37,473][flp2p.graph_runner][INFO] - Test, Round 251 : loss => 1.7375622879326345,  accuracy: 0.3984
[2025-09-15 11:23:47,290][flp2p.graph_runner][INFO] - Train, Round 252 : loss => 1.2152374669164419,  accuracy: 0.55072, gradient_norm : 3.9227267676040047
[2025-09-15 11:23:57,828][flp2p.graph_runner][INFO] - Test, Round 252 : loss => 1.7547273851692677,  accuracy: 0.3852
[2025-09-15 11:24:07,635][flp2p.graph_runner][INFO] - Train, Round 253 : loss => 1.1881809388846158,  accuracy: 0.56182, gradient_norm : 4.158009398015012
[2025-09-15 11:24:18,076][flp2p.graph_runner][INFO] - Test, Round 253 : loss => 2.073444414669275,  accuracy: 0.3493
[2025-09-15 11:24:27,869][flp2p.graph_runner][INFO] - Train, Round 254 : loss => 1.2892803483456374,  accuracy: 0.5143, gradient_norm : 4.208367757313716
[2025-09-15 11:24:38,475][flp2p.graph_runner][INFO] - Test, Round 254 : loss => 1.8654866209149361,  accuracy: 0.3604
[2025-09-15 11:24:48,392][flp2p.graph_runner][INFO] - Train, Round 255 : loss => 1.2339695742726327,  accuracy: 0.5372, gradient_norm : 4.2248297275095
[2025-09-15 11:24:58,910][flp2p.graph_runner][INFO] - Test, Round 255 : loss => 1.9107683859825135,  accuracy: 0.3625
[2025-09-15 11:25:08,744][flp2p.graph_runner][INFO] - Train, Round 256 : loss => 1.2696902184933423,  accuracy: 0.51964, gradient_norm : 4.007070265883472
[2025-09-15 11:25:19,310][flp2p.graph_runner][INFO] - Test, Round 256 : loss => 1.7706340634405613,  accuracy: 0.3746
[2025-09-15 11:25:29,021][flp2p.graph_runner][INFO] - Train, Round 257 : loss => 1.2196625524759293,  accuracy: 0.54684, gradient_norm : 3.9726177905169147
[2025-09-15 11:25:39,533][flp2p.graph_runner][INFO] - Test, Round 257 : loss => 1.70118480681777,  accuracy: 0.4021
[2025-09-15 11:25:49,430][flp2p.graph_runner][INFO] - Train, Round 258 : loss => 1.1961649571359159,  accuracy: 0.5575, gradient_norm : 3.949841565925796
[2025-09-15 11:26:00,012][flp2p.graph_runner][INFO] - Test, Round 258 : loss => 1.7551005196094513,  accuracy: 0.4091
[2025-09-15 11:26:09,836][flp2p.graph_runner][INFO] - Train, Round 259 : loss => 1.2317527544498443,  accuracy: 0.55286, gradient_norm : 4.151529260665972
[2025-09-15 11:26:20,471][flp2p.graph_runner][INFO] - Test, Round 259 : loss => 2.002590501886606,  accuracy: 0.341
[2025-09-15 11:26:30,243][flp2p.graph_runner][INFO] - Train, Round 260 : loss => 1.2495708943158388,  accuracy: 0.53432, gradient_norm : 4.622476476250602
[2025-09-15 11:26:40,831][flp2p.graph_runner][INFO] - Test, Round 260 : loss => 2.642229759246111,  accuracy: 0.2807
[2025-09-15 11:26:50,658][flp2p.graph_runner][INFO] - Train, Round 261 : loss => 1.3869727724790573,  accuracy: 0.4995, gradient_norm : 4.289635227300673
[2025-09-15 11:27:01,112][flp2p.graph_runner][INFO] - Test, Round 261 : loss => 2.0339644258916376,  accuracy: 0.3522
[2025-09-15 11:27:10,824][flp2p.graph_runner][INFO] - Train, Round 262 : loss => 1.1901229050755502,  accuracy: 0.57024, gradient_norm : 3.7315637362204597
[2025-09-15 11:27:21,467][flp2p.graph_runner][INFO] - Test, Round 262 : loss => 1.8900847447991371,  accuracy: 0.3819
[2025-09-15 11:27:31,293][flp2p.graph_runner][INFO] - Train, Round 263 : loss => 1.1383883079886437,  accuracy: 0.60084, gradient_norm : 3.512828210504781
[2025-09-15 11:27:42,231][flp2p.graph_runner][INFO] - Test, Round 263 : loss => 1.8256515840411187,  accuracy: 0.3842
[2025-09-15 11:27:52,122][flp2p.graph_runner][INFO] - Train, Round 264 : loss => 1.119737102985382,  accuracy: 0.60328, gradient_norm : 3.611043501754097
[2025-09-15 11:28:02,646][flp2p.graph_runner][INFO] - Test, Round 264 : loss => 1.8325635924637318,  accuracy: 0.3962
[2025-09-15 11:28:12,494][flp2p.graph_runner][INFO] - Train, Round 265 : loss => 1.1343634243309497,  accuracy: 0.59938, gradient_norm : 3.692785402709898
[2025-09-15 11:28:22,856][flp2p.graph_runner][INFO] - Test, Round 265 : loss => 1.8828011176466941,  accuracy: 0.3767
[2025-09-15 11:28:32,671][flp2p.graph_runner][INFO] - Train, Round 266 : loss => 1.158822711110115,  accuracy: 0.5797, gradient_norm : 4.089817780426315
[2025-09-15 11:28:43,256][flp2p.graph_runner][INFO] - Test, Round 266 : loss => 2.1671025121331216,  accuracy: 0.3384
[2025-09-15 11:28:53,074][flp2p.graph_runner][INFO] - Train, Round 267 : loss => 1.2163459713757039,  accuracy: 0.56156, gradient_norm : 4.3793875119807515
[2025-09-15 11:29:03,593][flp2p.graph_runner][INFO] - Test, Round 267 : loss => 2.0953121977448466,  accuracy: 0.3541
[2025-09-15 11:29:13,516][flp2p.graph_runner][INFO] - Train, Round 268 : loss => 1.2709928074479102,  accuracy: 0.54458, gradient_norm : 4.507094110970187
[2025-09-15 11:29:24,124][flp2p.graph_runner][INFO] - Test, Round 268 : loss => 1.9422267851889135,  accuracy: 0.372
[2025-09-15 11:29:33,948][flp2p.graph_runner][INFO] - Train, Round 269 : loss => 1.2322002683579922,  accuracy: 0.5558, gradient_norm : 4.556623831511326
[2025-09-15 11:29:44,510][flp2p.graph_runner][INFO] - Test, Round 269 : loss => 2.1547847637712954,  accuracy: 0.3519
[2025-09-15 11:29:54,265][flp2p.graph_runner][INFO] - Train, Round 270 : loss => 1.3031741891801358,  accuracy: 0.53398, gradient_norm : 4.527408237616061
[2025-09-15 11:30:04,730][flp2p.graph_runner][INFO] - Test, Round 270 : loss => 1.9310472168147563,  accuracy: 0.3608
[2025-09-15 11:30:14,598][flp2p.graph_runner][INFO] - Train, Round 271 : loss => 1.231664278358221,  accuracy: 0.55594, gradient_norm : 4.749994249243715
[2025-09-15 11:30:25,227][flp2p.graph_runner][INFO] - Test, Round 271 : loss => 2.5184959836661815,  accuracy: 0.3302
[2025-09-15 11:30:35,113][flp2p.graph_runner][INFO] - Train, Round 272 : loss => 1.3335577096790074,  accuracy: 0.5219, gradient_norm : 4.256025762014875
[2025-09-15 11:30:45,911][flp2p.graph_runner][INFO] - Test, Round 272 : loss => 1.976785401582718,  accuracy: 0.3577
[2025-09-15 11:30:55,765][flp2p.graph_runner][INFO] - Train, Round 273 : loss => 1.2149428223073482,  accuracy: 0.5677, gradient_norm : 4.137490533352224
[2025-09-15 11:31:06,143][flp2p.graph_runner][INFO] - Test, Round 273 : loss => 2.2164046374320985,  accuracy: 0.3333
[2025-09-15 11:31:15,994][flp2p.graph_runner][INFO] - Train, Round 274 : loss => 1.2298754687607287,  accuracy: 0.5528, gradient_norm : 4.304484626573021
[2025-09-15 11:31:26,679][flp2p.graph_runner][INFO] - Test, Round 274 : loss => 2.102940270382166,  accuracy: 0.3444
[2025-09-15 11:31:36,523][flp2p.graph_runner][INFO] - Train, Round 275 : loss => 1.2803237837553025,  accuracy: 0.53552, gradient_norm : 4.808378639699074
[2025-09-15 11:31:46,888][flp2p.graph_runner][INFO] - Test, Round 275 : loss => 2.402183718675375,  accuracy: 0.2882
[2025-09-15 11:31:56,567][flp2p.graph_runner][INFO] - Train, Round 276 : loss => 1.316059826016426,  accuracy: 0.50988, gradient_norm : 4.816349829772765
[2025-09-15 11:32:07,151][flp2p.graph_runner][INFO] - Test, Round 276 : loss => 1.982465725249052,  accuracy: 0.3656
[2025-09-15 11:32:16,867][flp2p.graph_runner][INFO] - Train, Round 277 : loss => 1.329586942270398,  accuracy: 0.5241, gradient_norm : 4.511758172921174
[2025-09-15 11:32:27,369][flp2p.graph_runner][INFO] - Test, Round 277 : loss => 1.8701136334598065,  accuracy: 0.3732
[2025-09-15 11:32:37,222][flp2p.graph_runner][INFO] - Train, Round 278 : loss => 1.1761695083975792,  accuracy: 0.57094, gradient_norm : 3.9646403686662213
[2025-09-15 11:32:47,685][flp2p.graph_runner][INFO] - Test, Round 278 : loss => 1.7365905677974225,  accuracy: 0.4088
[2025-09-15 11:32:57,486][flp2p.graph_runner][INFO] - Train, Round 279 : loss => 1.1666875001043082,  accuracy: 0.58688, gradient_norm : 3.9661873470711893
[2025-09-15 11:33:07,972][flp2p.graph_runner][INFO] - Test, Round 279 : loss => 1.8568630379736424,  accuracy: 0.3853
[2025-09-15 11:33:17,816][flp2p.graph_runner][INFO] - Train, Round 280 : loss => 1.1697086656838656,  accuracy: 0.58484, gradient_norm : 4.20587692032165
[2025-09-15 11:33:28,248][flp2p.graph_runner][INFO] - Test, Round 280 : loss => 2.036844679290056,  accuracy: 0.3486
[2025-09-15 11:33:38,101][flp2p.graph_runner][INFO] - Train, Round 281 : loss => 1.1990135072171688,  accuracy: 0.57182, gradient_norm : 3.896314474763477
[2025-09-15 11:33:48,626][flp2p.graph_runner][INFO] - Test, Round 281 : loss => 1.6615912365734578,  accuracy: 0.4107
[2025-09-15 11:33:58,351][flp2p.graph_runner][INFO] - Train, Round 282 : loss => 1.1088604632765056,  accuracy: 0.60628, gradient_norm : 3.826532836263938
[2025-09-15 11:34:08,958][flp2p.graph_runner][INFO] - Test, Round 282 : loss => 1.651140878123045,  accuracy: 0.4168
[2025-09-15 11:34:18,780][flp2p.graph_runner][INFO] - Train, Round 283 : loss => 1.1476940745860338,  accuracy: 0.58076, gradient_norm : 4.019944765993198
[2025-09-15 11:34:29,194][flp2p.graph_runner][INFO] - Test, Round 283 : loss => 1.604848627191782,  accuracy: 0.4383
[2025-09-15 11:34:38,992][flp2p.graph_runner][INFO] - Train, Round 284 : loss => 1.1862485558539628,  accuracy: 0.57214, gradient_norm : 4.394010884053197
[2025-09-15 11:34:49,591][flp2p.graph_runner][INFO] - Test, Round 284 : loss => 1.7070366373181343,  accuracy: 0.4057
[2025-09-15 11:34:59,442][flp2p.graph_runner][INFO] - Train, Round 285 : loss => 1.2269850777834654,  accuracy: 0.5442, gradient_norm : 4.5704701425476895
[2025-09-15 11:35:10,009][flp2p.graph_runner][INFO] - Test, Round 285 : loss => 1.7643734905183315,  accuracy: 0.4112
[2025-09-15 11:35:19,877][flp2p.graph_runner][INFO] - Train, Round 286 : loss => 1.287949699163437,  accuracy: 0.53936, gradient_norm : 4.620683061060073
[2025-09-15 11:35:30,543][flp2p.graph_runner][INFO] - Test, Round 286 : loss => 1.7382233631551265,  accuracy: 0.3918
[2025-09-15 11:35:40,372][flp2p.graph_runner][INFO] - Train, Round 287 : loss => 1.1651600589603186,  accuracy: 0.56794, gradient_norm : 3.9489815539443116
[2025-09-15 11:35:50,814][flp2p.graph_runner][INFO] - Test, Round 287 : loss => 1.6776497901141643,  accuracy: 0.4203
[2025-09-15 11:36:00,696][flp2p.graph_runner][INFO] - Train, Round 288 : loss => 1.1153109822422267,  accuracy: 0.5975, gradient_norm : 3.8326523935297927
[2025-09-15 11:36:11,214][flp2p.graph_runner][INFO] - Test, Round 288 : loss => 1.5883824022591113,  accuracy: 0.4394
[2025-09-15 11:36:21,004][flp2p.graph_runner][INFO] - Train, Round 289 : loss => 1.0880541680008173,  accuracy: 0.60756, gradient_norm : 3.789878941349536
[2025-09-15 11:36:31,516][flp2p.graph_runner][INFO] - Test, Round 289 : loss => 1.7893562280833721,  accuracy: 0.3918
[2025-09-15 11:36:41,341][flp2p.graph_runner][INFO] - Train, Round 290 : loss => 1.0975133758038282,  accuracy: 0.6066, gradient_norm : 4.059098950916548
[2025-09-15 11:36:51,893][flp2p.graph_runner][INFO] - Test, Round 290 : loss => 1.8426702647566795,  accuracy: 0.3858
[2025-09-15 11:37:01,690][flp2p.graph_runner][INFO] - Train, Round 291 : loss => 1.138688922598958,  accuracy: 0.59124, gradient_norm : 4.000856553271266
[2025-09-15 11:37:12,167][flp2p.graph_runner][INFO] - Test, Round 291 : loss => 1.802425274002552,  accuracy: 0.3914
[2025-09-15 11:37:22,056][flp2p.graph_runner][INFO] - Train, Round 292 : loss => 1.1016522438824177,  accuracy: 0.6098, gradient_norm : 3.9199550775698846
[2025-09-15 11:37:32,648][flp2p.graph_runner][INFO] - Test, Round 292 : loss => 1.6727861424028874,  accuracy: 0.4162
[2025-09-15 11:37:42,551][flp2p.graph_runner][INFO] - Train, Round 293 : loss => 1.0802959313243627,  accuracy: 0.61506, gradient_norm : 4.105837358528389
[2025-09-15 11:37:52,886][flp2p.graph_runner][INFO] - Test, Round 293 : loss => 1.9731327688097955,  accuracy: 0.3787
[2025-09-15 11:38:02,593][flp2p.graph_runner][INFO] - Train, Round 294 : loss => 1.1388783302158116,  accuracy: 0.58886, gradient_norm : 4.130952643816325
[2025-09-15 11:38:13,139][flp2p.graph_runner][INFO] - Test, Round 294 : loss => 1.7460972426354886,  accuracy: 0.4004
[2025-09-15 11:38:23,022][flp2p.graph_runner][INFO] - Train, Round 295 : loss => 1.1078215653449297,  accuracy: 0.59782, gradient_norm : 4.391368075552823
[2025-09-15 11:38:33,413][flp2p.graph_runner][INFO] - Test, Round 295 : loss => 1.8712969642639161,  accuracy: 0.3891
[2025-09-15 11:38:43,214][flp2p.graph_runner][INFO] - Train, Round 296 : loss => 1.2083271476626396,  accuracy: 0.55118, gradient_norm : 4.509494943530599
[2025-09-15 11:38:53,799][flp2p.graph_runner][INFO] - Test, Round 296 : loss => 1.8969585847198964,  accuracy: 0.3629
[2025-09-15 11:39:03,557][flp2p.graph_runner][INFO] - Train, Round 297 : loss => 1.1860369908064603,  accuracy: 0.55082, gradient_norm : 4.6659302577855115
[2025-09-15 11:39:13,980][flp2p.graph_runner][INFO] - Test, Round 297 : loss => 1.8870724962234497,  accuracy: 0.3779
[2025-09-15 11:39:23,719][flp2p.graph_runner][INFO] - Train, Round 298 : loss => 1.2353493501991033,  accuracy: 0.53254, gradient_norm : 4.794666701069002
[2025-09-15 11:39:34,247][flp2p.graph_runner][INFO] - Test, Round 298 : loss => 1.933418400156498,  accuracy: 0.3581
[2025-09-15 11:39:44,103][flp2p.graph_runner][INFO] - Train, Round 299 : loss => 1.251058686003089,  accuracy: 0.52718, gradient_norm : 4.875641788635196
[2025-09-15 11:39:54,389][flp2p.graph_runner][INFO] - Test, Round 299 : loss => 1.7596755746006965,  accuracy: 0.3933
[2025-09-15 11:40:04,180][flp2p.graph_runner][INFO] - Train, Round 300 : loss => 1.2329703202843667,  accuracy: 0.5326, gradient_norm : 4.524377618371232
[2025-09-15 11:40:14,696][flp2p.graph_runner][INFO] - Test, Round 300 : loss => 1.679409763121605,  accuracy: 0.4007
[2025-09-15 11:40:24,636][flp2p.graph_runner][INFO] - Train, Round 301 : loss => 1.1486916095018387,  accuracy: 0.56588, gradient_norm : 4.115523672515899
[2025-09-15 11:40:35,129][flp2p.graph_runner][INFO] - Test, Round 301 : loss => 1.661136435931921,  accuracy: 0.4157
[2025-09-15 11:40:44,864][flp2p.graph_runner][INFO] - Train, Round 302 : loss => 1.0938395655155182,  accuracy: 0.60104, gradient_norm : 4.0163695166002755
[2025-09-15 11:40:55,494][flp2p.graph_runner][INFO] - Test, Round 302 : loss => 1.6885087601423263,  accuracy: 0.4211
[2025-09-15 11:41:05,361][flp2p.graph_runner][INFO] - Train, Round 303 : loss => 1.0950646448135375,  accuracy: 0.60408, gradient_norm : 3.888631632561267
[2025-09-15 11:41:15,763][flp2p.graph_runner][INFO] - Test, Round 303 : loss => 1.669826820540428,  accuracy: 0.4146
[2025-09-15 11:41:25,652][flp2p.graph_runner][INFO] - Train, Round 304 : loss => 1.0572339505702257,  accuracy: 0.62312, gradient_norm : 4.062117294448164
[2025-09-15 11:41:36,257][flp2p.graph_runner][INFO] - Test, Round 304 : loss => 1.89759543851614,  accuracy: 0.3906
[2025-09-15 11:41:46,164][flp2p.graph_runner][INFO] - Train, Round 305 : loss => 1.107422826960683,  accuracy: 0.59664, gradient_norm : 4.014462972438135
[2025-09-15 11:41:56,615][flp2p.graph_runner][INFO] - Test, Round 305 : loss => 1.8005729797720909,  accuracy: 0.3802
[2025-09-15 11:42:06,513][flp2p.graph_runner][INFO] - Train, Round 306 : loss => 1.0666101896762847,  accuracy: 0.61766, gradient_norm : 4.170526813952777
[2025-09-15 11:42:17,055][flp2p.graph_runner][INFO] - Test, Round 306 : loss => 1.97905991396904,  accuracy: 0.3804
[2025-09-15 11:42:26,814][flp2p.graph_runner][INFO] - Train, Round 307 : loss => 1.1191805920004845,  accuracy: 0.59586, gradient_norm : 4.25354600939983
[2025-09-15 11:42:37,259][flp2p.graph_runner][INFO] - Test, Round 307 : loss => 2.1372766713619233,  accuracy: 0.3574
[2025-09-15 11:42:47,079][flp2p.graph_runner][INFO] - Train, Round 308 : loss => 1.119167774990201,  accuracy: 0.59928, gradient_norm : 4.795749977121795
[2025-09-15 11:42:57,700][flp2p.graph_runner][INFO] - Test, Round 308 : loss => 2.8707272124767305,  accuracy: 0.2784
[2025-09-15 11:43:07,459][flp2p.graph_runner][INFO] - Train, Round 309 : loss => 1.2602312605828048,  accuracy: 0.54268, gradient_norm : 5.12687015377929
[2025-09-15 11:43:17,923][flp2p.graph_runner][INFO] - Test, Round 309 : loss => 2.5346742668926714,  accuracy: 0.334
[2025-09-15 11:43:27,856][flp2p.graph_runner][INFO] - Train, Round 310 : loss => 1.2829592372477054,  accuracy: 0.55344, gradient_norm : 5.1393551056370965
[2025-09-15 11:43:38,375][flp2p.graph_runner][INFO] - Test, Round 310 : loss => 2.8304798251152037,  accuracy: 0.2711
[2025-09-15 11:43:48,222][flp2p.graph_runner][INFO] - Train, Round 311 : loss => 1.2322462076693774,  accuracy: 0.54992, gradient_norm : 5.226074059580376
[2025-09-15 11:43:58,669][flp2p.graph_runner][INFO] - Test, Round 311 : loss => 2.9071751311779024,  accuracy: 0.3065
[2025-09-15 11:44:08,520][flp2p.graph_runner][INFO] - Train, Round 312 : loss => 1.3549233792722226,  accuracy: 0.52424, gradient_norm : 4.841250775780897
[2025-09-15 11:44:19,105][flp2p.graph_runner][INFO] - Test, Round 312 : loss => 2.4031595815300943,  accuracy: 0.3125
[2025-09-15 11:44:28,910][flp2p.graph_runner][INFO] - Train, Round 313 : loss => 1.1666257613152267,  accuracy: 0.59082, gradient_norm : 4.232005157068373
[2025-09-15 11:44:39,414][flp2p.graph_runner][INFO] - Test, Round 313 : loss => 1.8317056857585907,  accuracy: 0.399
[2025-09-15 11:44:49,192][flp2p.graph_runner][INFO] - Train, Round 314 : loss => 1.0539275775104762,  accuracy: 0.6382, gradient_norm : 3.654007402385146
[2025-09-15 11:44:59,930][flp2p.graph_runner][INFO] - Test, Round 314 : loss => 1.6330244349956513,  accuracy: 0.4172
[2025-09-15 11:45:09,650][flp2p.graph_runner][INFO] - Train, Round 315 : loss => 0.9905108650773764,  accuracy: 0.65774, gradient_norm : 3.5947647554563837
[2025-09-15 11:45:20,202][flp2p.graph_runner][INFO] - Test, Round 315 : loss => 1.545902747631073,  accuracy: 0.4632
[2025-09-15 11:45:30,022][flp2p.graph_runner][INFO] - Train, Round 316 : loss => 0.9873432716727257,  accuracy: 0.65606, gradient_norm : 3.605098662073285
[2025-09-15 11:45:40,587][flp2p.graph_runner][INFO] - Test, Round 316 : loss => 1.5792385629057883,  accuracy: 0.4335
[2025-09-15 11:45:50,378][flp2p.graph_runner][INFO] - Train, Round 317 : loss => 0.9852183596044779,  accuracy: 0.65264, gradient_norm : 3.966819290779568
[2025-09-15 11:46:00,952][flp2p.graph_runner][INFO] - Test, Round 317 : loss => 1.6989654889404773,  accuracy: 0.419
[2025-09-15 11:46:10,735][flp2p.graph_runner][INFO] - Train, Round 318 : loss => 1.0547759805619716,  accuracy: 0.61468, gradient_norm : 4.227560054730453
[2025-09-15 11:46:21,317][flp2p.graph_runner][INFO] - Test, Round 318 : loss => 1.817138219845295,  accuracy: 0.3758
[2025-09-15 11:46:31,185][flp2p.graph_runner][INFO] - Train, Round 319 : loss => 1.0832994650304317,  accuracy: 0.59782, gradient_norm : 4.617757930491888
[2025-09-15 11:46:41,591][flp2p.graph_runner][INFO] - Test, Round 319 : loss => 2.4430492661058905,  accuracy: 0.3324
[2025-09-15 11:46:51,421][flp2p.graph_runner][INFO] - Train, Round 320 : loss => 1.1700419806689024,  accuracy: 0.57148, gradient_norm : 4.588061529623965
[2025-09-15 11:47:02,064][flp2p.graph_runner][INFO] - Test, Round 320 : loss => 1.8369636957883835,  accuracy: 0.3864
[2025-09-15 11:47:11,895][flp2p.graph_runner][INFO] - Train, Round 321 : loss => 1.1093502558022736,  accuracy: 0.5855, gradient_norm : 4.560734197829052
[2025-09-15 11:47:22,290][flp2p.graph_runner][INFO] - Test, Round 321 : loss => 1.761784706401825,  accuracy: 0.3955
[2025-09-15 11:47:32,134][flp2p.graph_runner][INFO] - Train, Round 322 : loss => 1.176846743747592,  accuracy: 0.56088, gradient_norm : 4.943421738055413
[2025-09-15 11:47:42,745][flp2p.graph_runner][INFO] - Test, Round 322 : loss => 1.9674622437119484,  accuracy: 0.3722
[2025-09-15 11:47:52,595][flp2p.graph_runner][INFO] - Train, Round 323 : loss => 1.2166681546717881,  accuracy: 0.557, gradient_norm : 4.8385784248890555
[2025-09-15 11:48:03,137][flp2p.graph_runner][INFO] - Test, Round 323 : loss => 1.644154205697775,  accuracy: 0.4228
[2025-09-15 11:48:12,919][flp2p.graph_runner][INFO] - Train, Round 324 : loss => 1.110233138948679,  accuracy: 0.58792, gradient_norm : 4.542390481782594
[2025-09-15 11:48:23,534][flp2p.graph_runner][INFO] - Test, Round 324 : loss => 1.7325116963267326,  accuracy: 0.4222
[2025-09-15 11:48:33,465][flp2p.graph_runner][INFO] - Train, Round 325 : loss => 1.107977853640914,  accuracy: 0.60268, gradient_norm : 4.198002687222646
[2025-09-15 11:48:43,936][flp2p.graph_runner][INFO] - Test, Round 325 : loss => 1.6659523507475853,  accuracy: 0.4195
[2025-09-15 11:48:53,764][flp2p.graph_runner][INFO] - Train, Round 326 : loss => 0.9973598335683346,  accuracy: 0.64426, gradient_norm : 3.921308256402173
[2025-09-15 11:49:04,271][flp2p.graph_runner][INFO] - Test, Round 326 : loss => 2.0643963556826113,  accuracy: 0.3685
[2025-09-15 11:49:14,151][flp2p.graph_runner][INFO] - Train, Round 327 : loss => 0.9993718899786472,  accuracy: 0.6489, gradient_norm : 3.9473709955091025
[2025-09-15 11:49:24,739][flp2p.graph_runner][INFO] - Test, Round 327 : loss => 1.8108603967487813,  accuracy: 0.4034
[2025-09-15 11:49:34,552][flp2p.graph_runner][INFO] - Train, Round 328 : loss => 1.0153151869028807,  accuracy: 0.63562, gradient_norm : 4.452731820075179
[2025-09-15 11:49:45,180][flp2p.graph_runner][INFO] - Test, Round 328 : loss => 2.7874788354575633,  accuracy: 0.3121
[2025-09-15 11:49:55,055][flp2p.graph_runner][INFO] - Train, Round 329 : loss => 1.1345784678310156,  accuracy: 0.59288, gradient_norm : 4.4953650350683585
[2025-09-15 11:50:05,462][flp2p.graph_runner][INFO] - Test, Round 329 : loss => 1.9762506255745889,  accuracy: 0.3719
[2025-09-15 11:50:15,274][flp2p.graph_runner][INFO] - Train, Round 330 : loss => 1.0654541459679603,  accuracy: 0.61308, gradient_norm : 4.507493994811939
[2025-09-15 11:50:25,771][flp2p.graph_runner][INFO] - Test, Round 330 : loss => 1.7826578304886818,  accuracy: 0.4115
[2025-09-15 11:50:35,584][flp2p.graph_runner][INFO] - Train, Round 331 : loss => 1.1061297951638698,  accuracy: 0.6036, gradient_norm : 4.6991724492454106
[2025-09-15 11:50:45,885][flp2p.graph_runner][INFO] - Test, Round 331 : loss => 1.8778191823840142,  accuracy: 0.3869
[2025-09-15 11:50:55,688][flp2p.graph_runner][INFO] - Train, Round 332 : loss => 1.1427068372815847,  accuracy: 0.58328, gradient_norm : 5.02415586540646
[2025-09-15 11:51:06,164][flp2p.graph_runner][INFO] - Test, Round 332 : loss => 2.0663661585509776,  accuracy: 0.3558
[2025-09-15 11:51:16,059][flp2p.graph_runner][INFO] - Train, Round 333 : loss => 1.1835037283599377,  accuracy: 0.56962, gradient_norm : 4.769979584108135
[2025-09-15 11:51:26,508][flp2p.graph_runner][INFO] - Test, Round 333 : loss => 1.77741353662014,  accuracy: 0.4081
[2025-09-15 11:51:36,369][flp2p.graph_runner][INFO] - Train, Round 334 : loss => 1.0530372904986143,  accuracy: 0.61792, gradient_norm : 4.1752230203043945
[2025-09-15 11:51:46,824][flp2p.graph_runner][INFO] - Test, Round 334 : loss => 1.6502756237566472,  accuracy: 0.43
[2025-09-15 11:51:56,610][flp2p.graph_runner][INFO] - Train, Round 335 : loss => 1.0020185378938913,  accuracy: 0.64346, gradient_norm : 4.065792541563547
[2025-09-15 11:52:07,022][flp2p.graph_runner][INFO] - Test, Round 335 : loss => 1.6520476927518846,  accuracy: 0.432
[2025-09-15 11:52:16,849][flp2p.graph_runner][INFO] - Train, Round 336 : loss => 0.9907458680868149,  accuracy: 0.64418, gradient_norm : 4.118714203858147
[2025-09-15 11:52:27,377][flp2p.graph_runner][INFO] - Test, Round 336 : loss => 1.7659733438253402,  accuracy: 0.4034
[2025-09-15 11:52:37,311][flp2p.graph_runner][INFO] - Train, Round 337 : loss => 1.0110271618515254,  accuracy: 0.63286, gradient_norm : 4.481538713680435
[2025-09-15 11:52:47,878][flp2p.graph_runner][INFO] - Test, Round 337 : loss => 1.8404774395823478,  accuracy: 0.3967
[2025-09-15 11:52:57,668][flp2p.graph_runner][INFO] - Train, Round 338 : loss => 1.0789290066808461,  accuracy: 0.61154, gradient_norm : 4.513055423882416
[2025-09-15 11:53:08,255][flp2p.graph_runner][INFO] - Test, Round 338 : loss => 1.8827090005040168,  accuracy: 0.391
[2025-09-15 11:53:18,001][flp2p.graph_runner][INFO] - Train, Round 339 : loss => 1.001887176260352,  accuracy: 0.63492, gradient_norm : 4.289528766303465
[2025-09-15 11:53:28,557][flp2p.graph_runner][INFO] - Test, Round 339 : loss => 1.958261420750618,  accuracy: 0.3821
[2025-09-15 11:53:38,381][flp2p.graph_runner][INFO] - Train, Round 340 : loss => 1.020826619565487,  accuracy: 0.62948, gradient_norm : 4.534388672939033
[2025-09-15 11:53:48,971][flp2p.graph_runner][INFO] - Test, Round 340 : loss => 2.0441903489232063,  accuracy: 0.3739
[2025-09-15 11:53:58,799][flp2p.graph_runner][INFO] - Train, Round 341 : loss => 1.0136197583377362,  accuracy: 0.6312, gradient_norm : 4.565616241821443
[2025-09-15 11:54:09,229][flp2p.graph_runner][INFO] - Test, Round 341 : loss => 2.30520008405447,  accuracy: 0.3359
[2025-09-15 11:54:18,941][flp2p.graph_runner][INFO] - Train, Round 342 : loss => 1.0818253953754902,  accuracy: 0.6158, gradient_norm : 4.7273213626325505
[2025-09-15 11:54:29,530][flp2p.graph_runner][INFO] - Test, Round 342 : loss => 2.263324331212044,  accuracy: 0.3498
[2025-09-15 11:54:39,446][flp2p.graph_runner][INFO] - Train, Round 343 : loss => 1.0264099486917257,  accuracy: 0.62744, gradient_norm : 4.342795627725197
[2025-09-15 11:54:49,817][flp2p.graph_runner][INFO] - Test, Round 343 : loss => 2.102912623924017,  accuracy: 0.3534
[2025-09-15 11:54:59,667][flp2p.graph_runner][INFO] - Train, Round 344 : loss => 1.003025203347206,  accuracy: 0.64234, gradient_norm : 4.786313409273883
[2025-09-15 11:55:10,458][flp2p.graph_runner][INFO] - Test, Round 344 : loss => 2.299472750967741,  accuracy: 0.3677
[2025-09-15 11:55:20,380][flp2p.graph_runner][INFO] - Train, Round 345 : loss => 1.1181272898614407,  accuracy: 0.6032, gradient_norm : 4.819385039247963
[2025-09-15 11:55:30,923][flp2p.graph_runner][INFO] - Test, Round 345 : loss => 2.2537585278630257,  accuracy: 0.3343
[2025-09-15 11:55:40,837][flp2p.graph_runner][INFO] - Train, Round 346 : loss => 1.0638454317301511,  accuracy: 0.61486, gradient_norm : 5.038433536083378
[2025-09-15 11:55:51,486][flp2p.graph_runner][INFO] - Test, Round 346 : loss => 2.73368199955225,  accuracy: 0.3125
[2025-09-15 11:56:01,289][flp2p.graph_runner][INFO] - Train, Round 347 : loss => 1.1492682046443223,  accuracy: 0.58514, gradient_norm : 4.88317196169503
[2025-09-15 11:56:11,686][flp2p.graph_runner][INFO] - Test, Round 347 : loss => 2.0492406382858754,  accuracy: 0.3695
[2025-09-15 11:56:21,480][flp2p.graph_runner][INFO] - Train, Round 348 : loss => 1.0275968568772078,  accuracy: 0.6349, gradient_norm : 4.732752504158107
[2025-09-15 11:56:31,962][flp2p.graph_runner][INFO] - Test, Round 348 : loss => 2.170264556020498,  accuracy: 0.3617
[2025-09-15 11:56:41,766][flp2p.graph_runner][INFO] - Train, Round 349 : loss => 1.093887065500021,  accuracy: 0.60092, gradient_norm : 4.768074361770455
[2025-09-15 11:56:52,123][flp2p.graph_runner][INFO] - Test, Round 349 : loss => 2.2925883953928947,  accuracy: 0.3375
[2025-09-15 11:57:01,943][flp2p.graph_runner][INFO] - Train, Round 350 : loss => 1.048635343387723,  accuracy: 0.62848, gradient_norm : 4.596833774584115
[2025-09-15 11:57:12,510][flp2p.graph_runner][INFO] - Test, Round 350 : loss => 2.0004623171806335,  accuracy: 0.3614
[2025-09-15 11:57:22,265][flp2p.graph_runner][INFO] - Train, Round 351 : loss => 1.023737539872527,  accuracy: 0.6172, gradient_norm : 4.439699123148056
[2025-09-15 11:57:32,920][flp2p.graph_runner][INFO] - Test, Round 351 : loss => 1.7822107809007168,  accuracy: 0.4076
[2025-09-15 11:57:42,773][flp2p.graph_runner][INFO] - Train, Round 352 : loss => 1.0169639831781387,  accuracy: 0.62826, gradient_norm : 4.599943779465709
[2025-09-15 11:57:53,476][flp2p.graph_runner][INFO] - Test, Round 352 : loss => 1.7404114914000035,  accuracy: 0.4044
[2025-09-15 11:58:03,244][flp2p.graph_runner][INFO] - Train, Round 353 : loss => 1.0394609037786722,  accuracy: 0.60796, gradient_norm : 4.684030772363361
[2025-09-15 11:58:13,552][flp2p.graph_runner][INFO] - Test, Round 353 : loss => 1.9427989626467228,  accuracy: 0.3885
[2025-09-15 11:58:23,401][flp2p.graph_runner][INFO] - Train, Round 354 : loss => 1.0863676108419895,  accuracy: 0.6026, gradient_norm : 4.86473785875037
[2025-09-15 11:58:34,066][flp2p.graph_runner][INFO] - Test, Round 354 : loss => 1.8475842240571976,  accuracy: 0.3839
[2025-09-15 11:58:43,852][flp2p.graph_runner][INFO] - Train, Round 355 : loss => 1.0854429972916841,  accuracy: 0.58864, gradient_norm : 4.923556629752244
[2025-09-15 11:58:54,305][flp2p.graph_runner][INFO] - Test, Round 355 : loss => 2.123845747089386,  accuracy: 0.3737
[2025-09-15 11:59:04,106][flp2p.graph_runner][INFO] - Train, Round 356 : loss => 1.1289710322767497,  accuracy: 0.58708, gradient_norm : 4.916071551069694
[2025-09-15 11:59:14,669][flp2p.graph_runner][INFO] - Test, Round 356 : loss => 2.132181619077921,  accuracy: 0.3503
[2025-09-15 11:59:24,498][flp2p.graph_runner][INFO] - Train, Round 357 : loss => 1.0670531240850687,  accuracy: 0.6043, gradient_norm : 4.659510335251917
[2025-09-15 11:59:34,956][flp2p.graph_runner][INFO] - Test, Round 357 : loss => 2.0350988882899284,  accuracy: 0.3735
[2025-09-15 11:59:44,788][flp2p.graph_runner][INFO] - Train, Round 358 : loss => 1.0235840363800526,  accuracy: 0.6314, gradient_norm : 4.622639204427269
[2025-09-15 11:59:55,380][flp2p.graph_runner][INFO] - Test, Round 358 : loss => 1.9040985819101333,  accuracy: 0.3982
[2025-09-15 12:00:05,329][flp2p.graph_runner][INFO] - Train, Round 359 : loss => 1.026728536337614,  accuracy: 0.63288, gradient_norm : 4.309940614686049
[2025-09-15 12:00:15,873][flp2p.graph_runner][INFO] - Test, Round 359 : loss => 2.4092685871839525,  accuracy: 0.3096
[2025-09-15 12:00:25,700][flp2p.graph_runner][INFO] - Train, Round 360 : loss => 0.9564639201015234,  accuracy: 0.66396, gradient_norm : 4.295043143404385
[2025-09-15 12:00:36,244][flp2p.graph_runner][INFO] - Test, Round 360 : loss => 1.9749640027940274,  accuracy: 0.3901
[2025-09-15 12:00:46,160][flp2p.graph_runner][INFO] - Train, Round 361 : loss => 1.0067399269342423,  accuracy: 0.64138, gradient_norm : 4.558598198549975
[2025-09-15 12:00:56,600][flp2p.graph_runner][INFO] - Test, Round 361 : loss => 2.409889032560587,  accuracy: 0.3141
[2025-09-15 12:01:06,369][flp2p.graph_runner][INFO] - Train, Round 362 : loss => 1.0077263194322585,  accuracy: 0.63722, gradient_norm : 4.833930193163605
[2025-09-15 12:01:16,896][flp2p.graph_runner][INFO] - Test, Round 362 : loss => 2.1307052300930023,  accuracy: 0.3552
[2025-09-15 12:01:26,700][flp2p.graph_runner][INFO] - Train, Round 363 : loss => 1.1030198414623738,  accuracy: 0.59886, gradient_norm : 5.080832575235496
[2025-09-15 12:01:37,192][flp2p.graph_runner][INFO] - Test, Round 363 : loss => 2.3890362813830377,  accuracy: 0.3218
[2025-09-15 12:01:46,959][flp2p.graph_runner][INFO] - Train, Round 364 : loss => 1.1251725722849368,  accuracy: 0.5843, gradient_norm : 5.194238531784144
[2025-09-15 12:01:57,584][flp2p.graph_runner][INFO] - Test, Round 364 : loss => 2.2095512909650803,  accuracy: 0.3241
[2025-09-15 12:02:07,459][flp2p.graph_runner][INFO] - Train, Round 365 : loss => 1.104656525105238,  accuracy: 0.58404, gradient_norm : 4.9102840644439985
[2025-09-15 12:02:17,771][flp2p.graph_runner][INFO] - Test, Round 365 : loss => 1.973171211117506,  accuracy: 0.3831
[2025-09-15 12:02:27,652][flp2p.graph_runner][INFO] - Train, Round 366 : loss => 1.0318909037858248,  accuracy: 0.62336, gradient_norm : 4.4098590111713705
[2025-09-15 12:02:38,254][flp2p.graph_runner][INFO] - Test, Round 366 : loss => 1.6514028855919838,  accuracy: 0.427
[2025-09-15 12:02:48,130][flp2p.graph_runner][INFO] - Train, Round 367 : loss => 0.9048721322417259,  accuracy: 0.67624, gradient_norm : 3.9887212011677633
[2025-09-15 12:02:58,685][flp2p.graph_runner][INFO] - Test, Round 367 : loss => 1.7533222126960755,  accuracy: 0.4123
[2025-09-15 12:03:08,463][flp2p.graph_runner][INFO] - Train, Round 368 : loss => 0.8938438987731934,  accuracy: 0.68514, gradient_norm : 4.0305355237659475
[2025-09-15 12:03:19,066][flp2p.graph_runner][INFO] - Test, Round 368 : loss => 1.6460711168169975,  accuracy: 0.4338
[2025-09-15 12:03:28,809][flp2p.graph_runner][INFO] - Train, Round 369 : loss => 0.8823298235237599,  accuracy: 0.68416, gradient_norm : 3.918068185854029
[2025-09-15 12:03:39,268][flp2p.graph_runner][INFO] - Test, Round 369 : loss => 1.6615564644157887,  accuracy: 0.4361
[2025-09-15 12:03:49,090][flp2p.graph_runner][INFO] - Train, Round 370 : loss => 0.8695955824106931,  accuracy: 0.68586, gradient_norm : 4.1675756095374545
[2025-09-15 12:03:59,640][flp2p.graph_runner][INFO] - Test, Round 370 : loss => 1.6916656161189079,  accuracy: 0.4239
[2025-09-15 12:04:09,487][flp2p.graph_runner][INFO] - Train, Round 371 : loss => 0.925709456205368,  accuracy: 0.66064, gradient_norm : 4.439379549424807
[2025-09-15 12:04:19,874][flp2p.graph_runner][INFO] - Test, Round 371 : loss => 1.8185615779161453,  accuracy: 0.4045
[2025-09-15 12:04:29,661][flp2p.graph_runner][INFO] - Train, Round 372 : loss => 0.9523321037739515,  accuracy: 0.64038, gradient_norm : 4.669627539038429
[2025-09-15 12:04:40,123][flp2p.graph_runner][INFO] - Test, Round 372 : loss => 1.9905332073807716,  accuracy: 0.3895
[2025-09-15 12:04:49,949][flp2p.graph_runner][INFO] - Train, Round 373 : loss => 1.0133092935383319,  accuracy: 0.62724, gradient_norm : 4.864439615030663
[2025-09-15 12:05:00,344][flp2p.graph_runner][INFO] - Test, Round 373 : loss => 1.939189457708597,  accuracy: 0.3852
[2025-09-15 12:05:10,202][flp2p.graph_runner][INFO] - Train, Round 374 : loss => 0.9985835453867913,  accuracy: 0.62656, gradient_norm : 4.8604582404300025
[2025-09-15 12:05:20,739][flp2p.graph_runner][INFO] - Test, Round 374 : loss => 1.910345949023962,  accuracy: 0.4011
[2025-09-15 12:05:30,584][flp2p.graph_runner][INFO] - Train, Round 375 : loss => 1.014849798604846,  accuracy: 0.62812, gradient_norm : 4.794194037232734
[2025-09-15 12:05:41,009][flp2p.graph_runner][INFO] - Test, Round 375 : loss => 1.7860267764806748,  accuracy: 0.4197
[2025-09-15 12:05:50,689][flp2p.graph_runner][INFO] - Train, Round 376 : loss => 0.9523117905110121,  accuracy: 0.6527, gradient_norm : 4.440122499259963
[2025-09-15 12:06:01,246][flp2p.graph_runner][INFO] - Test, Round 376 : loss => 1.7859912546277046,  accuracy: 0.4075
[2025-09-15 12:06:11,154][flp2p.graph_runner][INFO] - Train, Round 377 : loss => 0.9085923477262259,  accuracy: 0.6765, gradient_norm : 4.555968135391514
[2025-09-15 12:06:21,630][flp2p.graph_runner][INFO] - Test, Round 377 : loss => 2.0925673253297807,  accuracy: 0.3768
[2025-09-15 12:06:31,491][flp2p.graph_runner][INFO] - Train, Round 378 : loss => 0.9672130142897367,  accuracy: 0.6498, gradient_norm : 4.54715848272997
[2025-09-15 12:06:42,002][flp2p.graph_runner][INFO] - Test, Round 378 : loss => 2.156059940636158,  accuracy: 0.3493
[2025-09-15 12:06:51,847][flp2p.graph_runner][INFO] - Train, Round 379 : loss => 0.9199233351647854,  accuracy: 0.67278, gradient_norm : 4.452902447729464
[2025-09-15 12:07:02,332][flp2p.graph_runner][INFO] - Test, Round 379 : loss => 2.010788644826412,  accuracy: 0.3615
[2025-09-15 12:07:12,171][flp2p.graph_runner][INFO] - Train, Round 380 : loss => 0.8962284380942583,  accuracy: 0.6772, gradient_norm : 4.601179503389834
[2025-09-15 12:07:22,814][flp2p.graph_runner][INFO] - Test, Round 380 : loss => 2.0140378800630567,  accuracy: 0.3801
[2025-09-15 12:07:32,655][flp2p.graph_runner][INFO] - Train, Round 381 : loss => 0.9374640475958586,  accuracy: 0.66048, gradient_norm : 4.82997013020694
[2025-09-15 12:07:43,120][flp2p.graph_runner][INFO] - Test, Round 381 : loss => 2.117777154099941,  accuracy: 0.3424
[2025-09-15 12:07:53,008][flp2p.graph_runner][INFO] - Train, Round 382 : loss => 1.0582590614259244,  accuracy: 0.60168, gradient_norm : 5.687958429770266
[2025-09-15 12:08:03,513][flp2p.graph_runner][INFO] - Test, Round 382 : loss => 2.5824962788045407,  accuracy: 0.3611
[2025-09-15 12:08:13,360][flp2p.graph_runner][INFO] - Train, Round 383 : loss => 1.2836037964373828,  accuracy: 0.55632, gradient_norm : 6.035912850807025
[2025-09-15 12:08:23,836][flp2p.graph_runner][INFO] - Test, Round 383 : loss => 2.1856548954188826,  accuracy: 0.3481
[2025-09-15 12:08:33,748][flp2p.graph_runner][INFO] - Train, Round 384 : loss => 1.1885264550149441,  accuracy: 0.56258, gradient_norm : 5.530049586914696
[2025-09-15 12:08:44,400][flp2p.graph_runner][INFO] - Test, Round 384 : loss => 1.8937305165469647,  accuracy: 0.4077
[2025-09-15 12:08:54,309][flp2p.graph_runner][INFO] - Train, Round 385 : loss => 1.0838846556097268,  accuracy: 0.63232, gradient_norm : 4.712412908820369
[2025-09-15 12:09:04,743][flp2p.graph_runner][INFO] - Test, Round 385 : loss => 1.800797863906622,  accuracy: 0.4082
[2025-09-15 12:09:14,590][flp2p.graph_runner][INFO] - Train, Round 386 : loss => 0.8960903130471707,  accuracy: 0.69166, gradient_norm : 4.063824016091465
[2025-09-15 12:09:25,156][flp2p.graph_runner][INFO] - Test, Round 386 : loss => 2.0411601679801943,  accuracy: 0.3766
[2025-09-15 12:09:35,011][flp2p.graph_runner][INFO] - Train, Round 387 : loss => 0.8749330317229033,  accuracy: 0.70392, gradient_norm : 4.345314581169321
[2025-09-15 12:09:45,513][flp2p.graph_runner][INFO] - Test, Round 387 : loss => 2.1581931418061258,  accuracy: 0.3733
[2025-09-15 12:09:55,454][flp2p.graph_runner][INFO] - Train, Round 388 : loss => 0.9648479340225458,  accuracy: 0.66658, gradient_norm : 4.762897328181401
[2025-09-15 12:10:06,064][flp2p.graph_runner][INFO] - Test, Round 388 : loss => 2.8029159928441048,  accuracy: 0.3
[2025-09-15 12:10:15,923][flp2p.graph_runner][INFO] - Train, Round 389 : loss => 0.9790738289058208,  accuracy: 0.65878, gradient_norm : 5.338223018381311
[2025-09-15 12:10:26,404][flp2p.graph_runner][INFO] - Test, Round 389 : loss => 2.907770773887634,  accuracy: 0.3153
[2025-09-15 12:10:36,231][flp2p.graph_runner][INFO] - Train, Round 390 : loss => 1.1450469367206098,  accuracy: 0.60912, gradient_norm : 5.660248873432436
[2025-09-15 12:10:46,846][flp2p.graph_runner][INFO] - Test, Round 390 : loss => 3.187863102865219,  accuracy: 0.2745
[2025-09-15 12:10:56,647][flp2p.graph_runner][INFO] - Train, Round 391 : loss => 1.089565508812666,  accuracy: 0.61628, gradient_norm : 5.438351372770499
[2025-09-15 12:11:07,134][flp2p.graph_runner][INFO] - Test, Round 391 : loss => 3.2969975004434584,  accuracy: 0.2743
[2025-09-15 12:11:16,965][flp2p.graph_runner][INFO] - Train, Round 392 : loss => 1.0593017407506704,  accuracy: 0.63746, gradient_norm : 5.076799375092116
[2025-09-15 12:11:27,504][flp2p.graph_runner][INFO] - Test, Round 392 : loss => 2.305974206548929,  accuracy: 0.3458
[2025-09-15 12:11:37,327][flp2p.graph_runner][INFO] - Train, Round 393 : loss => 0.9659960409253836,  accuracy: 0.65278, gradient_norm : 4.4944786999495525
[2025-09-15 12:11:47,899][flp2p.graph_runner][INFO] - Test, Round 393 : loss => 1.9714222438633442,  accuracy: 0.3791
[2025-09-15 12:11:57,720][flp2p.graph_runner][INFO] - Train, Round 394 : loss => 0.8683710854500533,  accuracy: 0.70962, gradient_norm : 4.320029730848557
[2025-09-15 12:12:08,206][flp2p.graph_runner][INFO] - Test, Round 394 : loss => 1.8377185165166854,  accuracy: 0.4192
[2025-09-15 12:12:18,028][flp2p.graph_runner][INFO] - Train, Round 395 : loss => 0.8589503227174282,  accuracy: 0.69632, gradient_norm : 4.15507898620427
[2025-09-15 12:12:28,624][flp2p.graph_runner][INFO] - Test, Round 395 : loss => 1.9789549711585044,  accuracy: 0.3681
[2025-09-15 12:12:38,521][flp2p.graph_runner][INFO] - Train, Round 396 : loss => 0.8431921511888504,  accuracy: 0.70538, gradient_norm : 4.549602517114174
[2025-09-15 12:12:49,230][flp2p.graph_runner][INFO] - Test, Round 396 : loss => 1.9302297526359558,  accuracy: 0.4113
[2025-09-15 12:12:59,050][flp2p.graph_runner][INFO] - Train, Round 397 : loss => 0.9844946326315402,  accuracy: 0.63728, gradient_norm : 4.913531891823911
[2025-09-15 12:13:09,559][flp2p.graph_runner][INFO] - Test, Round 397 : loss => 2.068240579456091,  accuracy: 0.3654
[2025-09-15 12:13:19,423][flp2p.graph_runner][INFO] - Train, Round 398 : loss => 0.9921759045124054,  accuracy: 0.639, gradient_norm : 5.3115963786090665
[2025-09-15 12:13:30,041][flp2p.graph_runner][INFO] - Test, Round 398 : loss => 2.095430185776949,  accuracy: 0.378
[2025-09-15 12:13:39,851][flp2p.graph_runner][INFO] - Train, Round 399 : loss => 1.0521992906183004,  accuracy: 0.60458, gradient_norm : 5.237570592757639
[2025-09-15 12:13:50,264][flp2p.graph_runner][INFO] - Test, Round 399 : loss => 1.978266018128395,  accuracy: 0.3759
[2025-09-15 12:14:00,104][flp2p.graph_runner][INFO] - Train, Round 400 : loss => 1.0122629369795322,  accuracy: 0.6363, gradient_norm : 5.185380264854167
[2025-09-15 12:14:10,589][flp2p.graph_runner][INFO] - Test, Round 400 : loss => 1.7932773494541645,  accuracy: 0.4164
[2025-09-15 12:14:20,476][flp2p.graph_runner][INFO] - Train, Round 401 : loss => 0.9642382048815489,  accuracy: 0.63914, gradient_norm : 4.7083131297268155
[2025-09-15 12:14:30,995][flp2p.graph_runner][INFO] - Test, Round 401 : loss => 1.7139272249162196,  accuracy: 0.4272
[2025-09-15 12:14:40,809][flp2p.graph_runner][INFO] - Train, Round 402 : loss => 0.876678688749671,  accuracy: 0.6808, gradient_norm : 4.49583826046978
[2025-09-15 12:14:51,411][flp2p.graph_runner][INFO] - Test, Round 402 : loss => 1.6973823588967323,  accuracy: 0.4391
[2025-09-15 12:15:01,292][flp2p.graph_runner][INFO] - Train, Round 403 : loss => 0.8957656982541085,  accuracy: 0.66798, gradient_norm : 4.44846681352885
[2025-09-15 12:15:11,724][flp2p.graph_runner][INFO] - Test, Round 403 : loss => 1.6006019877672195,  accuracy: 0.4533
[2025-09-15 12:15:21,554][flp2p.graph_runner][INFO] - Train, Round 404 : loss => 0.8145068986713886,  accuracy: 0.7054, gradient_norm : 4.225033431125863
[2025-09-15 12:15:32,082][flp2p.graph_runner][INFO] - Test, Round 404 : loss => 1.7180937346816063,  accuracy: 0.4336
[2025-09-15 12:15:41,859][flp2p.graph_runner][INFO] - Train, Round 405 : loss => 0.8482150061428547,  accuracy: 0.69536, gradient_norm : 4.492327110164712
[2025-09-15 12:15:52,362][flp2p.graph_runner][INFO] - Test, Round 405 : loss => 1.6474888171255588,  accuracy: 0.4503
[2025-09-15 12:16:02,057][flp2p.graph_runner][INFO] - Train, Round 406 : loss => 0.8566755518317223,  accuracy: 0.68288, gradient_norm : 4.429047016181418
[2025-09-15 12:16:12,558][flp2p.graph_runner][INFO] - Test, Round 406 : loss => 1.8592088224709034,  accuracy: 0.4116
[2025-09-15 12:16:22,447][flp2p.graph_runner][INFO] - Train, Round 407 : loss => 0.8432877442240715,  accuracy: 0.69766, gradient_norm : 4.593526794186718
[2025-09-15 12:16:32,789][flp2p.graph_runner][INFO] - Test, Round 407 : loss => 1.8346697081387042,  accuracy: 0.423
[2025-09-15 12:16:42,685][flp2p.graph_runner][INFO] - Train, Round 408 : loss => 0.8453997688740492,  accuracy: 0.6896, gradient_norm : 4.608196910980392
[2025-09-15 12:16:53,518][flp2p.graph_runner][INFO] - Test, Round 408 : loss => 2.0177155125439166,  accuracy: 0.3863
[2025-09-15 12:17:03,312][flp2p.graph_runner][INFO] - Train, Round 409 : loss => 0.9069933684915304,  accuracy: 0.67288, gradient_norm : 5.120889426214421
[2025-09-15 12:17:13,720][flp2p.graph_runner][INFO] - Test, Round 409 : loss => 2.2954932220101356,  accuracy: 0.3547
[2025-09-15 12:17:23,555][flp2p.graph_runner][INFO] - Train, Round 410 : loss => 0.9605722653865815,  accuracy: 0.64542, gradient_norm : 5.509636709014578
[2025-09-15 12:17:34,252][flp2p.graph_runner][INFO] - Test, Round 410 : loss => 2.7870735404372216,  accuracy: 0.3256
[2025-09-15 12:17:44,033][flp2p.graph_runner][INFO] - Train, Round 411 : loss => 1.0842250358313321,  accuracy: 0.63136, gradient_norm : 5.7996746379813535
[2025-09-15 12:17:54,441][flp2p.graph_runner][INFO] - Test, Round 411 : loss => 2.2734316321194172,  accuracy: 0.3657
[2025-09-15 12:18:04,339][flp2p.graph_runner][INFO] - Train, Round 412 : loss => 1.0171143492311239,  accuracy: 0.63888, gradient_norm : 5.353786414044882
[2025-09-15 12:18:14,846][flp2p.graph_runner][INFO] - Test, Round 412 : loss => 2.732479070836306,  accuracy: 0.3096
[2025-09-15 12:18:24,733][flp2p.graph_runner][INFO] - Train, Round 413 : loss => 0.9600105996429921,  accuracy: 0.65384, gradient_norm : 5.045681126308379
[2025-09-15 12:18:35,170][flp2p.graph_runner][INFO] - Test, Round 413 : loss => 1.9283073744535446,  accuracy: 0.4112
[2025-09-15 12:18:45,008][flp2p.graph_runner][INFO] - Train, Round 414 : loss => 0.9382486866414547,  accuracy: 0.66188, gradient_norm : 4.767368799038242
[2025-09-15 12:18:55,575][flp2p.graph_runner][INFO] - Test, Round 414 : loss => 1.772406047707796,  accuracy: 0.4358
[2025-09-15 12:19:05,307][flp2p.graph_runner][INFO] - Train, Round 415 : loss => 0.8908244251459837,  accuracy: 0.68208, gradient_norm : 4.651079831933557
[2025-09-15 12:19:15,773][flp2p.graph_runner][INFO] - Test, Round 415 : loss => 1.659045000731945,  accuracy: 0.4475
[2025-09-15 12:19:25,636][flp2p.graph_runner][INFO] - Train, Round 416 : loss => 0.8985768447071314,  accuracy: 0.67892, gradient_norm : 4.448316966099514
[2025-09-15 12:19:36,230][flp2p.graph_runner][INFO] - Test, Round 416 : loss => 1.6190262229800225,  accuracy: 0.4582
[2025-09-15 12:19:46,099][flp2p.graph_runner][INFO] - Train, Round 417 : loss => 0.8019444084912538,  accuracy: 0.71706, gradient_norm : 4.2230410685729405
[2025-09-15 12:19:56,558][flp2p.graph_runner][INFO] - Test, Round 417 : loss => 1.6962275747656823,  accuracy: 0.4398
[2025-09-15 12:20:06,540][flp2p.graph_runner][INFO] - Train, Round 418 : loss => 0.8460487563163042,  accuracy: 0.69208, gradient_norm : 4.616283522454851
[2025-09-15 12:20:17,159][flp2p.graph_runner][INFO] - Test, Round 418 : loss => 1.8178824402093887,  accuracy: 0.4225
[2025-09-15 12:20:27,016][flp2p.graph_runner][INFO] - Train, Round 419 : loss => 0.8959296383708716,  accuracy: 0.66986, gradient_norm : 4.933405279948079
[2025-09-15 12:20:37,565][flp2p.graph_runner][INFO] - Test, Round 419 : loss => 2.080539796167612,  accuracy: 0.3679
[2025-09-15 12:20:47,399][flp2p.graph_runner][INFO] - Train, Round 420 : loss => 0.9354863072186709,  accuracy: 0.65488, gradient_norm : 5.354636335943674
[2025-09-15 12:20:57,992][flp2p.graph_runner][INFO] - Test, Round 420 : loss => 2.1827333206415176,  accuracy: 0.3767
[2025-09-15 12:21:07,769][flp2p.graph_runner][INFO] - Train, Round 421 : loss => 1.0335794515162706,  accuracy: 0.60832, gradient_norm : 5.5389307669095285
[2025-09-15 12:21:18,236][flp2p.graph_runner][INFO] - Test, Round 421 : loss => 2.066191176623106,  accuracy: 0.3655
[2025-09-15 12:21:28,039][flp2p.graph_runner][INFO] - Train, Round 422 : loss => 0.9733781161159277,  accuracy: 0.62746, gradient_norm : 5.329299308282751
[2025-09-15 12:21:38,617][flp2p.graph_runner][INFO] - Test, Round 422 : loss => 1.868879078513384,  accuracy: 0.4014
[2025-09-15 12:21:48,462][flp2p.graph_runner][INFO] - Train, Round 423 : loss => 0.9499314215034247,  accuracy: 0.63236, gradient_norm : 5.153284563013792
[2025-09-15 12:21:58,829][flp2p.graph_runner][INFO] - Test, Round 423 : loss => 1.844321019178629,  accuracy: 0.4056
[2025-09-15 12:22:08,611][flp2p.graph_runner][INFO] - Train, Round 424 : loss => 0.8740199539065361,  accuracy: 0.67254, gradient_norm : 4.745186428464942
[2025-09-15 12:22:19,132][flp2p.graph_runner][INFO] - Test, Round 424 : loss => 2.3599615170419215,  accuracy: 0.3367
[2025-09-15 12:22:28,965][flp2p.graph_runner][INFO] - Train, Round 425 : loss => 0.8566566613316536,  accuracy: 0.68564, gradient_norm : 4.623706153016532
[2025-09-15 12:22:39,366][flp2p.graph_runner][INFO] - Test, Round 425 : loss => 2.0326030993282793,  accuracy: 0.3931
[2025-09-15 12:22:49,114][flp2p.graph_runner][INFO] - Train, Round 426 : loss => 0.8461175411939621,  accuracy: 0.6912, gradient_norm : 4.96917103778488
[2025-09-15 12:22:59,781][flp2p.graph_runner][INFO] - Test, Round 426 : loss => 2.2368558191776278,  accuracy: 0.3681
[2025-09-15 12:23:09,594][flp2p.graph_runner][INFO] - Train, Round 427 : loss => 0.9793430490791798,  accuracy: 0.6392, gradient_norm : 5.645727767980596
[2025-09-15 12:23:19,992][flp2p.graph_runner][INFO] - Test, Round 427 : loss => 2.5077468406140806,  accuracy: 0.342
[2025-09-15 12:23:29,824][flp2p.graph_runner][INFO] - Train, Round 428 : loss => 1.0661040095984935,  accuracy: 0.61018, gradient_norm : 6.089440550727735
[2025-09-15 12:23:40,386][flp2p.graph_runner][INFO] - Test, Round 428 : loss => 3.1538578026533126,  accuracy: 0.2837
[2025-09-15 12:23:50,149][flp2p.graph_runner][INFO] - Train, Round 429 : loss => 1.066970362663269,  accuracy: 0.61218, gradient_norm : 5.67259748573129
[2025-09-15 12:24:00,583][flp2p.graph_runner][INFO] - Test, Round 429 : loss => 2.116919524663687,  accuracy: 0.3873
[2025-09-15 12:24:10,476][flp2p.graph_runner][INFO] - Train, Round 430 : loss => 0.9102840441465377,  accuracy: 0.67794, gradient_norm : 4.845789833941099
[2025-09-15 12:24:21,094][flp2p.graph_runner][INFO] - Test, Round 430 : loss => 1.8058244252800941,  accuracy: 0.4189
[2025-09-15 12:24:30,927][flp2p.graph_runner][INFO] - Train, Round 431 : loss => 0.767168205268681,  accuracy: 0.73834, gradient_norm : 4.171517132229957
[2025-09-15 12:24:41,407][flp2p.graph_runner][INFO] - Test, Round 431 : loss => 1.779464042276144,  accuracy: 0.4231
[2025-09-15 12:24:51,196][flp2p.graph_runner][INFO] - Train, Round 432 : loss => 0.7401011500880122,  accuracy: 0.74318, gradient_norm : 4.199448028611977
[2025-09-15 12:25:01,752][flp2p.graph_runner][INFO] - Test, Round 432 : loss => 1.8285064039945602,  accuracy: 0.4149
[2025-09-15 12:25:11,642][flp2p.graph_runner][INFO] - Train, Round 433 : loss => 0.7431604897230863,  accuracy: 0.74112, gradient_norm : 4.406849967289567
[2025-09-15 12:25:22,185][flp2p.graph_runner][INFO] - Test, Round 433 : loss => 2.0887750187635423,  accuracy: 0.377
[2025-09-15 12:25:32,011][flp2p.graph_runner][INFO] - Train, Round 434 : loss => 0.8015878338366746,  accuracy: 0.7057, gradient_norm : 4.731582991536802
[2025-09-15 12:25:42,741][flp2p.graph_runner][INFO] - Test, Round 434 : loss => 2.296555808711052,  accuracy: 0.3466
[2025-09-15 12:25:52,605][flp2p.graph_runner][INFO] - Train, Round 435 : loss => 0.8308335743844509,  accuracy: 0.69446, gradient_norm : 5.099570119913614
[2025-09-15 12:26:03,035][flp2p.graph_runner][INFO] - Test, Round 435 : loss => 2.5181261107802393,  accuracy: 0.3291
[2025-09-15 12:26:12,838][flp2p.graph_runner][INFO] - Train, Round 436 : loss => 0.9312636694312095,  accuracy: 0.64456, gradient_norm : 5.398284583210768
[2025-09-15 12:26:23,414][flp2p.graph_runner][INFO] - Test, Round 436 : loss => 2.4985139564991,  accuracy: 0.3283
[2025-09-15 12:26:33,263][flp2p.graph_runner][INFO] - Train, Round 437 : loss => 0.9523901681602002,  accuracy: 0.64812, gradient_norm : 5.441013396202379
[2025-09-15 12:26:43,680][flp2p.graph_runner][INFO] - Test, Round 437 : loss => 2.1702526604652403,  accuracy: 0.3556
[2025-09-15 12:26:53,587][flp2p.graph_runner][INFO] - Train, Round 438 : loss => 0.9244948254525661,  accuracy: 0.6446, gradient_norm : 5.337464596481779
[2025-09-15 12:27:04,284][flp2p.graph_runner][INFO] - Test, Round 438 : loss => 1.9455491747379303,  accuracy: 0.3937
[2025-09-15 12:27:14,097][flp2p.graph_runner][INFO] - Train, Round 439 : loss => 0.9252007497102022,  accuracy: 0.65658, gradient_norm : 5.1676760246466475
[2025-09-15 12:27:24,481][flp2p.graph_runner][INFO] - Test, Round 439 : loss => 1.7472389591991901,  accuracy: 0.4323
[2025-09-15 12:27:34,344][flp2p.graph_runner][INFO] - Train, Round 440 : loss => 0.8321406076848507,  accuracy: 0.6893, gradient_norm : 4.698888517990394
[2025-09-15 12:27:44,807][flp2p.graph_runner][INFO] - Test, Round 440 : loss => 1.7448542951107024,  accuracy: 0.4347
[2025-09-15 12:27:54,636][flp2p.graph_runner][INFO] - Train, Round 441 : loss => 0.793815134614706,  accuracy: 0.7257, gradient_norm : 4.605056788272078
[2025-09-15 12:28:05,228][flp2p.graph_runner][INFO] - Test, Round 441 : loss => 1.6617959542036056,  accuracy: 0.458
[2025-09-15 12:28:15,074][flp2p.graph_runner][INFO] - Train, Round 442 : loss => 0.769534007795155,  accuracy: 0.72876, gradient_norm : 4.403985509321324
[2025-09-15 12:28:25,648][flp2p.graph_runner][INFO] - Test, Round 442 : loss => 1.6817920206964017,  accuracy: 0.442
[2025-09-15 12:28:35,569][flp2p.graph_runner][INFO] - Train, Round 443 : loss => 0.7487223148345947,  accuracy: 0.74104, gradient_norm : 4.42747612171748
[2025-09-15 12:28:46,066][flp2p.graph_runner][INFO] - Test, Round 443 : loss => 1.6246394643187523,  accuracy: 0.4737
[2025-09-15 12:28:55,735][flp2p.graph_runner][INFO] - Train, Round 444 : loss => 0.7372630777209997,  accuracy: 0.74488, gradient_norm : 4.389058720066277
[2025-09-15 12:29:06,281][flp2p.graph_runner][INFO] - Test, Round 444 : loss => 1.6855235564112663,  accuracy: 0.4506
[2025-09-15 12:29:16,169][flp2p.graph_runner][INFO] - Train, Round 445 : loss => 0.7396413208916783,  accuracy: 0.7333, gradient_norm : 4.556261571111227
[2025-09-15 12:29:26,542][flp2p.graph_runner][INFO] - Test, Round 445 : loss => 1.6609781899094582,  accuracy: 0.4603
[2025-09-15 12:29:36,465][flp2p.graph_runner][INFO] - Train, Round 446 : loss => 0.7743362262472511,  accuracy: 0.72208, gradient_norm : 4.679990767555884
[2025-09-15 12:29:47,025][flp2p.graph_runner][INFO] - Test, Round 446 : loss => 1.6957450874388218,  accuracy: 0.454
[2025-09-15 12:29:56,878][flp2p.graph_runner][INFO] - Train, Round 447 : loss => 0.7845660693198443,  accuracy: 0.71048, gradient_norm : 4.860160539084211
[2025-09-15 12:30:07,350][flp2p.graph_runner][INFO] - Test, Round 447 : loss => 1.760266789996624,  accuracy: 0.4433
[2025-09-15 12:30:17,251][flp2p.graph_runner][INFO] - Train, Round 448 : loss => 0.8199858635663986,  accuracy: 0.69148, gradient_norm : 5.018923225111557
[2025-09-15 12:30:27,851][flp2p.graph_runner][INFO] - Test, Round 448 : loss => 1.8367215747058392,  accuracy: 0.4239
[2025-09-15 12:30:37,721][flp2p.graph_runner][INFO] - Train, Round 449 : loss => 0.8432254642248154,  accuracy: 0.68494, gradient_norm : 5.223296044562842
[2025-09-15 12:30:48,253][flp2p.graph_runner][INFO] - Test, Round 449 : loss => 2.6237093316376208,  accuracy: 0.3453
[2025-09-15 12:30:58,003][flp2p.graph_runner][INFO] - Train, Round 450 : loss => 0.9178511565178633,  accuracy: 0.65042, gradient_norm : 5.450406912315132
[2025-09-15 12:31:08,535][flp2p.graph_runner][INFO] - Test, Round 450 : loss => 2.095586870968342,  accuracy: 0.3863
[2025-09-15 12:31:18,421][flp2p.graph_runner][INFO] - Train, Round 451 : loss => 0.8978991743549705,  accuracy: 0.65008, gradient_norm : 5.717368571760456
[2025-09-15 12:31:28,977][flp2p.graph_runner][INFO] - Test, Round 451 : loss => 3.0956697015166283,  accuracy: 0.3043
[2025-09-15 12:31:38,850][flp2p.graph_runner][INFO] - Train, Round 452 : loss => 1.0528706403821706,  accuracy: 0.61744, gradient_norm : 6.0199516619788325
[2025-09-15 12:31:49,378][flp2p.graph_runner][INFO] - Test, Round 452 : loss => 2.9465619690537452,  accuracy: 0.2967
[2025-09-15 12:31:59,255][flp2p.graph_runner][INFO] - Train, Round 453 : loss => 1.0163154276460409,  accuracy: 0.61748, gradient_norm : 6.1212004716186605
[2025-09-15 12:32:09,696][flp2p.graph_runner][INFO] - Test, Round 453 : loss => 3.184872450208664,  accuracy: 0.2946
[2025-09-15 12:32:19,641][flp2p.graph_runner][INFO] - Train, Round 454 : loss => 1.0593948271870612,  accuracy: 0.62444, gradient_norm : 5.9332624318113
[2025-09-15 12:32:30,226][flp2p.graph_runner][INFO] - Test, Round 454 : loss => 3.1655248984456064,  accuracy: 0.2651
[2025-09-15 12:32:40,109][flp2p.graph_runner][INFO] - Train, Round 455 : loss => 0.9687264644354582,  accuracy: 0.65286, gradient_norm : 5.506247099208483
[2025-09-15 12:32:50,493][flp2p.graph_runner][INFO] - Test, Round 455 : loss => 2.4791738185822965,  accuracy: 0.3334
[2025-09-15 12:33:00,228][flp2p.graph_runner][INFO] - Train, Round 456 : loss => 0.8499338357150554,  accuracy: 0.69536, gradient_norm : 4.854781759455257
[2025-09-15 12:33:10,829][flp2p.graph_runner][INFO] - Test, Round 456 : loss => 1.891681309491396,  accuracy: 0.4241
[2025-09-15 12:33:20,689][flp2p.graph_runner][INFO] - Train, Round 457 : loss => 0.7833675383776426,  accuracy: 0.72366, gradient_norm : 4.376653345487151
[2025-09-15 12:33:31,118][flp2p.graph_runner][INFO] - Test, Round 457 : loss => 1.8209574246346951,  accuracy: 0.4225
[2025-09-15 12:33:40,927][flp2p.graph_runner][INFO] - Train, Round 458 : loss => 0.7120423571392894,  accuracy: 0.75552, gradient_norm : 4.206779878186348
[2025-09-15 12:33:51,571][flp2p.graph_runner][INFO] - Test, Round 458 : loss => 1.7430062063097953,  accuracy: 0.4543
[2025-09-15 12:34:01,413][flp2p.graph_runner][INFO] - Train, Round 459 : loss => 0.7281841201335192,  accuracy: 0.75124, gradient_norm : 4.405922347791647
[2025-09-15 12:34:11,834][flp2p.graph_runner][INFO] - Test, Round 459 : loss => 1.8384379283607006,  accuracy: 0.4177
[2025-09-15 12:34:21,628][flp2p.graph_runner][INFO] - Train, Round 460 : loss => 0.7679527316242456,  accuracy: 0.73394, gradient_norm : 4.655777153967153
[2025-09-15 12:34:32,134][flp2p.graph_runner][INFO] - Test, Round 460 : loss => 1.8348323574185372,  accuracy: 0.4327
[2025-09-15 12:34:41,931][flp2p.graph_runner][INFO] - Train, Round 461 : loss => 0.7517860446870327,  accuracy: 0.7372, gradient_norm : 4.508295207002008
[2025-09-15 12:34:52,286][flp2p.graph_runner][INFO] - Test, Round 461 : loss => 1.7591668521404267,  accuracy: 0.4413
[2025-09-15 12:35:02,021][flp2p.graph_runner][INFO] - Train, Round 462 : loss => 0.7302589382976293,  accuracy: 0.7442, gradient_norm : 4.354090059931393
[2025-09-15 12:35:12,651][flp2p.graph_runner][INFO] - Test, Round 462 : loss => 1.8077123054206372,  accuracy: 0.4294
[2025-09-15 12:35:22,507][flp2p.graph_runner][INFO] - Train, Round 463 : loss => 0.7035494489595294,  accuracy: 0.75512, gradient_norm : 4.374516415810931
[2025-09-15 12:35:32,932][flp2p.graph_runner][INFO] - Test, Round 463 : loss => 1.8501837555348872,  accuracy: 0.4327
[2025-09-15 12:35:42,831][flp2p.graph_runner][INFO] - Train, Round 464 : loss => 0.719344478994608,  accuracy: 0.7435, gradient_norm : 4.5289776703089215
[2025-09-15 12:35:53,332][flp2p.graph_runner][INFO] - Test, Round 464 : loss => 2.095566625481844,  accuracy: 0.388
[2025-09-15 12:36:03,194][flp2p.graph_runner][INFO] - Train, Round 465 : loss => 0.7369914047047496,  accuracy: 0.73246, gradient_norm : 4.897658941781789
[2025-09-15 12:36:13,576][flp2p.graph_runner][INFO] - Test, Round 465 : loss => 2.186887659829855,  accuracy: 0.4056
[2025-09-15 12:36:23,377][flp2p.graph_runner][INFO] - Train, Round 466 : loss => 0.8265925377607346,  accuracy: 0.699, gradient_norm : 5.524965276991669
[2025-09-15 12:36:33,926][flp2p.graph_runner][INFO] - Test, Round 466 : loss => 2.5651561062097548,  accuracy: 0.3351
[2025-09-15 12:36:43,738][flp2p.graph_runner][INFO] - Train, Round 467 : loss => 0.9009183630347252,  accuracy: 0.68238, gradient_norm : 5.708278188650249
[2025-09-15 12:36:54,180][flp2p.graph_runner][INFO] - Test, Round 467 : loss => 2.6646142159104347,  accuracy: 0.3575
[2025-09-15 12:37:04,059][flp2p.graph_runner][INFO] - Train, Round 468 : loss => 0.8601166955381632,  accuracy: 0.68558, gradient_norm : 5.375384119460643
[2025-09-15 12:37:14,650][flp2p.graph_runner][INFO] - Test, Round 468 : loss => 2.3705873293221,  accuracy: 0.3336
[2025-09-15 12:37:24,522][flp2p.graph_runner][INFO] - Train, Round 469 : loss => 0.7564484487101436,  accuracy: 0.71584, gradient_norm : 4.844981143754005
[2025-09-15 12:37:35,076][flp2p.graph_runner][INFO] - Test, Round 469 : loss => 2.215431857776642,  accuracy: 0.396
[2025-09-15 12:37:45,011][flp2p.graph_runner][INFO] - Train, Round 470 : loss => 0.7382466587051749,  accuracy: 0.7225, gradient_norm : 4.77155465326197
[2025-09-15 12:37:55,477][flp2p.graph_runner][INFO] - Test, Round 470 : loss => 1.9161706769406794,  accuracy: 0.3947
[2025-09-15 12:38:05,396][flp2p.graph_runner][INFO] - Train, Round 471 : loss => 0.7415034626051784,  accuracy: 0.73072, gradient_norm : 4.841727066527395
[2025-09-15 12:38:15,865][flp2p.graph_runner][INFO] - Test, Round 471 : loss => 2.2479968154609202,  accuracy: 0.3994
[2025-09-15 12:38:25,788][flp2p.graph_runner][INFO] - Train, Round 472 : loss => 0.7727363808825612,  accuracy: 0.71108, gradient_norm : 4.903001503175995
[2025-09-15 12:38:36,361][flp2p.graph_runner][INFO] - Test, Round 472 : loss => 2.048021964073181,  accuracy: 0.3884
[2025-09-15 12:38:46,311][flp2p.graph_runner][INFO] - Train, Round 473 : loss => 0.7569252176955342,  accuracy: 0.73054, gradient_norm : 4.93228965194113
[2025-09-15 12:38:56,699][flp2p.graph_runner][INFO] - Test, Round 473 : loss => 2.3590467806100843,  accuracy: 0.384
[2025-09-15 12:39:06,554][flp2p.graph_runner][INFO] - Train, Round 474 : loss => 0.7407175806537271,  accuracy: 0.72482, gradient_norm : 4.738743556793908
[2025-09-15 12:39:17,045][flp2p.graph_runner][INFO] - Test, Round 474 : loss => 2.0466256221711636,  accuracy: 0.3993
[2025-09-15 12:39:26,868][flp2p.graph_runner][INFO] - Train, Round 475 : loss => 0.7325322623178363,  accuracy: 0.74068, gradient_norm : 4.8892690037503765
[2025-09-15 12:39:37,281][flp2p.graph_runner][INFO] - Test, Round 475 : loss => 2.053742309355736,  accuracy: 0.4217
[2025-09-15 12:39:47,188][flp2p.graph_runner][INFO] - Train, Round 476 : loss => 0.7875210421904921,  accuracy: 0.70656, gradient_norm : 5.05892320471446
[2025-09-15 12:39:57,789][flp2p.graph_runner][INFO] - Test, Round 476 : loss => 2.1679451128780842,  accuracy: 0.3787
[2025-09-15 12:40:07,661][flp2p.graph_runner][INFO] - Train, Round 477 : loss => 0.7782242821156978,  accuracy: 0.72772, gradient_norm : 5.196212509689303
[2025-09-15 12:40:17,996][flp2p.graph_runner][INFO] - Test, Round 477 : loss => 2.7370985063254833,  accuracy: 0.3404
[2025-09-15 12:40:27,932][flp2p.graph_runner][INFO] - Train, Round 478 : loss => 0.8187357704341411,  accuracy: 0.70028, gradient_norm : 5.474029333352414
[2025-09-15 12:40:38,480][flp2p.graph_runner][INFO] - Test, Round 478 : loss => 2.751715737360716,  accuracy: 0.3194
[2025-09-15 12:40:48,354][flp2p.graph_runner][INFO] - Train, Round 479 : loss => 0.8277722126990557,  accuracy: 0.70422, gradient_norm : 5.974615414530104
[2025-09-15 12:40:58,913][flp2p.graph_runner][INFO] - Test, Round 479 : loss => 4.814827043223381,  accuracy: 0.2289
[2025-09-15 12:41:08,846][flp2p.graph_runner][INFO] - Train, Round 480 : loss => 1.0442511364072562,  accuracy: 0.62658, gradient_norm : 6.7776046573346695
[2025-09-15 12:41:19,440][flp2p.graph_runner][INFO] - Test, Round 480 : loss => 3.8372697923898698,  accuracy: 0.2606
[2025-09-15 12:41:29,303][flp2p.graph_runner][INFO] - Train, Round 481 : loss => 1.2339400016516446,  accuracy: 0.58612, gradient_norm : 7.392186222172824
[2025-09-15 12:41:39,734][flp2p.graph_runner][INFO] - Test, Round 481 : loss => 4.965855644452572,  accuracy: 0.2155
[2025-09-15 12:41:49,505][flp2p.graph_runner][INFO] - Train, Round 482 : loss => 1.227451912984252,  accuracy: 0.57708, gradient_norm : 6.790019472072973
[2025-09-15 12:42:00,003][flp2p.graph_runner][INFO] - Test, Round 482 : loss => 2.2383069323420526,  accuracy: 0.3711
[2025-09-15 12:42:09,939][flp2p.graph_runner][INFO] - Train, Round 483 : loss => 1.017384607195854,  accuracy: 0.65674, gradient_norm : 5.513793401452107
[2025-09-15 12:42:20,328][flp2p.graph_runner][INFO] - Test, Round 483 : loss => 1.9444959195017815,  accuracy: 0.4021
[2025-09-15 12:42:30,155][flp2p.graph_runner][INFO] - Train, Round 484 : loss => 0.7227277403697372,  accuracy: 0.75344, gradient_norm : 4.1075509411547815
[2025-09-15 12:42:40,971][flp2p.graph_runner][INFO] - Test, Round 484 : loss => 1.7205600685894489,  accuracy: 0.44
[2025-09-15 12:42:50,759][flp2p.graph_runner][INFO] - Train, Round 485 : loss => 0.6471777494996787,  accuracy: 0.7877, gradient_norm : 3.877492418463589
[2025-09-15 12:43:01,135][flp2p.graph_runner][INFO] - Test, Round 485 : loss => 1.8223558825075625,  accuracy: 0.4317
[2025-09-15 12:43:11,016][flp2p.graph_runner][INFO] - Train, Round 486 : loss => 0.6322126356512308,  accuracy: 0.78736, gradient_norm : 4.1006883268710945
[2025-09-15 12:43:21,564][flp2p.graph_runner][INFO] - Test, Round 486 : loss => 1.8503529118239879,  accuracy: 0.4325
[2025-09-15 12:43:31,415][flp2p.graph_runner][INFO] - Train, Round 487 : loss => 0.6600785661488772,  accuracy: 0.76906, gradient_norm : 4.3587007201236085
[2025-09-15 12:43:41,971][flp2p.graph_runner][INFO] - Test, Round 487 : loss => 2.035648128050566,  accuracy: 0.4022
[2025-09-15 12:43:51,819][flp2p.graph_runner][INFO] - Train, Round 488 : loss => 0.6830827413499355,  accuracy: 0.76042, gradient_norm : 4.568271096997159
[2025-09-15 12:44:02,382][flp2p.graph_runner][INFO] - Test, Round 488 : loss => 2.1711770555078984,  accuracy: 0.3914
[2025-09-15 12:44:12,210][flp2p.graph_runner][INFO] - Train, Round 489 : loss => 0.6954618622735143,  accuracy: 0.75652, gradient_norm : 4.846891207371932
[2025-09-15 12:44:22,621][flp2p.graph_runner][INFO] - Test, Round 489 : loss => 2.32438636597991,  accuracy: 0.3691
[2025-09-15 12:44:32,488][flp2p.graph_runner][INFO] - Train, Round 490 : loss => 0.7492006720602512,  accuracy: 0.7293, gradient_norm : 5.145171625763441
[2025-09-15 12:44:43,106][flp2p.graph_runner][INFO] - Test, Round 490 : loss => 2.4221015942394732,  accuracy: 0.3708
[2025-09-15 12:44:53,036][flp2p.graph_runner][INFO] - Train, Round 491 : loss => 0.7907066994532943,  accuracy: 0.72872, gradient_norm : 5.296537289643838
[2025-09-15 12:45:03,558][flp2p.graph_runner][INFO] - Test, Round 491 : loss => 2.4193780818760393,  accuracy: 0.3493
[2025-09-15 12:45:13,353][flp2p.graph_runner][INFO] - Train, Round 492 : loss => 0.7127301916107536,  accuracy: 0.74386, gradient_norm : 4.942887531492994
[2025-09-15 12:45:23,928][flp2p.graph_runner][INFO] - Test, Round 492 : loss => 2.4292963988006115,  accuracy: 0.3651
[2025-09-15 12:45:33,839][flp2p.graph_runner][INFO] - Train, Round 493 : loss => 0.7331269500777126,  accuracy: 0.74734, gradient_norm : 4.913109943881155
[2025-09-15 12:45:44,237][flp2p.graph_runner][INFO] - Test, Round 493 : loss => 2.103858446115255,  accuracy: 0.3985
[2025-09-15 12:45:53,973][flp2p.graph_runner][INFO] - Train, Round 494 : loss => 0.689256588332355,  accuracy: 0.7644, gradient_norm : 4.8553901904443055
[2025-09-15 12:46:04,659][flp2p.graph_runner][INFO] - Test, Round 494 : loss => 2.8516706498503686,  accuracy: 0.3287
[2025-09-15 12:46:14,410][flp2p.graph_runner][INFO] - Train, Round 495 : loss => 0.7258316988497973,  accuracy: 0.7354, gradient_norm : 5.094780207005299
[2025-09-15 12:46:24,769][flp2p.graph_runner][INFO] - Test, Round 495 : loss => 2.329133765339851,  accuracy: 0.3683
[2025-09-15 12:46:34,580][flp2p.graph_runner][INFO] - Train, Round 496 : loss => 0.7762283154949546,  accuracy: 0.71626, gradient_norm : 5.48819645349893
[2025-09-15 12:46:45,131][flp2p.graph_runner][INFO] - Test, Round 496 : loss => 2.609496855521202,  accuracy: 0.3539
[2025-09-15 12:46:55,010][flp2p.graph_runner][INFO] - Train, Round 497 : loss => 0.8449434775859117,  accuracy: 0.68332, gradient_norm : 5.518716292311069
[2025-09-15 12:47:05,429][flp2p.graph_runner][INFO] - Test, Round 497 : loss => 2.129828865760565,  accuracy: 0.3877
[2025-09-15 12:47:15,322][flp2p.graph_runner][INFO] - Train, Round 498 : loss => 0.7498907669261098,  accuracy: 0.73292, gradient_norm : 4.927411152638257
[2025-09-15 12:47:25,913][flp2p.graph_runner][INFO] - Test, Round 498 : loss => 1.9241075711786746,  accuracy: 0.4222
[2025-09-15 12:47:35,711][flp2p.graph_runner][INFO] - Train, Round 499 : loss => 0.6501141566038132,  accuracy: 0.77312, gradient_norm : 4.37101003390123
[2025-09-15 12:47:46,143][flp2p.graph_runner][INFO] - Test, Round 499 : loss => 1.7513839244067668,  accuracy: 0.4467
[2025-09-15 12:47:46,148][__main__][INFO] - Train, Round 001: loss=2.3098, accuracy=0.1049, gradient_norm=0.7361, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 002: loss=2.3032, accuracy=0.1092, gradient_norm=0.7083, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 003: loss=2.2974, accuracy=0.1145, gradient_norm=0.7032, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 004: loss=2.2926, accuracy=0.1239, gradient_norm=0.6925, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 005: loss=2.2884, accuracy=0.1310, gradient_norm=0.7104, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 006: loss=2.2838, accuracy=0.1386, gradient_norm=0.7003, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 007: loss=2.2793, accuracy=0.1486, gradient_norm=0.7085, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 008: loss=2.2746, accuracy=0.1577, gradient_norm=0.7270, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 009: loss=2.2697, accuracy=0.1709, gradient_norm=0.7238, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 010: loss=2.2644, accuracy=0.1815, gradient_norm=0.7424, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 011: loss=2.2589, accuracy=0.1891, gradient_norm=0.7562, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 012: loss=2.2528, accuracy=0.1980, gradient_norm=0.7652, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 013: loss=2.2460, accuracy=0.2075, gradient_norm=0.7972, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 014: loss=2.2386, accuracy=0.2164, gradient_norm=0.8018, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 015: loss=2.2306, accuracy=0.2267, gradient_norm=0.8317, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 016: loss=2.2213, accuracy=0.2375, gradient_norm=0.8617, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 017: loss=2.2109, accuracy=0.2475, gradient_norm=0.8899, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 018: loss=2.1994, accuracy=0.2579, gradient_norm=0.9291, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 019: loss=2.1877, accuracy=0.2640, gradient_norm=0.9529, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 020: loss=2.1750, accuracy=0.2692, gradient_norm=1.0157, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 021: loss=2.1610, accuracy=0.2729, gradient_norm=1.0266, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 022: loss=2.1459, accuracy=0.2729, gradient_norm=1.0729, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 023: loss=2.1308, accuracy=0.2779, gradient_norm=1.1184, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 024: loss=2.1152, accuracy=0.2757, gradient_norm=1.1831, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 025: loss=2.1007, accuracy=0.2800, gradient_norm=1.3008, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 026: loss=2.1026, accuracy=0.2624, gradient_norm=1.6331, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 027: loss=2.1158, accuracy=0.2566, gradient_norm=1.6179, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 028: loss=2.0891, accuracy=0.2707, gradient_norm=1.2658, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 029: loss=2.0542, accuracy=0.2817, gradient_norm=1.3359, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 030: loss=2.0303, accuracy=0.2909, gradient_norm=1.4514, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 031: loss=2.0146, accuracy=0.2915, gradient_norm=1.5456, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 032: loss=2.0412, accuracy=0.2706, gradient_norm=1.8639, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 033: loss=2.0550, accuracy=0.2665, gradient_norm=2.0179, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 034: loss=2.0033, accuracy=0.2893, gradient_norm=1.5694, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 035: loss=1.9771, accuracy=0.2977, gradient_norm=1.9289, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 036: loss=2.0020, accuracy=0.2981, gradient_norm=1.6688, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 037: loss=1.9612, accuracy=0.2992, gradient_norm=1.6505, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 038: loss=1.9267, accuracy=0.3109, gradient_norm=1.7681, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 039: loss=1.9248, accuracy=0.3060, gradient_norm=2.3774, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 040: loss=1.9851, accuracy=0.2964, gradient_norm=2.1369, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 041: loss=1.9407, accuracy=0.3061, gradient_norm=1.8100, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 042: loss=1.9031, accuracy=0.3202, gradient_norm=1.7170, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 043: loss=1.8786, accuracy=0.3292, gradient_norm=1.9161, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 044: loss=1.8484, accuracy=0.3320, gradient_norm=1.9879, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 045: loss=1.8272, accuracy=0.3444, gradient_norm=2.2158, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 046: loss=1.8163, accuracy=0.3438, gradient_norm=2.2623, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 047: loss=1.8902, accuracy=0.3091, gradient_norm=3.1206, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 048: loss=2.1130, accuracy=0.2447, gradient_norm=4.2529, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 049: loss=1.9549, accuracy=0.2930, gradient_norm=1.9629, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 050: loss=1.8865, accuracy=0.3288, gradient_norm=2.0303, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 051: loss=1.8495, accuracy=0.3311, gradient_norm=2.1360, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 052: loss=1.8116, accuracy=0.3519, gradient_norm=2.1489, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 053: loss=1.8192, accuracy=0.3334, gradient_norm=2.5823, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 054: loss=1.8702, accuracy=0.3295, gradient_norm=2.6298, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 055: loss=1.8129, accuracy=0.3427, gradient_norm=2.2860, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 056: loss=1.7906, accuracy=0.3485, gradient_norm=2.1323, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 057: loss=1.7695, accuracy=0.3500, gradient_norm=2.6656, 
[2025-09-15 12:47:46,149][__main__][INFO] - Train, Round 058: loss=1.8139, accuracy=0.3428, gradient_norm=2.3539, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 059: loss=1.7400, accuracy=0.3643, gradient_norm=2.3721, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 060: loss=1.7236, accuracy=0.3764, gradient_norm=2.3295, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 061: loss=1.7371, accuracy=0.3638, gradient_norm=2.9088, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 062: loss=1.8849, accuracy=0.3225, gradient_norm=4.0032, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 063: loss=1.8863, accuracy=0.3188, gradient_norm=2.5615, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 064: loss=1.8369, accuracy=0.3282, gradient_norm=2.5170, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 065: loss=1.8395, accuracy=0.3285, gradient_norm=2.8715, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 066: loss=1.8764, accuracy=0.3186, gradient_norm=2.8304, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 067: loss=1.8199, accuracy=0.3412, gradient_norm=2.7772, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 068: loss=1.7844, accuracy=0.3488, gradient_norm=2.6315, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 069: loss=1.7406, accuracy=0.3629, gradient_norm=2.5018, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 070: loss=1.7119, accuracy=0.3804, gradient_norm=2.5281, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 071: loss=1.6980, accuracy=0.3754, gradient_norm=2.4877, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 072: loss=1.6957, accuracy=0.3839, gradient_norm=2.6604, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 073: loss=1.6978, accuracy=0.3702, gradient_norm=2.5811, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 074: loss=1.6925, accuracy=0.3862, gradient_norm=2.8560, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 075: loss=1.7275, accuracy=0.3691, gradient_norm=2.9020, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 076: loss=1.6993, accuracy=0.3857, gradient_norm=2.5836, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 077: loss=1.6674, accuracy=0.3897, gradient_norm=2.5741, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 078: loss=1.6438, accuracy=0.4012, gradient_norm=2.4999, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 079: loss=1.6254, accuracy=0.4010, gradient_norm=2.4343, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 080: loss=1.6257, accuracy=0.4038, gradient_norm=2.6835, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 081: loss=1.6333, accuracy=0.3983, gradient_norm=2.5236, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 082: loss=1.6065, accuracy=0.4131, gradient_norm=2.5182, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 083: loss=1.6001, accuracy=0.4114, gradient_norm=2.5447, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 084: loss=1.6079, accuracy=0.4114, gradient_norm=2.8101, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 085: loss=1.6386, accuracy=0.3965, gradient_norm=2.8104, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 086: loss=1.6183, accuracy=0.4075, gradient_norm=2.7017, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 087: loss=1.6136, accuracy=0.4043, gradient_norm=2.8181, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 088: loss=1.6170, accuracy=0.4040, gradient_norm=3.0293, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 089: loss=1.6329, accuracy=0.3981, gradient_norm=3.1995, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 090: loss=1.6665, accuracy=0.3909, gradient_norm=3.2470, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 091: loss=1.6664, accuracy=0.3850, gradient_norm=3.0011, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 092: loss=1.6516, accuracy=0.3908, gradient_norm=3.0276, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 093: loss=1.6640, accuracy=0.3819, gradient_norm=3.7082, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 094: loss=1.7501, accuracy=0.3641, gradient_norm=3.2490, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 095: loss=1.6414, accuracy=0.4020, gradient_norm=3.0748, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 096: loss=1.6086, accuracy=0.4127, gradient_norm=2.8760, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 097: loss=1.5944, accuracy=0.4098, gradient_norm=2.9698, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 098: loss=1.6051, accuracy=0.4064, gradient_norm=2.9573, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 099: loss=1.5817, accuracy=0.4170, gradient_norm=2.8617, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 100: loss=1.5773, accuracy=0.4218, gradient_norm=2.8999, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 101: loss=1.5725, accuracy=0.4221, gradient_norm=2.8550, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 102: loss=1.5533, accuracy=0.4284, gradient_norm=2.7806, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 103: loss=1.5351, accuracy=0.4367, gradient_norm=2.8062, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 104: loss=1.5228, accuracy=0.4420, gradient_norm=2.8132, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 105: loss=1.5387, accuracy=0.4338, gradient_norm=2.9993, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 106: loss=1.5715, accuracy=0.4226, gradient_norm=3.1660, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 107: loss=1.5614, accuracy=0.4223, gradient_norm=2.9049, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 108: loss=1.5387, accuracy=0.4301, gradient_norm=2.8807, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 109: loss=1.5237, accuracy=0.4410, gradient_norm=2.9352, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 110: loss=1.5420, accuracy=0.4321, gradient_norm=3.0783, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 111: loss=1.5470, accuracy=0.4320, gradient_norm=3.2561, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 112: loss=1.5971, accuracy=0.4078, gradient_norm=3.4269, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 113: loss=1.6166, accuracy=0.4155, gradient_norm=3.7798, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 114: loss=1.6604, accuracy=0.3952, gradient_norm=3.4884, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 115: loss=1.5729, accuracy=0.4277, gradient_norm=3.3954, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 116: loss=1.5841, accuracy=0.4097, gradient_norm=3.6611, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 117: loss=1.6346, accuracy=0.4073, gradient_norm=3.5743, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 118: loss=1.6092, accuracy=0.4015, gradient_norm=3.5419, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 119: loss=1.6064, accuracy=0.4157, gradient_norm=3.4788, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 120: loss=1.6123, accuracy=0.4065, gradient_norm=3.5214, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 121: loss=1.6009, accuracy=0.4116, gradient_norm=3.0500, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 122: loss=1.5228, accuracy=0.4383, gradient_norm=2.8061, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 123: loss=1.4822, accuracy=0.4550, gradient_norm=2.6820, 
[2025-09-15 12:47:46,150][__main__][INFO] - Train, Round 124: loss=1.4867, accuracy=0.4528, gradient_norm=2.9653, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 125: loss=1.5060, accuracy=0.4458, gradient_norm=3.1239, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 126: loss=1.5371, accuracy=0.4357, gradient_norm=3.2558, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 127: loss=1.5344, accuracy=0.4305, gradient_norm=2.9840, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 128: loss=1.4940, accuracy=0.4425, gradient_norm=3.0062, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 129: loss=1.4960, accuracy=0.4466, gradient_norm=3.0715, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 130: loss=1.5015, accuracy=0.4363, gradient_norm=3.1527, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 131: loss=1.4945, accuracy=0.4414, gradient_norm=3.2522, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 132: loss=1.5318, accuracy=0.4249, gradient_norm=3.4730, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 133: loss=1.5274, accuracy=0.4245, gradient_norm=3.1410, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 134: loss=1.4777, accuracy=0.4468, gradient_norm=2.9987, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 135: loss=1.4646, accuracy=0.4599, gradient_norm=3.0719, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 136: loss=1.4643, accuracy=0.4504, gradient_norm=3.2206, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 137: loss=1.4969, accuracy=0.4413, gradient_norm=3.3343, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 138: loss=1.4959, accuracy=0.4367, gradient_norm=3.3963, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 139: loss=1.5014, accuracy=0.4432, gradient_norm=3.1247, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 140: loss=1.4483, accuracy=0.4567, gradient_norm=3.0489, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 141: loss=1.4416, accuracy=0.4605, gradient_norm=3.0320, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 142: loss=1.4341, accuracy=0.4613, gradient_norm=3.1769, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 143: loss=1.4577, accuracy=0.4526, gradient_norm=3.1827, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 144: loss=1.4467, accuracy=0.4635, gradient_norm=3.3405, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 145: loss=1.4853, accuracy=0.4529, gradient_norm=3.2860, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 146: loss=1.4463, accuracy=0.4651, gradient_norm=3.2702, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 147: loss=1.4425, accuracy=0.4736, gradient_norm=3.2651, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 148: loss=1.4757, accuracy=0.4639, gradient_norm=3.6684, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 149: loss=1.5465, accuracy=0.4368, gradient_norm=3.7976, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 150: loss=1.5103, accuracy=0.4498, gradient_norm=3.7283, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 151: loss=1.5043, accuracy=0.4556, gradient_norm=3.7041, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 152: loss=1.4778, accuracy=0.4665, gradient_norm=3.6501, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 153: loss=1.4725, accuracy=0.4638, gradient_norm=3.3390, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 154: loss=1.4472, accuracy=0.4769, gradient_norm=3.4707, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 155: loss=1.4789, accuracy=0.4656, gradient_norm=3.4208, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 156: loss=1.4509, accuracy=0.4745, gradient_norm=3.1924, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 157: loss=1.3840, accuracy=0.4933, gradient_norm=3.0896, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 158: loss=1.3977, accuracy=0.4942, gradient_norm=3.1906, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 159: loss=1.4050, accuracy=0.4890, gradient_norm=3.4000, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 160: loss=1.4204, accuracy=0.4797, gradient_norm=3.4794, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 161: loss=1.4334, accuracy=0.4705, gradient_norm=3.4784, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 162: loss=1.4487, accuracy=0.4676, gradient_norm=3.6703, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 163: loss=1.4799, accuracy=0.4527, gradient_norm=3.8288, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 164: loss=1.5179, accuracy=0.4447, gradient_norm=3.8988, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 165: loss=1.4848, accuracy=0.4506, gradient_norm=3.7929, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 166: loss=1.4941, accuracy=0.4565, gradient_norm=3.6195, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 167: loss=1.4063, accuracy=0.4853, gradient_norm=3.2576, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 168: loss=1.3781, accuracy=0.4983, gradient_norm=3.1438, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 169: loss=1.3617, accuracy=0.5075, gradient_norm=3.1411, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 170: loss=1.3578, accuracy=0.5060, gradient_norm=3.1097, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 171: loss=1.3506, accuracy=0.5107, gradient_norm=3.3527, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 172: loss=1.3859, accuracy=0.4894, gradient_norm=3.2560, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 173: loss=1.3568, accuracy=0.4974, gradient_norm=3.3925, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 174: loss=1.3805, accuracy=0.4901, gradient_norm=3.5289, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 175: loss=1.3914, accuracy=0.4774, gradient_norm=3.6516, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 176: loss=1.4211, accuracy=0.4761, gradient_norm=3.6966, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 177: loss=1.4050, accuracy=0.4789, gradient_norm=3.7993, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 178: loss=1.4259, accuracy=0.4755, gradient_norm=3.6761, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 179: loss=1.3769, accuracy=0.4897, gradient_norm=3.5897, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 180: loss=1.3985, accuracy=0.4871, gradient_norm=3.6193, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 181: loss=1.4274, accuracy=0.4802, gradient_norm=4.0582, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 182: loss=1.5098, accuracy=0.4477, gradient_norm=3.9476, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 183: loss=1.4280, accuracy=0.4787, gradient_norm=3.5579, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 184: loss=1.4030, accuracy=0.4883, gradient_norm=3.7145, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 185: loss=1.4455, accuracy=0.4734, gradient_norm=3.8584, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 186: loss=1.4114, accuracy=0.4901, gradient_norm=3.6626, 
[2025-09-15 12:47:46,151][__main__][INFO] - Train, Round 187: loss=1.3739, accuracy=0.4998, gradient_norm=3.5401, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 188: loss=1.3638, accuracy=0.5073, gradient_norm=3.4815, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 189: loss=1.3620, accuracy=0.5030, gradient_norm=3.4875, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 190: loss=1.3450, accuracy=0.5090, gradient_norm=3.5157, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 191: loss=1.3623, accuracy=0.4950, gradient_norm=3.6069, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 192: loss=1.3384, accuracy=0.5074, gradient_norm=3.6396, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 193: loss=1.3590, accuracy=0.4946, gradient_norm=3.6438, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 194: loss=1.3314, accuracy=0.5109, gradient_norm=3.5582, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 195: loss=1.3502, accuracy=0.5056, gradient_norm=3.5951, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 196: loss=1.3473, accuracy=0.5057, gradient_norm=3.8010, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 197: loss=1.3783, accuracy=0.4875, gradient_norm=3.7396, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 198: loss=1.3672, accuracy=0.5055, gradient_norm=3.8391, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 199: loss=1.3640, accuracy=0.4926, gradient_norm=3.6933, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 200: loss=1.3546, accuracy=0.5040, gradient_norm=3.8075, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 201: loss=1.3719, accuracy=0.4943, gradient_norm=3.7827, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 202: loss=1.3793, accuracy=0.4900, gradient_norm=4.0768, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 203: loss=1.3991, accuracy=0.4823, gradient_norm=3.6580, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 204: loss=1.2820, accuracy=0.5330, gradient_norm=3.4607, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 205: loss=1.2822, accuracy=0.5284, gradient_norm=3.4378, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 206: loss=1.3024, accuracy=0.5157, gradient_norm=3.8602, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 207: loss=1.4055, accuracy=0.4738, gradient_norm=4.0835, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 208: loss=1.3693, accuracy=0.4876, gradient_norm=3.9155, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 209: loss=1.3299, accuracy=0.5084, gradient_norm=3.6648, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 210: loss=1.2864, accuracy=0.5184, gradient_norm=3.5617, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 211: loss=1.3057, accuracy=0.5173, gradient_norm=3.7194, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 212: loss=1.2908, accuracy=0.5145, gradient_norm=3.6796, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 213: loss=1.3008, accuracy=0.5201, gradient_norm=3.7520, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 214: loss=1.2711, accuracy=0.5294, gradient_norm=3.6122, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 215: loss=1.2755, accuracy=0.5355, gradient_norm=3.6134, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 216: loss=1.2614, accuracy=0.5359, gradient_norm=3.6716, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 217: loss=1.2984, accuracy=0.5273, gradient_norm=3.8766, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 218: loss=1.3213, accuracy=0.5172, gradient_norm=4.3096, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 219: loss=1.4452, accuracy=0.4815, gradient_norm=4.1773, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 220: loss=1.3144, accuracy=0.5224, gradient_norm=3.9175, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 221: loss=1.3421, accuracy=0.5167, gradient_norm=4.2563, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 222: loss=1.3720, accuracy=0.4850, gradient_norm=4.0895, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 223: loss=1.3582, accuracy=0.5038, gradient_norm=3.9354, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 224: loss=1.2856, accuracy=0.5285, gradient_norm=3.8773, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 225: loss=1.2961, accuracy=0.5241, gradient_norm=3.7535, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 226: loss=1.2747, accuracy=0.5262, gradient_norm=3.7246, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 227: loss=1.2631, accuracy=0.5320, gradient_norm=3.5927, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 228: loss=1.2499, accuracy=0.5343, gradient_norm=3.7142, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 229: loss=1.2513, accuracy=0.5343, gradient_norm=3.6519, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 230: loss=1.2356, accuracy=0.5398, gradient_norm=3.7833, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 231: loss=1.2575, accuracy=0.5313, gradient_norm=3.5893, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 232: loss=1.2170, accuracy=0.5523, gradient_norm=3.6152, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 233: loss=1.2147, accuracy=0.5564, gradient_norm=3.5807, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 234: loss=1.2398, accuracy=0.5493, gradient_norm=3.9564, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 235: loss=1.3145, accuracy=0.5259, gradient_norm=4.3201, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 236: loss=1.3647, accuracy=0.5126, gradient_norm=4.5474, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 237: loss=1.4080, accuracy=0.4913, gradient_norm=4.6409, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 238: loss=1.3656, accuracy=0.5093, gradient_norm=4.4207, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 239: loss=1.3321, accuracy=0.5244, gradient_norm=4.1764, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 240: loss=1.2934, accuracy=0.5340, gradient_norm=3.8379, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 241: loss=1.2271, accuracy=0.5593, gradient_norm=3.5686, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 242: loss=1.1616, accuracy=0.5855, gradient_norm=3.3695, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 243: loss=1.1634, accuracy=0.5813, gradient_norm=3.5369, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 244: loss=1.1918, accuracy=0.5673, gradient_norm=3.8354, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 245: loss=1.2476, accuracy=0.5327, gradient_norm=4.1769, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 246: loss=1.2993, accuracy=0.5234, gradient_norm=4.1886, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 247: loss=1.2519, accuracy=0.5316, gradient_norm=4.1746, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 248: loss=1.2821, accuracy=0.5372, gradient_norm=4.2618, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 249: loss=1.2607, accuracy=0.5402, gradient_norm=4.1355, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 250: loss=1.2373, accuracy=0.5591, gradient_norm=3.8870, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 251: loss=1.2039, accuracy=0.5659, gradient_norm=3.9447, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 252: loss=1.2082, accuracy=0.5597, gradient_norm=3.9988, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 253: loss=1.2152, accuracy=0.5507, gradient_norm=3.9227, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 254: loss=1.1882, accuracy=0.5618, gradient_norm=4.1580, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 255: loss=1.2893, accuracy=0.5143, gradient_norm=4.2084, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 256: loss=1.2340, accuracy=0.5372, gradient_norm=4.2248, 
[2025-09-15 12:47:46,152][__main__][INFO] - Train, Round 257: loss=1.2697, accuracy=0.5196, gradient_norm=4.0071, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 258: loss=1.2197, accuracy=0.5468, gradient_norm=3.9726, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 259: loss=1.1962, accuracy=0.5575, gradient_norm=3.9498, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 260: loss=1.2318, accuracy=0.5529, gradient_norm=4.1515, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 261: loss=1.2496, accuracy=0.5343, gradient_norm=4.6225, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 262: loss=1.3870, accuracy=0.4995, gradient_norm=4.2896, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 263: loss=1.1901, accuracy=0.5702, gradient_norm=3.7316, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 264: loss=1.1384, accuracy=0.6008, gradient_norm=3.5128, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 265: loss=1.1197, accuracy=0.6033, gradient_norm=3.6110, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 266: loss=1.1344, accuracy=0.5994, gradient_norm=3.6928, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 267: loss=1.1588, accuracy=0.5797, gradient_norm=4.0898, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 268: loss=1.2163, accuracy=0.5616, gradient_norm=4.3794, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 269: loss=1.2710, accuracy=0.5446, gradient_norm=4.5071, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 270: loss=1.2322, accuracy=0.5558, gradient_norm=4.5566, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 271: loss=1.3032, accuracy=0.5340, gradient_norm=4.5274, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 272: loss=1.2317, accuracy=0.5559, gradient_norm=4.7500, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 273: loss=1.3336, accuracy=0.5219, gradient_norm=4.2560, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 274: loss=1.2149, accuracy=0.5677, gradient_norm=4.1375, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 275: loss=1.2299, accuracy=0.5528, gradient_norm=4.3045, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 276: loss=1.2803, accuracy=0.5355, gradient_norm=4.8084, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 277: loss=1.3161, accuracy=0.5099, gradient_norm=4.8163, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 278: loss=1.3296, accuracy=0.5241, gradient_norm=4.5118, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 279: loss=1.1762, accuracy=0.5709, gradient_norm=3.9646, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 280: loss=1.1667, accuracy=0.5869, gradient_norm=3.9662, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 281: loss=1.1697, accuracy=0.5848, gradient_norm=4.2059, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 282: loss=1.1990, accuracy=0.5718, gradient_norm=3.8963, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 283: loss=1.1089, accuracy=0.6063, gradient_norm=3.8265, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 284: loss=1.1477, accuracy=0.5808, gradient_norm=4.0199, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 285: loss=1.1862, accuracy=0.5721, gradient_norm=4.3940, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 286: loss=1.2270, accuracy=0.5442, gradient_norm=4.5705, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 287: loss=1.2879, accuracy=0.5394, gradient_norm=4.6207, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 288: loss=1.1652, accuracy=0.5679, gradient_norm=3.9490, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 289: loss=1.1153, accuracy=0.5975, gradient_norm=3.8327, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 290: loss=1.0881, accuracy=0.6076, gradient_norm=3.7899, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 291: loss=1.0975, accuracy=0.6066, gradient_norm=4.0591, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 292: loss=1.1387, accuracy=0.5912, gradient_norm=4.0009, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 293: loss=1.1017, accuracy=0.6098, gradient_norm=3.9200, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 294: loss=1.0803, accuracy=0.6151, gradient_norm=4.1058, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 295: loss=1.1389, accuracy=0.5889, gradient_norm=4.1310, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 296: loss=1.1078, accuracy=0.5978, gradient_norm=4.3914, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 297: loss=1.2083, accuracy=0.5512, gradient_norm=4.5095, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 298: loss=1.1860, accuracy=0.5508, gradient_norm=4.6659, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 299: loss=1.2353, accuracy=0.5325, gradient_norm=4.7947, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 300: loss=1.2511, accuracy=0.5272, gradient_norm=4.8756, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 301: loss=1.2330, accuracy=0.5326, gradient_norm=4.5244, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 302: loss=1.1487, accuracy=0.5659, gradient_norm=4.1155, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 303: loss=1.0938, accuracy=0.6010, gradient_norm=4.0164, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 304: loss=1.0951, accuracy=0.6041, gradient_norm=3.8886, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 305: loss=1.0572, accuracy=0.6231, gradient_norm=4.0621, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 306: loss=1.1074, accuracy=0.5966, gradient_norm=4.0145, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 307: loss=1.0666, accuracy=0.6177, gradient_norm=4.1705, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 308: loss=1.1192, accuracy=0.5959, gradient_norm=4.2535, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 309: loss=1.1192, accuracy=0.5993, gradient_norm=4.7957, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 310: loss=1.2602, accuracy=0.5427, gradient_norm=5.1269, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 311: loss=1.2830, accuracy=0.5534, gradient_norm=5.1394, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 312: loss=1.2322, accuracy=0.5499, gradient_norm=5.2261, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 313: loss=1.3549, accuracy=0.5242, gradient_norm=4.8413, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 314: loss=1.1666, accuracy=0.5908, gradient_norm=4.2320, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 315: loss=1.0539, accuracy=0.6382, gradient_norm=3.6540, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 316: loss=0.9905, accuracy=0.6577, gradient_norm=3.5948, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 317: loss=0.9873, accuracy=0.6561, gradient_norm=3.6051, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 318: loss=0.9852, accuracy=0.6526, gradient_norm=3.9668, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 319: loss=1.0548, accuracy=0.6147, gradient_norm=4.2276, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 320: loss=1.0833, accuracy=0.5978, gradient_norm=4.6178, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 321: loss=1.1700, accuracy=0.5715, gradient_norm=4.5881, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 322: loss=1.1094, accuracy=0.5855, gradient_norm=4.5607, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 323: loss=1.1768, accuracy=0.5609, gradient_norm=4.9434, 
[2025-09-15 12:47:46,153][__main__][INFO] - Train, Round 324: loss=1.2167, accuracy=0.5570, gradient_norm=4.8386, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 325: loss=1.1102, accuracy=0.5879, gradient_norm=4.5424, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 326: loss=1.1080, accuracy=0.6027, gradient_norm=4.1980, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 327: loss=0.9974, accuracy=0.6443, gradient_norm=3.9213, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 328: loss=0.9994, accuracy=0.6489, gradient_norm=3.9474, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 329: loss=1.0153, accuracy=0.6356, gradient_norm=4.4527, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 330: loss=1.1346, accuracy=0.5929, gradient_norm=4.4954, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 331: loss=1.0655, accuracy=0.6131, gradient_norm=4.5075, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 332: loss=1.1061, accuracy=0.6036, gradient_norm=4.6992, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 333: loss=1.1427, accuracy=0.5833, gradient_norm=5.0242, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 334: loss=1.1835, accuracy=0.5696, gradient_norm=4.7700, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 335: loss=1.0530, accuracy=0.6179, gradient_norm=4.1752, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 336: loss=1.0020, accuracy=0.6435, gradient_norm=4.0658, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 337: loss=0.9907, accuracy=0.6442, gradient_norm=4.1187, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 338: loss=1.0110, accuracy=0.6329, gradient_norm=4.4815, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 339: loss=1.0789, accuracy=0.6115, gradient_norm=4.5131, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 340: loss=1.0019, accuracy=0.6349, gradient_norm=4.2895, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 341: loss=1.0208, accuracy=0.6295, gradient_norm=4.5344, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 342: loss=1.0136, accuracy=0.6312, gradient_norm=4.5656, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 343: loss=1.0818, accuracy=0.6158, gradient_norm=4.7273, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 344: loss=1.0264, accuracy=0.6274, gradient_norm=4.3428, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 345: loss=1.0030, accuracy=0.6423, gradient_norm=4.7863, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 346: loss=1.1181, accuracy=0.6032, gradient_norm=4.8194, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 347: loss=1.0638, accuracy=0.6149, gradient_norm=5.0384, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 348: loss=1.1493, accuracy=0.5851, gradient_norm=4.8832, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 349: loss=1.0276, accuracy=0.6349, gradient_norm=4.7328, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 350: loss=1.0939, accuracy=0.6009, gradient_norm=4.7681, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 351: loss=1.0486, accuracy=0.6285, gradient_norm=4.5968, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 352: loss=1.0237, accuracy=0.6172, gradient_norm=4.4397, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 353: loss=1.0170, accuracy=0.6283, gradient_norm=4.5999, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 354: loss=1.0395, accuracy=0.6080, gradient_norm=4.6840, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 355: loss=1.0864, accuracy=0.6026, gradient_norm=4.8647, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 356: loss=1.0854, accuracy=0.5886, gradient_norm=4.9236, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 357: loss=1.1290, accuracy=0.5871, gradient_norm=4.9161, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 358: loss=1.0671, accuracy=0.6043, gradient_norm=4.6595, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 359: loss=1.0236, accuracy=0.6314, gradient_norm=4.6226, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 360: loss=1.0267, accuracy=0.6329, gradient_norm=4.3099, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 361: loss=0.9565, accuracy=0.6640, gradient_norm=4.2950, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 362: loss=1.0067, accuracy=0.6414, gradient_norm=4.5586, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 363: loss=1.0077, accuracy=0.6372, gradient_norm=4.8339, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 364: loss=1.1030, accuracy=0.5989, gradient_norm=5.0808, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 365: loss=1.1252, accuracy=0.5843, gradient_norm=5.1942, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 366: loss=1.1047, accuracy=0.5840, gradient_norm=4.9103, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 367: loss=1.0319, accuracy=0.6234, gradient_norm=4.4099, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 368: loss=0.9049, accuracy=0.6762, gradient_norm=3.9887, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 369: loss=0.8938, accuracy=0.6851, gradient_norm=4.0305, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 370: loss=0.8823, accuracy=0.6842, gradient_norm=3.9181, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 371: loss=0.8696, accuracy=0.6859, gradient_norm=4.1676, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 372: loss=0.9257, accuracy=0.6606, gradient_norm=4.4394, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 373: loss=0.9523, accuracy=0.6404, gradient_norm=4.6696, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 374: loss=1.0133, accuracy=0.6272, gradient_norm=4.8644, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 375: loss=0.9986, accuracy=0.6266, gradient_norm=4.8605, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 376: loss=1.0148, accuracy=0.6281, gradient_norm=4.7942, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 377: loss=0.9523, accuracy=0.6527, gradient_norm=4.4401, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 378: loss=0.9086, accuracy=0.6765, gradient_norm=4.5560, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 379: loss=0.9672, accuracy=0.6498, gradient_norm=4.5472, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 380: loss=0.9199, accuracy=0.6728, gradient_norm=4.4529, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 381: loss=0.8962, accuracy=0.6772, gradient_norm=4.6012, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 382: loss=0.9375, accuracy=0.6605, gradient_norm=4.8300, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 383: loss=1.0583, accuracy=0.6017, gradient_norm=5.6880, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 384: loss=1.2836, accuracy=0.5563, gradient_norm=6.0359, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 385: loss=1.1885, accuracy=0.5626, gradient_norm=5.5300, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 386: loss=1.0839, accuracy=0.6323, gradient_norm=4.7124, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 387: loss=0.8961, accuracy=0.6917, gradient_norm=4.0638, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 388: loss=0.8749, accuracy=0.7039, gradient_norm=4.3453, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 389: loss=0.9648, accuracy=0.6666, gradient_norm=4.7629, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 390: loss=0.9791, accuracy=0.6588, gradient_norm=5.3382, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 391: loss=1.1450, accuracy=0.6091, gradient_norm=5.6602, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 392: loss=1.0896, accuracy=0.6163, gradient_norm=5.4384, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 393: loss=1.0593, accuracy=0.6375, gradient_norm=5.0768, 
[2025-09-15 12:47:46,154][__main__][INFO] - Train, Round 394: loss=0.9660, accuracy=0.6528, gradient_norm=4.4945, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 395: loss=0.8684, accuracy=0.7096, gradient_norm=4.3200, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 396: loss=0.8590, accuracy=0.6963, gradient_norm=4.1551, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 397: loss=0.8432, accuracy=0.7054, gradient_norm=4.5496, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 398: loss=0.9845, accuracy=0.6373, gradient_norm=4.9135, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 399: loss=0.9922, accuracy=0.6390, gradient_norm=5.3116, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 400: loss=1.0522, accuracy=0.6046, gradient_norm=5.2376, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 401: loss=1.0123, accuracy=0.6363, gradient_norm=5.1854, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 402: loss=0.9642, accuracy=0.6391, gradient_norm=4.7083, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 403: loss=0.8767, accuracy=0.6808, gradient_norm=4.4958, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 404: loss=0.8958, accuracy=0.6680, gradient_norm=4.4485, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 405: loss=0.8145, accuracy=0.7054, gradient_norm=4.2250, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 406: loss=0.8482, accuracy=0.6954, gradient_norm=4.4923, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 407: loss=0.8567, accuracy=0.6829, gradient_norm=4.4290, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 408: loss=0.8433, accuracy=0.6977, gradient_norm=4.5935, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 409: loss=0.8454, accuracy=0.6896, gradient_norm=4.6082, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 410: loss=0.9070, accuracy=0.6729, gradient_norm=5.1209, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 411: loss=0.9606, accuracy=0.6454, gradient_norm=5.5096, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 412: loss=1.0842, accuracy=0.6314, gradient_norm=5.7997, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 413: loss=1.0171, accuracy=0.6389, gradient_norm=5.3538, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 414: loss=0.9600, accuracy=0.6538, gradient_norm=5.0457, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 415: loss=0.9382, accuracy=0.6619, gradient_norm=4.7674, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 416: loss=0.8908, accuracy=0.6821, gradient_norm=4.6511, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 417: loss=0.8986, accuracy=0.6789, gradient_norm=4.4483, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 418: loss=0.8019, accuracy=0.7171, gradient_norm=4.2230, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 419: loss=0.8460, accuracy=0.6921, gradient_norm=4.6163, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 420: loss=0.8959, accuracy=0.6699, gradient_norm=4.9334, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 421: loss=0.9355, accuracy=0.6549, gradient_norm=5.3546, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 422: loss=1.0336, accuracy=0.6083, gradient_norm=5.5389, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 423: loss=0.9734, accuracy=0.6275, gradient_norm=5.3293, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 424: loss=0.9499, accuracy=0.6324, gradient_norm=5.1533, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 425: loss=0.8740, accuracy=0.6725, gradient_norm=4.7452, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 426: loss=0.8567, accuracy=0.6856, gradient_norm=4.6237, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 427: loss=0.8461, accuracy=0.6912, gradient_norm=4.9692, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 428: loss=0.9793, accuracy=0.6392, gradient_norm=5.6457, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 429: loss=1.0661, accuracy=0.6102, gradient_norm=6.0894, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 430: loss=1.0670, accuracy=0.6122, gradient_norm=5.6726, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 431: loss=0.9103, accuracy=0.6779, gradient_norm=4.8458, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 432: loss=0.7672, accuracy=0.7383, gradient_norm=4.1715, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 433: loss=0.7401, accuracy=0.7432, gradient_norm=4.1994, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 434: loss=0.7432, accuracy=0.7411, gradient_norm=4.4068, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 435: loss=0.8016, accuracy=0.7057, gradient_norm=4.7316, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 436: loss=0.8308, accuracy=0.6945, gradient_norm=5.0996, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 437: loss=0.9313, accuracy=0.6446, gradient_norm=5.3983, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 438: loss=0.9524, accuracy=0.6481, gradient_norm=5.4410, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 439: loss=0.9245, accuracy=0.6446, gradient_norm=5.3375, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 440: loss=0.9252, accuracy=0.6566, gradient_norm=5.1677, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 441: loss=0.8321, accuracy=0.6893, gradient_norm=4.6989, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 442: loss=0.7938, accuracy=0.7257, gradient_norm=4.6051, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 443: loss=0.7695, accuracy=0.7288, gradient_norm=4.4040, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 444: loss=0.7487, accuracy=0.7410, gradient_norm=4.4275, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 445: loss=0.7373, accuracy=0.7449, gradient_norm=4.3891, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 446: loss=0.7396, accuracy=0.7333, gradient_norm=4.5563, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 447: loss=0.7743, accuracy=0.7221, gradient_norm=4.6800, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 448: loss=0.7846, accuracy=0.7105, gradient_norm=4.8602, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 449: loss=0.8200, accuracy=0.6915, gradient_norm=5.0189, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 450: loss=0.8432, accuracy=0.6849, gradient_norm=5.2233, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 451: loss=0.9179, accuracy=0.6504, gradient_norm=5.4504, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 452: loss=0.8979, accuracy=0.6501, gradient_norm=5.7174, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 453: loss=1.0529, accuracy=0.6174, gradient_norm=6.0200, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 454: loss=1.0163, accuracy=0.6175, gradient_norm=6.1212, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 455: loss=1.0594, accuracy=0.6244, gradient_norm=5.9333, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 456: loss=0.9687, accuracy=0.6529, gradient_norm=5.5062, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 457: loss=0.8499, accuracy=0.6954, gradient_norm=4.8548, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 458: loss=0.7834, accuracy=0.7237, gradient_norm=4.3767, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 459: loss=0.7120, accuracy=0.7555, gradient_norm=4.2068, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 460: loss=0.7282, accuracy=0.7512, gradient_norm=4.4059, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 461: loss=0.7680, accuracy=0.7339, gradient_norm=4.6558, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 462: loss=0.7518, accuracy=0.7372, gradient_norm=4.5083, 
[2025-09-15 12:47:46,155][__main__][INFO] - Train, Round 463: loss=0.7303, accuracy=0.7442, gradient_norm=4.3541, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 464: loss=0.7035, accuracy=0.7551, gradient_norm=4.3745, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 465: loss=0.7193, accuracy=0.7435, gradient_norm=4.5290, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 466: loss=0.7370, accuracy=0.7325, gradient_norm=4.8977, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 467: loss=0.8266, accuracy=0.6990, gradient_norm=5.5250, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 468: loss=0.9009, accuracy=0.6824, gradient_norm=5.7083, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 469: loss=0.8601, accuracy=0.6856, gradient_norm=5.3754, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 470: loss=0.7564, accuracy=0.7158, gradient_norm=4.8450, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 471: loss=0.7382, accuracy=0.7225, gradient_norm=4.7716, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 472: loss=0.7415, accuracy=0.7307, gradient_norm=4.8417, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 473: loss=0.7727, accuracy=0.7111, gradient_norm=4.9030, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 474: loss=0.7569, accuracy=0.7305, gradient_norm=4.9323, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 475: loss=0.7407, accuracy=0.7248, gradient_norm=4.7387, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 476: loss=0.7325, accuracy=0.7407, gradient_norm=4.8893, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 477: loss=0.7875, accuracy=0.7066, gradient_norm=5.0589, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 478: loss=0.7782, accuracy=0.7277, gradient_norm=5.1962, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 479: loss=0.8187, accuracy=0.7003, gradient_norm=5.4740, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 480: loss=0.8278, accuracy=0.7042, gradient_norm=5.9746, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 481: loss=1.0443, accuracy=0.6266, gradient_norm=6.7776, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 482: loss=1.2339, accuracy=0.5861, gradient_norm=7.3922, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 483: loss=1.2275, accuracy=0.5771, gradient_norm=6.7900, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 484: loss=1.0174, accuracy=0.6567, gradient_norm=5.5138, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 485: loss=0.7227, accuracy=0.7534, gradient_norm=4.1076, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 486: loss=0.6472, accuracy=0.7877, gradient_norm=3.8775, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 487: loss=0.6322, accuracy=0.7874, gradient_norm=4.1007, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 488: loss=0.6601, accuracy=0.7691, gradient_norm=4.3587, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 489: loss=0.6831, accuracy=0.7604, gradient_norm=4.5683, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 490: loss=0.6955, accuracy=0.7565, gradient_norm=4.8469, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 491: loss=0.7492, accuracy=0.7293, gradient_norm=5.1452, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 492: loss=0.7907, accuracy=0.7287, gradient_norm=5.2965, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 493: loss=0.7127, accuracy=0.7439, gradient_norm=4.9429, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 494: loss=0.7331, accuracy=0.7473, gradient_norm=4.9131, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 495: loss=0.6893, accuracy=0.7644, gradient_norm=4.8554, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 496: loss=0.7258, accuracy=0.7354, gradient_norm=5.0948, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 497: loss=0.7762, accuracy=0.7163, gradient_norm=5.4882, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 498: loss=0.8449, accuracy=0.6833, gradient_norm=5.5187, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 499: loss=0.7499, accuracy=0.7329, gradient_norm=4.9274, 
[2025-09-15 12:47:46,156][__main__][INFO] - Train, Round 500: loss=0.6501, accuracy=0.7731, gradient_norm=4.3710, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 001: loss=2.3049, accuracy=0.0988, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 002: loss=2.3027, accuracy=0.1050, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 003: loss=2.2992, accuracy=0.1161, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 004: loss=2.2944, accuracy=0.1266, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 005: loss=2.2891, accuracy=0.1387, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 006: loss=2.2840, accuracy=0.1453, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 007: loss=2.2788, accuracy=0.1536, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 008: loss=2.2739, accuracy=0.1646, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 009: loss=2.2684, accuracy=0.1753, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 010: loss=2.2631, accuracy=0.1839, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 011: loss=2.2570, accuracy=0.1897, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 012: loss=2.2503, accuracy=0.1969, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 013: loss=2.2432, accuracy=0.2042, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 014: loss=2.2353, accuracy=0.2173, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 015: loss=2.2261, accuracy=0.2276, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 016: loss=2.2154, accuracy=0.2363, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 017: loss=2.2041, accuracy=0.2538, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 018: loss=2.1922, accuracy=0.2586, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 019: loss=2.1785, accuracy=0.2671, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 020: loss=2.1671, accuracy=0.2618, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 021: loss=2.1497, accuracy=0.2646, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 022: loss=2.1360, accuracy=0.2673, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 023: loss=2.1190, accuracy=0.2687, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 024: loss=2.1091, accuracy=0.2613, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 025: loss=2.1041, accuracy=0.2397, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 026: loss=2.1850, accuracy=0.1904, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 027: loss=2.0994, accuracy=0.2298, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 028: loss=2.0782, accuracy=0.2615, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 029: loss=2.0558, accuracy=0.2804, 
[2025-09-15 12:47:46,156][__main__][INFO] - Test, Round 030: loss=2.0459, accuracy=0.2745, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 031: loss=2.0523, accuracy=0.2521, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 032: loss=2.1746, accuracy=0.2155, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 033: loss=2.1278, accuracy=0.2159, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 034: loss=2.0214, accuracy=0.2667, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 035: loss=2.1768, accuracy=0.2200, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 036: loss=1.9838, accuracy=0.2840, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 037: loss=1.9405, accuracy=0.3038, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 038: loss=1.9491, accuracy=0.2895, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 039: loss=2.4475, accuracy=0.2044, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 040: loss=2.0406, accuracy=0.2467, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 041: loss=1.9225, accuracy=0.3108, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 042: loss=1.9168, accuracy=0.3072, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 043: loss=1.8700, accuracy=0.3179, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 044: loss=1.8646, accuracy=0.3194, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 045: loss=1.8345, accuracy=0.3335, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 046: loss=1.9278, accuracy=0.2853, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 047: loss=2.7627, accuracy=0.1763, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 048: loss=2.2052, accuracy=0.2595, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 049: loss=1.9418, accuracy=0.3023, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 050: loss=1.9527, accuracy=0.2655, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 051: loss=1.8450, accuracy=0.3419, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 052: loss=1.9011, accuracy=0.2915, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 053: loss=2.2256, accuracy=0.2586, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 054: loss=2.1527, accuracy=0.2381, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 055: loss=1.8302, accuracy=0.3276, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 056: loss=1.8800, accuracy=0.2936, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 057: loss=2.1106, accuracy=0.2769, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 058: loss=1.9295, accuracy=0.2834, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 059: loss=1.8157, accuracy=0.3370, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 060: loss=1.8534, accuracy=0.3158, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 061: loss=2.6618, accuracy=0.2161, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 062: loss=2.4893, accuracy=0.2462, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 063: loss=1.8950, accuracy=0.3068, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 064: loss=2.0114, accuracy=0.2621, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 065: loss=2.1555, accuracy=0.2558, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 066: loss=1.8880, accuracy=0.2912, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 067: loss=1.8363, accuracy=0.3193, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 068: loss=1.7972, accuracy=0.3305, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 069: loss=1.7754, accuracy=0.3506, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 070: loss=1.7179, accuracy=0.3590, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 071: loss=1.7234, accuracy=0.3675, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 072: loss=1.7065, accuracy=0.3675, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 073: loss=1.7336, accuracy=0.3598, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 074: loss=1.7849, accuracy=0.3505, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 075: loss=2.0278, accuracy=0.2930, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 076: loss=1.7419, accuracy=0.3473, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 077: loss=1.7040, accuracy=0.3741, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 078: loss=1.7083, accuracy=0.3685, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 079: loss=1.6858, accuracy=0.3731, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 080: loss=1.7067, accuracy=0.3705, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 081: loss=1.7276, accuracy=0.3575, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 082: loss=1.6775, accuracy=0.3775, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 083: loss=1.7336, accuracy=0.3530, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 084: loss=1.8581, accuracy=0.3413, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 085: loss=2.0971, accuracy=0.2947, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 086: loss=1.8018, accuracy=0.3418, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 087: loss=1.9908, accuracy=0.3108, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 088: loss=1.9866, accuracy=0.3167, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 089: loss=2.5614, accuracy=0.2572, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 090: loss=2.1429, accuracy=0.2835, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 091: loss=1.8754, accuracy=0.3321, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 092: loss=1.9423, accuracy=0.2976, 
[2025-09-15 12:47:46,157][__main__][INFO] - Test, Round 093: loss=2.3052, accuracy=0.2807, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 094: loss=1.8315, accuracy=0.3313, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 095: loss=1.8221, accuracy=0.3367, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 096: loss=1.7936, accuracy=0.3413, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 097: loss=2.0401, accuracy=0.3085, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 098: loss=1.8643, accuracy=0.3416, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 099: loss=1.9651, accuracy=0.3237, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 100: loss=1.8594, accuracy=0.3383, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 101: loss=1.8566, accuracy=0.3407, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 102: loss=1.7221, accuracy=0.3719, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 103: loss=1.6760, accuracy=0.3886, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 104: loss=1.7493, accuracy=0.3743, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 105: loss=2.0862, accuracy=0.3070, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 106: loss=1.9549, accuracy=0.3290, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 107: loss=1.7762, accuracy=0.3614, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 108: loss=1.7336, accuracy=0.3707, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 109: loss=1.9134, accuracy=0.3322, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 110: loss=1.8297, accuracy=0.3505, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 111: loss=1.8942, accuracy=0.3410, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 112: loss=1.8532, accuracy=0.3469, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 113: loss=1.8377, accuracy=0.3577, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 114: loss=1.6169, accuracy=0.4049, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 115: loss=1.7213, accuracy=0.3644, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 116: loss=1.9084, accuracy=0.3423, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 117: loss=1.7513, accuracy=0.3443, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 118: loss=1.7824, accuracy=0.3690, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 119: loss=2.0851, accuracy=0.2766, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 120: loss=1.8347, accuracy=0.3448, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 121: loss=1.6354, accuracy=0.3922, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 122: loss=1.6304, accuracy=0.3883, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 123: loss=1.7076, accuracy=0.3711, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 124: loss=1.7429, accuracy=0.3681, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 125: loss=2.1341, accuracy=0.2892, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 126: loss=1.8446, accuracy=0.3436, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 127: loss=1.6610, accuracy=0.3813, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 128: loss=1.7471, accuracy=0.3626, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 129: loss=1.7851, accuracy=0.3568, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 130: loss=1.7538, accuracy=0.3636, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 131: loss=2.0134, accuracy=0.3023, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 132: loss=1.8811, accuracy=0.3417, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 133: loss=1.6866, accuracy=0.3752, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 134: loss=1.7311, accuracy=0.3736, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 135: loss=1.7760, accuracy=0.3564, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 136: loss=1.7563, accuracy=0.3642, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 137: loss=1.9382, accuracy=0.3217, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 138: loss=1.7819, accuracy=0.3636, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 139: loss=1.6095, accuracy=0.4006, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 140: loss=1.6195, accuracy=0.3903, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 141: loss=1.6155, accuracy=0.3919, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 142: loss=1.6448, accuracy=0.3883, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 143: loss=1.7235, accuracy=0.3691, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 144: loss=1.7637, accuracy=0.3738, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 145: loss=1.6585, accuracy=0.3853, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 146: loss=1.6003, accuracy=0.4044, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 147: loss=1.6725, accuracy=0.3799, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 148: loss=1.9743, accuracy=0.3312, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 149: loss=1.6950, accuracy=0.3712, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 150: loss=1.6841, accuracy=0.3865, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 151: loss=1.7356, accuracy=0.3640, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 152: loss=1.7657, accuracy=0.3797, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 153: loss=1.8460, accuracy=0.3512, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 154: loss=2.5009, accuracy=0.2945, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 155: loss=2.0347, accuracy=0.3326, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 156: loss=1.7897, accuracy=0.3643, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 157: loss=1.7662, accuracy=0.3836, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 158: loss=1.8906, accuracy=0.3515, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 159: loss=1.8941, accuracy=0.3527, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 160: loss=1.9120, accuracy=0.3438, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 161: loss=1.8805, accuracy=0.3639, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 162: loss=1.9372, accuracy=0.3379, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 163: loss=1.8778, accuracy=0.3487, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 164: loss=1.6730, accuracy=0.3949, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 165: loss=1.7704, accuracy=0.3670, 
[2025-09-15 12:47:46,158][__main__][INFO] - Test, Round 166: loss=1.6030, accuracy=0.4159, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 167: loss=1.5438, accuracy=0.4355, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 168: loss=1.5086, accuracy=0.4509, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 169: loss=1.5562, accuracy=0.4381, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 170: loss=1.5584, accuracy=0.4283, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 171: loss=1.6274, accuracy=0.4200, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 172: loss=1.5790, accuracy=0.4161, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 173: loss=1.6394, accuracy=0.4058, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 174: loss=1.6863, accuracy=0.3872, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 175: loss=1.8355, accuracy=0.3642, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 176: loss=1.7290, accuracy=0.3834, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 177: loss=1.7778, accuracy=0.3738, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 178: loss=1.7404, accuracy=0.3780, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 179: loss=1.7907, accuracy=0.3776, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 180: loss=2.2594, accuracy=0.2957, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 181: loss=2.6107, accuracy=0.2772, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 182: loss=2.3495, accuracy=0.2870, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 183: loss=1.7458, accuracy=0.3866, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 184: loss=1.9284, accuracy=0.3321, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 185: loss=1.8005, accuracy=0.3814, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 186: loss=1.6689, accuracy=0.3972, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 187: loss=1.6782, accuracy=0.4147, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 188: loss=1.7804, accuracy=0.3760, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 189: loss=1.8232, accuracy=0.3827, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 190: loss=1.8788, accuracy=0.3515, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 191: loss=1.7430, accuracy=0.3936, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 192: loss=1.8739, accuracy=0.3510, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 193: loss=1.7610, accuracy=0.3924, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 194: loss=1.9733, accuracy=0.3547, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 195: loss=1.8504, accuracy=0.3623, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 196: loss=1.9818, accuracy=0.3519, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 197: loss=1.8991, accuracy=0.3485, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 198: loss=1.8985, accuracy=0.3591, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 199: loss=1.7314, accuracy=0.3831, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 200: loss=1.7212, accuracy=0.3942, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 201: loss=1.7582, accuracy=0.3619, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 202: loss=1.7779, accuracy=0.3863, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 203: loss=1.5998, accuracy=0.4108, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 204: loss=1.5397, accuracy=0.4334, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 205: loss=1.5681, accuracy=0.4221, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 206: loss=1.7314, accuracy=0.3809, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 207: loss=1.8841, accuracy=0.3622, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 208: loss=1.6642, accuracy=0.3915, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 209: loss=1.5700, accuracy=0.4205, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 210: loss=1.6393, accuracy=0.4008, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 211: loss=1.5953, accuracy=0.4191, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 212: loss=1.6373, accuracy=0.4075, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 213: loss=1.5722, accuracy=0.4327, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 214: loss=1.6369, accuracy=0.4166, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 215: loss=1.6428, accuracy=0.4154, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 216: loss=1.8013, accuracy=0.3983, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 217: loss=2.1068, accuracy=0.3339, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 218: loss=2.8812, accuracy=0.2792, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 219: loss=2.4019, accuracy=0.2973, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 220: loss=1.9516, accuracy=0.3595, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 221: loss=2.0917, accuracy=0.3234, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 222: loss=1.8065, accuracy=0.3862, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 223: loss=1.7143, accuracy=0.3938, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 224: loss=1.8094, accuracy=0.3721, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 225: loss=1.7160, accuracy=0.3945, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 226: loss=1.8012, accuracy=0.3662, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 227: loss=1.6192, accuracy=0.4153, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 228: loss=1.6009, accuracy=0.4136, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 229: loss=1.6358, accuracy=0.4107, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 230: loss=1.7390, accuracy=0.3868, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 231: loss=1.6422, accuracy=0.4113, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 232: loss=1.6419, accuracy=0.4138, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 233: loss=1.7362, accuracy=0.3978, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 234: loss=1.8312, accuracy=0.3878, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 235: loss=2.6336, accuracy=0.2838, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 236: loss=2.3560, accuracy=0.3049, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 237: loss=2.4325, accuracy=0.2848, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 238: loss=1.9815, accuracy=0.3620, 
[2025-09-15 12:47:46,159][__main__][INFO] - Test, Round 239: loss=2.1508, accuracy=0.3252, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 240: loss=1.8133, accuracy=0.3812, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 241: loss=1.6148, accuracy=0.4202, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 242: loss=1.5987, accuracy=0.4266, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 243: loss=1.7020, accuracy=0.3923, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 244: loss=1.8185, accuracy=0.3667, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 245: loss=1.9651, accuracy=0.3509, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 246: loss=1.8530, accuracy=0.3595, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 247: loss=1.8526, accuracy=0.3718, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 248: loss=1.9090, accuracy=0.3514, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 249: loss=1.8484, accuracy=0.3798, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 250: loss=1.7870, accuracy=0.3780, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 251: loss=1.7051, accuracy=0.4064, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 252: loss=1.7376, accuracy=0.3984, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 253: loss=1.7547, accuracy=0.3852, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 254: loss=2.0734, accuracy=0.3493, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 255: loss=1.8655, accuracy=0.3604, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 256: loss=1.9108, accuracy=0.3625, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 257: loss=1.7706, accuracy=0.3746, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 258: loss=1.7012, accuracy=0.4021, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 259: loss=1.7551, accuracy=0.4091, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 260: loss=2.0026, accuracy=0.3410, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 261: loss=2.6422, accuracy=0.2807, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 262: loss=2.0340, accuracy=0.3522, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 263: loss=1.8901, accuracy=0.3819, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 264: loss=1.8257, accuracy=0.3842, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 265: loss=1.8326, accuracy=0.3962, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 266: loss=1.8828, accuracy=0.3767, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 267: loss=2.1671, accuracy=0.3384, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 268: loss=2.0953, accuracy=0.3541, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 269: loss=1.9422, accuracy=0.3720, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 270: loss=2.1548, accuracy=0.3519, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 271: loss=1.9310, accuracy=0.3608, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 272: loss=2.5185, accuracy=0.3302, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 273: loss=1.9768, accuracy=0.3577, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 274: loss=2.2164, accuracy=0.3333, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 275: loss=2.1029, accuracy=0.3444, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 276: loss=2.4022, accuracy=0.2882, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 277: loss=1.9825, accuracy=0.3656, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 278: loss=1.8701, accuracy=0.3732, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 279: loss=1.7366, accuracy=0.4088, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 280: loss=1.8569, accuracy=0.3853, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 281: loss=2.0368, accuracy=0.3486, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 282: loss=1.6616, accuracy=0.4107, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 283: loss=1.6511, accuracy=0.4168, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 284: loss=1.6048, accuracy=0.4383, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 285: loss=1.7070, accuracy=0.4057, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 286: loss=1.7644, accuracy=0.4112, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 287: loss=1.7382, accuracy=0.3918, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 288: loss=1.6776, accuracy=0.4203, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 289: loss=1.5884, accuracy=0.4394, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 290: loss=1.7894, accuracy=0.3918, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 291: loss=1.8427, accuracy=0.3858, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 292: loss=1.8024, accuracy=0.3914, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 293: loss=1.6728, accuracy=0.4162, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 294: loss=1.9731, accuracy=0.3787, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 295: loss=1.7461, accuracy=0.4004, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 296: loss=1.8713, accuracy=0.3891, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 297: loss=1.8970, accuracy=0.3629, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 298: loss=1.8871, accuracy=0.3779, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 299: loss=1.9334, accuracy=0.3581, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 300: loss=1.7597, accuracy=0.3933, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 301: loss=1.6794, accuracy=0.4007, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 302: loss=1.6611, accuracy=0.4157, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 303: loss=1.6885, accuracy=0.4211, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 304: loss=1.6698, accuracy=0.4146, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 305: loss=1.8976, accuracy=0.3906, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 306: loss=1.8006, accuracy=0.3802, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 307: loss=1.9791, accuracy=0.3804, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 308: loss=2.1373, accuracy=0.3574, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 309: loss=2.8707, accuracy=0.2784, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 310: loss=2.5347, accuracy=0.3340, 
[2025-09-15 12:47:46,160][__main__][INFO] - Test, Round 311: loss=2.8305, accuracy=0.2711, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 312: loss=2.9072, accuracy=0.3065, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 313: loss=2.4032, accuracy=0.3125, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 314: loss=1.8317, accuracy=0.3990, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 315: loss=1.6330, accuracy=0.4172, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 316: loss=1.5459, accuracy=0.4632, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 317: loss=1.5792, accuracy=0.4335, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 318: loss=1.6990, accuracy=0.4190, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 319: loss=1.8171, accuracy=0.3758, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 320: loss=2.4430, accuracy=0.3324, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 321: loss=1.8370, accuracy=0.3864, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 322: loss=1.7618, accuracy=0.3955, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 323: loss=1.9675, accuracy=0.3722, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 324: loss=1.6442, accuracy=0.4228, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 325: loss=1.7325, accuracy=0.4222, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 326: loss=1.6660, accuracy=0.4195, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 327: loss=2.0644, accuracy=0.3685, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 328: loss=1.8109, accuracy=0.4034, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 329: loss=2.7875, accuracy=0.3121, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 330: loss=1.9763, accuracy=0.3719, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 331: loss=1.7827, accuracy=0.4115, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 332: loss=1.8778, accuracy=0.3869, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 333: loss=2.0664, accuracy=0.3558, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 334: loss=1.7774, accuracy=0.4081, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 335: loss=1.6503, accuracy=0.4300, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 336: loss=1.6520, accuracy=0.4320, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 337: loss=1.7660, accuracy=0.4034, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 338: loss=1.8405, accuracy=0.3967, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 339: loss=1.8827, accuracy=0.3910, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 340: loss=1.9583, accuracy=0.3821, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 341: loss=2.0442, accuracy=0.3739, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 342: loss=2.3052, accuracy=0.3359, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 343: loss=2.2633, accuracy=0.3498, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 344: loss=2.1029, accuracy=0.3534, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 345: loss=2.2995, accuracy=0.3677, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 346: loss=2.2538, accuracy=0.3343, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 347: loss=2.7337, accuracy=0.3125, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 348: loss=2.0492, accuracy=0.3695, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 349: loss=2.1703, accuracy=0.3617, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 350: loss=2.2926, accuracy=0.3375, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 351: loss=2.0005, accuracy=0.3614, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 352: loss=1.7822, accuracy=0.4076, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 353: loss=1.7404, accuracy=0.4044, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 354: loss=1.9428, accuracy=0.3885, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 355: loss=1.8476, accuracy=0.3839, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 356: loss=2.1238, accuracy=0.3737, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 357: loss=2.1322, accuracy=0.3503, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 358: loss=2.0351, accuracy=0.3735, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 359: loss=1.9041, accuracy=0.3982, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 360: loss=2.4093, accuracy=0.3096, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 361: loss=1.9750, accuracy=0.3901, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 362: loss=2.4099, accuracy=0.3141, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 363: loss=2.1307, accuracy=0.3552, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 364: loss=2.3890, accuracy=0.3218, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 365: loss=2.2096, accuracy=0.3241, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 366: loss=1.9732, accuracy=0.3831, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 367: loss=1.6514, accuracy=0.4270, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 368: loss=1.7533, accuracy=0.4123, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 369: loss=1.6461, accuracy=0.4338, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 370: loss=1.6616, accuracy=0.4361, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 371: loss=1.6917, accuracy=0.4239, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 372: loss=1.8186, accuracy=0.4045, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 373: loss=1.9905, accuracy=0.3895, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 374: loss=1.9392, accuracy=0.3852, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 375: loss=1.9103, accuracy=0.4011, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 376: loss=1.7860, accuracy=0.4197, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 377: loss=1.7860, accuracy=0.4075, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 378: loss=2.0926, accuracy=0.3768, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 379: loss=2.1561, accuracy=0.3493, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 380: loss=2.0108, accuracy=0.3615, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 381: loss=2.0140, accuracy=0.3801, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 382: loss=2.1178, accuracy=0.3424, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 383: loss=2.5825, accuracy=0.3611, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 384: loss=2.1857, accuracy=0.3481, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 385: loss=1.8937, accuracy=0.4077, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 386: loss=1.8008, accuracy=0.4082, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 387: loss=2.0412, accuracy=0.3766, 
[2025-09-15 12:47:46,161][__main__][INFO] - Test, Round 388: loss=2.1582, accuracy=0.3733, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 389: loss=2.8029, accuracy=0.3000, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 390: loss=2.9078, accuracy=0.3153, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 391: loss=3.1879, accuracy=0.2745, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 392: loss=3.2970, accuracy=0.2743, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 393: loss=2.3060, accuracy=0.3458, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 394: loss=1.9714, accuracy=0.3791, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 395: loss=1.8377, accuracy=0.4192, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 396: loss=1.9790, accuracy=0.3681, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 397: loss=1.9302, accuracy=0.4113, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 398: loss=2.0682, accuracy=0.3654, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 399: loss=2.0954, accuracy=0.3780, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 400: loss=1.9783, accuracy=0.3759, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 401: loss=1.7933, accuracy=0.4164, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 402: loss=1.7139, accuracy=0.4272, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 403: loss=1.6974, accuracy=0.4391, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 404: loss=1.6006, accuracy=0.4533, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 405: loss=1.7181, accuracy=0.4336, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 406: loss=1.6475, accuracy=0.4503, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 407: loss=1.8592, accuracy=0.4116, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 408: loss=1.8347, accuracy=0.4230, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 409: loss=2.0177, accuracy=0.3863, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 410: loss=2.2955, accuracy=0.3547, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 411: loss=2.7871, accuracy=0.3256, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 412: loss=2.2734, accuracy=0.3657, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 413: loss=2.7325, accuracy=0.3096, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 414: loss=1.9283, accuracy=0.4112, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 415: loss=1.7724, accuracy=0.4358, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 416: loss=1.6590, accuracy=0.4475, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 417: loss=1.6190, accuracy=0.4582, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 418: loss=1.6962, accuracy=0.4398, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 419: loss=1.8179, accuracy=0.4225, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 420: loss=2.0805, accuracy=0.3679, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 421: loss=2.1827, accuracy=0.3767, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 422: loss=2.0662, accuracy=0.3655, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 423: loss=1.8689, accuracy=0.4014, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 424: loss=1.8443, accuracy=0.4056, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 425: loss=2.3600, accuracy=0.3367, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 426: loss=2.0326, accuracy=0.3931, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 427: loss=2.2369, accuracy=0.3681, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 428: loss=2.5077, accuracy=0.3420, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 429: loss=3.1539, accuracy=0.2837, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 430: loss=2.1169, accuracy=0.3873, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 431: loss=1.8058, accuracy=0.4189, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 432: loss=1.7795, accuracy=0.4231, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 433: loss=1.8285, accuracy=0.4149, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 434: loss=2.0888, accuracy=0.3770, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 435: loss=2.2966, accuracy=0.3466, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 436: loss=2.5181, accuracy=0.3291, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 437: loss=2.4985, accuracy=0.3283, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 438: loss=2.1703, accuracy=0.3556, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 439: loss=1.9455, accuracy=0.3937, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 440: loss=1.7472, accuracy=0.4323, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 441: loss=1.7449, accuracy=0.4347, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 442: loss=1.6618, accuracy=0.4580, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 443: loss=1.6818, accuracy=0.4420, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 444: loss=1.6246, accuracy=0.4737, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 445: loss=1.6855, accuracy=0.4506, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 446: loss=1.6610, accuracy=0.4603, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 447: loss=1.6957, accuracy=0.4540, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 448: loss=1.7603, accuracy=0.4433, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 449: loss=1.8367, accuracy=0.4239, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 450: loss=2.6237, accuracy=0.3453, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 451: loss=2.0956, accuracy=0.3863, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 452: loss=3.0957, accuracy=0.3043, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 453: loss=2.9466, accuracy=0.2967, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 454: loss=3.1849, accuracy=0.2946, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 455: loss=3.1655, accuracy=0.2651, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 456: loss=2.4792, accuracy=0.3334, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 457: loss=1.8917, accuracy=0.4241, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 458: loss=1.8210, accuracy=0.4225, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 459: loss=1.7430, accuracy=0.4543, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 460: loss=1.8384, accuracy=0.4177, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 461: loss=1.8348, accuracy=0.4327, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 462: loss=1.7592, accuracy=0.4413, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 463: loss=1.8077, accuracy=0.4294, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 464: loss=1.8502, accuracy=0.4327, 
[2025-09-15 12:47:46,162][__main__][INFO] - Test, Round 465: loss=2.0956, accuracy=0.3880, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 466: loss=2.1869, accuracy=0.4056, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 467: loss=2.5652, accuracy=0.3351, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 468: loss=2.6646, accuracy=0.3575, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 469: loss=2.3706, accuracy=0.3336, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 470: loss=2.2154, accuracy=0.3960, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 471: loss=1.9162, accuracy=0.3947, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 472: loss=2.2480, accuracy=0.3994, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 473: loss=2.0480, accuracy=0.3884, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 474: loss=2.3590, accuracy=0.3840, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 475: loss=2.0466, accuracy=0.3993, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 476: loss=2.0537, accuracy=0.4217, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 477: loss=2.1679, accuracy=0.3787, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 478: loss=2.7371, accuracy=0.3404, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 479: loss=2.7517, accuracy=0.3194, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 480: loss=4.8148, accuracy=0.2289, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 481: loss=3.8373, accuracy=0.2606, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 482: loss=4.9659, accuracy=0.2155, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 483: loss=2.2383, accuracy=0.3711, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 484: loss=1.9445, accuracy=0.4021, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 485: loss=1.7206, accuracy=0.4400, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 486: loss=1.8224, accuracy=0.4317, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 487: loss=1.8504, accuracy=0.4325, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 488: loss=2.0356, accuracy=0.4022, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 489: loss=2.1712, accuracy=0.3914, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 490: loss=2.3244, accuracy=0.3691, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 491: loss=2.4221, accuracy=0.3708, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 492: loss=2.4194, accuracy=0.3493, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 493: loss=2.4293, accuracy=0.3651, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 494: loss=2.1039, accuracy=0.3985, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 495: loss=2.8517, accuracy=0.3287, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 496: loss=2.3291, accuracy=0.3683, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 497: loss=2.6095, accuracy=0.3539, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 498: loss=2.1298, accuracy=0.3877, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 499: loss=1.9241, accuracy=0.4222, 
[2025-09-15 12:47:46,163][__main__][INFO] - Test, Round 500: loss=1.7514, accuracy=0.4467, 

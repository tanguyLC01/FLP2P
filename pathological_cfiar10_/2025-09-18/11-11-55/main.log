[2025-09-18 11:12:02,147][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 1.6424214765794922,  accuracy: 0.4966060606060606, gradient_norm : 0.9501455337868934
[2025-09-18 11:12:02,810][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 1.0356132734361176,  accuracy: 0.6014492753623188
[2025-09-18 11:12:05,667][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 1.2689187889972542,  accuracy: 0.5441818181818182, gradient_norm : 0.635953769928713
[2025-09-18 11:12:06,318][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 0.6496222307722377,  accuracy: 0.5852994555353902
[2025-09-18 11:12:09,193][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 1.2044919648361248,  accuracy: 0.559939393939394, gradient_norm : 0.6215701938786191
[2025-09-18 11:12:09,822][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 0.7631997200124122,  accuracy: 0.6212534059945504
[2025-09-18 11:12:12,717][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 1.2756314047173591,  accuracy: 0.542, gradient_norm : 0.6593314475021036
[2025-09-18 11:12:13,353][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 0.7722205985347527,  accuracy: 0.6112624886466849
[2025-09-18 11:12:15,970][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 1.4185650031046033,  accuracy: 0.5042666666666668, gradient_norm : 0.7423167106138685
[2025-09-18 11:12:16,585][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 0.7977625049351496,  accuracy: 0.558
[2025-09-18 11:12:19,437][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 0.980792785486471,  accuracy: 0.6750909090909092, gradient_norm : 0.5763746786488267
[2025-09-18 11:12:20,107][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 0.46148691013171694,  accuracy: 0.7229791099000908
[2025-09-18 11:12:23,001][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 1.1686158662950852,  accuracy: 0.6046666666666667, gradient_norm : 0.6692466850608612
[2025-09-18 11:12:23,713][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 0.6553011943886488,  accuracy: 0.6448683015440508
[2025-09-18 11:12:26,619][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 1.0783107555481721,  accuracy: 0.571939393939394, gradient_norm : 0.529203421707346
[2025-09-18 11:12:27,295][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.0194409895175507,  accuracy: 0.5912806539509536
[2025-09-18 11:12:30,160][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.110158980200465,  accuracy: 0.5952121212121212, gradient_norm : 0.5678775682417325
[2025-09-18 11:12:30,825][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 0.6756258924692484,  accuracy: 0.6239782016348774
[2025-09-18 11:12:33,698][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 0.8370556476669848,  accuracy: 0.5923636363636363, gradient_norm : 0.31948064930253905
[2025-09-18 11:12:34,374][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 0.597842454254506,  accuracy: 0.6376021798365122
[2025-09-18 11:12:37,279][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 1.2694385835883046,  accuracy: 0.5387878787878788, gradient_norm : 0.6250791148188845
[2025-09-18 11:12:37,942][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 0.6157357572071712,  accuracy: 0.5862068965517241
[2025-09-18 11:12:40,838][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 0.5107596585193337,  accuracy: 0.7240000000000001, gradient_norm : 0.19644277646424957
[2025-09-18 11:12:41,528][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 0.4695589170129589,  accuracy: 0.7327272727272728
[2025-09-18 11:12:44,484][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 0.7066301678970025,  accuracy: 0.6613939393939394, gradient_norm : 0.304356398157786
[2025-09-18 11:12:45,143][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 0.569012543602222,  accuracy: 0.6823956442831216
[2025-09-18 11:12:48,100][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 0.7045779789773708,  accuracy: 0.6856363636363636, gradient_norm : 0.34883868092241294
[2025-09-18 11:12:48,761][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 0.4863020472693976,  accuracy: 0.706630336058129
[2025-09-18 11:12:51,633][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 0.9757034578403477,  accuracy: 0.5653939393939394, gradient_norm : 0.4429047014602789
[2025-09-18 11:12:52,316][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 0.7843559611956205,  accuracy: 0.5672727272727273
[2025-09-18 11:12:55,251][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 0.6482308004387408,  accuracy: 0.6865454545454546, gradient_norm : 0.28491562229117684
[2025-09-18 11:12:55,904][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 0.9336171900863519,  accuracy: 0.7018181818181818
[2025-09-18 11:12:58,777][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 1.0428801970848913,  accuracy: 0.5885454545454546, gradient_norm : 0.5360139216920811
[2025-09-18 11:12:59,457][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 0.7194141955556721,  accuracy: 0.6030881017257039
[2025-09-18 11:13:02,055][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 0.7208691020244847,  accuracy: 0.6842, gradient_norm : 0.35609961912722465
[2025-09-18 11:13:02,677][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 0.6001979066277701,  accuracy: 0.6663336663336663
[2025-09-18 11:13:05,581][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 0.632582961631514,  accuracy: 0.7305454545454545, gradient_norm : 0.3280794467200751
[2025-09-18 11:13:06,258][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 0.49097437244507597,  accuracy: 0.7266121707538601
[2025-09-18 11:13:09,140][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 0.6399969408919767,  accuracy: 0.706060606060606, gradient_norm : 0.320000100226924
[2025-09-18 11:13:09,798][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 0.5625352983009756,  accuracy: 0.7081818181818181
[2025-09-18 11:13:12,667][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 0.7517725208183144,  accuracy: 0.6400606060606061, gradient_norm : 0.36008100978139784
[2025-09-18 11:13:13,397][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 0.7730541100010832,  accuracy: 0.6451905626134301
[2025-09-18 11:13:16,021][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 0.639301104611318,  accuracy: 0.6227333333333332, gradient_norm : 0.25600524998944657
[2025-09-18 11:13:16,616][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 0.665762109657149,  accuracy: 0.6146146146146146
[2025-09-18 11:13:19,511][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 0.6595284939918777,  accuracy: 0.6864242424242425, gradient_norm : 0.33831952626377376
[2025-09-18 11:13:20,182][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 0.6948955624003487,  accuracy: 0.6736363636363636
[2025-09-18 11:13:23,000][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 0.7932120705883566,  accuracy: 0.6055757575757575, gradient_norm : 0.3508162249784553
[2025-09-18 11:13:23,690][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 0.7074166594847363,  accuracy: 0.5787079162875342
[2025-09-18 11:13:26,562][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 0.5599508803162978,  accuracy: 0.691939393939394, gradient_norm : 0.21638479867316673
[2025-09-18 11:13:27,238][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 0.5416641306178619,  accuracy: 0.7241379310344828
[2025-09-18 11:13:30,120][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 0.6022979088390429,  accuracy: 0.6572727272727273, gradient_norm : 0.2199831552809255
[2025-09-18 11:13:30,803][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 0.6055902433886022,  accuracy: 0.6748410535876476
[2025-09-18 11:13:33,699][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 0.5457774263424456,  accuracy: 0.7386666666666667, gradient_norm : 0.24964721758859917
[2025-09-18 11:13:34,450][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 0.6219445910648694,  accuracy: 0.7175295186194369
[2025-09-18 11:13:37,084][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 0.4643558440606018,  accuracy: 0.7351333333333334, gradient_norm : 0.18168970039321228
[2025-09-18 11:13:37,691][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 0.6173619420010222,  accuracy: 0.7142857142857143
[2025-09-18 11:13:40,330][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 0.7804341827350597,  accuracy: 0.6688666666666667, gradient_norm : 0.40454099251821296
[2025-09-18 11:13:40,921][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 0.7042107820006636,  accuracy: 0.6553446553446554
[2025-09-18 11:13:43,807][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 0.40015122778191026,  accuracy: 0.7972727272727272, gradient_norm : 0.17487441702163
[2025-09-18 11:13:44,516][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 0.496104082766511,  accuracy: 0.7729336966394187
[2025-09-18 11:13:47,425][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 0.4910756537766566,  accuracy: 0.7149090909090909, gradient_norm : 0.17948966856080964
[2025-09-18 11:13:48,090][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 0.5808256258034008,  accuracy: 0.7602179836512262
[2025-09-18 11:13:50,944][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 0.458239118669273,  accuracy: 0.7298181818181818, gradient_norm : 0.13298156182858256
[2025-09-18 11:13:51,606][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 0.5701441387542348,  accuracy: 0.7002724795640327
[2025-09-18 11:13:54,482][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 0.615126181313679,  accuracy: 0.6679393939393938, gradient_norm : 0.236238293031148
[2025-09-18 11:13:55,212][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 0.6774066264339821,  accuracy: 0.6927272727272727
[2025-09-18 11:13:58,108][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 0.5085616859954916,  accuracy: 0.6873333333333332, gradient_norm : 0.13648503451760827
[2025-09-18 11:13:58,816][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 0.6023270219903198,  accuracy: 0.6627379873073436
[2025-09-18 11:14:01,440][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 0.5145289170767124,  accuracy: 0.6732, gradient_norm : 0.17226329545542912
[2025-09-18 11:14:02,059][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 0.6247699926498608,  accuracy: 0.6616616616616616
[2025-09-18 11:14:04,992][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 0.48526901847581305,  accuracy: 0.8043636363636364, gradient_norm : 0.2733590334859435
[2025-09-18 11:14:05,712][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 0.5046365655393693,  accuracy: 0.7918181818181819
[2025-09-18 11:14:08,583][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 0.44637366304373194,  accuracy: 0.7538181818181818, gradient_norm : 0.17770087739689144
[2025-09-18 11:14:09,267][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 0.5756767559034918,  accuracy: 0.7384196185286104
[2025-09-18 11:14:12,183][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 0.4104006287317843,  accuracy: 0.7683636363636364, gradient_norm : 0.11588075870280944
[2025-09-18 11:14:12,868][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 0.5263840391658675,  accuracy: 0.7538601271571299
[2025-09-18 11:14:15,776][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 0.5149844024374473,  accuracy: 0.7586060606060607, gradient_norm : 0.20459497005465135
[2025-09-18 11:14:16,470][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 0.5864429405751663,  accuracy: 0.7311534968210718
[2025-09-18 11:14:19,351][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 0.5981294920809735,  accuracy: 0.7194545454545455, gradient_norm : 0.27664783715896096
[2025-09-18 11:14:20,029][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 0.6447778151733394,  accuracy: 0.6881818181818182
[2025-09-18 11:14:22,895][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 0.4543280807633125,  accuracy: 0.7658181818181818, gradient_norm : 0.21345178610893376
[2025-09-18 11:14:23,576][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 0.5419879222231989,  accuracy: 0.7818181818181819
[2025-09-18 11:14:26,483][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 0.3669060544450039,  accuracy: 0.8057575757575757, gradient_norm : 0.1715078817168102
[2025-09-18 11:14:27,162][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 0.5285253792978173,  accuracy: 0.769090909090909
[2025-09-18 11:14:30,087][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 0.46359046645184077,  accuracy: 0.7381818181818182, gradient_norm : 0.17391454191317735
[2025-09-18 11:14:30,802][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 0.5927900018739086,  accuracy: 0.7115559599636033
[2025-09-18 11:14:33,680][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 0.36025215396354954,  accuracy: 0.816060606060606, gradient_norm : 0.1539555514685513
[2025-09-18 11:14:34,343][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 0.5141464625107978,  accuracy: 0.7695810564663024
[2025-09-18 11:14:37,279][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 0.3125194928787721,  accuracy: 0.8378787878787878, gradient_norm : 0.12483570449929692
[2025-09-18 11:14:37,945][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 0.4768739523321607,  accuracy: 0.7963636363636364
[2025-09-18 11:14:40,837][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 0.38688482872197283,  accuracy: 0.7969090909090909, gradient_norm : 0.1650663172705479
[2025-09-18 11:14:41,523][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 0.5240637155147614,  accuracy: 0.7520435967302452
[2025-09-18 11:14:44,410][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 0.44662955711364605,  accuracy: 0.7502424242424244, gradient_norm : 0.17897561655437016
[2025-09-18 11:14:45,090][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 0.5851075007954378,  accuracy: 0.7345454545454545
[2025-09-18 11:14:47,993][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 0.40050509483677904,  accuracy: 0.7670303030303031, gradient_norm : 0.14895202361291324
[2025-09-18 11:14:48,675][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 0.5967430817776256,  accuracy: 0.720508166969147
[2025-09-18 11:14:51,583][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 0.2996952927810485,  accuracy: 0.8435151515151517, gradient_norm : 0.1187025383158029
[2025-09-18 11:14:52,266][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 0.42106555375656757,  accuracy: 0.8356039963669392
[2025-09-18 11:14:55,158][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 0.4168635993996113,  accuracy: 0.7571515151515152, gradient_norm : 0.15145471710818023
[2025-09-18 11:14:55,815][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 0.5974999422888323,  accuracy: 0.7218181818181818
[2025-09-18 11:14:58,499][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 0.3025580860524671,  accuracy: 0.8404, gradient_norm : 0.16056074629961808
[2025-09-18 11:14:59,108][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 0.5422883705163668,  accuracy: 0.780439121756487
[2025-09-18 11:15:01,730][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 0.44669500656710753,  accuracy: 0.7497333333333334, gradient_norm : 0.17553122298493914
[2025-09-18 11:15:02,372][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 0.6009681116086785,  accuracy: 0.7422577422577422
[2025-09-18 11:15:05,269][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 0.3354015080272727,  accuracy: 0.8267272727272728, gradient_norm : 0.16382579341433354
[2025-09-18 11:15:05,955][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 0.466828104892007,  accuracy: 0.8019981834695731
[2025-09-18 11:15:08,871][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 0.3754647039454355,  accuracy: 0.7963030303030304, gradient_norm : 0.1423583194080982
[2025-09-18 11:15:09,528][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 0.5627832254456714,  accuracy: 0.7674841053587648
[2025-09-18 11:15:12,458][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 0.3688461657087237,  accuracy: 0.8052727272727273, gradient_norm : 0.14492303984447982
[2025-09-18 11:15:13,155][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 0.5642811900519501,  accuracy: 0.7686025408348457
[2025-09-18 11:15:16,035][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 0.3798439411270781,  accuracy: 0.7779393939393938, gradient_norm : 0.12885055035093865
[2025-09-18 11:15:16,695][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 0.5243369219725601,  accuracy: 0.7479526842584168
[2025-09-18 11:15:19,646][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 0.4140285154935078,  accuracy: 0.7683030303030302, gradient_norm : 0.14182895501514958
[2025-09-18 11:15:20,347][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 0.5846135733075798,  accuracy: 0.7132486388384754
[2025-09-18 11:15:23,235][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 0.41743016729230475,  accuracy: 0.743030303030303, gradient_norm : 0.11297815412256068
[2025-09-18 11:15:23,932][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 0.6088086820216123,  accuracy: 0.7041742286751361
[2025-09-18 11:15:26,817][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 0.337132905227869,  accuracy: 0.8170303030303029, gradient_norm : 0.13299958546715823
[2025-09-18 11:15:27,489][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 0.5442139135012694,  accuracy: 0.7776769509981851
[2025-09-18 11:15:30,354][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 0.3310444546928773,  accuracy: 0.8234545454545457, gradient_norm : 0.12314360432057848
[2025-09-18 11:15:31,020][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 0.524877599232008,  accuracy: 0.769090909090909
[2025-09-18 11:15:33,935][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 0.3196652964565951,  accuracy: 0.8276969696969696, gradient_norm : 0.13175362170403282
[2025-09-18 11:15:34,630][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 0.5219282020131312,  accuracy: 0.7736363636363637
[2025-09-18 11:15:37,496][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.4175915383164007,  accuracy: 0.7815757575757575, gradient_norm : 0.1294114808279294
[2025-09-18 11:15:38,183][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 0.5575047797265397,  accuracy: 0.759090909090909
[2025-09-18 11:15:41,086][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 0.37233501623939985,  accuracy: 0.8135757575757575, gradient_norm : 0.16779024188513542
[2025-09-18 11:15:41,758][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 0.609000718111913,  accuracy: 0.7618181818181818
[2025-09-18 11:15:44,628][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 0.2613028956559096,  accuracy: 0.8671515151515152, gradient_norm : 0.15348596626141336
[2025-09-18 11:15:45,279][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 0.46106566692781636,  accuracy: 0.8145454545454546
[2025-09-18 11:15:48,150][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.3192117407603949,  accuracy: 0.845939393939394, gradient_norm : 0.15011693298635126
[2025-09-18 11:15:48,838][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 0.5036380354415103,  accuracy: 0.8083560399636693
[2025-09-18 11:15:51,750][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 0.32676533235284116,  accuracy: 0.8387878787878789, gradient_norm : 0.15652700593604496
[2025-09-18 11:15:52,436][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 0.5733544778024703,  accuracy: 0.779291553133515
[2025-09-18 11:15:55,321][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 0.22114765549391954,  accuracy: 0.9058181818181819, gradient_norm : 0.14190803300927207
[2025-09-18 11:15:55,985][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 0.39989825064828677,  accuracy: 0.8702359346642469
[2025-09-18 11:15:58,905][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.36185155772006106,  accuracy: 0.8182424242424243, gradient_norm : 0.1667183209503655
[2025-09-18 11:15:59,646][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 0.5664109994606182,  accuracy: 0.7645454545454545
[2025-09-18 11:16:02,529][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 0.36688270845903664,  accuracy: 0.8012727272727272, gradient_norm : 0.14159191293223486
[2025-09-18 11:16:03,214][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 0.5501602686900552,  accuracy: 0.76497277676951
[2025-09-18 11:16:05,892][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 0.3186691850548258,  accuracy: 0.8360666666666666, gradient_norm : 0.11858776739525811
[2025-09-18 11:16:06,530][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 0.5369489448981766,  accuracy: 0.7654690618762475
[2025-09-18 11:16:09,404][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 0.32305838896560135,  accuracy: 0.8369696969696969, gradient_norm : 0.12074607645861929
[2025-09-18 11:16:10,156][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 0.5637315894467246,  accuracy: 0.7881818181818182
[2025-09-18 11:16:13,068][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.3405189147085454,  accuracy: 0.8181212121212121, gradient_norm : 0.12453419560490984
[2025-09-18 11:16:13,777][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 0.5640528841423906,  accuracy: 0.7679057116953762
[2025-09-18 11:16:16,700][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.3675602016501463,  accuracy: 0.8038181818181817, gradient_norm : 0.14856838207659617
[2025-09-18 11:16:17,399][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 0.5483806909647594,  accuracy: 0.7418181818181818
[2025-09-18 11:16:20,384][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.3234579261357755,  accuracy: 0.8453333333333335, gradient_norm : 0.14021909874846455
[2025-09-18 11:16:21,059][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 0.4754223046727322,  accuracy: 0.8185117967332124
[2025-09-18 11:16:23,993][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.3681656069462278,  accuracy: 0.8189090909090909, gradient_norm : 0.15037799037158353
[2025-09-18 11:16:24,694][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 0.5633255782263076,  accuracy: 0.771117166212534
[2025-09-18 11:16:27,608][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.2997629466045836,  accuracy: 0.8298181818181818, gradient_norm : 0.09902742099393785
[2025-09-18 11:16:28,301][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 0.521152330255078,  accuracy: 0.7883742052679382
[2025-09-18 11:16:31,246][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.40661749936109975,  accuracy: 0.7929090909090909, gradient_norm : 0.14758880798664237
[2025-09-18 11:16:31,907][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 0.5720486317679783,  accuracy: 0.759090909090909
[2025-09-18 11:16:34,846][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.29315354209423455,  accuracy: 0.863939393939394, gradient_norm : 0.1647197700635588
[2025-09-18 11:16:35,526][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 0.4944009749942515,  accuracy: 0.8138056312443234
[2025-09-18 11:16:38,445][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.316697954436886,  accuracy: 0.8516969696969698, gradient_norm : 0.13780480724928726
[2025-09-18 11:16:39,136][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 0.5247716079275399,  accuracy: 0.7854545454545454
[2025-09-18 11:16:42,102][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.28261024707090726,  accuracy: 0.8575151515151515, gradient_norm : 0.12024351695657991
[2025-09-18 11:16:42,779][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 0.5607958709334806,  accuracy: 0.8003629764065335
[2025-09-18 11:16:45,426][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.15818970536814336,  accuracy: 0.9321333333333334, gradient_norm : 0.10257159977985772
[2025-09-18 11:16:46,022][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 0.4691083526388057,  accuracy: 0.8498498498498499
[2025-09-18 11:16:48,690][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.24061929404317517,  accuracy: 0.8857333333333334, gradient_norm : 0.12409915779806033
[2025-09-18 11:16:49,292][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 0.43898477067510994,  accuracy: 0.847
[2025-09-18 11:16:52,214][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.2867100155355057,  accuracy: 0.8581212121212122, gradient_norm : 0.1682229812301067
[2025-09-18 11:16:52,888][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 0.5534809466804379,  accuracy: 0.8090909090909091
[2025-09-18 11:16:55,820][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.3593719018835647,  accuracy: 0.818909090909091, gradient_norm : 0.15458331944792308
[2025-09-18 11:16:56,502][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 0.5986174617225277,  accuracy: 0.7663636363636364
[2025-09-18 11:16:59,135][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.2493073628267935,  accuracy: 0.8802666666666666, gradient_norm : 0.14194439554770025
[2025-09-18 11:16:59,773][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 0.5252203527790849,  accuracy: 0.8158158158158159
[2025-09-18 11:17:02,746][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.25843784645168366,  accuracy: 0.873939393939394, gradient_norm : 0.11965266084970788
[2025-09-18 11:17:03,423][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 0.4796536695716883,  accuracy: 0.821071752951862
[2025-09-18 11:17:06,348][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.24441402254075695,  accuracy: 0.8809090909090909, gradient_norm : 0.14376781144839745
[2025-09-18 11:17:07,036][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 0.4953745744376347,  accuracy: 0.8237965485921889
[2025-09-18 11:17:09,940][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.3810768119343869,  accuracy: 0.8018787878787879, gradient_norm : 0.14871358420538353
[2025-09-18 11:17:10,638][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 0.6106799896536648,  accuracy: 0.7484105358764759
[2025-09-18 11:17:13,598][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.15592921423018438,  accuracy: 0.9310303030303029, gradient_norm : 0.11755123117094218
[2025-09-18 11:17:14,289][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 0.4505094472914143,  accuracy: 0.8624772313296903
[2025-09-18 11:17:17,185][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.31369593292125436,  accuracy: 0.8412121212121213, gradient_norm : 0.13508206579437457
[2025-09-18 11:17:17,842][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 0.5167023198479925,  accuracy: 0.7947320617620345
[2025-09-18 11:17:20,740][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.23625326021175594,  accuracy: 0.883090909090909, gradient_norm : 0.11805105829431183
[2025-09-18 11:17:21,411][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 0.5108741981816536,  accuracy: 0.8346957311534968
[2025-09-18 11:17:24,142][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.408173890533092,  accuracy: 0.7831333333333333, gradient_norm : 0.15290952507256542
[2025-09-18 11:17:24,765][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 0.6023137981859857,  accuracy: 0.7335329341317365
[2025-09-18 11:17:27,612][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.37205849756184173,  accuracy: 0.8069090909090909, gradient_norm : 0.15964813711267956
[2025-09-18 11:17:28,318][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 0.6328571023073815,  accuracy: 0.732484076433121
[2025-09-18 11:17:31,245][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.2608188517725724,  accuracy: 0.8614545454545456, gradient_norm : 0.130599597561187
[2025-09-18 11:17:31,930][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 0.5117501898091595,  accuracy: 0.8139745916515426
[2025-09-18 11:17:34,872][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.22210879708306083,  accuracy: 0.8940606060606059, gradient_norm : 0.13257115117122367
[2025-09-18 11:17:35,582][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 0.4914708491354528,  accuracy: 0.8401453224341507
[2025-09-18 11:17:38,541][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.28059143913018064,  accuracy: 0.8526666666666667, gradient_norm : 0.11787946799420342
[2025-09-18 11:17:39,244][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 0.5047958406136789,  accuracy: 0.7920072661217076
[2025-09-18 11:17:42,182][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.18895281624344984,  accuracy: 0.9195757575757576, gradient_norm : 0.1356050808531734
[2025-09-18 11:17:42,887][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 0.45322962715614445,  accuracy: 0.8575317604355717
[2025-09-18 11:17:45,804][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.3343832922023877,  accuracy: 0.8469696969696969, gradient_norm : 0.15524789811659132
[2025-09-18 11:17:46,465][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 0.5056073908585896,  accuracy: 0.8214936247723132
[2025-09-18 11:17:49,166][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.21543543496442188,  accuracy: 0.9070666666666666, gradient_norm : 0.16492982102806455
[2025-09-18 11:17:49,794][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 0.5836852838741807,  accuracy: 0.8111888111888111
[2025-09-18 11:17:52,699][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.22958083181481775,  accuracy: 0.8847272727272727, gradient_norm : 0.09384122184689049
[2025-09-18 11:17:53,415][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 0.5166715066435582,  accuracy: 0.8074477747502271
[2025-09-18 11:17:56,389][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.19736983595068544,  accuracy: 0.9113333333333333, gradient_norm : 0.13880235035099409
[2025-09-18 11:17:57,105][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 0.42983595423012694,  accuracy: 0.8628519527702089
[2025-09-18 11:18:00,052][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.285840762819677,  accuracy: 0.8676969696969696, gradient_norm : 0.14813252023115941
[2025-09-18 11:18:00,738][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 0.5192699579080927,  accuracy: 0.8119891008174387
[2025-09-18 11:18:03,661][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.2869944483968009,  accuracy: 0.865030303030303, gradient_norm : 0.15207894597063107
[2025-09-18 11:18:04,401][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 0.5062575521754167,  accuracy: 0.8237965485921889
[2025-09-18 11:18:07,289][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.2587653501695881,  accuracy: 0.8815757575757575, gradient_norm : 0.15546735428742123
[2025-09-18 11:18:07,953][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 0.4863854237593145,  accuracy: 0.8310626702997275
[2025-09-18 11:18:10,871][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.22149113065690493,  accuracy: 0.8958181818181818, gradient_norm : 0.12383204044274948
[2025-09-18 11:18:11,532][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 0.5004753683456981,  accuracy: 0.8254545454545454
[2025-09-18 11:18:14,506][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.19629416019051,  accuracy: 0.9097575757575758, gradient_norm : 0.11571977169071958
[2025-09-18 11:18:15,210][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 0.4920442994462249,  accuracy: 0.8363636363636363
[2025-09-18 11:18:18,129][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.2636552649176766,  accuracy: 0.874, gradient_norm : 0.13679121247696788
[2025-09-18 11:18:18,817][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 0.4825546030606161,  accuracy: 0.8318181818181818
[2025-09-18 11:18:21,717][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.2844601276961802,  accuracy: 0.8724848484848485, gradient_norm : 0.14725347210445633
[2025-09-18 11:18:22,423][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 0.5417928796204031,  accuracy: 0.8110808356039964
[2025-09-18 11:18:25,339][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.3449891923027866,  accuracy: 0.8275757575757575, gradient_norm : 0.17262166785030716
[2025-09-18 11:18:26,016][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 0.6343400868560477,  accuracy: 0.7522686025408348
[2025-09-18 11:18:28,925][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.3516510042514408,  accuracy: 0.823939393939394, gradient_norm : 0.1649102097348394
[2025-09-18 11:18:29,617][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 0.6820837496115281,  accuracy: 0.7181818181818181
[2025-09-18 11:18:32,510][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.2482474611801349,  accuracy: 0.8873939393939393, gradient_norm : 0.1395115581356946
[2025-09-18 11:18:33,183][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 0.5182666800980168,  accuracy: 0.8049001814882033
[2025-09-18 11:18:36,148][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.1554821706318117,  accuracy: 0.9356363636363636, gradient_norm : 0.11245619458175292
[2025-09-18 11:18:36,830][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 0.4186402710207282,  accuracy: 0.8789808917197452
[2025-09-18 11:18:39,479][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.21711476295635052,  accuracy: 0.908, gradient_norm : 0.14434183449046323
[2025-09-18 11:18:40,112][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 0.5387706978429114,  accuracy: 0.8371628371628371
[2025-09-18 11:18:43,022][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.2841991540432518,  accuracy: 0.8663030303030304, gradient_norm : 0.1322343458792217
[2025-09-18 11:18:43,689][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 0.5709112438952529,  accuracy: 0.7888989990900819
[2025-09-18 11:18:46,354][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.22476299670506705,  accuracy: 0.9087333333333334, gradient_norm : 0.1881787434295618
[2025-09-18 11:18:46,975][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 0.5531082795216486,  accuracy: 0.8191808191808192
[2025-09-18 11:18:49,853][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.20708505942782887,  accuracy: 0.9065454545454545, gradient_norm : 0.11585981342840003
[2025-09-18 11:18:50,544][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 0.44272661946199066,  accuracy: 0.8518181818181818
[2025-09-18 11:18:53,443][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.18186793259344589,  accuracy: 0.9234545454545454, gradient_norm : 0.13678598964719588
[2025-09-18 11:18:54,140][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 0.46817412126393987,  accuracy: 0.8510445049954587
[2025-09-18 11:18:57,101][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.2880493892857378,  accuracy: 0.8547272727272728, gradient_norm : 0.13049908287211748
[2025-09-18 11:18:57,768][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 0.5366449628639921,  accuracy: 0.8116469517743403
[2025-09-18 11:19:00,654][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.22936124465596805,  accuracy: 0.8895151515151515, gradient_norm : 0.11723631658939516
[2025-09-18 11:19:01,357][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 0.5811015867143596,  accuracy: 0.8010899182561307
[2025-09-18 11:19:04,231][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.22097486239171685,  accuracy: 0.8924848484848485, gradient_norm : 0.13693799267368495
[2025-09-18 11:19:04,884][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 0.5181804228989417,  accuracy: 0.8119891008174387
[2025-09-18 11:19:07,818][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.20361508405402604,  accuracy: 0.9072727272727272, gradient_norm : 0.12181181367929093
[2025-09-18 11:19:08,518][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 0.4489662585207948,  accuracy: 0.8489535941765242
[2025-09-18 11:19:11,429][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.15817607692819788,  accuracy: 0.9373939393939393, gradient_norm : 0.17344448381448357
[2025-09-18 11:19:12,108][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 0.5912609103437001,  accuracy: 0.8201634877384196
[2025-09-18 11:19:15,050][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.24174363856583245,  accuracy: 0.884, gradient_norm : 0.1527944057572846
[2025-09-18 11:19:15,724][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 0.5015491379155682,  accuracy: 0.8366606170598911
[2025-09-18 11:19:18,656][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.1614513143127166,  accuracy: 0.9307878787878787, gradient_norm : 0.1372962918588421
[2025-09-18 11:19:19,337][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 0.4583945044059917,  accuracy: 0.8593466424682396
[2025-09-18 11:19:22,231][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.10435241058483644,  accuracy: 0.9604848484848484, gradient_norm : 0.10311459422630133
[2025-09-18 11:19:22,937][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 0.39894811910982814,  accuracy: 0.8837420526793823
[2025-09-18 11:19:25,855][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.2542232476160108,  accuracy: 0.8849090909090911, gradient_norm : 0.1347044862561639
[2025-09-18 11:19:26,545][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 0.5225268141454934,  accuracy: 0.82
[2025-09-18 11:19:29,480][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.19218930460480896,  accuracy: 0.9064242424242424, gradient_norm : 0.11840141212255674
[2025-09-18 11:19:30,169][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 0.5120950001808837,  accuracy: 0.8301544050862852
[2025-09-18 11:19:33,105][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.21698461509143552,  accuracy: 0.898060606060606, gradient_norm : 0.13056538501570783
[2025-09-18 11:19:33,789][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 0.6202522084700203,  accuracy: 0.8092643051771117
[2025-09-18 11:19:36,696][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.141366801711576,  accuracy: 0.9412121212121211, gradient_norm : 0.14685549450883395
[2025-09-18 11:19:37,445][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 0.47719857147447076,  accuracy: 0.8628519527702089
[2025-09-18 11:19:40,357][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.23905657593740812,  accuracy: 0.8914545454545455, gradient_norm : 0.14178867915508342
[2025-09-18 11:19:41,105][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 0.5293004966184488,  accuracy: 0.8010899182561307
[2025-09-18 11:19:44,006][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.10511756186116186,  accuracy: 0.9597575757575758, gradient_norm : 0.11746448876858705
[2025-09-18 11:19:44,691][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 0.4511739757566057,  accuracy: 0.8702359346642469
[2025-09-18 11:19:47,602][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.2878018804879698,  accuracy: 0.862181818181818, gradient_norm : 0.1651210125190422
[2025-09-18 11:19:48,302][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 0.6418704620352147,  accuracy: 0.740236148955495
[2025-09-18 11:19:51,215][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.2520879240448336,  accuracy: 0.8800606060606062, gradient_norm : 0.14502807304971024
[2025-09-18 11:19:51,891][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 0.5630102724873105,  accuracy: 0.7976406533575318
[2025-09-18 11:19:54,814][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.2039101138077288,  accuracy: 0.9087878787878789, gradient_norm : 0.14546148851618923
[2025-09-18 11:19:55,511][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 0.5885760848624172,  accuracy: 0.8056312443233424
[2025-09-18 11:19:58,437][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.18858301837019123,  accuracy: 0.9187878787878787, gradient_norm : 0.13787587086454095
[2025-09-18 11:19:59,152][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 0.5554475321079022,  accuracy: 0.8309090909090909
[2025-09-18 11:20:02,057][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.1656832209001041,  accuracy: 0.9371515151515151, gradient_norm : 0.142989730903409
[2025-09-18 11:20:02,788][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 0.576588801952097,  accuracy: 0.8389444949954504
[2025-09-18 11:20:05,704][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.19213002908893093,  accuracy: 0.9064242424242426, gradient_norm : 0.10596542514542899
[2025-09-18 11:20:06,417][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 0.4091705733868749,  accuracy: 0.8631006346328196
[2025-09-18 11:20:09,398][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.14220669246863574,  accuracy: 0.9313333333333331, gradient_norm : 0.1305768306413773
[2025-09-18 11:20:10,086][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 0.45455416782731417,  accuracy: 0.8655767484105359
[2025-09-18 11:20:12,970][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.15438101509767968,  accuracy: 0.938121212121212, gradient_norm : 0.12912197586751753
[2025-09-18 11:20:13,648][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 0.4575006238997857,  accuracy: 0.8629764065335753
[2025-09-18 11:20:16,537][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.21246073697824733,  accuracy: 0.8911515151515152, gradient_norm : 0.12191232690017208
[2025-09-18 11:20:17,221][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 0.6189874007184744,  accuracy: 0.7931034482758621
[2025-09-18 11:20:20,156][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.0871001740988031,  accuracy: 0.9663636363636363, gradient_norm : 0.09867308722308542
[2025-09-18 11:20:20,835][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 0.5055054246678906,  accuracy: 0.8638838475499092
[2025-09-18 11:20:23,746][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.16220914853317128,  accuracy: 0.9287878787878789, gradient_norm : 0.12262755172195082
[2025-09-18 11:20:24,454][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 0.5788312832099621,  accuracy: 0.8281818181818181
[2025-09-18 11:20:27,350][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.23876228200598099,  accuracy: 0.8899393939393938, gradient_norm : 0.1542800705251499
[2025-09-18 11:20:28,052][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 0.6241134203798165,  accuracy: 0.7912885662431942
[2025-09-18 11:20:31,021][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.2087484226427508,  accuracy: 0.9073333333333333, gradient_norm : 0.12881842186681242
[2025-09-18 11:20:31,698][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 0.4927666324499705,  accuracy: 0.8321234119782214
[2025-09-18 11:20:34,616][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.19478409249839182,  accuracy: 0.9106060606060605, gradient_norm : 0.1325506025803099
[2025-09-18 11:20:35,303][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 0.609581670130575,  accuracy: 0.8092643051771117
[2025-09-18 11:20:38,202][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.13043685527039697,  accuracy: 0.9421212121212121, gradient_norm : 0.10329540764432954
[2025-09-18 11:20:38,886][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 0.468205069531164,  accuracy: 0.8623188405797102
[2025-09-18 11:20:41,842][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.09360923213999571,  accuracy: 0.9664242424242425, gradient_norm : 0.1121289609516987
[2025-09-18 11:20:42,504][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 0.5290412803273683,  accuracy: 0.8516833484986351
[2025-09-18 11:20:45,395][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.1526795677173942,  accuracy: 0.9366060606060606, gradient_norm : 0.14688805848523676
[2025-09-18 11:20:46,098][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 0.5067279306013264,  accuracy: 0.8363636363636363
[2025-09-18 11:20:49,000][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.23351717144793585,  accuracy: 0.8986666666666667, gradient_norm : 0.14401599036685922
[2025-09-18 11:20:49,730][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 0.5885216211437664,  accuracy: 0.7996373526745241
[2025-09-18 11:20:52,406][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.05886508177065421,  accuracy: 0.9819333333333332, gradient_norm : 0.09058844690019965
[2025-09-18 11:20:53,055][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 0.5457980759567205,  accuracy: 0.8721278721278721
[2025-09-18 11:20:56,008][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.24457357080709297,  accuracy: 0.8947272727272729, gradient_norm : 0.17604381714902703
[2025-09-18 11:20:56,697][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 0.562859599663351,  accuracy: 0.8119891008174387
[2025-09-18 11:20:59,620][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.19863673231015308,  accuracy: 0.9132727272727272, gradient_norm : 0.14341646393365423
[2025-09-18 11:21:00,342][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 0.6506793284191735,  accuracy: 0.794010889292196
[2025-09-18 11:21:03,272][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.1318445040238235,  accuracy: 0.9398787878787879, gradient_norm : 0.09873807735416452
[2025-09-18 11:21:03,949][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 0.6101395140967109,  accuracy: 0.8340888485947416
[2025-09-18 11:21:06,880][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.12362012699094044,  accuracy: 0.9466060606060607, gradient_norm : 0.09137884597164768
[2025-09-18 11:21:07,576][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 0.5136656336389436,  accuracy: 0.8603807796917498
[2025-09-18 11:21:10,538][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.12309363599543419,  accuracy: 0.951878787878788, gradient_norm : 0.11295682422360893
[2025-09-18 11:21:11,239][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 0.4482112267240575,  accuracy: 0.8753412192902639
[2025-09-18 11:21:14,115][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.08711770098832966,  accuracy: 0.9677575757575756, gradient_norm : 0.12859223399527786
[2025-09-18 11:21:14,826][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 0.5801166565822994,  accuracy: 0.846503178928247
[2025-09-18 11:21:17,712][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.12531606535740147,  accuracy: 0.952060606060606, gradient_norm : 0.11957955212338245
[2025-09-18 11:21:18,397][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 0.607625588507444,  accuracy: 0.8374205267938238
[2025-09-18 11:21:21,430][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.10119497602589989,  accuracy: 0.956181818181818, gradient_norm : 0.10368061443635267
[2025-09-18 11:21:22,117][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 0.5747238041088525,  accuracy: 0.8516833484986351
[2025-09-18 11:21:24,807][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.10236635963340397,  accuracy: 0.9585333333333333, gradient_norm : 0.08277685110527125
[2025-09-18 11:21:25,429][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 0.8596952904609682,  accuracy: 0.808
[2025-09-18 11:21:28,347][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.15621896397063725,  accuracy: 0.933878787878788, gradient_norm : 0.1275968058824551
[2025-09-18 11:21:29,091][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 0.4611415666968318,  accuracy: 0.8619436875567665
[2025-09-18 11:21:32,037][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.08931368455847434,  accuracy: 0.9653939393939395, gradient_norm : 0.11823535950187081
[2025-09-18 11:21:32,721][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 0.5727026070012173,  accuracy: 0.8533697632058288
[2025-09-18 11:21:35,702][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.1661165365515946,  accuracy: 0.930121212121212, gradient_norm : 0.1424383513120919
[2025-09-18 11:21:36,386][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 0.5186371500180696,  accuracy: 0.8377153218495014
[2025-09-18 11:21:39,313][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.05290026273463826,  accuracy: 0.9827878787878788, gradient_norm : 0.09713760108111603
[2025-09-18 11:21:39,976][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 0.43626808925743127,  accuracy: 0.9019963702359347
[2025-09-18 11:21:42,925][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.14541871531910386,  accuracy: 0.9375757575757576, gradient_norm : 0.12687556268041617
[2025-09-18 11:21:43,611][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 0.5518867781975744,  accuracy: 0.86
[2025-09-18 11:21:46,551][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.06596076459388955,  accuracy: 0.9775757575757577, gradient_norm : 0.12304226566758412
[2025-09-18 11:21:47,247][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 0.4642142727233532,  accuracy: 0.8793103448275862
[2025-09-18 11:21:50,219][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.1896434168114444,  accuracy: 0.9193939393939394, gradient_norm : 0.1723521899320111
[2025-09-18 11:21:50,917][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 0.6053318810348653,  accuracy: 0.82
[2025-09-18 11:21:53,852][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.11019848943977041,  accuracy: 0.952848484848485, gradient_norm : 0.14405706342326988
[2025-09-18 11:21:54,529][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 0.5156968287105256,  accuracy: 0.8555858310626703
[2025-09-18 11:21:57,484][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.11428438636283714,  accuracy: 0.9527878787878785, gradient_norm : 0.09659696275470685
[2025-09-18 11:21:58,190][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 0.6621790769423536,  accuracy: 0.8310626702997275
[2025-09-18 11:22:01,212][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.1304055744901345,  accuracy: 0.9377575757575758, gradient_norm : 0.12422511684108282
[2025-09-18 11:22:01,911][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 0.6214166248756146,  accuracy: 0.8165304268846503
[2025-09-18 11:22:04,891][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.07913617541536626,  accuracy: 0.970969696969697, gradient_norm : 0.09877264444406625
[2025-09-18 11:22:05,597][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 0.5134492556627415,  accuracy: 0.8662420382165605
[2025-09-18 11:22:08,592][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.1418030122992503,  accuracy: 0.9442424242424243, gradient_norm : 0.15365327192468028
[2025-09-18 11:22:09,253][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 0.5642022225692587,  accuracy: 0.8407643312101911
[2025-09-18 11:22:12,168][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.12089986881706223,  accuracy: 0.954, gradient_norm : 0.16362444521487876
[2025-09-18 11:22:12,924][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 0.5876717597240249,  accuracy: 0.8356039963669392
[2025-09-18 11:22:15,856][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.10460116995388855,  accuracy: 0.9592121212121213, gradient_norm : 0.12909976791184458
[2025-09-18 11:22:16,522][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 0.4914899993464806,  accuracy: 0.8683015440508629
[2025-09-18 11:22:19,414][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.08441810721691921,  accuracy: 0.9690303030303031, gradient_norm : 0.12263216339510129
[2025-09-18 11:22:20,111][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 0.5721110352624513,  accuracy: 0.8546775658492279
[2025-09-18 11:22:22,980][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.09560442397481315,  accuracy: 0.9544848484848485, gradient_norm : 0.09651927816924642
[2025-09-18 11:22:23,733][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 0.4838279572563397,  accuracy: 0.860127157129882
[2025-09-18 11:22:26,665][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.0888991197822707,  accuracy: 0.9632121212121213, gradient_norm : 0.09826209355149555
[2025-09-18 11:22:27,392][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 0.41272097854423945,  accuracy: 0.8847549909255898
[2025-09-18 11:22:30,358][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.10369378148443428,  accuracy: 0.9589090909090909, gradient_norm : 0.11332866207030547
[2025-09-18 11:22:31,028][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 0.5037189100966603,  accuracy: 0.8666061705989111
[2025-09-18 11:22:33,708][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.048980287710087986,  accuracy: 0.9826666666666668, gradient_norm : 0.06087687671907323
[2025-09-18 11:22:34,336][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 0.3974537093203547,  accuracy: 0.8981018981018981
[2025-09-18 11:22:37,233][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.0909541074882726,  accuracy: 0.965878787878788, gradient_norm : 0.096511031737922
[2025-09-18 11:22:37,886][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 0.5689337009359795,  accuracy: 0.8703535811423391
[2025-09-18 11:22:40,795][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.12871225958001387,  accuracy: 0.9444848484848486, gradient_norm : 0.12123555641176814
[2025-09-18 11:22:41,469][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 0.541430178632684,  accuracy: 0.850909090909091
[2025-09-18 11:22:44,400][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.04831802223327737,  accuracy: 0.9824848484848485, gradient_norm : 0.08383364350851237
[2025-09-18 11:22:45,078][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 0.47098827851876796,  accuracy: 0.8864668483197093
[2025-09-18 11:22:48,006][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.11884109302289775,  accuracy: 0.9493939393939392, gradient_norm : 0.11872537485446583
[2025-09-18 11:22:48,706][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 0.6063116064697693,  accuracy: 0.8247048138056312
[2025-09-18 11:22:51,680][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.09160850627825302,  accuracy: 0.9653333333333333, gradient_norm : 0.13529211822060863
[2025-09-18 11:22:52,379][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 0.6190860345466788,  accuracy: 0.8327272727272728
[2025-09-18 11:22:55,306][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.12152779549314524,  accuracy: 0.9501818181818181, gradient_norm : 0.10941782355579287
[2025-09-18 11:22:56,000][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 0.6191851078726576,  accuracy: 0.824385805277525
[2025-09-18 11:22:58,895][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.10554015922434781,  accuracy: 0.9594545454545454, gradient_norm : 0.12495941657301995
[2025-09-18 11:22:59,579][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 0.543808311453298,  accuracy: 0.8502722323049002
[2025-09-18 11:23:02,481][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.13664964196755675,  accuracy: 0.9408484848484847, gradient_norm : 0.14966815664939032
[2025-09-18 11:23:03,171][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 0.6747307303470839,  accuracy: 0.7956403269754768
[2025-09-18 11:23:06,137][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.10126507881540073,  accuracy: 0.958, gradient_norm : 0.08691194846494339
[2025-09-18 11:23:06,839][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 0.47286061090285203,  accuracy: 0.8754545454545455
[2025-09-18 11:23:09,752][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.08344784109646942,  accuracy: 0.9671515151515151, gradient_norm : 0.1058732061933464
[2025-09-18 11:23:10,445][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 0.6384121412013126,  accuracy: 0.8481818181818181
[2025-09-18 11:23:13,385][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.08845524475781803,  accuracy: 0.9597575757575758, gradient_norm : 0.08743672870018235
[2025-09-18 11:23:14,082][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 0.5007115528743334,  accuracy: 0.8448275862068966
[2025-09-18 11:23:17,018][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.04158904319822415,  accuracy: 0.985878787878788, gradient_norm : 0.08056814400463075
[2025-09-18 11:23:17,717][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 0.7086443438774517,  accuracy: 0.8439201451905626
[2025-09-18 11:23:20,623][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.09706384818794672,  accuracy: 0.9641818181818181, gradient_norm : 0.12065633968314605
[2025-09-18 11:23:21,339][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 0.5207204668785662,  accuracy: 0.857402361489555
[2025-09-18 11:23:24,238][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.09873621988742971,  accuracy: 0.9626666666666666, gradient_norm : 0.11061540356082235
[2025-09-18 11:23:24,920][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 0.6392715562146118,  accuracy: 0.83
[2025-09-18 11:23:27,860][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.010848308958194169,  accuracy: 0.9978181818181818, gradient_norm : 0.032075120697287796
[2025-09-18 11:23:28,551][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 0.5437534041070722,  accuracy: 0.8921124206708976
[2025-09-18 11:23:31,472][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.11344717734592177,  accuracy: 0.9513333333333333, gradient_norm : 0.11322581996213908
[2025-09-18 11:23:32,194][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 0.6004468841798667,  accuracy: 0.8310626702997275
[2025-09-18 11:23:35,114][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.10633286148424785,  accuracy: 0.9592727272727273, gradient_norm : 0.10984875334873972
[2025-09-18 11:23:35,847][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 0.6363090019600113,  accuracy: 0.8256130790190735
[2025-09-18 11:23:38,742][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.06902990881475425,  accuracy: 0.976909090909091, gradient_norm : 0.09058888222756913
[2025-09-18 11:23:39,396][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 0.48182803488232406,  accuracy: 0.8709090909090909
[2025-09-18 11:23:42,278][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.07724292796773435,  accuracy: 0.9637575757575757, gradient_norm : 0.06256389512712338
[2025-09-18 11:23:42,978][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 0.4694021635420097,  accuracy: 0.8701180744777475
[2025-09-18 11:23:45,912][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.1398170440348663,  accuracy: 0.9434545454545454, gradient_norm : 0.12186358803845346
[2025-09-18 11:23:46,638][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 0.6382397066860049,  accuracy: 0.8168631006346329
[2025-09-18 11:23:49,538][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.10606485509239746,  accuracy: 0.9593939393939395, gradient_norm : 0.10718183599658736
[2025-09-18 11:23:50,211][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 0.6575459570702676,  accuracy: 0.8263636363636364
[2025-09-18 11:23:53,117][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.0798732746528948,  accuracy: 0.9707272727272729, gradient_norm : 0.10380746923219265
[2025-09-18 11:23:53,792][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 0.5034551563393929,  accuracy: 0.860909090909091
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 001: loss=1.6424, accuracy=0.4966, gradient_norm=0.9501, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 002: loss=1.2689, accuracy=0.5442, gradient_norm=0.6360, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 003: loss=1.2045, accuracy=0.5599, gradient_norm=0.6216, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 004: loss=1.2756, accuracy=0.5420, gradient_norm=0.6593, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 005: loss=1.4186, accuracy=0.5043, gradient_norm=0.7423, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 006: loss=0.9808, accuracy=0.6751, gradient_norm=0.5764, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 007: loss=1.1686, accuracy=0.6047, gradient_norm=0.6692, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 008: loss=1.0783, accuracy=0.5719, gradient_norm=0.5292, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 009: loss=1.1102, accuracy=0.5952, gradient_norm=0.5679, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 010: loss=0.8371, accuracy=0.5924, gradient_norm=0.3195, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 011: loss=1.2694, accuracy=0.5388, gradient_norm=0.6251, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 012: loss=0.5108, accuracy=0.7240, gradient_norm=0.1964, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 013: loss=0.7066, accuracy=0.6614, gradient_norm=0.3044, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 014: loss=0.7046, accuracy=0.6856, gradient_norm=0.3488, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 015: loss=0.9757, accuracy=0.5654, gradient_norm=0.4429, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 016: loss=0.6482, accuracy=0.6865, gradient_norm=0.2849, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 017: loss=1.0429, accuracy=0.5885, gradient_norm=0.5360, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 018: loss=0.7209, accuracy=0.6842, gradient_norm=0.3561, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 019: loss=0.6326, accuracy=0.7305, gradient_norm=0.3281, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 020: loss=0.6400, accuracy=0.7061, gradient_norm=0.3200, 
[2025-09-18 11:23:53,793][__main__][INFO] - Train, Round 021: loss=0.7518, accuracy=0.6401, gradient_norm=0.3601, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 022: loss=0.6393, accuracy=0.6227, gradient_norm=0.2560, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 023: loss=0.6595, accuracy=0.6864, gradient_norm=0.3383, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 024: loss=0.7932, accuracy=0.6056, gradient_norm=0.3508, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 025: loss=0.5600, accuracy=0.6919, gradient_norm=0.2164, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 026: loss=0.6023, accuracy=0.6573, gradient_norm=0.2200, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 027: loss=0.5458, accuracy=0.7387, gradient_norm=0.2496, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 028: loss=0.4644, accuracy=0.7351, gradient_norm=0.1817, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 029: loss=0.7804, accuracy=0.6689, gradient_norm=0.4045, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 030: loss=0.4002, accuracy=0.7973, gradient_norm=0.1749, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 031: loss=0.4911, accuracy=0.7149, gradient_norm=0.1795, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 032: loss=0.4582, accuracy=0.7298, gradient_norm=0.1330, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 033: loss=0.6151, accuracy=0.6679, gradient_norm=0.2362, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 034: loss=0.5086, accuracy=0.6873, gradient_norm=0.1365, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 035: loss=0.5145, accuracy=0.6732, gradient_norm=0.1723, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 036: loss=0.4853, accuracy=0.8044, gradient_norm=0.2734, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 037: loss=0.4464, accuracy=0.7538, gradient_norm=0.1777, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 038: loss=0.4104, accuracy=0.7684, gradient_norm=0.1159, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 039: loss=0.5150, accuracy=0.7586, gradient_norm=0.2046, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 040: loss=0.5981, accuracy=0.7195, gradient_norm=0.2766, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 041: loss=0.4543, accuracy=0.7658, gradient_norm=0.2135, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 042: loss=0.3669, accuracy=0.8058, gradient_norm=0.1715, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 043: loss=0.4636, accuracy=0.7382, gradient_norm=0.1739, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 044: loss=0.3603, accuracy=0.8161, gradient_norm=0.1540, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 045: loss=0.3125, accuracy=0.8379, gradient_norm=0.1248, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 046: loss=0.3869, accuracy=0.7969, gradient_norm=0.1651, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 047: loss=0.4466, accuracy=0.7502, gradient_norm=0.1790, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 048: loss=0.4005, accuracy=0.7670, gradient_norm=0.1490, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 049: loss=0.2997, accuracy=0.8435, gradient_norm=0.1187, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 050: loss=0.4169, accuracy=0.7572, gradient_norm=0.1515, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 051: loss=0.3026, accuracy=0.8404, gradient_norm=0.1606, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 052: loss=0.4467, accuracy=0.7497, gradient_norm=0.1755, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 053: loss=0.3354, accuracy=0.8267, gradient_norm=0.1638, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 054: loss=0.3755, accuracy=0.7963, gradient_norm=0.1424, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 055: loss=0.3688, accuracy=0.8053, gradient_norm=0.1449, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 056: loss=0.3798, accuracy=0.7779, gradient_norm=0.1289, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 057: loss=0.4140, accuracy=0.7683, gradient_norm=0.1418, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 058: loss=0.4174, accuracy=0.7430, gradient_norm=0.1130, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 059: loss=0.3371, accuracy=0.8170, gradient_norm=0.1330, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 060: loss=0.3310, accuracy=0.8235, gradient_norm=0.1231, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 061: loss=0.3197, accuracy=0.8277, gradient_norm=0.1318, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 062: loss=0.4176, accuracy=0.7816, gradient_norm=0.1294, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 063: loss=0.3723, accuracy=0.8136, gradient_norm=0.1678, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 064: loss=0.2613, accuracy=0.8672, gradient_norm=0.1535, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 065: loss=0.3192, accuracy=0.8459, gradient_norm=0.1501, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 066: loss=0.3268, accuracy=0.8388, gradient_norm=0.1565, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 067: loss=0.2211, accuracy=0.9058, gradient_norm=0.1419, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 068: loss=0.3619, accuracy=0.8182, gradient_norm=0.1667, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 069: loss=0.3669, accuracy=0.8013, gradient_norm=0.1416, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 070: loss=0.3187, accuracy=0.8361, gradient_norm=0.1186, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 071: loss=0.3231, accuracy=0.8370, gradient_norm=0.1207, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 072: loss=0.3405, accuracy=0.8181, gradient_norm=0.1245, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 073: loss=0.3676, accuracy=0.8038, gradient_norm=0.1486, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 074: loss=0.3235, accuracy=0.8453, gradient_norm=0.1402, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 075: loss=0.3682, accuracy=0.8189, gradient_norm=0.1504, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 076: loss=0.2998, accuracy=0.8298, gradient_norm=0.0990, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 077: loss=0.4066, accuracy=0.7929, gradient_norm=0.1476, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 078: loss=0.2932, accuracy=0.8639, gradient_norm=0.1647, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 079: loss=0.3167, accuracy=0.8517, gradient_norm=0.1378, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 080: loss=0.2826, accuracy=0.8575, gradient_norm=0.1202, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 081: loss=0.1582, accuracy=0.9321, gradient_norm=0.1026, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 082: loss=0.2406, accuracy=0.8857, gradient_norm=0.1241, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 083: loss=0.2867, accuracy=0.8581, gradient_norm=0.1682, 
[2025-09-18 11:23:53,794][__main__][INFO] - Train, Round 084: loss=0.3594, accuracy=0.8189, gradient_norm=0.1546, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 085: loss=0.2493, accuracy=0.8803, gradient_norm=0.1419, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 086: loss=0.2584, accuracy=0.8739, gradient_norm=0.1197, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 087: loss=0.2444, accuracy=0.8809, gradient_norm=0.1438, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 088: loss=0.3811, accuracy=0.8019, gradient_norm=0.1487, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 089: loss=0.1559, accuracy=0.9310, gradient_norm=0.1176, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 090: loss=0.3137, accuracy=0.8412, gradient_norm=0.1351, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 091: loss=0.2363, accuracy=0.8831, gradient_norm=0.1181, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 092: loss=0.4082, accuracy=0.7831, gradient_norm=0.1529, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 093: loss=0.3721, accuracy=0.8069, gradient_norm=0.1596, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 094: loss=0.2608, accuracy=0.8615, gradient_norm=0.1306, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 095: loss=0.2221, accuracy=0.8941, gradient_norm=0.1326, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 096: loss=0.2806, accuracy=0.8527, gradient_norm=0.1179, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 097: loss=0.1890, accuracy=0.9196, gradient_norm=0.1356, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 098: loss=0.3344, accuracy=0.8470, gradient_norm=0.1552, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 099: loss=0.2154, accuracy=0.9071, gradient_norm=0.1649, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 100: loss=0.2296, accuracy=0.8847, gradient_norm=0.0938, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 101: loss=0.1974, accuracy=0.9113, gradient_norm=0.1388, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 102: loss=0.2858, accuracy=0.8677, gradient_norm=0.1481, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 103: loss=0.2870, accuracy=0.8650, gradient_norm=0.1521, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 104: loss=0.2588, accuracy=0.8816, gradient_norm=0.1555, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 105: loss=0.2215, accuracy=0.8958, gradient_norm=0.1238, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 106: loss=0.1963, accuracy=0.9098, gradient_norm=0.1157, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 107: loss=0.2637, accuracy=0.8740, gradient_norm=0.1368, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 108: loss=0.2845, accuracy=0.8725, gradient_norm=0.1473, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 109: loss=0.3450, accuracy=0.8276, gradient_norm=0.1726, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 110: loss=0.3517, accuracy=0.8239, gradient_norm=0.1649, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 111: loss=0.2482, accuracy=0.8874, gradient_norm=0.1395, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 112: loss=0.1555, accuracy=0.9356, gradient_norm=0.1125, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 113: loss=0.2171, accuracy=0.9080, gradient_norm=0.1443, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 114: loss=0.2842, accuracy=0.8663, gradient_norm=0.1322, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 115: loss=0.2248, accuracy=0.9087, gradient_norm=0.1882, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 116: loss=0.2071, accuracy=0.9065, gradient_norm=0.1159, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 117: loss=0.1819, accuracy=0.9235, gradient_norm=0.1368, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 118: loss=0.2880, accuracy=0.8547, gradient_norm=0.1305, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 119: loss=0.2294, accuracy=0.8895, gradient_norm=0.1172, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 120: loss=0.2210, accuracy=0.8925, gradient_norm=0.1369, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 121: loss=0.2036, accuracy=0.9073, gradient_norm=0.1218, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 122: loss=0.1582, accuracy=0.9374, gradient_norm=0.1734, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 123: loss=0.2417, accuracy=0.8840, gradient_norm=0.1528, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 124: loss=0.1615, accuracy=0.9308, gradient_norm=0.1373, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 125: loss=0.1044, accuracy=0.9605, gradient_norm=0.1031, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 126: loss=0.2542, accuracy=0.8849, gradient_norm=0.1347, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 127: loss=0.1922, accuracy=0.9064, gradient_norm=0.1184, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 128: loss=0.2170, accuracy=0.8981, gradient_norm=0.1306, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 129: loss=0.1414, accuracy=0.9412, gradient_norm=0.1469, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 130: loss=0.2391, accuracy=0.8915, gradient_norm=0.1418, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 131: loss=0.1051, accuracy=0.9598, gradient_norm=0.1175, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 132: loss=0.2878, accuracy=0.8622, gradient_norm=0.1651, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 133: loss=0.2521, accuracy=0.8801, gradient_norm=0.1450, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 134: loss=0.2039, accuracy=0.9088, gradient_norm=0.1455, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 135: loss=0.1886, accuracy=0.9188, gradient_norm=0.1379, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 136: loss=0.1657, accuracy=0.9372, gradient_norm=0.1430, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 137: loss=0.1921, accuracy=0.9064, gradient_norm=0.1060, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 138: loss=0.1422, accuracy=0.9313, gradient_norm=0.1306, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 139: loss=0.1544, accuracy=0.9381, gradient_norm=0.1291, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 140: loss=0.2125, accuracy=0.8912, gradient_norm=0.1219, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 141: loss=0.0871, accuracy=0.9664, gradient_norm=0.0987, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 142: loss=0.1622, accuracy=0.9288, gradient_norm=0.1226, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 143: loss=0.2388, accuracy=0.8899, gradient_norm=0.1543, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 144: loss=0.2087, accuracy=0.9073, gradient_norm=0.1288, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 145: loss=0.1948, accuracy=0.9106, gradient_norm=0.1326, 
[2025-09-18 11:23:53,795][__main__][INFO] - Train, Round 146: loss=0.1304, accuracy=0.9421, gradient_norm=0.1033, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 147: loss=0.0936, accuracy=0.9664, gradient_norm=0.1121, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 148: loss=0.1527, accuracy=0.9366, gradient_norm=0.1469, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 149: loss=0.2335, accuracy=0.8987, gradient_norm=0.1440, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 150: loss=0.0589, accuracy=0.9819, gradient_norm=0.0906, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 151: loss=0.2446, accuracy=0.8947, gradient_norm=0.1760, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 152: loss=0.1986, accuracy=0.9133, gradient_norm=0.1434, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 153: loss=0.1318, accuracy=0.9399, gradient_norm=0.0987, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 154: loss=0.1236, accuracy=0.9466, gradient_norm=0.0914, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 155: loss=0.1231, accuracy=0.9519, gradient_norm=0.1130, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 156: loss=0.0871, accuracy=0.9678, gradient_norm=0.1286, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 157: loss=0.1253, accuracy=0.9521, gradient_norm=0.1196, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 158: loss=0.1012, accuracy=0.9562, gradient_norm=0.1037, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 159: loss=0.1024, accuracy=0.9585, gradient_norm=0.0828, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 160: loss=0.1562, accuracy=0.9339, gradient_norm=0.1276, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 161: loss=0.0893, accuracy=0.9654, gradient_norm=0.1182, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 162: loss=0.1661, accuracy=0.9301, gradient_norm=0.1424, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 163: loss=0.0529, accuracy=0.9828, gradient_norm=0.0971, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 164: loss=0.1454, accuracy=0.9376, gradient_norm=0.1269, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 165: loss=0.0660, accuracy=0.9776, gradient_norm=0.1230, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 166: loss=0.1896, accuracy=0.9194, gradient_norm=0.1724, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 167: loss=0.1102, accuracy=0.9528, gradient_norm=0.1441, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 168: loss=0.1143, accuracy=0.9528, gradient_norm=0.0966, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 169: loss=0.1304, accuracy=0.9378, gradient_norm=0.1242, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 170: loss=0.0791, accuracy=0.9710, gradient_norm=0.0988, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 171: loss=0.1418, accuracy=0.9442, gradient_norm=0.1537, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 172: loss=0.1209, accuracy=0.9540, gradient_norm=0.1636, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 173: loss=0.1046, accuracy=0.9592, gradient_norm=0.1291, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 174: loss=0.0844, accuracy=0.9690, gradient_norm=0.1226, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 175: loss=0.0956, accuracy=0.9545, gradient_norm=0.0965, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 176: loss=0.0889, accuracy=0.9632, gradient_norm=0.0983, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 177: loss=0.1037, accuracy=0.9589, gradient_norm=0.1133, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 178: loss=0.0490, accuracy=0.9827, gradient_norm=0.0609, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 179: loss=0.0910, accuracy=0.9659, gradient_norm=0.0965, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 180: loss=0.1287, accuracy=0.9445, gradient_norm=0.1212, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 181: loss=0.0483, accuracy=0.9825, gradient_norm=0.0838, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 182: loss=0.1188, accuracy=0.9494, gradient_norm=0.1187, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 183: loss=0.0916, accuracy=0.9653, gradient_norm=0.1353, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 184: loss=0.1215, accuracy=0.9502, gradient_norm=0.1094, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 185: loss=0.1055, accuracy=0.9595, gradient_norm=0.1250, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 186: loss=0.1366, accuracy=0.9408, gradient_norm=0.1497, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 187: loss=0.1013, accuracy=0.9580, gradient_norm=0.0869, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 188: loss=0.0834, accuracy=0.9672, gradient_norm=0.1059, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 189: loss=0.0885, accuracy=0.9598, gradient_norm=0.0874, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 190: loss=0.0416, accuracy=0.9859, gradient_norm=0.0806, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 191: loss=0.0971, accuracy=0.9642, gradient_norm=0.1207, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 192: loss=0.0987, accuracy=0.9627, gradient_norm=0.1106, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 193: loss=0.0108, accuracy=0.9978, gradient_norm=0.0321, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 194: loss=0.1134, accuracy=0.9513, gradient_norm=0.1132, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 195: loss=0.1063, accuracy=0.9593, gradient_norm=0.1098, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 196: loss=0.0690, accuracy=0.9769, gradient_norm=0.0906, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 197: loss=0.0772, accuracy=0.9638, gradient_norm=0.0626, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 198: loss=0.1398, accuracy=0.9435, gradient_norm=0.1219, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 199: loss=0.1061, accuracy=0.9594, gradient_norm=0.1072, 
[2025-09-18 11:23:53,796][__main__][INFO] - Train, Round 200: loss=0.0799, accuracy=0.9707, gradient_norm=0.1038, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 001: loss=1.0356, accuracy=0.6014, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 002: loss=0.6496, accuracy=0.5853, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 003: loss=0.7632, accuracy=0.6213, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 004: loss=0.7722, accuracy=0.6113, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 005: loss=0.7978, accuracy=0.5580, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 006: loss=0.4615, accuracy=0.7230, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 007: loss=0.6553, accuracy=0.6449, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 008: loss=1.0194, accuracy=0.5913, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 009: loss=0.6756, accuracy=0.6240, 
[2025-09-18 11:23:53,796][__main__][INFO] - Test, Round 010: loss=0.5978, accuracy=0.6376, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 011: loss=0.6157, accuracy=0.5862, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 012: loss=0.4696, accuracy=0.7327, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 013: loss=0.5690, accuracy=0.6824, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 014: loss=0.4863, accuracy=0.7066, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 015: loss=0.7844, accuracy=0.5673, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 016: loss=0.9336, accuracy=0.7018, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 017: loss=0.7194, accuracy=0.6031, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 018: loss=0.6002, accuracy=0.6663, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 019: loss=0.4910, accuracy=0.7266, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 020: loss=0.5625, accuracy=0.7082, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 021: loss=0.7731, accuracy=0.6452, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 022: loss=0.6658, accuracy=0.6146, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 023: loss=0.6949, accuracy=0.6736, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 024: loss=0.7074, accuracy=0.5787, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 025: loss=0.5417, accuracy=0.7241, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 026: loss=0.6056, accuracy=0.6748, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 027: loss=0.6219, accuracy=0.7175, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 028: loss=0.6174, accuracy=0.7143, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 029: loss=0.7042, accuracy=0.6553, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 030: loss=0.4961, accuracy=0.7729, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 031: loss=0.5808, accuracy=0.7602, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 032: loss=0.5701, accuracy=0.7003, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 033: loss=0.6774, accuracy=0.6927, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 034: loss=0.6023, accuracy=0.6627, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 035: loss=0.6248, accuracy=0.6617, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 036: loss=0.5046, accuracy=0.7918, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 037: loss=0.5757, accuracy=0.7384, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 038: loss=0.5264, accuracy=0.7539, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 039: loss=0.5864, accuracy=0.7312, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 040: loss=0.6448, accuracy=0.6882, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 041: loss=0.5420, accuracy=0.7818, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 042: loss=0.5285, accuracy=0.7691, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 043: loss=0.5928, accuracy=0.7116, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 044: loss=0.5141, accuracy=0.7696, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 045: loss=0.4769, accuracy=0.7964, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 046: loss=0.5241, accuracy=0.7520, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 047: loss=0.5851, accuracy=0.7345, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 048: loss=0.5967, accuracy=0.7205, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 049: loss=0.4211, accuracy=0.8356, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 050: loss=0.5975, accuracy=0.7218, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 051: loss=0.5423, accuracy=0.7804, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 052: loss=0.6010, accuracy=0.7423, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 053: loss=0.4668, accuracy=0.8020, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 054: loss=0.5628, accuracy=0.7675, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 055: loss=0.5643, accuracy=0.7686, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 056: loss=0.5243, accuracy=0.7480, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 057: loss=0.5846, accuracy=0.7132, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 058: loss=0.6088, accuracy=0.7042, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 059: loss=0.5442, accuracy=0.7777, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 060: loss=0.5249, accuracy=0.7691, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 061: loss=0.5219, accuracy=0.7736, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 062: loss=0.5575, accuracy=0.7591, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 063: loss=0.6090, accuracy=0.7618, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 064: loss=0.4611, accuracy=0.8145, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 065: loss=0.5036, accuracy=0.8084, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 066: loss=0.5734, accuracy=0.7793, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 067: loss=0.3999, accuracy=0.8702, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 068: loss=0.5664, accuracy=0.7645, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 069: loss=0.5502, accuracy=0.7650, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 070: loss=0.5369, accuracy=0.7655, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 071: loss=0.5637, accuracy=0.7882, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 072: loss=0.5641, accuracy=0.7679, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 073: loss=0.5484, accuracy=0.7418, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 074: loss=0.4754, accuracy=0.8185, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 075: loss=0.5633, accuracy=0.7711, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 076: loss=0.5212, accuracy=0.7884, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 077: loss=0.5720, accuracy=0.7591, 
[2025-09-18 11:23:53,797][__main__][INFO] - Test, Round 078: loss=0.4944, accuracy=0.8138, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 079: loss=0.5248, accuracy=0.7855, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 080: loss=0.5608, accuracy=0.8004, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 081: loss=0.4691, accuracy=0.8498, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 082: loss=0.4390, accuracy=0.8470, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 083: loss=0.5535, accuracy=0.8091, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 084: loss=0.5986, accuracy=0.7664, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 085: loss=0.5252, accuracy=0.8158, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 086: loss=0.4797, accuracy=0.8211, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 087: loss=0.4954, accuracy=0.8238, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 088: loss=0.6107, accuracy=0.7484, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 089: loss=0.4505, accuracy=0.8625, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 090: loss=0.5167, accuracy=0.7947, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 091: loss=0.5109, accuracy=0.8347, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 092: loss=0.6023, accuracy=0.7335, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 093: loss=0.6329, accuracy=0.7325, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 094: loss=0.5118, accuracy=0.8140, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 095: loss=0.4915, accuracy=0.8401, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 096: loss=0.5048, accuracy=0.7920, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 097: loss=0.4532, accuracy=0.8575, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 098: loss=0.5056, accuracy=0.8215, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 099: loss=0.5837, accuracy=0.8112, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 100: loss=0.5167, accuracy=0.8074, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 101: loss=0.4298, accuracy=0.8629, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 102: loss=0.5193, accuracy=0.8120, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 103: loss=0.5063, accuracy=0.8238, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 104: loss=0.4864, accuracy=0.8311, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 105: loss=0.5005, accuracy=0.8255, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 106: loss=0.4920, accuracy=0.8364, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 107: loss=0.4826, accuracy=0.8318, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 108: loss=0.5418, accuracy=0.8111, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 109: loss=0.6343, accuracy=0.7523, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 110: loss=0.6821, accuracy=0.7182, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 111: loss=0.5183, accuracy=0.8049, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 112: loss=0.4186, accuracy=0.8790, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 113: loss=0.5388, accuracy=0.8372, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 114: loss=0.5709, accuracy=0.7889, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 115: loss=0.5531, accuracy=0.8192, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 116: loss=0.4427, accuracy=0.8518, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 117: loss=0.4682, accuracy=0.8510, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 118: loss=0.5366, accuracy=0.8116, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 119: loss=0.5811, accuracy=0.8011, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 120: loss=0.5182, accuracy=0.8120, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 121: loss=0.4490, accuracy=0.8490, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 122: loss=0.5913, accuracy=0.8202, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 123: loss=0.5015, accuracy=0.8367, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 124: loss=0.4584, accuracy=0.8593, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 125: loss=0.3989, accuracy=0.8837, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 126: loss=0.5225, accuracy=0.8200, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 127: loss=0.5121, accuracy=0.8302, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 128: loss=0.6203, accuracy=0.8093, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 129: loss=0.4772, accuracy=0.8629, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 130: loss=0.5293, accuracy=0.8011, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 131: loss=0.4512, accuracy=0.8702, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 132: loss=0.6419, accuracy=0.7402, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 133: loss=0.5630, accuracy=0.7976, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 134: loss=0.5886, accuracy=0.8056, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 135: loss=0.5554, accuracy=0.8309, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 136: loss=0.5766, accuracy=0.8389, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 137: loss=0.4092, accuracy=0.8631, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 138: loss=0.4546, accuracy=0.8656, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 139: loss=0.4575, accuracy=0.8630, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 140: loss=0.6190, accuracy=0.7931, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 141: loss=0.5055, accuracy=0.8639, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 142: loss=0.5788, accuracy=0.8282, 
[2025-09-18 11:23:53,798][__main__][INFO] - Test, Round 143: loss=0.6241, accuracy=0.7913, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 144: loss=0.4928, accuracy=0.8321, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 145: loss=0.6096, accuracy=0.8093, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 146: loss=0.4682, accuracy=0.8623, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 147: loss=0.5290, accuracy=0.8517, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 148: loss=0.5067, accuracy=0.8364, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 149: loss=0.5885, accuracy=0.7996, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 150: loss=0.5458, accuracy=0.8721, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 151: loss=0.5629, accuracy=0.8120, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 152: loss=0.6507, accuracy=0.7940, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 153: loss=0.6101, accuracy=0.8341, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 154: loss=0.5137, accuracy=0.8604, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 155: loss=0.4482, accuracy=0.8753, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 156: loss=0.5801, accuracy=0.8465, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 157: loss=0.6076, accuracy=0.8374, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 158: loss=0.5747, accuracy=0.8517, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 159: loss=0.8597, accuracy=0.8080, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 160: loss=0.4611, accuracy=0.8619, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 161: loss=0.5727, accuracy=0.8534, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 162: loss=0.5186, accuracy=0.8377, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 163: loss=0.4363, accuracy=0.9020, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 164: loss=0.5519, accuracy=0.8600, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 165: loss=0.4642, accuracy=0.8793, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 166: loss=0.6053, accuracy=0.8200, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 167: loss=0.5157, accuracy=0.8556, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 168: loss=0.6622, accuracy=0.8311, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 169: loss=0.6214, accuracy=0.8165, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 170: loss=0.5134, accuracy=0.8662, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 171: loss=0.5642, accuracy=0.8408, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 172: loss=0.5877, accuracy=0.8356, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 173: loss=0.4915, accuracy=0.8683, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 174: loss=0.5721, accuracy=0.8547, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 175: loss=0.4838, accuracy=0.8601, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 176: loss=0.4127, accuracy=0.8848, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 177: loss=0.5037, accuracy=0.8666, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 178: loss=0.3975, accuracy=0.8981, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 179: loss=0.5689, accuracy=0.8704, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 180: loss=0.5414, accuracy=0.8509, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 181: loss=0.4710, accuracy=0.8865, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 182: loss=0.6063, accuracy=0.8247, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 183: loss=0.6191, accuracy=0.8327, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 184: loss=0.6192, accuracy=0.8244, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 185: loss=0.5438, accuracy=0.8503, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 186: loss=0.6747, accuracy=0.7956, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 187: loss=0.4729, accuracy=0.8755, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 188: loss=0.6384, accuracy=0.8482, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 189: loss=0.5007, accuracy=0.8448, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 190: loss=0.7086, accuracy=0.8439, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 191: loss=0.5207, accuracy=0.8574, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 192: loss=0.6393, accuracy=0.8300, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 193: loss=0.5438, accuracy=0.8921, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 194: loss=0.6004, accuracy=0.8311, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 195: loss=0.6363, accuracy=0.8256, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 196: loss=0.4818, accuracy=0.8709, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 197: loss=0.4694, accuracy=0.8701, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 198: loss=0.6382, accuracy=0.8169, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 199: loss=0.6575, accuracy=0.8264, 
[2025-09-18 11:23:53,799][__main__][INFO] - Test, Round 200: loss=0.5035, accuracy=0.8609, 

[2025-09-17 15:14:59,745][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.276954406102498,  accuracy: 0.12816666666666668, gradient_norm : 286.3237828098231
[2025-09-17 15:15:00,352][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.24739735083321,  accuracy: 0.2655935613682093
[2025-09-17 15:15:03,040][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.26186230023702,  accuracy: 0.17166666666666666, gradient_norm : 288.94922427581514
[2025-09-17 15:15:03,647][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.2278404461306107,  accuracy: 0.32595573440643866
[2025-09-17 15:15:06,543][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 2.246523289969473,  accuracy: 0.18686868686868685, gradient_norm : 299.3687502525561
[2025-09-17 15:15:07,199][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.21149987318911,  accuracy: 0.29143897996357016
[2025-09-17 15:15:09,908][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 2.1978397591908774,  accuracy: 0.2673333333333333, gradient_norm : 320.90650870022813
[2025-09-17 15:15:10,508][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 2.1496770287940126,  accuracy: 0.3782435129740519
[2025-09-17 15:15:13,558][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 2.133767209269784,  accuracy: 0.34085858585858586, gradient_norm : 343.5482614138078
[2025-09-17 15:15:14,286][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 2.066599060040321,  accuracy: 0.38321167883211676
[2025-09-17 15:15:17,219][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 2.1435530070102575,  accuracy: 0.22848484848484849, gradient_norm : 324.31404751296986
[2025-09-17 15:15:17,880][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 2.1033245701880805,  accuracy: 0.32515894641235243
[2025-09-17 15:15:20,629][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 2.041809914112091,  accuracy: 0.29733333333333334, gradient_norm : 348.44522267559563
[2025-09-17 15:15:21,237][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 1.9920042975322827,  accuracy: 0.3756243756243756
[2025-09-17 15:15:24,188][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 2.026231922344728,  accuracy: 0.38010101010101005, gradient_norm : 331.28899627170335
[2025-09-17 15:15:24,900][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 1.9815447498112917,  accuracy: 0.4338235294117647
[2025-09-17 15:15:27,850][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 1.9831810248620583,  accuracy: 0.3908080808080808, gradient_norm : 324.597450515457
[2025-09-17 15:15:28,543][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 1.9410530343950338,  accuracy: 0.4471766848816029
[2025-09-17 15:15:31,586][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 1.9482274199977065,  accuracy: 0.43565656565656563, gradient_norm : 326.9915102561828
[2025-09-17 15:15:32,255][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 1.9043424219301301,  accuracy: 0.4621004566210046
[2025-09-17 15:15:35,203][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 1.9531722330685817,  accuracy: 0.3624242424242425, gradient_norm : 310.9233107210317
[2025-09-17 15:15:35,908][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 1.9259798246622086,  accuracy: 0.4163636363636364
[2025-09-17 15:15:38,876][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 1.942408524498795,  accuracy: 0.3995959595959596, gradient_norm : 302.1287356577681
[2025-09-17 15:15:39,602][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 1.9147075736023256,  accuracy: 0.44808743169398907
[2025-09-17 15:15:42,529][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 1.9054909328619638,  accuracy: 0.40520202020202023, gradient_norm : 323.6555980253565
[2025-09-17 15:15:43,200][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 1.8683200763216394,  accuracy: 0.46203110704483075
[2025-09-17 15:15:46,201][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 1.879243508613471,  accuracy: 0.3997474747474747, gradient_norm : 324.2059867274009
[2025-09-17 15:15:46,881][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 1.8405866323538254,  accuracy: 0.4656907593778591
[2025-09-17 15:15:49,891][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 1.9498770665941816,  accuracy: 0.3190909090909091, gradient_norm : 284.1534787835893
[2025-09-17 15:15:50,578][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 1.940228534923805,  accuracy: 0.38553113553113555
[2025-09-17 15:15:53,529][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 1.8962846147291588,  accuracy: 0.41707070707070704, gradient_norm : 302.48027841814434
[2025-09-17 15:15:54,193][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 1.8627902285738305,  accuracy: 0.45695970695970695
[2025-09-17 15:15:56,942][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 1.80152528633674,  accuracy: 0.5016111111111111, gradient_norm : 329.5619239032262
[2025-09-17 15:15:57,543][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 1.7569712061637364,  accuracy: 0.5140845070422535
[2025-09-17 15:16:00,560][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 1.858548844944347,  accuracy: 0.4419191919191919, gradient_norm : 309.02319039639684
[2025-09-17 15:16:01,244][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 1.8263318249607694,  accuracy: 0.495897903372835
[2025-09-17 15:16:03,956][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 1.7678442565600077,  accuracy: 0.5261666666666667, gradient_norm : 338.04541671346294
[2025-09-17 15:16:04,580][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 1.7157593191925478,  accuracy: 0.526579739217653
[2025-09-17 15:16:07,618][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 1.8483523509719155,  accuracy: 0.4352525252525253, gradient_norm : 308.8347903876072
[2025-09-17 15:16:08,303][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 1.8161055058677555,  accuracy: 0.47527472527472525
[2025-09-17 15:16:11,342][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 1.7688029106819267,  accuracy: 0.4636868686868687, gradient_norm : 338.20850480436116
[2025-09-17 15:16:12,021][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 1.7193218549238032,  accuracy: 0.4794144556267155
[2025-09-17 15:16:15,010][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 1.768035394766114,  accuracy: 0.4603030303030303, gradient_norm : 329.23992222501596
[2025-09-17 15:16:15,668][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 1.727429203254028,  accuracy: 0.5009124087591241
[2025-09-17 15:16:18,641][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 1.709133666934389,  accuracy: 0.5461616161616162, gradient_norm : 371.8788129944729
[2025-09-17 15:16:19,302][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 1.642741261606347,  accuracy: 0.5406392694063927
[2025-09-17 15:16:22,264][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 1.7081632607814037,  accuracy: 0.5073737373737373, gradient_norm : 356.27136441457066
[2025-09-17 15:16:22,945][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 1.6581648316605857,  accuracy: 0.5132662397072278
[2025-09-17 15:16:25,949][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 1.6824996238405054,  accuracy: 0.5139393939393939, gradient_norm : 361.9564137847386
[2025-09-17 15:16:26,634][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 1.6294599153094627,  accuracy: 0.5196706312900274
[2025-09-17 15:16:29,659][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 1.6227877969994688,  accuracy: 0.575050505050505, gradient_norm : 380.51572360096634
[2025-09-17 15:16:30,358][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 1.567120475265739,  accuracy: 0.5632393084622384
[2025-09-17 15:16:33,379][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 1.497374584458091,  accuracy: 0.6152020202020202, gradient_norm : 396.5803635874039
[2025-09-17 15:16:34,056][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 1.4245185869501364,  accuracy: 0.5892040256175664
[2025-09-17 15:16:37,021][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 1.7058683408932251,  accuracy: 0.5470707070707072, gradient_norm : 354.8138353046571
[2025-09-17 15:16:37,703][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 1.660636051702152,  accuracy: 0.5355191256830601
[2025-09-17 15:16:40,665][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 1.501232006333091,  accuracy: 0.6255050505050506, gradient_norm : 396.87602719965815
[2025-09-17 15:16:41,338][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 1.4340611701676709,  accuracy: 0.6189608021877848
[2025-09-17 15:16:44,424][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 1.6254116397012364,  accuracy: 0.546010101010101, gradient_norm : 364.6305589807444
[2025-09-17 15:16:45,078][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 1.5788074004954111,  accuracy: 0.5664845173041895
[2025-09-17 15:16:47,803][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 1.3780522276461125,  accuracy: 0.6341111111111111, gradient_norm : 368.1294364508946
[2025-09-17 15:16:48,419][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 1.343098385778362,  accuracy: 0.6142284569138277
[2025-09-17 15:16:51,136][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 1.5605132747689883,  accuracy: 0.5772777777777778, gradient_norm : 353.7580828469493
[2025-09-17 15:16:51,775][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 1.535369815536771,  accuracy: 0.5732931726907631
[2025-09-17 15:16:54,816][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 1.5643935749476605,  accuracy: 0.5876262626262625, gradient_norm : 363.43491073156207
[2025-09-17 15:16:55,503][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 1.5187828359538562,  accuracy: 0.5908675799086758
[2025-09-17 15:16:58,241][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 1.6660703146954376,  accuracy: 0.5344444444444444, gradient_norm : 343.5908592745829
[2025-09-17 15:16:58,875][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 1.6323898588418961,  accuracy: 0.549
[2025-09-17 15:17:01,892][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 1.4669220999334798,  accuracy: 0.6136868686868687, gradient_norm : 349.9397774596074
[2025-09-17 15:17:02,642][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 1.4499775415811784,  accuracy: 0.5943223443223443
[2025-09-17 15:17:05,685][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 1.4786418715209673,  accuracy: 0.5823737373737374, gradient_norm : 377.2549292777895
[2025-09-17 15:17:06,375][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 1.4377076354200982,  accuracy: 0.5835616438356165
[2025-09-17 15:17:09,385][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 1.5052731263818162,  accuracy: 0.6047979797979799, gradient_norm : 404.06734343998
[2025-09-17 15:17:10,046][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 1.4637786585990697,  accuracy: 0.5780821917808219
[2025-09-17 15:17:13,089][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 1.3706932592121037,  accuracy: 0.6266161616161615, gradient_norm : 365.4678958032365
[2025-09-17 15:17:13,797][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 1.3578799649446494,  accuracy: 0.6252285191956124
[2025-09-17 15:17:16,814][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 1.6226365899046262,  accuracy: 0.5914646464646465, gradient_norm : 359.63187125632373
[2025-09-17 15:17:17,541][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 1.5952949555953777,  accuracy: 0.5719489981785064
[2025-09-17 15:17:20,266][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 1.243386846681436,  accuracy: 0.6657777777777778, gradient_norm : 390.2373403944755
[2025-09-17 15:17:20,890][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 1.2179464020485147,  accuracy: 0.6519558676028084
[2025-09-17 15:17:23,965][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 1.4832532168563568,  accuracy: 0.5534343434343435, gradient_norm : 345.00944446974694
[2025-09-17 15:17:24,665][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 1.482466417486253,  accuracy: 0.5443840579710145
[2025-09-17 15:17:27,704][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 1.394385396711754,  accuracy: 0.6284343434343435, gradient_norm : 369.1043720046901
[2025-09-17 15:17:28,396][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 1.370582748612348,  accuracy: 0.6058394160583942
[2025-09-17 15:17:31,331][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 1.4765916734708078,  accuracy: 0.6269696969696968, gradient_norm : 349.2721158893236
[2025-09-17 15:17:32,053][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 1.46690365707623,  accuracy: 0.5976168652612283
[2025-09-17 15:17:35,093][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 1.463192838136897,  accuracy: 0.611010101010101, gradient_norm : 367.8815742782324
[2025-09-17 15:17:35,814][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 1.4546737543640345,  accuracy: 0.6049270072992701
[2025-09-17 15:17:38,534][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 1.3487190387646357,  accuracy: 0.657611111111111, gradient_norm : 367.2535988947151
[2025-09-17 15:17:39,177][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 1.3452945476500833,  accuracy: 0.6130653266331658
[2025-09-17 15:17:42,226][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 1.4320085316896438,  accuracy: 0.6383838383838385, gradient_norm : 372.49864699591944
[2025-09-17 15:17:42,938][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 1.4295894269123268,  accuracy: 0.6125226860254084
[2025-09-17 15:17:46,003][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 1.3172809700396928,  accuracy: 0.6418181818181818, gradient_norm : 391.22251310428413
[2025-09-17 15:17:46,723][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 1.2861649201903151,  accuracy: 0.6318681318681318
[2025-09-17 15:17:49,820][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 1.31919109726494,  accuracy: 0.6565656565656566, gradient_norm : 354.00430912291154
[2025-09-17 15:17:50,530][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 1.344538050365972,  accuracy: 0.6263736263736264
[2025-09-17 15:17:53,582][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 1.3707056808878075,  accuracy: 0.6604545454545453, gradient_norm : 372.2458753257532
[2025-09-17 15:17:54,372][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 1.369377564455642,  accuracy: 0.6275045537340619
[2025-09-17 15:17:57,389][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 1.2948075149434082,  accuracy: 0.6615151515151515, gradient_norm : 386.02770418892834
[2025-09-17 15:17:58,093][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 1.2864851607433867,  accuracy: 0.6520947176684881
[2025-09-17 15:18:00,794][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 1.111635239670674,  accuracy: 0.7022222222222223, gradient_norm : 335.80455140340354
[2025-09-17 15:18:01,446][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 1.143391806534838,  accuracy: 0.6750503018108652
[2025-09-17 15:18:04,452][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 1.4118096314370632,  accuracy: 0.6514646464646465, gradient_norm : 371.9194376285247
[2025-09-17 15:18:05,196][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 1.4101428635566617,  accuracy: 0.6274864376130199
[2025-09-17 15:18:08,159][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 1.020739149866682,  accuracy: 0.7244444444444444, gradient_norm : 358.9172338952732
[2025-09-17 15:18:08,850][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 1.0531764665659327,  accuracy: 0.6651459854014599
[2025-09-17 15:18:11,849][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 1.1274494692796106,  accuracy: 0.7161616161616162, gradient_norm : 355.0732931336039
[2025-09-17 15:18:12,523][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 1.1446426704211807,  accuracy: 0.6846929422548121
[2025-09-17 15:18:15,581][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 1.2519188367959224,  accuracy: 0.6849494949494949, gradient_norm : 355.38488176724314
[2025-09-17 15:18:16,265][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 1.2678855892615044,  accuracy: 0.6495882891125343
[2025-09-17 15:18:19,345][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 1.2116739376589205,  accuracy: 0.6835353535353534, gradient_norm : 373.4056789180997
[2025-09-17 15:18:20,062][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 1.2067575538429347,  accuracy: 0.6454545454545455
[2025-09-17 15:18:22,784][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 1.1746552002678314,  accuracy: 0.6920555555555556, gradient_norm : 370.69953708213353
[2025-09-17 15:18:23,461][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 1.1735415688847586,  accuracy: 0.6599799398194583
[2025-09-17 15:18:26,541][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 1.199945958771489,  accuracy: 0.6809595959595959, gradient_norm : 349.5072029993639
[2025-09-17 15:18:27,260][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 1.2140878401424764,  accuracy: 0.6642335766423357
[2025-09-17 15:18:30,285][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 1.0635487911827637,  accuracy: 0.7147979797979797, gradient_norm : 340.7060964100291
[2025-09-17 15:18:31,032][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.1160292489396682,  accuracy: 0.6660617059891107
[2025-09-17 15:18:34,071][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 1.146088028631427,  accuracy: 0.7045959595959597, gradient_norm : 366.0834887069863
[2025-09-17 15:18:34,785][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.1740451750696683,  accuracy: 0.6703096539162113
[2025-09-17 15:18:37,877][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 1.1444840124159148,  accuracy: 0.7010101010101011, gradient_norm : 382.62459116532085
[2025-09-17 15:18:38,575][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 1.1580968583907787,  accuracy: 0.6693914623069936
[2025-09-17 15:18:41,642][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 0.948390775151325,  accuracy: 0.7496969696969695, gradient_norm : 325.85346632272007
[2025-09-17 15:18:42,357][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.0140301595549261,  accuracy: 0.6974405850091407
[2025-09-17 15:18:45,074][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 1.0544791303326686,  accuracy: 0.7265, gradient_norm : 346.6442900961184
[2025-09-17 15:18:45,728][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.1018576240419742,  accuracy: 0.6773869346733669
[2025-09-17 15:18:48,765][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 1.0358551514758305,  accuracy: 0.7206565656565658, gradient_norm : 354.6413029723917
[2025-09-17 15:18:49,482][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.0960520187723135,  accuracy: 0.6837294332723949
[2025-09-17 15:18:52,481][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 0.9890866669910875,  accuracy: 0.7293939393939394, gradient_norm : 340.59270651447065
[2025-09-17 15:18:53,220][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.0442592452378034,  accuracy: 0.6776255707762557
[2025-09-17 15:18:56,195][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 1.053173051164909,  accuracy: 0.7235858585858584, gradient_norm : 367.3324601720648
[2025-09-17 15:18:56,947][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.0988939236169748,  accuracy: 0.676094890510949
[2025-09-17 15:18:59,975][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 1.0249954662878404,  accuracy: 0.7392929292929292, gradient_norm : 331.18708848091376
[2025-09-17 15:19:00,657][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.0953211549309867,  accuracy: 0.6958105646630237
[2025-09-17 15:19:03,731][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 0.9471270244342811,  accuracy: 0.7456565656565656, gradient_norm : 340.55657559304086
[2025-09-17 15:19:04,463][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.0280862726677549,  accuracy: 0.6872727272727273
[2025-09-17 15:19:07,573][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 1.0769948417038628,  accuracy: 0.7145454545454546, gradient_norm : 362.4404908437255
[2025-09-17 15:19:08,272][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.1136854464944812,  accuracy: 0.6848816029143898
[2025-09-17 15:19:11,281][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 1.251273116017833,  accuracy: 0.6477272727272727, gradient_norm : 354.0606655568666
[2025-09-17 15:19:11,996][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.2815320333981925,  accuracy: 0.628519527702089
[2025-09-17 15:19:14,783][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 1.0648383533706267,  accuracy: 0.7188333333333333, gradient_norm : 368.88729648970923
[2025-09-17 15:19:15,427][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.0811533684457713,  accuracy: 0.6945273631840796
[2025-09-17 15:19:18,518][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 0.8908757659747745,  accuracy: 0.7547979797979797, gradient_norm : 325.6162625690808
[2025-09-17 15:19:19,220][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 0.9561883005165104,  accuracy: 0.7192028985507246
[2025-09-17 15:19:21,982][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 0.8608999462984502,  accuracy: 0.7609444444444443, gradient_norm : 301.55614774654885
[2025-09-17 15:19:22,645][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.010090877692304,  accuracy: 0.6944723618090453
[2025-09-17 15:19:25,655][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 0.9783575376495719,  accuracy: 0.7385858585858587, gradient_norm : 339.81529210542374
[2025-09-17 15:19:26,357][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.0493821053065522,  accuracy: 0.6952554744525548
[2025-09-17 15:19:29,417][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 0.9342396249599529,  accuracy: 0.733030303030303, gradient_norm : 293.490672147468
[2025-09-17 15:19:30,136][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.0446364256836798,  accuracy: 0.6965579710144928
[2025-09-17 15:19:33,185][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 0.8874567726401217,  accuracy: 0.7509595959595959, gradient_norm : 309.57529984222384
[2025-09-17 15:19:33,901][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 0.9705411156917589,  accuracy: 0.7031674208144797
[2025-09-17 15:19:36,933][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 0.8907299652074774,  accuracy: 0.7513131313131314, gradient_norm : 321.1038739735752
[2025-09-17 15:19:37,628][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 0.9533836608335852,  accuracy: 0.7159817351598173
[2025-09-17 15:19:40,704][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 0.8866443476696132,  accuracy: 0.7443434343434344, gradient_norm : 286.7912560034047
[2025-09-17 15:19:41,428][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 0.9825672900752864,  accuracy: 0.6952554744525548
[2025-09-17 15:19:44,521][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 0.850478435900401,  accuracy: 0.7660606060606061, gradient_norm : 292.59878656376185
[2025-09-17 15:19:45,240][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 0.9668195342821796,  accuracy: 0.7198905109489051
[2025-09-17 15:19:48,360][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 0.9181368263551232,  accuracy: 0.7456060606060606, gradient_norm : 317.61814378178855
[2025-09-17 15:19:49,077][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.0104812212574417,  accuracy: 0.7020109689213894
[2025-09-17 15:19:52,179][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 0.9627720737392365,  accuracy: 0.7417171717171717, gradient_norm : 291.8811408040546
[2025-09-17 15:19:52,903][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.0603880714133613,  accuracy: 0.7088262056414922
[2025-09-17 15:19:55,923][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 0.7262322377018404,  accuracy: 0.783080808080808, gradient_norm : 253.8548121141939
[2025-09-17 15:19:56,632][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 0.862068866730825,  accuracy: 0.7242009132420091
[2025-09-17 15:19:59,654][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 0.7675285620699552,  accuracy: 0.7718181818181818, gradient_norm : 265.54917096735
[2025-09-17 15:20:00,366][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 0.8977702230187955,  accuracy: 0.7206551410373067
[2025-09-17 15:20:03,093][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 0.8413431940972805,  accuracy: 0.7693333333333335, gradient_norm : 299.91199652503474
[2025-09-17 15:20:03,754][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 0.9599223985816493,  accuracy: 0.7161616161616161
[2025-09-17 15:20:06,747][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 0.6310431008565832,  accuracy: 0.804141414141414, gradient_norm : 223.81341324784506
[2025-09-17 15:20:07,467][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 0.8101685571626825,  accuracy: 0.7268560953253895
[2025-09-17 15:20:10,516][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 0.7337715841857999,  accuracy: 0.7793434343434343, gradient_norm : 253.83739216715358
[2025-09-17 15:20:11,215][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 0.8716248050944446,  accuracy: 0.7269406392694064
[2025-09-17 15:20:14,285][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 0.7519194646032922,  accuracy: 0.7882828282828281, gradient_norm : 269.96529477233287
[2025-09-17 15:20:14,977][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 0.9099558443103456,  accuracy: 0.7093235831809872
[2025-09-17 15:20:17,737][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 0.9446757805161178,  accuracy: 0.745611111111111, gradient_norm : 286.85503993068926
[2025-09-17 15:20:18,427][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.0711819488921004,  accuracy: 0.6923847695390781
[2025-09-17 15:20:21,450][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 0.6693257892645444,  accuracy: 0.7934848484848485, gradient_norm : 227.6277676129773
[2025-09-17 15:20:22,155][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 0.8231136265138513,  accuracy: 0.7342465753424657
[2025-09-17 15:20:25,185][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 0.7542557962944336,  accuracy: 0.7745959595959594, gradient_norm : 267.4634932468367
[2025-09-17 15:20:25,861][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 0.8826318077607588,  accuracy: 0.7009090909090909
[2025-09-17 15:20:28,871][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 0.8266191404820843,  accuracy: 0.7625757575757576, gradient_norm : 272.9331719787198
[2025-09-17 15:20:29,609][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 0.9743711617378055,  accuracy: 0.6996370235934665
[2025-09-17 15:20:32,649][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 0.6730356471838824,  accuracy: 0.7959595959595961, gradient_norm : 240.2053153816023
[2025-09-17 15:20:33,340][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 0.8498634002980192,  accuracy: 0.7358318098720292
[2025-09-17 15:20:36,342][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 0.7306965848882542,  accuracy: 0.7837878787878788, gradient_norm : 257.6779516259076
[2025-09-17 15:20:37,021][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 0.8637933741355764,  accuracy: 0.7286751361161524
[2025-09-17 15:20:40,038][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 0.8965868551396963,  accuracy: 0.7472222222222221, gradient_norm : 297.49459380725847
[2025-09-17 15:20:40,787][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 0.9834835240005577,  accuracy: 0.708029197080292
[2025-09-17 15:20:43,847][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 0.668075910605716,  accuracy: 0.7905050505050506, gradient_norm : 233.1191675658142
[2025-09-17 15:20:44,582][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 0.8099097306083052,  accuracy: 0.7293369663941871
[2025-09-17 15:20:47,593][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 0.6991390045393597,  accuracy: 0.786212121212121, gradient_norm : 246.40313981288992
[2025-09-17 15:20:48,340][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 0.8433128723115081,  accuracy: 0.7338782924613987
[2025-09-17 15:20:51,410][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 0.7369598720702484,  accuracy: 0.790050505050505, gradient_norm : 249.79814146701756
[2025-09-17 15:20:52,147][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 0.8875803986333147,  accuracy: 0.7326642335766423
[2025-09-17 15:20:55,191][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 0.8074656816481641,  accuracy: 0.7707575757575758, gradient_norm : 265.825256520137
[2025-09-17 15:20:55,908][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 0.9490414204171104,  accuracy: 0.7208029197080292
[2025-09-17 15:20:58,911][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 0.6626609437619195,  accuracy: 0.7983333333333333, gradient_norm : 235.6995472758463
[2025-09-17 15:20:59,610][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 0.8404497452250355,  accuracy: 0.7269406392694064
[2025-09-17 15:21:02,672][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 0.6551884225823662,  accuracy: 0.7960101010101011, gradient_norm : 232.24612669339578
[2025-09-17 15:21:03,400][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 0.8205688165113343,  accuracy: 0.7384196185286104
[2025-09-17 15:21:06,149][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 0.6974748562943811,  accuracy: 0.7891111111111112, gradient_norm : 247.5896809755442
[2025-09-17 15:21:06,807][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 0.8755069056886339,  accuracy: 0.7409274193548387
[2025-09-17 15:21:09,846][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 0.6219103864634015,  accuracy: 0.8158080808080808, gradient_norm : 221.37545805747456
[2025-09-17 15:21:10,592][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 0.8433383392463282,  accuracy: 0.740673339399454
[2025-09-17 15:21:13,346][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 0.6357700070746554,  accuracy: 0.8075, gradient_norm : 227.79311171610024
[2025-09-17 15:21:13,986][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 0.8095027127538819,  accuracy: 0.7329317269076305
[2025-09-17 15:21:17,006][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 0.7384236445509349,  accuracy: 0.7825252525252526, gradient_norm : 251.3139914926373
[2025-09-17 15:21:17,706][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 0.895832698839892,  accuracy: 0.7212065813528337
[2025-09-17 15:21:20,720][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 0.674267946042572,  accuracy: 0.7983333333333333, gradient_norm : 240.41927705319688
[2025-09-17 15:21:21,473][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 0.8559855692068302,  accuracy: 0.7275204359673024
[2025-09-17 15:21:24,588][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 0.6264228569922234,  accuracy: 0.7999494949494949, gradient_norm : 217.34317733447585
[2025-09-17 15:21:25,296][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 0.8134275584518096,  accuracy: 0.7306642402183804
[2025-09-17 15:21:28,398][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 0.7035385119418304,  accuracy: 0.7877777777777777, gradient_norm : 242.1909997291427
[2025-09-17 15:21:29,090][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 0.8688893051869279,  accuracy: 0.7247706422018348
[2025-09-17 15:21:31,780][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 0.5487891282948355,  accuracy: 0.8221666666666667, gradient_norm : 192.01378931359395
[2025-09-17 15:21:32,494][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 0.7732838940632415,  accuracy: 0.7515090543259557
[2025-09-17 15:21:35,527][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 0.7043914465219573,  accuracy: 0.795757575757576, gradient_norm : 246.60505643795693
[2025-09-17 15:21:36,234][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 0.8901663315874753,  accuracy: 0.7152014652014652
[2025-09-17 15:21:39,246][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 0.7180798219107656,  accuracy: 0.7813131313131314, gradient_norm : 250.8486161587556
[2025-09-17 15:21:39,975][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 0.8608997448379858,  accuracy: 0.7349177330895795
[2025-09-17 15:21:43,112][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 0.6694369333203544,  accuracy: 0.79989898989899, gradient_norm : 233.54853830845605
[2025-09-17 15:21:43,825][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 0.8577731293710795,  accuracy: 0.7118181818181818
[2025-09-17 15:21:46,890][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 0.6459300251084973,  accuracy: 0.8006565656565656, gradient_norm : 222.32129543368154
[2025-09-17 15:21:47,598][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 0.8297644894915617,  accuracy: 0.7337006427915519
[2025-09-17 15:21:50,615][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 0.6634260819491112,  accuracy: 0.7928282828282828, gradient_norm : 231.89299984554827
[2025-09-17 15:21:51,313][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 0.84551077554089,  accuracy: 0.7265268915223336
[2025-09-17 15:21:54,357][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 0.650988128891384,  accuracy: 0.8012121212121214, gradient_norm : 228.6609169492158
[2025-09-17 15:21:55,070][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 0.83838659317656,  accuracy: 0.7327272727272728
[2025-09-17 15:21:57,812][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 0.5395453641175603,  accuracy: 0.8185, gradient_norm : 183.24002251343126
[2025-09-17 15:21:58,496][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 0.7522088741992321,  accuracy: 0.7525150905432596
[2025-09-17 15:22:01,548][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 0.6519531167676729,  accuracy: 0.8001010101010102, gradient_norm : 228.07366493709708
[2025-09-17 15:22:02,231][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 0.8251534452086517,  accuracy: 0.7387717690192483
[2025-09-17 15:22:05,009][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 0.5824411650048569,  accuracy: 0.8187777777777777, gradient_norm : 200.25990110879928
[2025-09-17 15:22:05,672][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 0.8351999808806013,  accuracy: 0.7279116465863453
[2025-09-17 15:22:08,729][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 0.657836028389548,  accuracy: 0.8013636363636365, gradient_norm : 233.72188861126722
[2025-09-17 15:22:09,467][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 0.8671998411986479,  accuracy: 0.7306642402183804
[2025-09-17 15:22:12,470][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 0.6227666814007203,  accuracy: 0.8053535353535353, gradient_norm : 220.7331369701971
[2025-09-17 15:22:13,184][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 0.8095637004781555,  accuracy: 0.7371794871794872
[2025-09-17 15:22:16,235][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 0.5714784927398079,  accuracy: 0.8201010101010103, gradient_norm : 199.4488473823806
[2025-09-17 15:22:16,945][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 0.7866277518622372,  accuracy: 0.7477064220183486
[2025-09-17 15:22:19,952][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 0.5786678145399712,  accuracy: 0.8111111111111111, gradient_norm : 205.08507652360788
[2025-09-17 15:22:20,668][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 0.7842621930736754,  accuracy: 0.7361237488626023
[2025-09-17 15:22:23,688][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 0.5319914661411366,  accuracy: 0.8243434343434343, gradient_norm : 186.39144995653152
[2025-09-17 15:22:24,437][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 0.7688794900837554,  accuracy: 0.7470319634703196
[2025-09-17 15:22:27,411][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 0.583975091491205,  accuracy: 0.8107575757575756, gradient_norm : 199.84240146077636
[2025-09-17 15:22:28,109][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 0.7847857675595915,  accuracy: 0.7351598173515982
[2025-09-17 15:22:31,143][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 0.5422282646135004,  accuracy: 0.8197979797979799, gradient_norm : 184.16932278828094
[2025-09-17 15:22:31,816][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 0.7652462733018658,  accuracy: 0.7463768115942029
[2025-09-17 15:22:34,893][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 0.610281819917939,  accuracy: 0.806060606060606, gradient_norm : 213.35163911875864
[2025-09-17 15:22:35,631][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 0.8184344535642635,  accuracy: 0.726775956284153
[2025-09-17 15:22:38,645][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 0.6451409747929905,  accuracy: 0.8096464646464647, gradient_norm : 227.0615862884908
[2025-09-17 15:22:39,337][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 0.855148332982982,  accuracy: 0.718348623853211
[2025-09-17 15:22:42,420][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 0.5302179538320299,  accuracy: 0.826060606060606, gradient_norm : 188.51862500791515
[2025-09-17 15:22:43,111][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 0.7873182128637265,  accuracy: 0.7472527472527473
[2025-09-17 15:22:46,210][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 0.5536353812997483,  accuracy: 0.8175757575757576, gradient_norm : 189.77130541226472
[2025-09-17 15:22:46,923][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 0.8300744964046912,  accuracy: 0.7227272727272728
[2025-09-17 15:22:50,009][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 0.5668378063696295,  accuracy: 0.8241414141414141, gradient_norm : 197.88770463091788
[2025-09-17 15:22:50,723][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 0.7959314902008827,  accuracy: 0.732484076433121
[2025-09-17 15:22:53,751][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 0.5809347050970025,  accuracy: 0.8172222222222223, gradient_norm : 200.39222608287307
[2025-09-17 15:22:54,463][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 0.7984887769319353,  accuracy: 0.7447963800904978
[2025-09-17 15:22:57,527][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 0.5640883496031165,  accuracy: 0.8214141414141415, gradient_norm : 197.29953568322188
[2025-09-17 15:22:58,252][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 0.7768699197821278,  accuracy: 0.7622950819672131
[2025-09-17 15:23:01,242][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 0.5287915132735207,  accuracy: 0.820858585858586, gradient_norm : 180.4983364961344
[2025-09-17 15:23:01,954][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 0.7717626594237725,  accuracy: 0.738615664845173
[2025-09-17 15:23:04,961][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 0.602686136033894,  accuracy: 0.8143939393939392, gradient_norm : 216.28807035954267
[2025-09-17 15:23:05,728][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 0.8369871212346275,  accuracy: 0.7281021897810219
[2025-09-17 15:23:08,781][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 0.5094029507557438,  accuracy: 0.8283333333333334, gradient_norm : 174.69874575588884
[2025-09-17 15:23:09,522][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 0.7454181374412764,  accuracy: 0.7432188065099458
[2025-09-17 15:23:12,297][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 0.476890787895148,  accuracy: 0.8367222222222221, gradient_norm : 167.8523925474163
[2025-09-17 15:23:12,939][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 0.7308730993483279,  accuracy: 0.7487487487487487
[2025-09-17 15:23:16,038][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 0.4839978877497329,  accuracy: 0.8388888888888889, gradient_norm : 173.05701090975302
[2025-09-17 15:23:16,746][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 0.7498306319580653,  accuracy: 0.7385740402193784
[2025-09-17 15:23:19,707][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 0.5468937319661067,  accuracy: 0.8229292929292928, gradient_norm : 188.14485501071704
[2025-09-17 15:23:20,415][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 0.8003074417231406,  accuracy: 0.7343039126478617
[2025-09-17 15:23:23,406][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 0.5049231856454616,  accuracy: 0.8397979797979797, gradient_norm : 181.96229918488527
[2025-09-17 15:23:24,113][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 0.7793376687727018,  accuracy: 0.7315068493150685
[2025-09-17 15:23:27,129][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 0.5120310364157018,  accuracy: 0.828131313131313, gradient_norm : 180.51317215444422
[2025-09-17 15:23:27,867][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 0.7570251874348735,  accuracy: 0.7388939256572983
[2025-09-17 15:23:30,915][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 0.6163749312509247,  accuracy: 0.8001010101010102, gradient_norm : 215.09537697125015
[2025-09-17 15:23:31,613][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 0.8270632666229767,  accuracy: 0.7290145985401459
[2025-09-17 15:23:34,615][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 0.5565245713336591,  accuracy: 0.8158585858585857, gradient_norm : 190.65381552532187
[2025-09-17 15:23:35,318][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 0.7876313411497161,  accuracy: 0.7313974591651543
[2025-09-17 15:23:38,412][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 0.5210327338476693,  accuracy: 0.8259595959595959, gradient_norm : 178.92847901779362
[2025-09-17 15:23:39,118][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 0.7595541335132024,  accuracy: 0.736986301369863
[2025-09-17 15:23:42,183][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 0.48255211352723454,  accuracy: 0.834848484848485, gradient_norm : 165.87492458475202
[2025-09-17 15:23:42,892][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 0.7366566672134052,  accuracy: 0.7595628415300546
[2025-09-17 15:23:45,890][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 0.5147542107850314,  accuracy: 0.8260101010101011, gradient_norm : 175.8396580732973
[2025-09-17 15:23:46,626][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 0.7582507107131787,  accuracy: 0.7283500455788514
[2025-09-17 15:23:49,681][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 0.4998402981320396,  accuracy: 0.8423232323232323, gradient_norm : 184.80019776835317
[2025-09-17 15:23:50,408][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 0.7979575217586674,  accuracy: 0.7397260273972602
[2025-09-17 15:23:53,491][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 0.4986836487328577,  accuracy: 0.8336363636363637, gradient_norm : 171.02371069996744
[2025-09-17 15:23:54,221][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 0.736837972097518,  accuracy: 0.7513611615245009
[2025-09-17 15:23:57,309][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 0.4927689005042229,  accuracy: 0.8353030303030303, gradient_norm : 169.60351963737156
[2025-09-17 15:23:58,037][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 0.7989683494012502,  accuracy: 0.7488626023657871
[2025-09-17 15:24:01,067][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 0.4424665420513713,  accuracy: 0.8511616161616161, gradient_norm : 161.0543636953677
[2025-09-17 15:24:01,776][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 0.7660096179355275,  accuracy: 0.7472727272727273
[2025-09-17 15:24:04,854][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 0.4690320200110419,  accuracy: 0.8387373737373737, gradient_norm : 161.63464674676544
[2025-09-17 15:24:05,559][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 0.717863913485993,  accuracy: 0.7552511415525114
[2025-09-17 15:24:08,609][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 0.5302024685234452,  accuracy: 0.8225757575757576, gradient_norm : 181.43136071995988
[2025-09-17 15:24:09,362][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 0.7681534781127516,  accuracy: 0.7363138686131386
[2025-09-17 15:24:12,405][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 0.43781963980361593,  accuracy: 0.8530808080808079, gradient_norm : 161.43841629307263
[2025-09-17 15:24:13,106][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 0.7141826464124499,  accuracy: 0.7641165755919854
[2025-09-17 15:24:16,085][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 0.42737781713984796,  accuracy: 0.8529797979797981, gradient_norm : 164.89020331518353
[2025-09-17 15:24:16,800][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 0.7426025922646622,  accuracy: 0.7552320291173794
[2025-09-17 15:24:19,879][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 0.5454337062546983,  accuracy: 0.8194949494949495, gradient_norm : 182.4377699476267
[2025-09-17 15:24:20,573][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 0.7520197329714018,  accuracy: 0.7454044117647058
[2025-09-17 15:24:23,575][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 0.48204481227245805,  accuracy: 0.8351515151515152, gradient_norm : 170.94468539322213
[2025-09-17 15:24:24,270][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 0.7314221110106386,  accuracy: 0.7550274223034735
[2025-09-17 15:24:27,258][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 0.46496134838371567,  accuracy: 0.844848484848485, gradient_norm : 161.89484981678027
[2025-09-17 15:24:27,988][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 0.7298893472527849,  accuracy: 0.7529626253418414
[2025-09-17 15:24:30,735][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 0.4639322896115482,  accuracy: 0.8445555555555556, gradient_norm : 169.7005931817807
[2025-09-17 15:24:31,394][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 0.7364898223474802,  accuracy: 0.7530120481927711
[2025-09-17 15:24:34,428][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 0.43788620906698544,  accuracy: 0.8563131313131314, gradient_norm : 160.82516439191787
[2025-09-17 15:24:35,109][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 0.7566946634216692,  accuracy: 0.7410795974382434
[2025-09-17 15:24:38,121][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 0.45991723434047094,  accuracy: 0.8437878787878788, gradient_norm : 157.85905813992704
[2025-09-17 15:24:38,882][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 0.7418509403431448,  accuracy: 0.7565849227974568
[2025-09-17 15:24:41,913][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 0.4711422210128865,  accuracy: 0.8396464646464649, gradient_norm : 164.72658264830804
[2025-09-17 15:24:42,606][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 0.7578000657666814,  accuracy: 0.7481818181818182
[2025-09-17 15:24:45,655][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 0.41573551519717455,  accuracy: 0.8569191919191919, gradient_norm : 155.7802427011544
[2025-09-17 15:24:46,386][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 0.6880745655281948,  accuracy: 0.7604735883424408
[2025-09-17 15:24:49,451][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 0.443473955148577,  accuracy: 0.8493939393939395, gradient_norm : 158.31218371569753
[2025-09-17 15:24:50,165][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 0.7510148034458904,  accuracy: 0.7488667271078876
[2025-09-17 15:24:53,187][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 0.46789007633395324,  accuracy: 0.8426262626262624, gradient_norm : 164.9887153042049
[2025-09-17 15:24:53,908][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 0.7665674440109329,  accuracy: 0.7393278837420527
[2025-09-17 15:24:56,923][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 0.4549789169390516,  accuracy: 0.8473232323232324, gradient_norm : 168.39942627267263
[2025-09-17 15:24:57,656][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 0.7739137843714335,  accuracy: 0.7330895795246801
[2025-09-17 15:25:00,661][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 0.44605475658776633,  accuracy: 0.8480808080808082, gradient_norm : 162.0020568079252
[2025-09-17 15:25:01,356][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 0.7376970149462453,  accuracy: 0.7493237150586114
[2025-09-17 15:25:04,428][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 0.4373861011706829,  accuracy: 0.8532323232323233, gradient_norm : 159.83631630521296
[2025-09-17 15:25:05,121][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 0.7110885261676528,  accuracy: 0.7518181818181818
[2025-09-17 15:25:08,249][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 0.4202460024982098,  accuracy: 0.857070707070707, gradient_norm : 164.0281337472111
[2025-09-17 15:25:08,992][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 0.7419407978112047,  accuracy: 0.7527272727272727
[2025-09-17 15:25:12,045][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 0.42203680449659287,  accuracy: 0.8525252525252526, gradient_norm : 147.71446973288246
[2025-09-17 15:25:12,747][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 0.7096748734104126,  accuracy: 0.7588395285584769
[2025-09-17 15:25:15,486][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 0.4062077705577637,  accuracy: 0.8679444444444445, gradient_norm : 157.45029207609736
[2025-09-17 15:25:16,129][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 0.7545195491469685,  accuracy: 0.7587939698492462
[2025-09-17 15:25:19,161][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 0.4703702963609954,  accuracy: 0.8378787878787879, gradient_norm : 160.8578594547904
[2025-09-17 15:25:19,852][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 0.7294122560050486,  accuracy: 0.7470210815765352
[2025-09-17 15:25:22,862][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 0.42590472234931603,  accuracy: 0.8509090909090911, gradient_norm : 157.42513482643858
[2025-09-17 15:25:23,569][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 0.7185822602820723,  accuracy: 0.7634703196347032
[2025-09-17 15:25:26,559][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 0.4220725233116272,  accuracy: 0.8568181818181819, gradient_norm : 152.69303196180033
[2025-09-17 15:25:27,265][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 0.7177443687983176,  accuracy: 0.7447584320875114
[2025-09-17 15:25:30,255][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 0.4226367327568093,  accuracy: 0.8536868686868688, gradient_norm : 156.82649287970898
[2025-09-17 15:25:31,012][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 0.7275249005618274,  accuracy: 0.7483989021043
[2025-09-17 15:25:34,025][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 0.4046628368810299,  accuracy: 0.8621717171717173, gradient_norm : 157.27711873704217
[2025-09-17 15:25:34,720][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 0.7174565246932583,  accuracy: 0.7616438356164383
[2025-09-17 15:25:37,691][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 0.49855645135164994,  accuracy: 0.8333838383838384, gradient_norm : 189.0582727631734
[2025-09-17 15:25:38,395][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 0.7846566268842514,  accuracy: 0.7452054794520548
[2025-09-17 15:25:41,503][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 0.41642480305057356,  accuracy: 0.8563636363636362, gradient_norm : 151.87709454123956
[2025-09-17 15:25:42,240][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 0.7334030812165954,  accuracy: 0.7518181818181818
[2025-09-17 15:25:45,241][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 0.36061203346171444,  accuracy: 0.879040404040404, gradient_norm : 147.9631460281532
[2025-09-17 15:25:45,952][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 0.7272252395083498,  accuracy: 0.7411121239744758
[2025-09-17 15:25:48,709][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 0.4295764173871915,  accuracy: 0.8485, gradient_norm : 155.01091166526356
[2025-09-17 15:25:49,387][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 0.7894127371916202,  accuracy: 0.7291875626880642
[2025-09-17 15:25:52,486][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 0.37541253274151437,  accuracy: 0.8719191919191919, gradient_norm : 154.2182650223783
[2025-09-17 15:25:53,200][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 0.7099446264387917,  accuracy: 0.7609489051094891
[2025-09-17 15:25:55,984][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 0.4065305918544376,  accuracy: 0.8592777777777778, gradient_norm : 151.9060851565171
[2025-09-17 15:25:56,672][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 0.7367583554211925,  accuracy: 0.7542627883650953
[2025-09-17 15:25:59,706][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 0.3945255803903847,  accuracy: 0.8668686868686868, gradient_norm : 149.89879597164884
[2025-09-17 15:26:00,420][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 0.7111918656547065,  accuracy: 0.7541133455210237
[2025-09-17 15:26:03,216][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 0.3753567432348306,  accuracy: 0.8739444444444445, gradient_norm : 144.06699409212928
[2025-09-17 15:26:03,886][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 0.6867804243950777,  accuracy: 0.7676056338028169
[2025-09-17 15:26:06,826][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 0.3876994242785837,  accuracy: 0.865, gradient_norm : 153.8270588822772
[2025-09-17 15:26:07,540][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 0.7420417412503125,  accuracy: 0.7479452054794521
[2025-09-17 15:26:10,579][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 0.3827617727788024,  accuracy: 0.8712626262626262, gradient_norm : 147.78754721114035
[2025-09-17 15:26:11,311][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 0.7499696158420812,  accuracy: 0.737511353315168
[2025-09-17 15:26:14,409][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 0.3659878132928332,  accuracy: 0.8751515151515151, gradient_norm : 149.42318635432738
[2025-09-17 15:26:15,182][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 0.7406504884471788,  accuracy: 0.7463235294117647
[2025-09-17 15:26:18,285][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 0.46268655946548803,  accuracy: 0.8456565656565657, gradient_norm : 166.82123360706723
[2025-09-17 15:26:19,027][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 0.7323182031962983,  accuracy: 0.7589367552703942
[2025-09-17 15:26:22,048][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 0.3292825519647026,  accuracy: 0.8944949494949495, gradient_norm : 145.92523068247976
[2025-09-17 15:26:22,826][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 0.6887387515862637,  accuracy: 0.766269477543538
[2025-09-17 15:26:25,884][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 0.3753978983670205,  accuracy: 0.8709090909090909, gradient_norm : 152.9265307985942
[2025-09-17 15:26:26,630][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 0.6884889393474367,  accuracy: 0.7575205104831358
[2025-09-17 15:26:29,454][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 0.36750238563205734,  accuracy: 0.8772222222222223, gradient_norm : 146.21423948759275
[2025-09-17 15:26:30,097][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 0.6911736290230371,  accuracy: 0.7643504531722054
[2025-09-17 15:26:33,197][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 0.4223245378206202,  accuracy: 0.8572222222222221, gradient_norm : 154.5287574204561
[2025-09-17 15:26:33,933][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 0.7238075526005794,  accuracy: 0.7470427661510464
[2025-09-17 15:26:36,774][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 0.3893591018494529,  accuracy: 0.8712222222222221, gradient_norm : 151.18365418661023
[2025-09-17 15:26:37,416][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 0.7542723189233426,  accuracy: 0.7228315054835494
[2025-09-17 15:26:40,606][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 0.35640723839874916,  accuracy: 0.8847979797979797, gradient_norm : 150.2856750368282
[2025-09-17 15:26:41,392][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 0.7320953548334899,  accuracy: 0.7657247037374658
[2025-09-17 15:26:44,670][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 0.4346893852015703,  accuracy: 0.8542929292929292, gradient_norm : 165.30112067819502
[2025-09-17 15:26:45,495][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 0.7269635210579884,  accuracy: 0.7513711151736746
[2025-09-17 15:26:48,678][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 0.4276052402686963,  accuracy: 0.864949494949495, gradient_norm : 173.45903779290384
[2025-09-17 15:26:49,449][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 0.7656961283090448,  accuracy: 0.7438468550592525
[2025-09-17 15:26:52,583][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 0.3242244823943386,  accuracy: 0.8914646464646464, gradient_norm : 144.6076407671823
[2025-09-17 15:26:53,366][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 0.7396214496500967,  accuracy: 0.7513711151736746
[2025-09-17 15:26:56,629][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 0.4173566379870119,  accuracy: 0.8633838383838385, gradient_norm : 167.39839605402022
[2025-09-17 15:26:57,394][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 0.7795800224068158,  accuracy: 0.7280145058930191
[2025-09-17 15:27:00,498][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 0.3706930321461352,  accuracy: 0.8758080808080809, gradient_norm : 147.64101244732848
[2025-09-17 15:27:01,265][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 0.7006166252900253,  accuracy: 0.7536363636363637
[2025-09-17 15:27:04,458][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 0.3491593426026432,  accuracy: 0.8853030303030305, gradient_norm : 146.56000186660393
[2025-09-17 15:27:05,183][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 0.721079721254673,  accuracy: 0.7552703941338221
[2025-09-17 15:27:08,384][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 0.3847918004735909,  accuracy: 0.872929292929293, gradient_norm : 149.95616254620313
[2025-09-17 15:27:09,213][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 0.7019437998125743,  accuracy: 0.7702825888787602
[2025-09-17 15:27:12,310][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 0.4199432051936376,  accuracy: 0.8558080808080809, gradient_norm : 157.92029330794705
[2025-09-17 15:27:13,041][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 0.7572647453117894,  accuracy: 0.747483989021043
[2025-09-17 15:27:16,141][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 0.35153031446371286,  accuracy: 0.8815656565656566, gradient_norm : 148.58184276862193
[2025-09-17 15:27:16,872][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 0.7292006907669921,  accuracy: 0.7534246575342466
[2025-09-17 15:27:19,653][flp2p.graph_runner][INFO] - Train, Round 200 : loss => 0.3654161372115292,  accuracy: 0.8824999999999998, gradient_norm : 150.65388446683284
[2025-09-17 15:27:20,332][flp2p.graph_runner][INFO] - Test, Round 200 : loss => 0.754805546735928,  accuracy: 0.7542627883650953
[2025-09-17 15:27:23,577][flp2p.graph_runner][INFO] - Train, Round 201 : loss => 0.37242414402108726,  accuracy: 0.8692424242424243, gradient_norm : 146.47124144157985
[2025-09-17 15:27:24,345][flp2p.graph_runner][INFO] - Test, Round 201 : loss => 0.7335481543701784,  accuracy: 0.7374658158614403
[2025-09-17 15:27:27,570][flp2p.graph_runner][INFO] - Train, Round 202 : loss => 0.3616980310148475,  accuracy: 0.8802525252525252, gradient_norm : 150.23461196673932
[2025-09-17 15:27:28,402][flp2p.graph_runner][INFO] - Test, Round 202 : loss => 0.7402075798867938,  accuracy: 0.7620783956244302
[2025-09-17 15:27:31,710][flp2p.graph_runner][INFO] - Train, Round 203 : loss => 0.3349517621399807,  accuracy: 0.8878787878787879, gradient_norm : 144.03548926955173
[2025-09-17 15:27:32,577][flp2p.graph_runner][INFO] - Test, Round 203 : loss => 0.6783488760617646,  accuracy: 0.769090909090909
[2025-09-17 15:27:35,926][flp2p.graph_runner][INFO] - Train, Round 204 : loss => 0.34173903381205023,  accuracy: 0.8883838383838385, gradient_norm : 143.15789572936174
[2025-09-17 15:27:36,769][flp2p.graph_runner][INFO] - Test, Round 204 : loss => 0.746130516262076,  accuracy: 0.7520361990950226
[2025-09-17 15:27:40,076][flp2p.graph_runner][INFO] - Train, Round 205 : loss => 0.391703485349673,  accuracy: 0.8653535353535354, gradient_norm : 148.71765041154381
[2025-09-17 15:27:40,942][flp2p.graph_runner][INFO] - Test, Round 205 : loss => 0.7054269617914829,  accuracy: 0.7778785131459656
[2025-09-17 15:27:44,247][flp2p.graph_runner][INFO] - Train, Round 206 : loss => 0.362986680846238,  accuracy: 0.8762121212121212, gradient_norm : 145.8798118585155
[2025-09-17 15:27:45,094][flp2p.graph_runner][INFO] - Test, Round 206 : loss => 0.7187478649324432,  accuracy: 0.7479601087941976
[2025-09-17 15:27:48,444][flp2p.graph_runner][INFO] - Train, Round 207 : loss => 0.35010184866542027,  accuracy: 0.8824242424242424, gradient_norm : 144.51539624129413
[2025-09-17 15:27:49,319][flp2p.graph_runner][INFO] - Test, Round 207 : loss => 0.7333661342139883,  accuracy: 0.7629899726526892
[2025-09-17 15:27:52,668][flp2p.graph_runner][INFO] - Train, Round 208 : loss => 0.36855501147396297,  accuracy: 0.8813131313131314, gradient_norm : 147.865989284905
[2025-09-17 15:27:53,530][flp2p.graph_runner][INFO] - Test, Round 208 : loss => 0.7596848096457415,  accuracy: 0.7556973564266181
[2025-09-17 15:27:56,898][flp2p.graph_runner][INFO] - Train, Round 209 : loss => 0.37211569399594074,  accuracy: 0.8813131313131314, gradient_norm : 153.24179282464004
[2025-09-17 15:27:57,768][flp2p.graph_runner][INFO] - Test, Round 209 : loss => 0.7189028649112114,  accuracy: 0.7643312101910829
[2025-09-17 15:28:01,102][flp2p.graph_runner][INFO] - Train, Round 210 : loss => 0.36985937722034357,  accuracy: 0.8736363636363635, gradient_norm : 152.1431511784037
[2025-09-17 15:28:01,952][flp2p.graph_runner][INFO] - Test, Round 210 : loss => 0.7368525522289867,  accuracy: 0.7247037374658158
[2025-09-17 15:28:05,229][flp2p.graph_runner][INFO] - Train, Round 211 : loss => 0.31109745324973836,  accuracy: 0.8991414141414141, gradient_norm : 141.1109466464742
[2025-09-17 15:28:06,085][flp2p.graph_runner][INFO] - Test, Round 211 : loss => 0.7140683381795229,  accuracy: 0.7612076852698993
[2025-09-17 15:28:09,428][flp2p.graph_runner][INFO] - Train, Round 212 : loss => 0.32988255709501435,  accuracy: 0.8946464646464647, gradient_norm : 140.19152097484414
[2025-09-17 15:28:10,281][flp2p.graph_runner][INFO] - Test, Round 212 : loss => 0.7603437456626909,  accuracy: 0.7361237488626023
[2025-09-17 15:28:13,600][flp2p.graph_runner][INFO] - Train, Round 213 : loss => 0.32218930859076367,  accuracy: 0.8939393939393939, gradient_norm : 140.74585308883476
[2025-09-17 15:28:14,453][flp2p.graph_runner][INFO] - Test, Round 213 : loss => 0.711076341671115,  accuracy: 0.7761601455868972
[2025-09-17 15:28:17,776][flp2p.graph_runner][INFO] - Train, Round 214 : loss => 0.3328630207268747,  accuracy: 0.8905555555555557, gradient_norm : 146.897807112196
[2025-09-17 15:28:18,643][flp2p.graph_runner][INFO] - Test, Round 214 : loss => 0.743740271837985,  accuracy: 0.7522768670309654
[2025-09-17 15:28:21,940][flp2p.graph_runner][INFO] - Train, Round 215 : loss => 0.3350128539758523,  accuracy: 0.8887373737373738, gradient_norm : 149.60203259860617
[2025-09-17 15:28:22,823][flp2p.graph_runner][INFO] - Test, Round 215 : loss => 0.7143486697219977,  accuracy: 0.7577413479052824
[2025-09-17 15:28:26,142][flp2p.graph_runner][INFO] - Train, Round 216 : loss => 0.31935780196129626,  accuracy: 0.8987878787878787, gradient_norm : 141.73151785943617
[2025-09-17 15:28:27,036][flp2p.graph_runner][INFO] - Test, Round 216 : loss => 0.6852739855088124,  accuracy: 0.7712717291857274
[2025-09-17 15:28:30,349][flp2p.graph_runner][INFO] - Train, Round 217 : loss => 0.3532944843668674,  accuracy: 0.8852020202020201, gradient_norm : 147.9584735120582
[2025-09-17 15:28:31,212][flp2p.graph_runner][INFO] - Test, Round 217 : loss => 0.70453100599838,  accuracy: 0.7609489051094891
[2025-09-17 15:28:34,239][flp2p.graph_runner][INFO] - Train, Round 218 : loss => 0.2996580905263545,  accuracy: 0.9057222222222223, gradient_norm : 140.82425678562237
[2025-09-17 15:28:35,019][flp2p.graph_runner][INFO] - Test, Round 218 : loss => 0.721026679506531,  accuracy: 0.7777777777777778
[2025-09-17 15:28:38,371][flp2p.graph_runner][INFO] - Train, Round 219 : loss => 0.30999212691394584,  accuracy: 0.8980303030303031, gradient_norm : 141.78248755224368
[2025-09-17 15:28:39,247][flp2p.graph_runner][INFO] - Test, Round 219 : loss => 0.7023402439392898,  accuracy: 0.7568555758683729
[2025-09-17 15:28:42,572][flp2p.graph_runner][INFO] - Train, Round 220 : loss => 0.28505576968380025,  accuracy: 0.909090909090909, gradient_norm : 135.19160353665976
[2025-09-17 15:28:43,436][flp2p.graph_runner][INFO] - Test, Round 220 : loss => 0.7186683121594516,  accuracy: 0.7554545454545455
[2025-09-17 15:28:46,770][flp2p.graph_runner][INFO] - Train, Round 221 : loss => 0.3139087104591343,  accuracy: 0.8962121212121212, gradient_norm : 146.510613816392
[2025-09-17 15:28:47,644][flp2p.graph_runner][INFO] - Test, Round 221 : loss => 0.7023112588174587,  accuracy: 0.7472627737226277
[2025-09-17 15:28:50,655][flp2p.graph_runner][INFO] - Train, Round 222 : loss => 0.34209840136618974,  accuracy: 0.886, gradient_norm : 145.90468863628976
[2025-09-17 15:28:51,442][flp2p.graph_runner][INFO] - Test, Round 222 : loss => 0.7083068810171684,  accuracy: 0.7622868605817452
[2025-09-17 15:28:54,764][flp2p.graph_runner][INFO] - Train, Round 223 : loss => 0.34611950986083795,  accuracy: 0.8896464646464647, gradient_norm : 145.95815334443716
[2025-09-17 15:28:55,591][flp2p.graph_runner][INFO] - Test, Round 223 : loss => 0.7370954491813249,  accuracy: 0.763302752293578
[2025-09-17 15:28:58,983][flp2p.graph_runner][INFO] - Train, Round 224 : loss => 0.3099026848816059,  accuracy: 0.898080808080808, gradient_norm : 137.27678178867203
[2025-09-17 15:28:59,827][flp2p.graph_runner][INFO] - Test, Round 224 : loss => 0.6822133784899946,  accuracy: 0.7795992714025501
[2025-09-17 15:29:02,825][flp2p.graph_runner][INFO] - Train, Round 225 : loss => 0.27903254511591513,  accuracy: 0.9117222222222223, gradient_norm : 139.50122480025496
[2025-09-17 15:29:03,612][flp2p.graph_runner][INFO] - Test, Round 225 : loss => 0.7647789436369086,  accuracy: 0.7557788944723618
[2025-09-17 15:29:06,983][flp2p.graph_runner][INFO] - Train, Round 226 : loss => 0.3888767922475271,  accuracy: 0.8711616161616162, gradient_norm : 151.88799012622619
[2025-09-17 15:29:07,821][flp2p.graph_runner][INFO] - Test, Round 226 : loss => 0.7175590340389219,  accuracy: 0.7408424908424909
[2025-09-17 15:29:11,137][flp2p.graph_runner][INFO] - Train, Round 227 : loss => 0.34001754432789644,  accuracy: 0.886010101010101, gradient_norm : 146.83508614145978
[2025-09-17 15:29:11,990][flp2p.graph_runner][INFO] - Test, Round 227 : loss => 0.7057974443724166,  accuracy: 0.7634703196347032
[2025-09-17 15:29:15,342][flp2p.graph_runner][INFO] - Train, Round 228 : loss => 0.3383230533099832,  accuracy: 0.8889393939393938, gradient_norm : 145.10231255790816
[2025-09-17 15:29:16,197][flp2p.graph_runner][INFO] - Test, Round 228 : loss => 0.730402420875023,  accuracy: 0.763519706691109
[2025-09-17 15:29:19,499][flp2p.graph_runner][INFO] - Train, Round 229 : loss => 0.2683425326882791,  accuracy: 0.915909090909091, gradient_norm : 139.47783414418487
[2025-09-17 15:29:20,354][flp2p.graph_runner][INFO] - Test, Round 229 : loss => 0.7474693634022366,  accuracy: 0.7445454545454545
[2025-09-17 15:29:23,621][flp2p.graph_runner][INFO] - Train, Round 230 : loss => 0.3162841874516964,  accuracy: 0.8944444444444444, gradient_norm : 146.2868533876213
[2025-09-17 15:29:24,485][flp2p.graph_runner][INFO] - Test, Round 230 : loss => 0.6912001802797413,  accuracy: 0.7684594348222424
[2025-09-17 15:29:27,833][flp2p.graph_runner][INFO] - Train, Round 231 : loss => 0.3742485000224516,  accuracy: 0.8752020202020203, gradient_norm : 150.02439217914372
[2025-09-17 15:29:28,693][flp2p.graph_runner][INFO] - Test, Round 231 : loss => 0.7134768756421189,  accuracy: 0.7570776255707763
[2025-09-17 15:29:32,001][flp2p.graph_runner][INFO] - Train, Round 232 : loss => 0.28831512968260514,  accuracy: 0.9065151515151515, gradient_norm : 141.85749260076315
[2025-09-17 15:29:32,859][flp2p.graph_runner][INFO] - Test, Round 232 : loss => 0.7370522418618202,  accuracy: 0.7563636363636363
[2025-09-17 15:29:36,152][flp2p.graph_runner][INFO] - Train, Round 233 : loss => 0.24582519760570545,  accuracy: 0.9253030303030304, gradient_norm : 134.76802371527722
[2025-09-17 15:29:36,994][flp2p.graph_runner][INFO] - Test, Round 233 : loss => 0.7222652942645355,  accuracy: 0.7613430127041743
[2025-09-17 15:29:40,297][flp2p.graph_runner][INFO] - Train, Round 234 : loss => 0.30100891098757554,  accuracy: 0.905808080808081, gradient_norm : 150.13843283483587
[2025-09-17 15:29:41,112][flp2p.graph_runner][INFO] - Test, Round 234 : loss => 0.7421362247786235,  accuracy: 0.7622950819672131
[2025-09-17 15:29:44,130][flp2p.graph_runner][INFO] - Train, Round 235 : loss => 0.3118994101658851,  accuracy: 0.9011666666666668, gradient_norm : 137.9752532001421
[2025-09-17 15:29:44,919][flp2p.graph_runner][INFO] - Test, Round 235 : loss => 0.727300080190222,  accuracy: 0.7560240963855421
[2025-09-17 15:29:48,182][flp2p.graph_runner][INFO] - Train, Round 236 : loss => 0.35705471733094646,  accuracy: 0.8806565656565656, gradient_norm : 145.70923325494408
[2025-09-17 15:29:49,058][flp2p.graph_runner][INFO] - Test, Round 236 : loss => 0.7079188038796296,  accuracy: 0.76007326007326
[2025-09-17 15:29:52,423][flp2p.graph_runner][INFO] - Train, Round 237 : loss => 0.29447906299398957,  accuracy: 0.9027272727272726, gradient_norm : 139.14205446988973
[2025-09-17 15:29:53,277][flp2p.graph_runner][INFO] - Test, Round 237 : loss => 0.6908990089087755,  accuracy: 0.7741347905282332
[2025-09-17 15:29:56,574][flp2p.graph_runner][INFO] - Train, Round 238 : loss => 0.31416626239890433,  accuracy: 0.9017171717171718, gradient_norm : 142.7441242721222
[2025-09-17 15:29:57,433][flp2p.graph_runner][INFO] - Test, Round 238 : loss => 0.7164945194438168,  accuracy: 0.7488584474885844
[2025-09-17 15:30:00,751][flp2p.graph_runner][INFO] - Train, Round 239 : loss => 0.30574543442009156,  accuracy: 0.9006565656565657, gradient_norm : 143.92941792496538
[2025-09-17 15:30:01,632][flp2p.graph_runner][INFO] - Test, Round 239 : loss => 0.7629881747284509,  accuracy: 0.7563868613138686
[2025-09-17 15:30:05,000][flp2p.graph_runner][INFO] - Train, Round 240 : loss => 0.3566041578976155,  accuracy: 0.881919191919192, gradient_norm : 149.9705466628887
[2025-09-17 15:30:05,857][flp2p.graph_runner][INFO] - Test, Round 240 : loss => 0.7303330470899959,  accuracy: 0.7536630036630036
[2025-09-17 15:30:09,153][flp2p.graph_runner][INFO] - Train, Round 241 : loss => 0.2836420148381766,  accuracy: 0.9105050505050505, gradient_norm : 139.31486369907364
[2025-09-17 15:30:09,865][flp2p.graph_runner][INFO] - Test, Round 241 : loss => 0.740505420767009,  accuracy: 0.7607305936073059
[2025-09-17 15:30:13,005][flp2p.graph_runner][INFO] - Train, Round 242 : loss => 0.3069736943641946,  accuracy: 0.8958080808080809, gradient_norm : 141.25941624600884
[2025-09-17 15:30:13,727][flp2p.graph_runner][INFO] - Test, Round 242 : loss => 0.6953083474793421,  accuracy: 0.7809349220898258
[2025-09-17 15:30:16,756][flp2p.graph_runner][INFO] - Train, Round 243 : loss => 0.2852677031023301,  accuracy: 0.9118686868686867, gradient_norm : 139.65107049770566
[2025-09-17 15:30:17,498][flp2p.graph_runner][INFO] - Test, Round 243 : loss => 0.7643530778688187,  accuracy: 0.7470534904805077
[2025-09-17 15:30:20,625][flp2p.graph_runner][INFO] - Train, Round 244 : loss => 0.3384358296796122,  accuracy: 0.8901515151515152, gradient_norm : 146.10859801463482
[2025-09-17 15:30:21,410][flp2p.graph_runner][INFO] - Test, Round 244 : loss => 0.6944333622934167,  accuracy: 0.7656675749318801
[2025-09-17 15:30:24,465][flp2p.graph_runner][INFO] - Train, Round 245 : loss => 0.2598738710865181,  accuracy: 0.9195959595959595, gradient_norm : 141.90318427044988
[2025-09-17 15:30:25,217][flp2p.graph_runner][INFO] - Test, Round 245 : loss => 0.788458311612453,  accuracy: 0.7339449541284404
[2025-09-17 15:30:28,294][flp2p.graph_runner][INFO] - Train, Round 246 : loss => 0.32677155178124934,  accuracy: 0.8961111111111112, gradient_norm : 137.85154959259174
[2025-09-17 15:30:29,028][flp2p.graph_runner][INFO] - Test, Round 246 : loss => 0.6906783345127453,  accuracy: 0.7652411282984531
[2025-09-17 15:30:32,147][flp2p.graph_runner][INFO] - Train, Round 247 : loss => 0.2832947202697114,  accuracy: 0.9104545454545454, gradient_norm : 138.03020185308444
[2025-09-17 15:30:32,901][flp2p.graph_runner][INFO] - Test, Round 247 : loss => 0.7149677154803471,  accuracy: 0.773841961852861
[2025-09-17 15:30:36,006][flp2p.graph_runner][INFO] - Train, Round 248 : loss => 0.3397463989459952,  accuracy: 0.8896464646464647, gradient_norm : 141.68078005724448
[2025-09-17 15:30:36,721][flp2p.graph_runner][INFO] - Test, Round 248 : loss => 0.7236259549228481,  accuracy: 0.7527472527472527
[2025-09-17 15:30:39,787][flp2p.graph_runner][INFO] - Train, Round 249 : loss => 0.2758126363708553,  accuracy: 0.9188383838383841, gradient_norm : 143.16333483661492
[2025-09-17 15:30:40,502][flp2p.graph_runner][INFO] - Test, Round 249 : loss => 0.7268472981027972,  accuracy: 0.7687385740402194
[2025-09-17 15:30:43,705][flp2p.graph_runner][INFO] - Train, Round 250 : loss => 0.2670805846870115,  accuracy: 0.9180808080808082, gradient_norm : 127.445489632783
[2025-09-17 15:30:44,486][flp2p.graph_runner][INFO] - Test, Round 250 : loss => 0.7581754705478766,  accuracy: 0.7623400365630713
[2025-09-17 15:30:47,265][flp2p.graph_runner][INFO] - Train, Round 251 : loss => 0.2807053384883329,  accuracy: 0.9116111111111111, gradient_norm : 136.24115563410166
[2025-09-17 15:30:47,930][flp2p.graph_runner][INFO] - Test, Round 251 : loss => 0.6912623984473092,  accuracy: 0.7696177062374245
[2025-09-17 15:30:50,736][flp2p.graph_runner][INFO] - Train, Round 252 : loss => 0.2955652467093508,  accuracy: 0.9038333333333332, gradient_norm : 133.84461928873966
[2025-09-17 15:30:51,401][flp2p.graph_runner][INFO] - Test, Round 252 : loss => 0.7076537554076094,  accuracy: 0.7534930139720559
[2025-09-17 15:30:54,536][flp2p.graph_runner][INFO] - Train, Round 253 : loss => 0.30959041443826263,  accuracy: 0.9013636363636364, gradient_norm : 139.63047191545252
[2025-09-17 15:30:55,247][flp2p.graph_runner][INFO] - Test, Round 253 : loss => 0.7682216406031385,  accuracy: 0.738615664845173
[2025-09-17 15:30:58,313][flp2p.graph_runner][INFO] - Train, Round 254 : loss => 0.25516225290520006,  accuracy: 0.926969696969697, gradient_norm : 137.0955440432745
[2025-09-17 15:30:59,033][flp2p.graph_runner][INFO] - Test, Round 254 : loss => 0.6607268488942049,  accuracy: 0.7912087912087912
[2025-09-17 15:31:02,067][flp2p.graph_runner][INFO] - Train, Round 255 : loss => 0.2774727228418642,  accuracy: 0.9159090909090909, gradient_norm : 143.0295279281605
[2025-09-17 15:31:02,859][flp2p.graph_runner][INFO] - Test, Round 255 : loss => 0.6999163941462325,  accuracy: 0.7785910338517841
[2025-09-17 15:31:05,910][flp2p.graph_runner][INFO] - Train, Round 256 : loss => 0.2690041556292051,  accuracy: 0.916969696969697, gradient_norm : 135.46232975230555
[2025-09-17 15:31:06,617][flp2p.graph_runner][INFO] - Test, Round 256 : loss => 0.6934391310865726,  accuracy: 0.7853211009174312
[2025-09-17 15:31:09,690][flp2p.graph_runner][INFO] - Train, Round 257 : loss => 0.27973426177102906,  accuracy: 0.9107070707070706, gradient_norm : 136.4843489583527
[2025-09-17 15:31:10,391][flp2p.graph_runner][INFO] - Test, Round 257 : loss => 0.6903598138787708,  accuracy: 0.7777777777777778
[2025-09-17 15:31:13,506][flp2p.graph_runner][INFO] - Train, Round 258 : loss => 0.2507533803682732,  accuracy: 0.9229292929292929, gradient_norm : 137.85406825057612
[2025-09-17 15:31:14,226][flp2p.graph_runner][INFO] - Test, Round 258 : loss => 0.728630866702846,  accuracy: 0.7634212920837125
[2025-09-17 15:31:17,277][flp2p.graph_runner][INFO] - Train, Round 259 : loss => 0.259436466664986,  accuracy: 0.9188888888888888, gradient_norm : 138.7407832861318
[2025-09-17 15:31:17,990][flp2p.graph_runner][INFO] - Test, Round 259 : loss => 0.7133858124919898,  accuracy: 0.7831215970961888
[2025-09-17 15:31:21,126][flp2p.graph_runner][INFO] - Train, Round 260 : loss => 0.24196597861186037,  accuracy: 0.9288383838383839, gradient_norm : 130.17293935911536
[2025-09-17 15:31:21,852][flp2p.graph_runner][INFO] - Test, Round 260 : loss => 0.7135998618694536,  accuracy: 0.7817028985507246
[2025-09-17 15:31:24,976][flp2p.graph_runner][INFO] - Train, Round 261 : loss => 0.2354143221679172,  accuracy: 0.9326262626262627, gradient_norm : 131.62043117252017
[2025-09-17 15:31:25,670][flp2p.graph_runner][INFO] - Test, Round 261 : loss => 0.737714239342572,  accuracy: 0.7561643835616438
[2025-09-17 15:31:28,821][flp2p.graph_runner][INFO] - Train, Round 262 : loss => 0.26316122020097366,  accuracy: 0.9197474747474745, gradient_norm : 131.36699226633206
[2025-09-17 15:31:29,560][flp2p.graph_runner][INFO] - Test, Round 262 : loss => 0.7307752894278425,  accuracy: 0.7636861313868614
[2025-09-17 15:31:32,635][flp2p.graph_runner][INFO] - Train, Round 263 : loss => 0.27496742919655376,  accuracy: 0.9141414141414143, gradient_norm : 133.77876947530413
[2025-09-17 15:31:33,335][flp2p.graph_runner][INFO] - Test, Round 263 : loss => 0.7372377771144598,  accuracy: 0.7465690759377859
[2025-09-17 15:31:36,422][flp2p.graph_runner][INFO] - Train, Round 264 : loss => 0.20717210690199864,  accuracy: 0.9435353535353534, gradient_norm : 135.42223196750098
[2025-09-17 15:31:37,162][flp2p.graph_runner][INFO] - Test, Round 264 : loss => 0.7464036913164543,  accuracy: 0.7604735883424408
[2025-09-17 15:31:40,227][flp2p.graph_runner][INFO] - Train, Round 265 : loss => 0.3311423803880726,  accuracy: 0.8908585858585859, gradient_norm : 141.04796665636445
[2025-09-17 15:31:40,898][flp2p.graph_runner][INFO] - Test, Round 265 : loss => 0.7121104735321614,  accuracy: 0.7545787545787546
[2025-09-17 15:31:43,968][flp2p.graph_runner][INFO] - Train, Round 266 : loss => 0.2446752356756902,  accuracy: 0.927979797979798, gradient_norm : 129.96716348537262
[2025-09-17 15:31:44,689][flp2p.graph_runner][INFO] - Test, Round 266 : loss => 0.6710582677062166,  accuracy: 0.7815049864007253
[2025-09-17 15:31:47,720][flp2p.graph_runner][INFO] - Train, Round 267 : loss => 0.2477219371149796,  accuracy: 0.9246969696969696, gradient_norm : 135.8425812439652
[2025-09-17 15:31:48,461][flp2p.graph_runner][INFO] - Test, Round 267 : loss => 0.6893634726875993,  accuracy: 0.7789954337899543
[2025-09-17 15:31:51,490][flp2p.graph_runner][INFO] - Train, Round 268 : loss => 0.23912412007753808,  accuracy: 0.9308585858585859, gradient_norm : 131.34034378239483
[2025-09-17 15:31:52,245][flp2p.graph_runner][INFO] - Test, Round 268 : loss => 0.6991940272966876,  accuracy: 0.7849954254345837
[2025-09-17 15:31:55,417][flp2p.graph_runner][INFO] - Train, Round 269 : loss => 0.2414090617736237,  accuracy: 0.9286363636363636, gradient_norm : 130.80672156200094
[2025-09-17 15:31:56,188][flp2p.graph_runner][INFO] - Test, Round 269 : loss => 0.671487172118953,  accuracy: 0.7841530054644809
[2025-09-17 15:31:59,275][flp2p.graph_runner][INFO] - Train, Round 270 : loss => 0.2569021472033593,  accuracy: 0.9231313131313131, gradient_norm : 133.98211787686932
[2025-09-17 15:31:59,990][flp2p.graph_runner][INFO] - Test, Round 270 : loss => 0.6878964604580239,  accuracy: 0.7799086757990867
[2025-09-17 15:32:03,073][flp2p.graph_runner][INFO] - Train, Round 271 : loss => 0.244964305606713,  accuracy: 0.9282828282828284, gradient_norm : 135.73754741895263
[2025-09-17 15:32:03,809][flp2p.graph_runner][INFO] - Test, Round 271 : loss => 0.7319873880305791,  accuracy: 0.7726027397260274
[2025-09-17 15:32:06,893][flp2p.graph_runner][INFO] - Train, Round 272 : loss => 0.23695498563994824,  accuracy: 0.9278787878787877, gradient_norm : 133.16121888420417
[2025-09-17 15:32:07,628][flp2p.graph_runner][INFO] - Test, Round 272 : loss => 0.7154676295668695,  accuracy: 0.7603978300180831
[2025-09-17 15:32:10,713][flp2p.graph_runner][INFO] - Train, Round 273 : loss => 0.24850398413316616,  accuracy: 0.924848484848485, gradient_norm : 133.31462312115968
[2025-09-17 15:32:11,443][flp2p.graph_runner][INFO] - Test, Round 273 : loss => 0.7409286446143976,  accuracy: 0.7707006369426752
[2025-09-17 15:32:14,509][flp2p.graph_runner][INFO] - Train, Round 274 : loss => 0.2306381723762377,  accuracy: 0.9327272727272728, gradient_norm : 141.3800499244296
[2025-09-17 15:32:15,285][flp2p.graph_runner][INFO] - Test, Round 274 : loss => 0.7729939536358467,  accuracy: 0.7488626023657871
[2025-09-17 15:32:18,292][flp2p.graph_runner][INFO] - Train, Round 275 : loss => 0.2822061994217096,  accuracy: 0.916010101010101, gradient_norm : 145.62499386300678
[2025-09-17 15:32:18,996][flp2p.graph_runner][INFO] - Test, Round 275 : loss => 0.7420360624301628,  accuracy: 0.7586520947176685
[2025-09-17 15:32:22,046][flp2p.graph_runner][INFO] - Train, Round 276 : loss => 0.2012523346540878,  accuracy: 0.9446464646464645, gradient_norm : 133.91452059801114
[2025-09-17 15:32:22,763][flp2p.graph_runner][INFO] - Test, Round 276 : loss => 0.7298171105603938,  accuracy: 0.7716105550500455
[2025-09-17 15:32:25,848][flp2p.graph_runner][INFO] - Train, Round 277 : loss => 0.2423134409790774,  accuracy: 0.9263131313131312, gradient_norm : 142.39334016489903
[2025-09-17 15:32:26,569][flp2p.graph_runner][INFO] - Test, Round 277 : loss => 0.7176669859973184,  accuracy: 0.781021897810219
[2025-09-17 15:32:29,614][flp2p.graph_runner][INFO] - Train, Round 278 : loss => 0.2018022184320161,  accuracy: 0.9445959595959597, gradient_norm : 126.20455895812698
[2025-09-17 15:32:30,345][flp2p.graph_runner][INFO] - Test, Round 278 : loss => 0.7475361058266584,  accuracy: 0.7436823104693141
[2025-09-17 15:32:33,393][flp2p.graph_runner][INFO] - Train, Round 279 : loss => 0.2263751248623576,  accuracy: 0.9366161616161616, gradient_norm : 134.28030311926858
[2025-09-17 15:32:34,098][flp2p.graph_runner][INFO] - Test, Round 279 : loss => 0.7441602350906892,  accuracy: 0.7645454545454545
[2025-09-17 15:32:37,207][flp2p.graph_runner][INFO] - Train, Round 280 : loss => 0.19875598514018664,  accuracy: 0.9479292929292931, gradient_norm : 128.07910958236457
[2025-09-17 15:32:37,951][flp2p.graph_runner][INFO] - Test, Round 280 : loss => 0.6864123410694131,  accuracy: 0.7908675799086758
[2025-09-17 15:32:41,023][flp2p.graph_runner][INFO] - Train, Round 281 : loss => 0.2415558642642502,  accuracy: 0.9297979797979798, gradient_norm : 143.54378255651946
[2025-09-17 15:32:41,730][flp2p.graph_runner][INFO] - Test, Round 281 : loss => 0.7323935041425433,  accuracy: 0.7696526508226691
[2025-09-17 15:32:44,790][flp2p.graph_runner][INFO] - Train, Round 282 : loss => 0.22693413360958045,  accuracy: 0.9346464646464645, gradient_norm : 134.12046827895787
[2025-09-17 15:32:45,515][flp2p.graph_runner][INFO] - Test, Round 282 : loss => 0.6809087202454611,  accuracy: 0.7843494085532302
[2025-09-17 15:32:48,570][flp2p.graph_runner][INFO] - Train, Round 283 : loss => 0.24203745655364456,  accuracy: 0.9266666666666666, gradient_norm : 136.11308160607075
[2025-09-17 15:32:49,253][flp2p.graph_runner][INFO] - Test, Round 283 : loss => 0.6852809900626771,  accuracy: 0.7711941659070192
[2025-09-17 15:32:52,328][flp2p.graph_runner][INFO] - Train, Round 284 : loss => 0.2563057156896155,  accuracy: 0.9228787878787879, gradient_norm : 132.67894469557424
[2025-09-17 15:32:53,060][flp2p.graph_runner][INFO] - Test, Round 284 : loss => 0.6949865577354336,  accuracy: 0.7625113739763422
[2025-09-17 15:32:56,075][flp2p.graph_runner][INFO] - Train, Round 285 : loss => 0.2913972403345256,  accuracy: 0.9074242424242425, gradient_norm : 139.0172913979861
[2025-09-17 15:32:56,849][flp2p.graph_runner][INFO] - Test, Round 285 : loss => 0.7164650512354652,  accuracy: 0.7658402203856749
[2025-09-17 15:32:59,916][flp2p.graph_runner][INFO] - Train, Round 286 : loss => 0.25651566880238313,  accuracy: 0.9236363636363638, gradient_norm : 133.00127650496205
[2025-09-17 15:33:00,598][flp2p.graph_runner][INFO] - Test, Round 286 : loss => 0.7127373825459584,  accuracy: 0.7627737226277372
[2025-09-17 15:33:03,647][flp2p.graph_runner][INFO] - Train, Round 287 : loss => 0.24768716170572477,  accuracy: 0.9272222222222222, gradient_norm : 138.50238869930416
[2025-09-17 15:33:04,399][flp2p.graph_runner][INFO] - Test, Round 287 : loss => 0.7371204050712812,  accuracy: 0.7648673376029277
[2025-09-17 15:33:07,470][flp2p.graph_runner][INFO] - Train, Round 288 : loss => 0.2411797126857423,  accuracy: 0.9311616161616163, gradient_norm : 137.4461876788314
[2025-09-17 15:33:08,192][flp2p.graph_runner][INFO] - Test, Round 288 : loss => 0.7221704128815796,  accuracy: 0.7619047619047619
[2025-09-17 15:33:11,197][flp2p.graph_runner][INFO] - Train, Round 289 : loss => 0.19282250354347827,  accuracy: 0.9493939393939397, gradient_norm : 130.74970933997645
[2025-09-17 15:33:11,917][flp2p.graph_runner][INFO] - Test, Round 289 : loss => 0.7351861321426697,  accuracy: 0.7714025500910747
[2025-09-17 15:33:15,028][flp2p.graph_runner][INFO] - Train, Round 290 : loss => 0.22126487517750568,  accuracy: 0.9327777777777778, gradient_norm : 126.09688351095396
[2025-09-17 15:33:15,770][flp2p.graph_runner][INFO] - Test, Round 290 : loss => 0.7126682493699729,  accuracy: 0.7645985401459854
[2025-09-17 15:33:18,868][flp2p.graph_runner][INFO] - Train, Round 291 : loss => 0.24294040331274808,  accuracy: 0.9260101010101011, gradient_norm : 136.54877326614312
[2025-09-17 15:33:19,586][flp2p.graph_runner][INFO] - Test, Round 291 : loss => 0.7313330424158541,  accuracy: 0.7634703196347032
[2025-09-17 15:33:22,613][flp2p.graph_runner][INFO] - Train, Round 292 : loss => 0.21188314073493308,  accuracy: 0.9426767676767677, gradient_norm : 131.71036414352304
[2025-09-17 15:33:23,325][flp2p.graph_runner][INFO] - Test, Round 292 : loss => 0.7598167184441194,  accuracy: 0.760036496350365
[2025-09-17 15:33:26,330][flp2p.graph_runner][INFO] - Train, Round 293 : loss => 0.23054622725643584,  accuracy: 0.9353030303030303, gradient_norm : 137.65064710965987
[2025-09-17 15:33:27,025][flp2p.graph_runner][INFO] - Test, Round 293 : loss => 0.743975272839838,  accuracy: 0.7595628415300546
[2025-09-17 15:33:30,142][flp2p.graph_runner][INFO] - Train, Round 294 : loss => 0.23535233894371865,  accuracy: 0.9338383838383838, gradient_norm : 133.23069495049828
[2025-09-17 15:33:30,886][flp2p.graph_runner][INFO] - Test, Round 294 : loss => 0.7234637648654332,  accuracy: 0.7668488160291439
[2025-09-17 15:33:33,978][flp2p.graph_runner][INFO] - Train, Round 295 : loss => 0.2091959720179368,  accuracy: 0.943787878787879, gradient_norm : 132.81636297925886
[2025-09-17 15:33:34,712][flp2p.graph_runner][INFO] - Test, Round 295 : loss => 0.7015175929388208,  accuracy: 0.7691605839416058
[2025-09-17 15:33:37,802][flp2p.graph_runner][INFO] - Train, Round 296 : loss => 0.1965996049930144,  accuracy: 0.9466666666666667, gradient_norm : 130.63285637849125
[2025-09-17 15:33:38,606][flp2p.graph_runner][INFO] - Test, Round 296 : loss => 0.7383708043531938,  accuracy: 0.7727272727272727
[2025-09-17 15:33:41,672][flp2p.graph_runner][INFO] - Train, Round 297 : loss => 0.24015684039799398,  accuracy: 0.9293939393939394, gradient_norm : 134.14215109729787
[2025-09-17 15:33:42,434][flp2p.graph_runner][INFO] - Test, Round 297 : loss => 0.7750599418410703,  accuracy: 0.7637867647058824
[2025-09-17 15:33:45,516][flp2p.graph_runner][INFO] - Train, Round 298 : loss => 0.20664183353894094,  accuracy: 0.9421212121212122, gradient_norm : 133.4913795260521
[2025-09-17 15:33:46,214][flp2p.graph_runner][INFO] - Test, Round 298 : loss => 0.7663449365031588,  accuracy: 0.7619047619047619
[2025-09-17 15:33:49,284][flp2p.graph_runner][INFO] - Train, Round 299 : loss => 0.19036404775988283,  accuracy: 0.9494444444444444, gradient_norm : 131.0246242711563
[2025-09-17 15:33:50,021][flp2p.graph_runner][INFO] - Test, Round 299 : loss => 0.7575458130207811,  accuracy: 0.7673357664233577
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 001: loss=2.2770, accuracy=0.1282, gradient_norm=286.3238, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 002: loss=2.2619, accuracy=0.1717, gradient_norm=288.9492, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 003: loss=2.2465, accuracy=0.1869, gradient_norm=299.3688, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 004: loss=2.1978, accuracy=0.2673, gradient_norm=320.9065, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 005: loss=2.1338, accuracy=0.3409, gradient_norm=343.5483, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 006: loss=2.1436, accuracy=0.2285, gradient_norm=324.3140, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 007: loss=2.0418, accuracy=0.2973, gradient_norm=348.4452, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 008: loss=2.0262, accuracy=0.3801, gradient_norm=331.2890, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 009: loss=1.9832, accuracy=0.3908, gradient_norm=324.5975, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 010: loss=1.9482, accuracy=0.4357, gradient_norm=326.9915, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 011: loss=1.9532, accuracy=0.3624, gradient_norm=310.9233, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 012: loss=1.9424, accuracy=0.3996, gradient_norm=302.1287, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 013: loss=1.9055, accuracy=0.4052, gradient_norm=323.6556, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 014: loss=1.8792, accuracy=0.3997, gradient_norm=324.2060, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 015: loss=1.9499, accuracy=0.3191, gradient_norm=284.1535, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 016: loss=1.8963, accuracy=0.4171, gradient_norm=302.4803, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 017: loss=1.8015, accuracy=0.5016, gradient_norm=329.5619, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 018: loss=1.8585, accuracy=0.4419, gradient_norm=309.0232, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 019: loss=1.7678, accuracy=0.5262, gradient_norm=338.0454, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 020: loss=1.8484, accuracy=0.4353, gradient_norm=308.8348, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 021: loss=1.7688, accuracy=0.4637, gradient_norm=338.2085, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 022: loss=1.7680, accuracy=0.4603, gradient_norm=329.2399, 
[2025-09-17 15:33:50,022][__main__][INFO] - Train, Round 023: loss=1.7091, accuracy=0.5462, gradient_norm=371.8788, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 024: loss=1.7082, accuracy=0.5074, gradient_norm=356.2714, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 025: loss=1.6825, accuracy=0.5139, gradient_norm=361.9564, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 026: loss=1.6228, accuracy=0.5751, gradient_norm=380.5157, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 027: loss=1.4974, accuracy=0.6152, gradient_norm=396.5804, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 028: loss=1.7059, accuracy=0.5471, gradient_norm=354.8138, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 029: loss=1.5012, accuracy=0.6255, gradient_norm=396.8760, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 030: loss=1.6254, accuracy=0.5460, gradient_norm=364.6306, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 031: loss=1.3781, accuracy=0.6341, gradient_norm=368.1294, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 032: loss=1.5605, accuracy=0.5773, gradient_norm=353.7581, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 033: loss=1.5644, accuracy=0.5876, gradient_norm=363.4349, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 034: loss=1.6661, accuracy=0.5344, gradient_norm=343.5909, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 035: loss=1.4669, accuracy=0.6137, gradient_norm=349.9398, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 036: loss=1.4786, accuracy=0.5824, gradient_norm=377.2549, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 037: loss=1.5053, accuracy=0.6048, gradient_norm=404.0673, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 038: loss=1.3707, accuracy=0.6266, gradient_norm=365.4679, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 039: loss=1.6226, accuracy=0.5915, gradient_norm=359.6319, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 040: loss=1.2434, accuracy=0.6658, gradient_norm=390.2373, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 041: loss=1.4833, accuracy=0.5534, gradient_norm=345.0094, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 042: loss=1.3944, accuracy=0.6284, gradient_norm=369.1044, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 043: loss=1.4766, accuracy=0.6270, gradient_norm=349.2721, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 044: loss=1.4632, accuracy=0.6110, gradient_norm=367.8816, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 045: loss=1.3487, accuracy=0.6576, gradient_norm=367.2536, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 046: loss=1.4320, accuracy=0.6384, gradient_norm=372.4986, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 047: loss=1.3173, accuracy=0.6418, gradient_norm=391.2225, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 048: loss=1.3192, accuracy=0.6566, gradient_norm=354.0043, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 049: loss=1.3707, accuracy=0.6605, gradient_norm=372.2459, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 050: loss=1.2948, accuracy=0.6615, gradient_norm=386.0277, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 051: loss=1.1116, accuracy=0.7022, gradient_norm=335.8046, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 052: loss=1.4118, accuracy=0.6515, gradient_norm=371.9194, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 053: loss=1.0207, accuracy=0.7244, gradient_norm=358.9172, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 054: loss=1.1274, accuracy=0.7162, gradient_norm=355.0733, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 055: loss=1.2519, accuracy=0.6849, gradient_norm=355.3849, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 056: loss=1.2117, accuracy=0.6835, gradient_norm=373.4057, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 057: loss=1.1747, accuracy=0.6921, gradient_norm=370.6995, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 058: loss=1.1999, accuracy=0.6810, gradient_norm=349.5072, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 059: loss=1.0635, accuracy=0.7148, gradient_norm=340.7061, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 060: loss=1.1461, accuracy=0.7046, gradient_norm=366.0835, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 061: loss=1.1445, accuracy=0.7010, gradient_norm=382.6246, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 062: loss=0.9484, accuracy=0.7497, gradient_norm=325.8535, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 063: loss=1.0545, accuracy=0.7265, gradient_norm=346.6443, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 064: loss=1.0359, accuracy=0.7207, gradient_norm=354.6413, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 065: loss=0.9891, accuracy=0.7294, gradient_norm=340.5927, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 066: loss=1.0532, accuracy=0.7236, gradient_norm=367.3325, 
[2025-09-17 15:33:50,023][__main__][INFO] - Train, Round 067: loss=1.0250, accuracy=0.7393, gradient_norm=331.1871, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 068: loss=0.9471, accuracy=0.7457, gradient_norm=340.5566, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 069: loss=1.0770, accuracy=0.7145, gradient_norm=362.4405, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 070: loss=1.2513, accuracy=0.6477, gradient_norm=354.0607, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 071: loss=1.0648, accuracy=0.7188, gradient_norm=368.8873, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 072: loss=0.8909, accuracy=0.7548, gradient_norm=325.6163, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 073: loss=0.8609, accuracy=0.7609, gradient_norm=301.5561, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 074: loss=0.9784, accuracy=0.7386, gradient_norm=339.8153, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 075: loss=0.9342, accuracy=0.7330, gradient_norm=293.4907, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 076: loss=0.8875, accuracy=0.7510, gradient_norm=309.5753, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 077: loss=0.8907, accuracy=0.7513, gradient_norm=321.1039, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 078: loss=0.8866, accuracy=0.7443, gradient_norm=286.7913, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 079: loss=0.8505, accuracy=0.7661, gradient_norm=292.5988, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 080: loss=0.9181, accuracy=0.7456, gradient_norm=317.6181, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 081: loss=0.9628, accuracy=0.7417, gradient_norm=291.8811, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 082: loss=0.7262, accuracy=0.7831, gradient_norm=253.8548, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 083: loss=0.7675, accuracy=0.7718, gradient_norm=265.5492, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 084: loss=0.8413, accuracy=0.7693, gradient_norm=299.9120, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 085: loss=0.6310, accuracy=0.8041, gradient_norm=223.8134, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 086: loss=0.7338, accuracy=0.7793, gradient_norm=253.8374, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 087: loss=0.7519, accuracy=0.7883, gradient_norm=269.9653, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 088: loss=0.9447, accuracy=0.7456, gradient_norm=286.8550, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 089: loss=0.6693, accuracy=0.7935, gradient_norm=227.6278, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 090: loss=0.7543, accuracy=0.7746, gradient_norm=267.4635, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 091: loss=0.8266, accuracy=0.7626, gradient_norm=272.9332, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 092: loss=0.6730, accuracy=0.7960, gradient_norm=240.2053, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 093: loss=0.7307, accuracy=0.7838, gradient_norm=257.6780, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 094: loss=0.8966, accuracy=0.7472, gradient_norm=297.4946, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 095: loss=0.6681, accuracy=0.7905, gradient_norm=233.1192, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 096: loss=0.6991, accuracy=0.7862, gradient_norm=246.4031, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 097: loss=0.7370, accuracy=0.7901, gradient_norm=249.7981, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 098: loss=0.8075, accuracy=0.7708, gradient_norm=265.8253, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 099: loss=0.6627, accuracy=0.7983, gradient_norm=235.6995, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 100: loss=0.6552, accuracy=0.7960, gradient_norm=232.2461, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 101: loss=0.6975, accuracy=0.7891, gradient_norm=247.5897, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 102: loss=0.6219, accuracy=0.8158, gradient_norm=221.3755, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 103: loss=0.6358, accuracy=0.8075, gradient_norm=227.7931, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 104: loss=0.7384, accuracy=0.7825, gradient_norm=251.3140, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 105: loss=0.6743, accuracy=0.7983, gradient_norm=240.4193, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 106: loss=0.6264, accuracy=0.7999, gradient_norm=217.3432, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 107: loss=0.7035, accuracy=0.7878, gradient_norm=242.1910, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 108: loss=0.5488, accuracy=0.8222, gradient_norm=192.0138, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 109: loss=0.7044, accuracy=0.7958, gradient_norm=246.6051, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 110: loss=0.7181, accuracy=0.7813, gradient_norm=250.8486, 
[2025-09-17 15:33:50,024][__main__][INFO] - Train, Round 111: loss=0.6694, accuracy=0.7999, gradient_norm=233.5485, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 112: loss=0.6459, accuracy=0.8007, gradient_norm=222.3213, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 113: loss=0.6634, accuracy=0.7928, gradient_norm=231.8930, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 114: loss=0.6510, accuracy=0.8012, gradient_norm=228.6609, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 115: loss=0.5395, accuracy=0.8185, gradient_norm=183.2400, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 116: loss=0.6520, accuracy=0.8001, gradient_norm=228.0737, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 117: loss=0.5824, accuracy=0.8188, gradient_norm=200.2599, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 118: loss=0.6578, accuracy=0.8014, gradient_norm=233.7219, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 119: loss=0.6228, accuracy=0.8054, gradient_norm=220.7331, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 120: loss=0.5715, accuracy=0.8201, gradient_norm=199.4488, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 121: loss=0.5787, accuracy=0.8111, gradient_norm=205.0851, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 122: loss=0.5320, accuracy=0.8243, gradient_norm=186.3914, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 123: loss=0.5840, accuracy=0.8108, gradient_norm=199.8424, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 124: loss=0.5422, accuracy=0.8198, gradient_norm=184.1693, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 125: loss=0.6103, accuracy=0.8061, gradient_norm=213.3516, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 126: loss=0.6451, accuracy=0.8096, gradient_norm=227.0616, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 127: loss=0.5302, accuracy=0.8261, gradient_norm=188.5186, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 128: loss=0.5536, accuracy=0.8176, gradient_norm=189.7713, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 129: loss=0.5668, accuracy=0.8241, gradient_norm=197.8877, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 130: loss=0.5809, accuracy=0.8172, gradient_norm=200.3922, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 131: loss=0.5641, accuracy=0.8214, gradient_norm=197.2995, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 132: loss=0.5288, accuracy=0.8209, gradient_norm=180.4983, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 133: loss=0.6027, accuracy=0.8144, gradient_norm=216.2881, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 134: loss=0.5094, accuracy=0.8283, gradient_norm=174.6987, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 135: loss=0.4769, accuracy=0.8367, gradient_norm=167.8524, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 136: loss=0.4840, accuracy=0.8389, gradient_norm=173.0570, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 137: loss=0.5469, accuracy=0.8229, gradient_norm=188.1449, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 138: loss=0.5049, accuracy=0.8398, gradient_norm=181.9623, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 139: loss=0.5120, accuracy=0.8281, gradient_norm=180.5132, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 140: loss=0.6164, accuracy=0.8001, gradient_norm=215.0954, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 141: loss=0.5565, accuracy=0.8159, gradient_norm=190.6538, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 142: loss=0.5210, accuracy=0.8260, gradient_norm=178.9285, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 143: loss=0.4826, accuracy=0.8348, gradient_norm=165.8749, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 144: loss=0.5148, accuracy=0.8260, gradient_norm=175.8397, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 145: loss=0.4998, accuracy=0.8423, gradient_norm=184.8002, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 146: loss=0.4987, accuracy=0.8336, gradient_norm=171.0237, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 147: loss=0.4928, accuracy=0.8353, gradient_norm=169.6035, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 148: loss=0.4425, accuracy=0.8512, gradient_norm=161.0544, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 149: loss=0.4690, accuracy=0.8387, gradient_norm=161.6346, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 150: loss=0.5302, accuracy=0.8226, gradient_norm=181.4314, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 151: loss=0.4378, accuracy=0.8531, gradient_norm=161.4384, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 152: loss=0.4274, accuracy=0.8530, gradient_norm=164.8902, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 153: loss=0.5454, accuracy=0.8195, gradient_norm=182.4378, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 154: loss=0.4820, accuracy=0.8352, gradient_norm=170.9447, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 155: loss=0.4650, accuracy=0.8448, gradient_norm=161.8948, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 156: loss=0.4639, accuracy=0.8446, gradient_norm=169.7006, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 157: loss=0.4379, accuracy=0.8563, gradient_norm=160.8252, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 158: loss=0.4599, accuracy=0.8438, gradient_norm=157.8591, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 159: loss=0.4711, accuracy=0.8396, gradient_norm=164.7266, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 160: loss=0.4157, accuracy=0.8569, gradient_norm=155.7802, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 161: loss=0.4435, accuracy=0.8494, gradient_norm=158.3122, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 162: loss=0.4679, accuracy=0.8426, gradient_norm=164.9887, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 163: loss=0.4550, accuracy=0.8473, gradient_norm=168.3994, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 164: loss=0.4461, accuracy=0.8481, gradient_norm=162.0021, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 165: loss=0.4374, accuracy=0.8532, gradient_norm=159.8363, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 166: loss=0.4202, accuracy=0.8571, gradient_norm=164.0281, 
[2025-09-17 15:33:50,025][__main__][INFO] - Train, Round 167: loss=0.4220, accuracy=0.8525, gradient_norm=147.7145, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 168: loss=0.4062, accuracy=0.8679, gradient_norm=157.4503, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 169: loss=0.4704, accuracy=0.8379, gradient_norm=160.8579, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 170: loss=0.4259, accuracy=0.8509, gradient_norm=157.4251, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 171: loss=0.4221, accuracy=0.8568, gradient_norm=152.6930, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 172: loss=0.4226, accuracy=0.8537, gradient_norm=156.8265, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 173: loss=0.4047, accuracy=0.8622, gradient_norm=157.2771, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 174: loss=0.4986, accuracy=0.8334, gradient_norm=189.0583, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 175: loss=0.4164, accuracy=0.8564, gradient_norm=151.8771, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 176: loss=0.3606, accuracy=0.8790, gradient_norm=147.9631, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 177: loss=0.4296, accuracy=0.8485, gradient_norm=155.0109, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 178: loss=0.3754, accuracy=0.8719, gradient_norm=154.2183, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 179: loss=0.4065, accuracy=0.8593, gradient_norm=151.9061, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 180: loss=0.3945, accuracy=0.8669, gradient_norm=149.8988, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 181: loss=0.3754, accuracy=0.8739, gradient_norm=144.0670, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 182: loss=0.3877, accuracy=0.8650, gradient_norm=153.8271, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 183: loss=0.3828, accuracy=0.8713, gradient_norm=147.7875, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 184: loss=0.3660, accuracy=0.8752, gradient_norm=149.4232, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 185: loss=0.4627, accuracy=0.8457, gradient_norm=166.8212, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 186: loss=0.3293, accuracy=0.8945, gradient_norm=145.9252, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 187: loss=0.3754, accuracy=0.8709, gradient_norm=152.9265, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 188: loss=0.3675, accuracy=0.8772, gradient_norm=146.2142, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 189: loss=0.4223, accuracy=0.8572, gradient_norm=154.5288, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 190: loss=0.3894, accuracy=0.8712, gradient_norm=151.1837, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 191: loss=0.3564, accuracy=0.8848, gradient_norm=150.2857, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 192: loss=0.4347, accuracy=0.8543, gradient_norm=165.3011, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 193: loss=0.4276, accuracy=0.8649, gradient_norm=173.4590, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 194: loss=0.3242, accuracy=0.8915, gradient_norm=144.6076, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 195: loss=0.4174, accuracy=0.8634, gradient_norm=167.3984, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 196: loss=0.3707, accuracy=0.8758, gradient_norm=147.6410, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 197: loss=0.3492, accuracy=0.8853, gradient_norm=146.5600, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 198: loss=0.3848, accuracy=0.8729, gradient_norm=149.9562, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 199: loss=0.4199, accuracy=0.8558, gradient_norm=157.9203, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 200: loss=0.3515, accuracy=0.8816, gradient_norm=148.5818, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 201: loss=0.3654, accuracy=0.8825, gradient_norm=150.6539, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 202: loss=0.3724, accuracy=0.8692, gradient_norm=146.4712, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 203: loss=0.3617, accuracy=0.8803, gradient_norm=150.2346, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 204: loss=0.3350, accuracy=0.8879, gradient_norm=144.0355, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 205: loss=0.3417, accuracy=0.8884, gradient_norm=143.1579, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 206: loss=0.3917, accuracy=0.8654, gradient_norm=148.7177, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 207: loss=0.3630, accuracy=0.8762, gradient_norm=145.8798, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 208: loss=0.3501, accuracy=0.8824, gradient_norm=144.5154, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 209: loss=0.3686, accuracy=0.8813, gradient_norm=147.8660, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 210: loss=0.3721, accuracy=0.8813, gradient_norm=153.2418, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 211: loss=0.3699, accuracy=0.8736, gradient_norm=152.1432, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 212: loss=0.3111, accuracy=0.8991, gradient_norm=141.1109, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 213: loss=0.3299, accuracy=0.8946, gradient_norm=140.1915, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 214: loss=0.3222, accuracy=0.8939, gradient_norm=140.7459, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 215: loss=0.3329, accuracy=0.8906, gradient_norm=146.8978, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 216: loss=0.3350, accuracy=0.8887, gradient_norm=149.6020, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 217: loss=0.3194, accuracy=0.8988, gradient_norm=141.7315, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 218: loss=0.3533, accuracy=0.8852, gradient_norm=147.9585, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 219: loss=0.2997, accuracy=0.9057, gradient_norm=140.8243, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 220: loss=0.3100, accuracy=0.8980, gradient_norm=141.7825, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 221: loss=0.2851, accuracy=0.9091, gradient_norm=135.1916, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 222: loss=0.3139, accuracy=0.8962, gradient_norm=146.5106, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 223: loss=0.3421, accuracy=0.8860, gradient_norm=145.9047, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 224: loss=0.3461, accuracy=0.8896, gradient_norm=145.9582, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 225: loss=0.3099, accuracy=0.8981, gradient_norm=137.2768, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 226: loss=0.2790, accuracy=0.9117, gradient_norm=139.5012, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 227: loss=0.3889, accuracy=0.8712, gradient_norm=151.8880, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 228: loss=0.3400, accuracy=0.8860, gradient_norm=146.8351, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 229: loss=0.3383, accuracy=0.8889, gradient_norm=145.1023, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 230: loss=0.2683, accuracy=0.9159, gradient_norm=139.4778, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 231: loss=0.3163, accuracy=0.8944, gradient_norm=146.2869, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 232: loss=0.3742, accuracy=0.8752, gradient_norm=150.0244, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 233: loss=0.2883, accuracy=0.9065, gradient_norm=141.8575, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 234: loss=0.2458, accuracy=0.9253, gradient_norm=134.7680, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 235: loss=0.3010, accuracy=0.9058, gradient_norm=150.1384, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 236: loss=0.3119, accuracy=0.9012, gradient_norm=137.9753, 
[2025-09-17 15:33:50,026][__main__][INFO] - Train, Round 237: loss=0.3571, accuracy=0.8807, gradient_norm=145.7092, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 238: loss=0.2945, accuracy=0.9027, gradient_norm=139.1421, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 239: loss=0.3142, accuracy=0.9017, gradient_norm=142.7441, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 240: loss=0.3057, accuracy=0.9007, gradient_norm=143.9294, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 241: loss=0.3566, accuracy=0.8819, gradient_norm=149.9705, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 242: loss=0.2836, accuracy=0.9105, gradient_norm=139.3149, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 243: loss=0.3070, accuracy=0.8958, gradient_norm=141.2594, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 244: loss=0.2853, accuracy=0.9119, gradient_norm=139.6511, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 245: loss=0.3384, accuracy=0.8902, gradient_norm=146.1086, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 246: loss=0.2599, accuracy=0.9196, gradient_norm=141.9032, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 247: loss=0.3268, accuracy=0.8961, gradient_norm=137.8515, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 248: loss=0.2833, accuracy=0.9105, gradient_norm=138.0302, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 249: loss=0.3397, accuracy=0.8896, gradient_norm=141.6808, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 250: loss=0.2758, accuracy=0.9188, gradient_norm=143.1633, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 251: loss=0.2671, accuracy=0.9181, gradient_norm=127.4455, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 252: loss=0.2807, accuracy=0.9116, gradient_norm=136.2412, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 253: loss=0.2956, accuracy=0.9038, gradient_norm=133.8446, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 254: loss=0.3096, accuracy=0.9014, gradient_norm=139.6305, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 255: loss=0.2552, accuracy=0.9270, gradient_norm=137.0955, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 256: loss=0.2775, accuracy=0.9159, gradient_norm=143.0295, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 257: loss=0.2690, accuracy=0.9170, gradient_norm=135.4623, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 258: loss=0.2797, accuracy=0.9107, gradient_norm=136.4843, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 259: loss=0.2508, accuracy=0.9229, gradient_norm=137.8541, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 260: loss=0.2594, accuracy=0.9189, gradient_norm=138.7408, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 261: loss=0.2420, accuracy=0.9288, gradient_norm=130.1729, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 262: loss=0.2354, accuracy=0.9326, gradient_norm=131.6204, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 263: loss=0.2632, accuracy=0.9197, gradient_norm=131.3670, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 264: loss=0.2750, accuracy=0.9141, gradient_norm=133.7788, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 265: loss=0.2072, accuracy=0.9435, gradient_norm=135.4222, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 266: loss=0.3311, accuracy=0.8909, gradient_norm=141.0480, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 267: loss=0.2447, accuracy=0.9280, gradient_norm=129.9672, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 268: loss=0.2477, accuracy=0.9247, gradient_norm=135.8426, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 269: loss=0.2391, accuracy=0.9309, gradient_norm=131.3403, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 270: loss=0.2414, accuracy=0.9286, gradient_norm=130.8067, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 271: loss=0.2569, accuracy=0.9231, gradient_norm=133.9821, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 272: loss=0.2450, accuracy=0.9283, gradient_norm=135.7375, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 273: loss=0.2370, accuracy=0.9279, gradient_norm=133.1612, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 274: loss=0.2485, accuracy=0.9248, gradient_norm=133.3146, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 275: loss=0.2306, accuracy=0.9327, gradient_norm=141.3800, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 276: loss=0.2822, accuracy=0.9160, gradient_norm=145.6250, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 277: loss=0.2013, accuracy=0.9446, gradient_norm=133.9145, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 278: loss=0.2423, accuracy=0.9263, gradient_norm=142.3933, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 279: loss=0.2018, accuracy=0.9446, gradient_norm=126.2046, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 280: loss=0.2264, accuracy=0.9366, gradient_norm=134.2803, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 281: loss=0.1988, accuracy=0.9479, gradient_norm=128.0791, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 282: loss=0.2416, accuracy=0.9298, gradient_norm=143.5438, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 283: loss=0.2269, accuracy=0.9346, gradient_norm=134.1205, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 284: loss=0.2420, accuracy=0.9267, gradient_norm=136.1131, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 285: loss=0.2563, accuracy=0.9229, gradient_norm=132.6789, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 286: loss=0.2914, accuracy=0.9074, gradient_norm=139.0173, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 287: loss=0.2565, accuracy=0.9236, gradient_norm=133.0013, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 288: loss=0.2477, accuracy=0.9272, gradient_norm=138.5024, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 289: loss=0.2412, accuracy=0.9312, gradient_norm=137.4462, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 290: loss=0.1928, accuracy=0.9494, gradient_norm=130.7497, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 291: loss=0.2213, accuracy=0.9328, gradient_norm=126.0969, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 292: loss=0.2429, accuracy=0.9260, gradient_norm=136.5488, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 293: loss=0.2119, accuracy=0.9427, gradient_norm=131.7104, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 294: loss=0.2305, accuracy=0.9353, gradient_norm=137.6506, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 295: loss=0.2354, accuracy=0.9338, gradient_norm=133.2307, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 296: loss=0.2092, accuracy=0.9438, gradient_norm=132.8164, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 297: loss=0.1966, accuracy=0.9467, gradient_norm=130.6329, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 298: loss=0.2402, accuracy=0.9294, gradient_norm=134.1422, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 299: loss=0.2066, accuracy=0.9421, gradient_norm=133.4914, 
[2025-09-17 15:33:50,027][__main__][INFO] - Train, Round 300: loss=0.1904, accuracy=0.9494, gradient_norm=131.0246, 
[2025-09-17 15:33:50,027][__main__][INFO] - Test, Round 001: loss=2.2474, accuracy=0.2656, 
[2025-09-17 15:33:50,027][__main__][INFO] - Test, Round 002: loss=2.2278, accuracy=0.3260, 
[2025-09-17 15:33:50,027][__main__][INFO] - Test, Round 003: loss=2.2115, accuracy=0.2914, 
[2025-09-17 15:33:50,027][__main__][INFO] - Test, Round 004: loss=2.1497, accuracy=0.3782, 
[2025-09-17 15:33:50,027][__main__][INFO] - Test, Round 005: loss=2.0666, accuracy=0.3832, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 006: loss=2.1033, accuracy=0.3252, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 007: loss=1.9920, accuracy=0.3756, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 008: loss=1.9815, accuracy=0.4338, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 009: loss=1.9411, accuracy=0.4472, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 010: loss=1.9043, accuracy=0.4621, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 011: loss=1.9260, accuracy=0.4164, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 012: loss=1.9147, accuracy=0.4481, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 013: loss=1.8683, accuracy=0.4620, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 014: loss=1.8406, accuracy=0.4657, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 015: loss=1.9402, accuracy=0.3855, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 016: loss=1.8628, accuracy=0.4570, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 017: loss=1.7570, accuracy=0.5141, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 018: loss=1.8263, accuracy=0.4959, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 019: loss=1.7158, accuracy=0.5266, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 020: loss=1.8161, accuracy=0.4753, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 021: loss=1.7193, accuracy=0.4794, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 022: loss=1.7274, accuracy=0.5009, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 023: loss=1.6427, accuracy=0.5406, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 024: loss=1.6582, accuracy=0.5133, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 025: loss=1.6295, accuracy=0.5197, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 026: loss=1.5671, accuracy=0.5632, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 027: loss=1.4245, accuracy=0.5892, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 028: loss=1.6606, accuracy=0.5355, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 029: loss=1.4341, accuracy=0.6190, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 030: loss=1.5788, accuracy=0.5665, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 031: loss=1.3431, accuracy=0.6142, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 032: loss=1.5354, accuracy=0.5733, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 033: loss=1.5188, accuracy=0.5909, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 034: loss=1.6324, accuracy=0.5490, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 035: loss=1.4500, accuracy=0.5943, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 036: loss=1.4377, accuracy=0.5836, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 037: loss=1.4638, accuracy=0.5781, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 038: loss=1.3579, accuracy=0.6252, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 039: loss=1.5953, accuracy=0.5719, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 040: loss=1.2179, accuracy=0.6520, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 041: loss=1.4825, accuracy=0.5444, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 042: loss=1.3706, accuracy=0.6058, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 043: loss=1.4669, accuracy=0.5976, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 044: loss=1.4547, accuracy=0.6049, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 045: loss=1.3453, accuracy=0.6131, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 046: loss=1.4296, accuracy=0.6125, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 047: loss=1.2862, accuracy=0.6319, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 048: loss=1.3445, accuracy=0.6264, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 049: loss=1.3694, accuracy=0.6275, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 050: loss=1.2865, accuracy=0.6521, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 051: loss=1.1434, accuracy=0.6751, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 052: loss=1.4101, accuracy=0.6275, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 053: loss=1.0532, accuracy=0.6651, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 054: loss=1.1446, accuracy=0.6847, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 055: loss=1.2679, accuracy=0.6496, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 056: loss=1.2068, accuracy=0.6455, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 057: loss=1.1735, accuracy=0.6600, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 058: loss=1.2141, accuracy=0.6642, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 059: loss=1.1160, accuracy=0.6661, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 060: loss=1.1740, accuracy=0.6703, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 061: loss=1.1581, accuracy=0.6694, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 062: loss=1.0140, accuracy=0.6974, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 063: loss=1.1019, accuracy=0.6774, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 064: loss=1.0961, accuracy=0.6837, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 065: loss=1.0443, accuracy=0.6776, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 066: loss=1.0989, accuracy=0.6761, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 067: loss=1.0953, accuracy=0.6958, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 068: loss=1.0281, accuracy=0.6873, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 069: loss=1.1137, accuracy=0.6849, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 070: loss=1.2815, accuracy=0.6285, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 071: loss=1.0812, accuracy=0.6945, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 072: loss=0.9562, accuracy=0.7192, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 073: loss=1.0101, accuracy=0.6945, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 074: loss=1.0494, accuracy=0.6953, 
[2025-09-17 15:33:50,028][__main__][INFO] - Test, Round 075: loss=1.0446, accuracy=0.6966, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 076: loss=0.9705, accuracy=0.7032, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 077: loss=0.9534, accuracy=0.7160, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 078: loss=0.9826, accuracy=0.6953, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 079: loss=0.9668, accuracy=0.7199, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 080: loss=1.0105, accuracy=0.7020, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 081: loss=1.0604, accuracy=0.7088, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 082: loss=0.8621, accuracy=0.7242, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 083: loss=0.8978, accuracy=0.7207, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 084: loss=0.9599, accuracy=0.7162, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 085: loss=0.8102, accuracy=0.7269, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 086: loss=0.8716, accuracy=0.7269, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 087: loss=0.9100, accuracy=0.7093, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 088: loss=1.0712, accuracy=0.6924, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 089: loss=0.8231, accuracy=0.7342, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 090: loss=0.8826, accuracy=0.7009, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 091: loss=0.9744, accuracy=0.6996, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 092: loss=0.8499, accuracy=0.7358, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 093: loss=0.8638, accuracy=0.7287, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 094: loss=0.9835, accuracy=0.7080, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 095: loss=0.8099, accuracy=0.7293, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 096: loss=0.8433, accuracy=0.7339, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 097: loss=0.8876, accuracy=0.7327, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 098: loss=0.9490, accuracy=0.7208, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 099: loss=0.8404, accuracy=0.7269, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 100: loss=0.8206, accuracy=0.7384, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 101: loss=0.8755, accuracy=0.7409, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 102: loss=0.8433, accuracy=0.7407, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 103: loss=0.8095, accuracy=0.7329, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 104: loss=0.8958, accuracy=0.7212, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 105: loss=0.8560, accuracy=0.7275, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 106: loss=0.8134, accuracy=0.7307, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 107: loss=0.8689, accuracy=0.7248, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 108: loss=0.7733, accuracy=0.7515, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 109: loss=0.8902, accuracy=0.7152, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 110: loss=0.8609, accuracy=0.7349, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 111: loss=0.8578, accuracy=0.7118, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 112: loss=0.8298, accuracy=0.7337, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 113: loss=0.8455, accuracy=0.7265, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 114: loss=0.8384, accuracy=0.7327, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 115: loss=0.7522, accuracy=0.7525, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 116: loss=0.8252, accuracy=0.7388, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 117: loss=0.8352, accuracy=0.7279, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 118: loss=0.8672, accuracy=0.7307, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 119: loss=0.8096, accuracy=0.7372, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 120: loss=0.7866, accuracy=0.7477, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 121: loss=0.7843, accuracy=0.7361, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 122: loss=0.7689, accuracy=0.7470, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 123: loss=0.7848, accuracy=0.7352, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 124: loss=0.7652, accuracy=0.7464, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 125: loss=0.8184, accuracy=0.7268, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 126: loss=0.8551, accuracy=0.7183, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 127: loss=0.7873, accuracy=0.7473, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 128: loss=0.8301, accuracy=0.7227, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 129: loss=0.7959, accuracy=0.7325, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 130: loss=0.7985, accuracy=0.7448, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 131: loss=0.7769, accuracy=0.7623, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 132: loss=0.7718, accuracy=0.7386, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 133: loss=0.8370, accuracy=0.7281, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 134: loss=0.7454, accuracy=0.7432, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 135: loss=0.7309, accuracy=0.7487, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 136: loss=0.7498, accuracy=0.7386, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 137: loss=0.8003, accuracy=0.7343, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 138: loss=0.7793, accuracy=0.7315, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 139: loss=0.7570, accuracy=0.7389, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 140: loss=0.8271, accuracy=0.7290, 
[2025-09-17 15:33:50,029][__main__][INFO] - Test, Round 141: loss=0.7876, accuracy=0.7314, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 142: loss=0.7596, accuracy=0.7370, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 143: loss=0.7367, accuracy=0.7596, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 144: loss=0.7583, accuracy=0.7284, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 145: loss=0.7980, accuracy=0.7397, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 146: loss=0.7368, accuracy=0.7514, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 147: loss=0.7990, accuracy=0.7489, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 148: loss=0.7660, accuracy=0.7473, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 149: loss=0.7179, accuracy=0.7553, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 150: loss=0.7682, accuracy=0.7363, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 151: loss=0.7142, accuracy=0.7641, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 152: loss=0.7426, accuracy=0.7552, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 153: loss=0.7520, accuracy=0.7454, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 154: loss=0.7314, accuracy=0.7550, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 155: loss=0.7299, accuracy=0.7530, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 156: loss=0.7365, accuracy=0.7530, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 157: loss=0.7567, accuracy=0.7411, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 158: loss=0.7419, accuracy=0.7566, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 159: loss=0.7578, accuracy=0.7482, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 160: loss=0.6881, accuracy=0.7605, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 161: loss=0.7510, accuracy=0.7489, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 162: loss=0.7666, accuracy=0.7393, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 163: loss=0.7739, accuracy=0.7331, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 164: loss=0.7377, accuracy=0.7493, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 165: loss=0.7111, accuracy=0.7518, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 166: loss=0.7419, accuracy=0.7527, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 167: loss=0.7097, accuracy=0.7588, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 168: loss=0.7545, accuracy=0.7588, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 169: loss=0.7294, accuracy=0.7470, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 170: loss=0.7186, accuracy=0.7635, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 171: loss=0.7177, accuracy=0.7448, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 172: loss=0.7275, accuracy=0.7484, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 173: loss=0.7175, accuracy=0.7616, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 174: loss=0.7847, accuracy=0.7452, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 175: loss=0.7334, accuracy=0.7518, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 176: loss=0.7272, accuracy=0.7411, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 177: loss=0.7894, accuracy=0.7292, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 178: loss=0.7099, accuracy=0.7609, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 179: loss=0.7368, accuracy=0.7543, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 180: loss=0.7112, accuracy=0.7541, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 181: loss=0.6868, accuracy=0.7676, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 182: loss=0.7420, accuracy=0.7479, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 183: loss=0.7500, accuracy=0.7375, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 184: loss=0.7407, accuracy=0.7463, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 185: loss=0.7323, accuracy=0.7589, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 186: loss=0.6887, accuracy=0.7663, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 187: loss=0.6885, accuracy=0.7575, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 188: loss=0.6912, accuracy=0.7644, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 189: loss=0.7238, accuracy=0.7470, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 190: loss=0.7543, accuracy=0.7228, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 191: loss=0.7321, accuracy=0.7657, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 192: loss=0.7270, accuracy=0.7514, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 193: loss=0.7657, accuracy=0.7438, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 194: loss=0.7396, accuracy=0.7514, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 195: loss=0.7796, accuracy=0.7280, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 196: loss=0.7006, accuracy=0.7536, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 197: loss=0.7211, accuracy=0.7553, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 198: loss=0.7019, accuracy=0.7703, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 199: loss=0.7573, accuracy=0.7475, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 200: loss=0.7292, accuracy=0.7534, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 201: loss=0.7548, accuracy=0.7543, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 202: loss=0.7335, accuracy=0.7375, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 203: loss=0.7402, accuracy=0.7621, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 204: loss=0.6783, accuracy=0.7691, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 205: loss=0.7461, accuracy=0.7520, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 206: loss=0.7054, accuracy=0.7779, 
[2025-09-17 15:33:50,030][__main__][INFO] - Test, Round 207: loss=0.7187, accuracy=0.7480, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 208: loss=0.7334, accuracy=0.7630, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 209: loss=0.7597, accuracy=0.7557, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 210: loss=0.7189, accuracy=0.7643, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 211: loss=0.7369, accuracy=0.7247, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 212: loss=0.7141, accuracy=0.7612, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 213: loss=0.7603, accuracy=0.7361, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 214: loss=0.7111, accuracy=0.7762, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 215: loss=0.7437, accuracy=0.7523, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 216: loss=0.7143, accuracy=0.7577, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 217: loss=0.6853, accuracy=0.7713, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 218: loss=0.7045, accuracy=0.7609, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 219: loss=0.7210, accuracy=0.7778, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 220: loss=0.7023, accuracy=0.7569, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 221: loss=0.7187, accuracy=0.7555, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 222: loss=0.7023, accuracy=0.7473, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 223: loss=0.7083, accuracy=0.7623, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 224: loss=0.7371, accuracy=0.7633, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 225: loss=0.6822, accuracy=0.7796, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 226: loss=0.7648, accuracy=0.7558, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 227: loss=0.7176, accuracy=0.7408, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 228: loss=0.7058, accuracy=0.7635, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 229: loss=0.7304, accuracy=0.7635, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 230: loss=0.7475, accuracy=0.7445, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 231: loss=0.6912, accuracy=0.7685, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 232: loss=0.7135, accuracy=0.7571, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 233: loss=0.7371, accuracy=0.7564, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 234: loss=0.7223, accuracy=0.7613, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 235: loss=0.7421, accuracy=0.7623, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 236: loss=0.7273, accuracy=0.7560, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 237: loss=0.7079, accuracy=0.7601, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 238: loss=0.6909, accuracy=0.7741, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 239: loss=0.7165, accuracy=0.7489, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 240: loss=0.7630, accuracy=0.7564, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 241: loss=0.7303, accuracy=0.7537, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 242: loss=0.7405, accuracy=0.7607, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 243: loss=0.6953, accuracy=0.7809, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 244: loss=0.7644, accuracy=0.7471, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 245: loss=0.6944, accuracy=0.7657, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 246: loss=0.7885, accuracy=0.7339, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 247: loss=0.6907, accuracy=0.7652, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 248: loss=0.7150, accuracy=0.7738, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 249: loss=0.7236, accuracy=0.7527, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 250: loss=0.7268, accuracy=0.7687, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 251: loss=0.7582, accuracy=0.7623, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 252: loss=0.6913, accuracy=0.7696, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 253: loss=0.7077, accuracy=0.7535, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 254: loss=0.7682, accuracy=0.7386, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 255: loss=0.6607, accuracy=0.7912, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 256: loss=0.6999, accuracy=0.7786, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 257: loss=0.6934, accuracy=0.7853, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 258: loss=0.6904, accuracy=0.7778, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 259: loss=0.7286, accuracy=0.7634, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 260: loss=0.7134, accuracy=0.7831, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 261: loss=0.7136, accuracy=0.7817, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 262: loss=0.7377, accuracy=0.7562, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 263: loss=0.7308, accuracy=0.7637, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 264: loss=0.7372, accuracy=0.7466, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 265: loss=0.7464, accuracy=0.7605, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 266: loss=0.7121, accuracy=0.7546, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 267: loss=0.6711, accuracy=0.7815, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 268: loss=0.6894, accuracy=0.7790, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 269: loss=0.6992, accuracy=0.7850, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 270: loss=0.6715, accuracy=0.7842, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 271: loss=0.6879, accuracy=0.7799, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 272: loss=0.7320, accuracy=0.7726, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 273: loss=0.7155, accuracy=0.7604, 
[2025-09-17 15:33:50,031][__main__][INFO] - Test, Round 274: loss=0.7409, accuracy=0.7707, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 275: loss=0.7730, accuracy=0.7489, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 276: loss=0.7420, accuracy=0.7587, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 277: loss=0.7298, accuracy=0.7716, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 278: loss=0.7177, accuracy=0.7810, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 279: loss=0.7475, accuracy=0.7437, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 280: loss=0.7442, accuracy=0.7645, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 281: loss=0.6864, accuracy=0.7909, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 282: loss=0.7324, accuracy=0.7697, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 283: loss=0.6809, accuracy=0.7843, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 284: loss=0.6853, accuracy=0.7712, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 285: loss=0.6950, accuracy=0.7625, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 286: loss=0.7165, accuracy=0.7658, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 287: loss=0.7127, accuracy=0.7628, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 288: loss=0.7371, accuracy=0.7649, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 289: loss=0.7222, accuracy=0.7619, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 290: loss=0.7352, accuracy=0.7714, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 291: loss=0.7127, accuracy=0.7646, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 292: loss=0.7313, accuracy=0.7635, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 293: loss=0.7598, accuracy=0.7600, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 294: loss=0.7440, accuracy=0.7596, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 295: loss=0.7235, accuracy=0.7668, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 296: loss=0.7015, accuracy=0.7692, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 297: loss=0.7384, accuracy=0.7727, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 298: loss=0.7751, accuracy=0.7638, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 299: loss=0.7663, accuracy=0.7619, 
[2025-09-17 15:33:50,032][__main__][INFO] - Test, Round 300: loss=0.7575, accuracy=0.7673, 

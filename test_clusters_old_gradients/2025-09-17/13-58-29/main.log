[2025-09-17 13:58:34,162][flp2p.graph_runner][INFO] - Train, Round 0 : loss => 2.306499971548716,  accuracy: 0.0761111111111111, gradient_norm : 301.93402112456545
[2025-09-17 13:58:34,794][flp2p.graph_runner][INFO] - Test, Round 0 : loss => 2.290582514264934,  accuracy: 0.1006036217303823
[2025-09-17 13:58:37,532][flp2p.graph_runner][INFO] - Train, Round 1 : loss => 2.304059986273448,  accuracy: 0.08044444444444444, gradient_norm : 299.5179988669346
[2025-09-17 13:58:38,186][flp2p.graph_runner][INFO] - Test, Round 1 : loss => 2.2878803236623644,  accuracy: 0.09456740442655935
[2025-09-17 13:58:41,223][flp2p.graph_runner][INFO] - Train, Round 2 : loss => 2.303036242542845,  accuracy: 0.08181818181818182, gradient_norm : 297.29673693088444
[2025-09-17 13:58:41,916][flp2p.graph_runner][INFO] - Test, Round 2 : loss => 2.287970340968481,  accuracy: 0.1092896174863388
[2025-09-17 13:58:44,656][flp2p.graph_runner][INFO] - Train, Round 3 : loss => 2.296186655362447,  accuracy: 0.08977777777777778, gradient_norm : 293.1064757084852
[2025-09-17 13:58:45,264][flp2p.graph_runner][INFO] - Test, Round 3 : loss => 2.280095379628583,  accuracy: 0.10978043912175649
[2025-09-17 13:58:48,216][flp2p.graph_runner][INFO] - Train, Round 4 : loss => 2.285714872678121,  accuracy: 0.11045454545454546, gradient_norm : 287.64440253353126
[2025-09-17 13:58:48,909][flp2p.graph_runner][INFO] - Test, Round 4 : loss => 2.2667948708046963,  accuracy: 0.1551094890510949
[2025-09-17 13:58:51,945][flp2p.graph_runner][INFO] - Train, Round 5 : loss => 2.2972394704818724,  accuracy: 0.09035353535353534, gradient_norm : 292.9583727979083
[2025-09-17 13:58:52,645][flp2p.graph_runner][INFO] - Test, Round 5 : loss => 2.27973458747448,  accuracy: 0.11625794732061762
[2025-09-17 13:58:55,450][flp2p.graph_runner][INFO] - Train, Round 6 : loss => 2.2852381308873495,  accuracy: 0.12066666666666667, gradient_norm : 293.422947827591
[2025-09-17 13:58:56,059][flp2p.graph_runner][INFO] - Test, Round 6 : loss => 2.269648574687146,  accuracy: 0.13886113886113885
[2025-09-17 13:58:59,110][flp2p.graph_runner][INFO] - Train, Round 7 : loss => 2.280275905493534,  accuracy: 0.12010101010101011, gradient_norm : 290.4595130651253
[2025-09-17 13:58:59,789][flp2p.graph_runner][INFO] - Test, Round 7 : loss => 2.2625719522509504,  accuracy: 0.17738970588235295
[2025-09-17 13:59:02,710][flp2p.graph_runner][INFO] - Train, Round 8 : loss => 2.274917725360755,  accuracy: 0.12696969696969695, gradient_norm : 282.5601776590498
[2025-09-17 13:59:03,427][flp2p.graph_runner][INFO] - Test, Round 8 : loss => 2.258618422978997,  accuracy: 0.16757741347905283
[2025-09-17 13:59:06,477][flp2p.graph_runner][INFO] - Train, Round 9 : loss => 2.2715055574070324,  accuracy: 0.1548989898989899, gradient_norm : 284.1118718541201
[2025-09-17 13:59:07,212][flp2p.graph_runner][INFO] - Test, Round 9 : loss => 2.2534270698077057,  accuracy: 0.2356164383561644
[2025-09-17 13:59:10,219][flp2p.graph_runner][INFO] - Train, Round 10 : loss => 2.27521814288515,  accuracy: 0.14212121212121212, gradient_norm : 286.98554043145134
[2025-09-17 13:59:10,913][flp2p.graph_runner][INFO] - Test, Round 10 : loss => 2.2614125602895565,  accuracy: 0.17727272727272728
[2025-09-17 13:59:13,959][flp2p.graph_runner][INFO] - Train, Round 11 : loss => 2.272272815126361,  accuracy: 0.14388888888888887, gradient_norm : 287.20633139982385
[2025-09-17 13:59:14,664][flp2p.graph_runner][INFO] - Test, Round 11 : loss => 2.2570072947738384,  accuracy: 0.19216757741347906
[2025-09-17 13:59:17,688][flp2p.graph_runner][INFO] - Train, Round 12 : loss => 2.2661953377001214,  accuracy: 0.16797979797979798, gradient_norm : 293.0349259940806
[2025-09-17 13:59:18,401][flp2p.graph_runner][INFO] - Test, Round 12 : loss => 2.2516589239989524,  accuracy: 0.20494053064958828
[2025-09-17 13:59:21,444][flp2p.graph_runner][INFO] - Train, Round 13 : loss => 2.262022592082168,  accuracy: 0.17585858585858588, gradient_norm : 292.43933203054587
[2025-09-17 13:59:22,173][flp2p.graph_runner][INFO] - Test, Round 13 : loss => 2.2473649373320628,  accuracy: 0.20494053064958828
[2025-09-17 13:59:25,807][flp2p.graph_runner][INFO] - Train, Round 14 : loss => 2.2788133852409596,  accuracy: 0.13752525252525255, gradient_norm : 293.9220772981521
[2025-09-17 13:59:26,778][flp2p.graph_runner][INFO] - Test, Round 14 : loss => 2.263759298093153,  accuracy: 0.16483516483516483
[2025-09-17 13:59:30,883][flp2p.graph_runner][INFO] - Train, Round 15 : loss => 2.2630773999474267,  accuracy: 0.1684343434343434, gradient_norm : 288.7530867634204
[2025-09-17 13:59:31,847][flp2p.graph_runner][INFO] - Test, Round 15 : loss => 2.2465154036279125,  accuracy: 0.21062271062271062
[2025-09-17 13:59:35,662][flp2p.graph_runner][INFO] - Train, Round 16 : loss => 2.2471496152877806,  accuracy: 0.22011111111111112, gradient_norm : 287.5955735568899
[2025-09-17 13:59:36,553][flp2p.graph_runner][INFO] - Test, Round 16 : loss => 2.230987712291165,  accuracy: 0.26458752515090544
[2025-09-17 13:59:40,796][flp2p.graph_runner][INFO] - Train, Round 17 : loss => 2.254540943376946,  accuracy: 0.18762626262626264, gradient_norm : 288.50621379264254
[2025-09-17 13:59:41,781][flp2p.graph_runner][INFO] - Test, Round 17 : loss => 2.2384372855058667,  accuracy: 0.23701002734731086
[2025-09-17 13:59:45,717][flp2p.graph_runner][INFO] - Train, Round 18 : loss => 2.237823788324992,  accuracy: 0.22411111111111112, gradient_norm : 287.86181925999506
[2025-09-17 13:59:46,593][flp2p.graph_runner][INFO] - Test, Round 18 : loss => 2.2207237480875244,  accuracy: 0.2748244734202608
[2025-09-17 13:59:50,922][flp2p.graph_runner][INFO] - Train, Round 19 : loss => 2.2509193687727955,  accuracy: 0.19974747474747473, gradient_norm : 292.98328009099083
[2025-09-17 13:59:51,919][flp2p.graph_runner][INFO] - Test, Round 19 : loss => 2.236040805394833,  accuracy: 0.23626373626373626
[2025-09-17 13:59:56,245][flp2p.graph_runner][INFO] - Train, Round 20 : loss => 2.2382025371898306,  accuracy: 0.24404040404040403, gradient_norm : 295.74277279803573
[2025-09-17 13:59:57,226][flp2p.graph_runner][INFO] - Test, Round 20 : loss => 2.221200809932475,  accuracy: 0.2845379688929552
[2025-09-17 14:00:01,464][flp2p.graph_runner][INFO] - Train, Round 21 : loss => 2.238577711943424,  accuracy: 0.22479797979797977, gradient_norm : 300.44620557240916
[2025-09-17 14:00:02,478][flp2p.graph_runner][INFO] - Test, Round 21 : loss => 2.2213248052518733,  accuracy: 0.2728102189781022
[2025-09-17 14:00:06,686][flp2p.graph_runner][INFO] - Train, Round 22 : loss => 2.2216478593421707,  accuracy: 0.28429292929292926, gradient_norm : 299.39934072988683
[2025-09-17 14:00:07,679][flp2p.graph_runner][INFO] - Test, Round 22 : loss => 2.2051920086281487,  accuracy: 0.30684931506849317
[2025-09-17 14:00:11,944][flp2p.graph_runner][INFO] - Train, Round 23 : loss => 2.2241709434624872,  accuracy: 0.2811616161616161, gradient_norm : 304.3864132360164
[2025-09-17 14:00:12,926][flp2p.graph_runner][INFO] - Test, Round 23 : loss => 2.2096642934174464,  accuracy: 0.3010064043915828
[2025-09-17 14:00:17,067][flp2p.graph_runner][INFO] - Train, Round 24 : loss => 2.2176798206387143,  accuracy: 0.2938888888888889, gradient_norm : 305.3578027278868
[2025-09-17 14:00:18,076][flp2p.graph_runner][INFO] - Test, Round 24 : loss => 2.200204455296271,  accuracy: 0.3220494053064959
[2025-09-17 14:00:22,281][flp2p.graph_runner][INFO] - Train, Round 25 : loss => 2.207468429478732,  accuracy: 0.31585858585858584, gradient_norm : 310.8338606220741
[2025-09-17 14:00:23,267][flp2p.graph_runner][INFO] - Test, Round 25 : loss => 2.1898993338315025,  accuracy: 0.34303912647861695
[2025-09-17 14:00:27,539][flp2p.graph_runner][INFO] - Train, Round 26 : loss => 2.187771195353884,  accuracy: 0.3565151515151515, gradient_norm : 315.8195656811823
[2025-09-17 14:00:28,549][flp2p.graph_runner][INFO] - Test, Round 26 : loss => 2.168870507198414,  accuracy: 0.3870082342177493
[2025-09-17 14:00:32,775][flp2p.graph_runner][INFO] - Train, Round 27 : loss => 2.2147676915833445,  accuracy: 0.2617171717171717, gradient_norm : 303.16737769849124
[2025-09-17 14:00:33,775][flp2p.graph_runner][INFO] - Test, Round 27 : loss => 2.1988697129086283,  accuracy: 0.2959927140255009
[2025-09-17 14:00:38,090][flp2p.graph_runner][INFO] - Train, Round 28 : loss => 2.1816121007456926,  accuracy: 0.34984848484848485, gradient_norm : 321.3254247564007
[2025-09-17 14:00:39,107][flp2p.graph_runner][INFO] - Test, Round 28 : loss => 2.1626087634696023,  accuracy: 0.3600729261622607
[2025-09-17 14:00:43,318][flp2p.graph_runner][INFO] - Train, Round 29 : loss => 2.1996206001801926,  accuracy: 0.2958585858585858, gradient_norm : 314.85132212452095
[2025-09-17 14:00:44,319][flp2p.graph_runner][INFO] - Test, Round 29 : loss => 2.1824504956738764,  accuracy: 0.34335154826958103
[2025-09-17 14:00:48,274][flp2p.graph_runner][INFO] - Train, Round 30 : loss => 2.1645392537117005,  accuracy: 0.3491111111111111, gradient_norm : 332.9848125286329
[2025-09-17 14:00:49,181][flp2p.graph_runner][INFO] - Test, Round 30 : loss => 2.1433981708390917,  accuracy: 0.3877755511022044
[2025-09-17 14:00:52,962][flp2p.graph_runner][INFO] - Train, Round 31 : loss => 2.186297438542048,  accuracy: 0.3048888888888889, gradient_norm : 323.8603364370369
[2025-09-17 14:00:53,877][flp2p.graph_runner][INFO] - Test, Round 31 : loss => 2.1700364779755774,  accuracy: 0.3373493975903614
[2025-09-17 14:00:58,090][flp2p.graph_runner][INFO] - Train, Round 32 : loss => 2.1798654556274415,  accuracy: 0.3302020202020202, gradient_norm : 322.70511338004434
[2025-09-17 14:00:59,095][flp2p.graph_runner][INFO] - Test, Round 32 : loss => 2.164915143735877,  accuracy: 0.35799086757990867
[2025-09-17 14:01:03,032][flp2p.graph_runner][INFO] - Train, Round 33 : loss => 2.196862558921178,  accuracy: 0.2653888888888889, gradient_norm : 317.4262682150196
[2025-09-17 14:01:03,942][flp2p.graph_runner][INFO] - Test, Round 33 : loss => 2.1824379663467406,  accuracy: 0.297
[2025-09-17 14:01:08,234][flp2p.graph_runner][INFO] - Train, Round 34 : loss => 2.1591227693991226,  accuracy: 0.3609090909090909, gradient_norm : 335.800095408718
[2025-09-17 14:01:09,268][flp2p.graph_runner][INFO] - Test, Round 34 : loss => 2.1390978417772075,  accuracy: 0.36996336996337
[2025-09-17 14:01:13,537][flp2p.graph_runner][INFO] - Train, Round 35 : loss => 2.166146106792219,  accuracy: 0.35328282828282825, gradient_norm : 332.75373005153693
[2025-09-17 14:01:14,520][flp2p.graph_runner][INFO] - Test, Round 35 : loss => 2.1460576147793633,  accuracy: 0.3735159817351598
[2025-09-17 14:01:18,854][flp2p.graph_runner][INFO] - Train, Round 36 : loss => 2.1629206198634523,  accuracy: 0.34277777777777774, gradient_norm : 328.40855530781204
[2025-09-17 14:01:19,881][flp2p.graph_runner][INFO] - Test, Round 36 : loss => 2.1486009385487805,  accuracy: 0.3561643835616438
[2025-09-17 14:01:24,161][flp2p.graph_runner][INFO] - Train, Round 37 : loss => 2.138598700364431,  accuracy: 0.3744949494949495, gradient_norm : 343.27053909979605
[2025-09-17 14:01:25,161][flp2p.graph_runner][INFO] - Test, Round 37 : loss => 2.1183810219904187,  accuracy: 0.3903107861060329
[2025-09-17 14:01:29,268][flp2p.graph_runner][INFO] - Train, Round 38 : loss => 2.1758714589205654,  accuracy: 0.28454545454545455, gradient_norm : 321.668255006009
[2025-09-17 14:01:29,963][flp2p.graph_runner][INFO] - Test, Round 38 : loss => 2.1601473175545642,  accuracy: 0.33060109289617484
[2025-09-17 14:01:32,746][flp2p.graph_runner][INFO] - Train, Round 39 : loss => 2.113608562548955,  accuracy: 0.4118888888888889, gradient_norm : 355.01282512807984
[2025-09-17 14:01:33,416][flp2p.graph_runner][INFO] - Test, Round 39 : loss => 2.0911703029630657,  accuracy: 0.4272818455366098
[2025-09-17 14:01:36,489][flp2p.graph_runner][INFO] - Train, Round 40 : loss => 2.1546022111719303,  accuracy: 0.3259595959595959, gradient_norm : 340.71569097796953
[2025-09-17 14:01:37,216][flp2p.graph_runner][INFO] - Test, Round 40 : loss => 2.1372129436636316,  accuracy: 0.35054347826086957
[2025-09-17 14:01:41,287][flp2p.graph_runner][INFO] - Train, Round 41 : loss => 2.133765370918043,  accuracy: 0.352979797979798, gradient_norm : 340.7536767730032
[2025-09-17 14:01:42,311][flp2p.graph_runner][INFO] - Test, Round 41 : loss => 2.116316001454409,  accuracy: 0.3813868613138686
[2025-09-17 14:01:46,524][flp2p.graph_runner][INFO] - Train, Round 42 : loss => 2.1389297582886435,  accuracy: 0.33636363636363636, gradient_norm : 338.2226626623321
[2025-09-17 14:01:47,517][flp2p.graph_runner][INFO] - Test, Round 42 : loss => 2.1203453886082806,  accuracy: 0.3510540788267644
[2025-09-17 14:01:51,824][flp2p.graph_runner][INFO] - Train, Round 43 : loss => 2.1378661556677385,  accuracy: 0.3425252525252525, gradient_norm : 341.7553878965898
[2025-09-17 14:01:52,842][flp2p.graph_runner][INFO] - Test, Round 43 : loss => 2.1188839027916426,  accuracy: 0.3585766423357664
[2025-09-17 14:01:56,714][flp2p.graph_runner][INFO] - Train, Round 44 : loss => 2.10864732782046,  accuracy: 0.3917777777777777, gradient_norm : 352.95117803717926
[2025-09-17 14:01:57,617][flp2p.graph_runner][INFO] - Test, Round 44 : loss => 2.0924855383197265,  accuracy: 0.40904522613065325
[2025-09-17 14:02:01,486][flp2p.graph_runner][INFO] - Train, Round 45 : loss => 2.126597013979247,  accuracy: 0.36742424242424243, gradient_norm : 344.8618779681475
[2025-09-17 14:02:02,235][flp2p.graph_runner][INFO] - Test, Round 45 : loss => 2.111352875639436,  accuracy: 0.397459165154265
[2025-09-17 14:02:05,304][flp2p.graph_runner][INFO] - Train, Round 46 : loss => 2.1012750567811906,  accuracy: 0.4041414141414141, gradient_norm : 353.58234773929195
[2025-09-17 14:02:06,022][flp2p.graph_runner][INFO] - Test, Round 46 : loss => 2.081428439298392,  accuracy: 0.4084249084249084
[2025-09-17 14:02:09,144][flp2p.graph_runner][INFO] - Train, Round 47 : loss => 2.097682040749174,  accuracy: 0.39156565656565656, gradient_norm : 357.97309929322813
[2025-09-17 14:02:09,848][flp2p.graph_runner][INFO] - Test, Round 47 : loss => 2.080728665976734,  accuracy: 0.3891941391941392
[2025-09-17 14:02:13,915][flp2p.graph_runner][INFO] - Train, Round 48 : loss => 2.100168307622274,  accuracy: 0.38818181818181824, gradient_norm : 350.18446600217356
[2025-09-17 14:02:14,900][flp2p.graph_runner][INFO] - Test, Round 48 : loss => 2.0807858206643868,  accuracy: 0.3989071038251366
[2025-09-17 14:02:19,204][flp2p.graph_runner][INFO] - Train, Round 49 : loss => 2.0882801138993465,  accuracy: 0.40949494949494947, gradient_norm : 356.191891435478
[2025-09-17 14:02:20,230][flp2p.graph_runner][INFO] - Test, Round 49 : loss => 2.0744449015306428,  accuracy: 0.4225865209471767
[2025-09-17 14:02:24,143][flp2p.graph_runner][INFO] - Train, Round 50 : loss => 2.045017723242442,  accuracy: 0.44783333333333336, gradient_norm : 379.59987017775325
[2025-09-17 14:02:25,069][flp2p.graph_runner][INFO] - Test, Round 50 : loss => 2.0213402639812146,  accuracy: 0.45472837022132795
[2025-09-17 14:02:29,419][flp2p.graph_runner][INFO] - Train, Round 51 : loss => 2.0991138740019366,  accuracy: 0.368080808080808, gradient_norm : 347.86891285071783
[2025-09-17 14:02:30,419][flp2p.graph_runner][INFO] - Test, Round 51 : loss => 2.0842144345935387,  accuracy: 0.3996383363471971
[2025-09-17 14:02:34,696][flp2p.graph_runner][INFO] - Train, Round 52 : loss => 2.0335629788312044,  accuracy: 0.480959595959596, gradient_norm : 385.2380959157203
[2025-09-17 14:02:35,705][flp2p.graph_runner][INFO] - Test, Round 52 : loss => 2.0109308265203976,  accuracy: 0.45711678832116787
[2025-09-17 14:02:39,993][flp2p.graph_runner][INFO] - Train, Round 53 : loss => 2.042579419685133,  accuracy: 0.4529292929292929, gradient_norm : 379.37042278728944
[2025-09-17 14:02:40,997][flp2p.graph_runner][INFO] - Test, Round 53 : loss => 2.0189906262564725,  accuracy: 0.46471127406049495
[2025-09-17 14:02:44,404][flp2p.graph_runner][INFO] - Train, Round 54 : loss => 2.0540402965112166,  accuracy: 0.4157070707070707, gradient_norm : 368.13709014872506
[2025-09-17 14:02:45,087][flp2p.graph_runner][INFO] - Test, Round 54 : loss => 2.0338326565519127,  accuracy: 0.41079597438243365
[2025-09-17 14:02:48,162][flp2p.graph_runner][INFO] - Train, Round 55 : loss => 2.0447651942571006,  accuracy: 0.4447474747474748, gradient_norm : 371.7549572888359
[2025-09-17 14:02:48,905][flp2p.graph_runner][INFO] - Test, Round 55 : loss => 2.025626107562672,  accuracy: 0.4709090909090909
[2025-09-17 14:02:52,041][flp2p.graph_runner][INFO] - Train, Round 56 : loss => 2.0293492718537647,  accuracy: 0.45266666666666666, gradient_norm : 370.5938046874695
[2025-09-17 14:02:53,016][flp2p.graph_runner][INFO] - Test, Round 56 : loss => 2.0027328572995446,  accuracy: 0.4704112337011033
[2025-09-17 14:02:57,225][flp2p.graph_runner][INFO] - Train, Round 57 : loss => 2.025504779815674,  accuracy: 0.42671717171717166, gradient_norm : 376.05571586892387
[2025-09-17 14:02:58,236][flp2p.graph_runner][INFO] - Test, Round 57 : loss => 2.001325923487218,  accuracy: 0.4443430656934307
[2025-09-17 14:03:02,444][flp2p.graph_runner][INFO] - Train, Round 58 : loss => 1.9958093000180794,  accuracy: 0.4665656565656567, gradient_norm : 391.70075866953215
[2025-09-17 14:03:03,513][flp2p.graph_runner][INFO] - Test, Round 58 : loss => 1.9714572516197302,  accuracy: 0.4618874773139746
[2025-09-17 14:03:07,792][flp2p.graph_runner][INFO] - Train, Round 59 : loss => 2.020034756082477,  accuracy: 0.4484343434343434, gradient_norm : 377.86729458655157
[2025-09-17 14:03:08,818][flp2p.graph_runner][INFO] - Test, Round 59 : loss => 1.9981481858507097,  accuracy: 0.42805100182149364
[2025-09-17 14:03:13,117][flp2p.graph_runner][INFO] - Train, Round 60 : loss => 2.025940186327154,  accuracy: 0.4479292929292929, gradient_norm : 376.6360212325582
[2025-09-17 14:03:14,212][flp2p.graph_runner][INFO] - Test, Round 60 : loss => 2.00762622622768,  accuracy: 0.4623069936421435
[2025-09-17 14:03:18,424][flp2p.graph_runner][INFO] - Train, Round 61 : loss => 1.9629171714638218,  accuracy: 0.4868686868686869, gradient_norm : 405.89339540689986
[2025-09-17 14:03:19,440][flp2p.graph_runner][INFO] - Test, Round 61 : loss => 1.9377884257864038,  accuracy: 0.4689213893967093
[2025-09-17 14:03:23,294][flp2p.graph_runner][INFO] - Train, Round 62 : loss => 1.994640349149704,  accuracy: 0.4867222222222222, gradient_norm : 383.50258043620454
[2025-09-17 14:03:24,276][flp2p.graph_runner][INFO] - Test, Round 62 : loss => 1.9789709514109932,  accuracy: 0.4904522613065327
[2025-09-17 14:03:28,508][flp2p.graph_runner][INFO] - Train, Round 63 : loss => 1.978549075126648,  accuracy: 0.48287878787878796, gradient_norm : 392.2734919212344
[2025-09-17 14:03:29,524][flp2p.graph_runner][INFO] - Test, Round 63 : loss => 1.9551700216324717,  accuracy: 0.4670932358318099
[2025-09-17 14:03:33,822][flp2p.graph_runner][INFO] - Train, Round 64 : loss => 1.955640429800207,  accuracy: 0.4799494949494949, gradient_norm : 401.55164219351013
[2025-09-17 14:03:34,873][flp2p.graph_runner][INFO] - Test, Round 64 : loss => 1.9332823407160094,  accuracy: 0.46301369863013697
[2025-09-17 14:03:39,135][flp2p.graph_runner][INFO] - Train, Round 65 : loss => 1.9796477924693714,  accuracy: 0.4777272727272727, gradient_norm : 385.2055402244845
[2025-09-17 14:03:40,148][flp2p.graph_runner][INFO] - Test, Round 65 : loss => 1.9617714711131842,  accuracy: 0.4744525547445255
[2025-09-17 14:03:44,365][flp2p.graph_runner][INFO] - Train, Round 66 : loss => 1.9526461973334803,  accuracy: 0.48545454545454547, gradient_norm : 392.6282231127901
[2025-09-17 14:03:45,323][flp2p.graph_runner][INFO] - Test, Round 66 : loss => 1.9343060147024027,  accuracy: 0.4681238615664845
[2025-09-17 14:03:48,399][flp2p.graph_runner][INFO] - Train, Round 67 : loss => 1.9352910608956309,  accuracy: 0.49929292929292923, gradient_norm : 401.6479246485087
[2025-09-17 14:03:49,110][flp2p.graph_runner][INFO] - Test, Round 67 : loss => 1.9152283897183158,  accuracy: 0.48727272727272725
[2025-09-17 14:03:52,172][flp2p.graph_runner][INFO] - Train, Round 68 : loss => 1.973593643578616,  accuracy: 0.48287878787878796, gradient_norm : 383.7955778934171
[2025-09-17 14:03:52,905][flp2p.graph_runner][INFO] - Test, Round 68 : loss => 1.9530722656862332,  accuracy: 0.49271402550091076
[2025-09-17 14:03:56,036][flp2p.graph_runner][INFO] - Train, Round 69 : loss => 2.00858234203223,  accuracy: 0.43055555555555547, gradient_norm : 361.86516144448365
[2025-09-17 14:03:56,739][flp2p.graph_runner][INFO] - Test, Round 69 : loss => 1.9941393125609417,  accuracy: 0.4250681198910082
[2025-09-17 14:03:59,468][flp2p.graph_runner][INFO] - Train, Round 70 : loss => 2.004736502567927,  accuracy: 0.4848333333333334, gradient_norm : 386.5661354596083
[2025-09-17 14:04:00,134][flp2p.graph_runner][INFO] - Test, Round 70 : loss => 1.9750288138935221,  accuracy: 0.48955223880597015
[2025-09-17 14:04:03,191][flp2p.graph_runner][INFO] - Train, Round 71 : loss => 1.9107748273647194,  accuracy: 0.5191414141414141, gradient_norm : 407.2198881458557
[2025-09-17 14:04:03,911][flp2p.graph_runner][INFO] - Test, Round 71 : loss => 1.8779146676154241,  accuracy: 0.5081521739130435
[2025-09-17 14:04:06,730][flp2p.graph_runner][INFO] - Train, Round 72 : loss => 1.8673703102270762,  accuracy: 0.517888888888889, gradient_norm : 411.29947942826664
[2025-09-17 14:04:07,370][flp2p.graph_runner][INFO] - Test, Round 72 : loss => 1.8530425283777054,  accuracy: 0.49748743718592964
[2025-09-17 14:04:10,466][flp2p.graph_runner][INFO] - Train, Round 73 : loss => 1.9431714812914531,  accuracy: 0.4801010101010101, gradient_norm : 387.5786902992748
[2025-09-17 14:04:11,183][flp2p.graph_runner][INFO] - Test, Round 73 : loss => 1.925108867405105,  accuracy: 0.4781021897810219
[2025-09-17 14:04:14,267][flp2p.graph_runner][INFO] - Train, Round 74 : loss => 1.9142834627267087,  accuracy: 0.4992424242424243, gradient_norm : 406.8648047170043
[2025-09-17 14:04:14,973][flp2p.graph_runner][INFO] - Test, Round 74 : loss => 1.891974244752656,  accuracy: 0.4891304347826087
[2025-09-17 14:04:18,137][flp2p.graph_runner][INFO] - Train, Round 75 : loss => 1.9096935550371805,  accuracy: 0.5109090909090909, gradient_norm : 401.5176756932724
[2025-09-17 14:04:18,869][flp2p.graph_runner][INFO] - Test, Round 75 : loss => 1.8859196512407848,  accuracy: 0.5113122171945701
[2025-09-17 14:04:21,965][flp2p.graph_runner][INFO] - Train, Round 76 : loss => 1.9278808723796497,  accuracy: 0.5081313131313131, gradient_norm : 390.88656420002025
[2025-09-17 14:04:22,715][flp2p.graph_runner][INFO] - Test, Round 76 : loss => 1.909230673803042,  accuracy: 0.5031963470319635
[2025-09-17 14:04:25,786][flp2p.graph_runner][INFO] - Train, Round 77 : loss => 1.8877010961373648,  accuracy: 0.49772727272727285, gradient_norm : 407.3615148573708
[2025-09-17 14:04:26,573][flp2p.graph_runner][INFO] - Test, Round 77 : loss => 1.8625325410470475,  accuracy: 0.4981751824817518
[2025-09-17 14:04:29,592][flp2p.graph_runner][INFO] - Train, Round 78 : loss => 1.852169924071341,  accuracy: 0.52489898989899, gradient_norm : 417.51142808562685
[2025-09-17 14:04:30,317][flp2p.graph_runner][INFO] - Test, Round 78 : loss => 1.8351862508341343,  accuracy: 0.5228102189781022
[2025-09-17 14:04:33,325][flp2p.graph_runner][INFO] - Train, Round 79 : loss => 1.8807312820896958,  accuracy: 0.5220202020202019, gradient_norm : 402.07884007376066
[2025-09-17 14:04:34,046][flp2p.graph_runner][INFO] - Test, Round 79 : loss => 1.8589247464044003,  accuracy: 0.506398537477148
[2025-09-17 14:04:37,159][flp2p.graph_runner][INFO] - Train, Round 80 : loss => 1.9030190751408085,  accuracy: 0.5079292929292929, gradient_norm : 391.1744562967122
[2025-09-17 14:04:37,892][flp2p.graph_runner][INFO] - Test, Round 80 : loss => 1.887592940302303,  accuracy: 0.5059144676979072
[2025-09-17 14:04:41,009][flp2p.graph_runner][INFO] - Train, Round 81 : loss => 1.833205000740109,  accuracy: 0.5576767676767677, gradient_norm : 427.1555482823914
[2025-09-17 14:04:41,739][flp2p.graph_runner][INFO] - Test, Round 81 : loss => 1.8126749796410129,  accuracy: 0.54337899543379
[2025-09-17 14:04:44,831][flp2p.graph_runner][INFO] - Train, Round 82 : loss => 1.8023594556432783,  accuracy: 0.540959595959596, gradient_norm : 426.22463032917
[2025-09-17 14:04:45,547][flp2p.graph_runner][INFO] - Test, Round 82 : loss => 1.7791506884529766,  accuracy: 0.5395814376706096
[2025-09-17 14:04:48,885][flp2p.graph_runner][INFO] - Train, Round 83 : loss => 1.8647252559661864,  accuracy: 0.546, gradient_norm : 401.20013655370985
[2025-09-17 14:04:49,786][flp2p.graph_runner][INFO] - Test, Round 83 : loss => 1.8527125975098273,  accuracy: 0.5141414141414141
[2025-09-17 14:04:54,023][flp2p.graph_runner][INFO] - Train, Round 84 : loss => 1.73282159223701,  accuracy: 0.5886868686868686, gradient_norm : 445.9559877809986
[2025-09-17 14:04:55,031][flp2p.graph_runner][INFO] - Test, Round 84 : loss => 1.7154835749393642,  accuracy: 0.5756186984417965
[2025-09-17 14:04:59,311][flp2p.graph_runner][INFO] - Train, Round 85 : loss => 1.8162629813858957,  accuracy: 0.5495959595959596, gradient_norm : 419.649027835244
[2025-09-17 14:05:00,309][flp2p.graph_runner][INFO] - Test, Round 85 : loss => 1.7938880505082815,  accuracy: 0.5205479452054794
[2025-09-17 14:05:04,549][flp2p.graph_runner][INFO] - Train, Round 86 : loss => 1.7524031801657243,  accuracy: 0.5393939393939394, gradient_norm : 421.2649838302498
[2025-09-17 14:05:05,559][flp2p.graph_runner][INFO] - Test, Round 86 : loss => 1.7320216294289508,  accuracy: 0.5301645338208409
[2025-09-17 14:05:09,509][flp2p.graph_runner][INFO] - Train, Round 87 : loss => 1.8456588486830394,  accuracy: 0.5002777777777778, gradient_norm : 396.07757508302194
[2025-09-17 14:05:10,413][flp2p.graph_runner][INFO] - Test, Round 87 : loss => 1.8358216061142978,  accuracy: 0.49198396793587174
[2025-09-17 14:05:14,590][flp2p.graph_runner][INFO] - Train, Round 88 : loss => 1.7680614603288245,  accuracy: 0.5768181818181818, gradient_norm : 439.06730939432543
[2025-09-17 14:05:15,614][flp2p.graph_runner][INFO] - Test, Round 88 : loss => 1.743788126015772,  accuracy: 0.5506849315068493
[2025-09-17 14:05:19,913][flp2p.graph_runner][INFO] - Train, Round 89 : loss => 1.7942502863479384,  accuracy: 0.5394444444444445, gradient_norm : 414.29699690662534
[2025-09-17 14:05:20,944][flp2p.graph_runner][INFO] - Test, Round 89 : loss => 1.769793325825171,  accuracy: 0.5336363636363637
[2025-09-17 14:05:25,193][flp2p.graph_runner][INFO] - Train, Round 90 : loss => 1.7882452061682037,  accuracy: 0.5304545454545455, gradient_norm : 411.23979833424977
[2025-09-17 14:05:26,205][flp2p.graph_runner][INFO] - Test, Round 90 : loss => 1.776616917818298,  accuracy: 0.5245009074410163
[2025-09-17 14:05:30,471][flp2p.graph_runner][INFO] - Train, Round 91 : loss => 1.7609352698831848,  accuracy: 0.566010101010101, gradient_norm : 434.41192682058374
[2025-09-17 14:05:31,484][flp2p.graph_runner][INFO] - Test, Round 91 : loss => 1.746102487801198,  accuracy: 0.5648994515539305
[2025-09-17 14:05:35,731][flp2p.graph_runner][INFO] - Train, Round 92 : loss => 1.797488342812567,  accuracy: 0.5451010101010102, gradient_norm : 418.97782906488897
[2025-09-17 14:05:36,816][flp2p.graph_runner][INFO] - Test, Round 92 : loss => 1.7724741061240057,  accuracy: 0.5399274047186933
[2025-09-17 14:05:41,134][flp2p.graph_runner][INFO] - Train, Round 93 : loss => 1.8133360987359828,  accuracy: 0.5353535353535354, gradient_norm : 393.5500988580152
[2025-09-17 14:05:42,171][flp2p.graph_runner][INFO] - Test, Round 93 : loss => 1.7877578835961592,  accuracy: 0.5364963503649635
[2025-09-17 14:05:46,528][flp2p.graph_runner][INFO] - Train, Round 94 : loss => 1.7596514882463397,  accuracy: 0.5598989898989899, gradient_norm : 426.76240514945385
[2025-09-17 14:05:47,556][flp2p.graph_runner][INFO] - Test, Round 94 : loss => 1.7270477747072641,  accuracy: 0.5395095367847411
[2025-09-17 14:05:51,870][flp2p.graph_runner][INFO] - Train, Round 95 : loss => 1.7420802318688595,  accuracy: 0.5536868686868687, gradient_norm : 423.4508523507712
[2025-09-17 14:05:52,877][flp2p.graph_runner][INFO] - Test, Round 95 : loss => 1.7201123337221622,  accuracy: 0.5622161671207992
[2025-09-17 14:05:57,019][flp2p.graph_runner][INFO] - Train, Round 96 : loss => 1.7398809537743076,  accuracy: 0.5694444444444444, gradient_norm : 422.95461522115824
[2025-09-17 14:05:58,042][flp2p.graph_runner][INFO] - Test, Round 96 : loss => 1.7228493635563085,  accuracy: 0.5374087591240876
[2025-09-17 14:06:02,247][flp2p.graph_runner][INFO] - Train, Round 97 : loss => 1.7422264182206355,  accuracy: 0.5502020202020202, gradient_norm : 402.76622803130505
[2025-09-17 14:06:03,278][flp2p.graph_runner][INFO] - Test, Round 97 : loss => 1.721317702238142,  accuracy: 0.5374087591240876
[2025-09-17 14:06:07,533][flp2p.graph_runner][INFO] - Train, Round 98 : loss => 1.7131628890832264,  accuracy: 0.5677272727272726, gradient_norm : 428.7521984562732
[2025-09-17 14:06:08,560][flp2p.graph_runner][INFO] - Test, Round 98 : loss => 1.6971402354436378,  accuracy: 0.5424657534246575
[2025-09-17 14:06:12,919][flp2p.graph_runner][INFO] - Train, Round 99 : loss => 1.7112292883974134,  accuracy: 0.5533838383838383, gradient_norm : 425.0338101707004
[2025-09-17 14:06:13,971][flp2p.graph_runner][INFO] - Test, Round 99 : loss => 1.6949941387076901,  accuracy: 0.5413260672116258
[2025-09-17 14:06:17,868][flp2p.graph_runner][INFO] - Train, Round 100 : loss => 1.720351108511289,  accuracy: 0.5624444444444444, gradient_norm : 410.8103907832963
[2025-09-17 14:06:18,811][flp2p.graph_runner][INFO] - Test, Round 100 : loss => 1.707455079041181,  accuracy: 0.5564516129032258
[2025-09-17 14:06:23,137][flp2p.graph_runner][INFO] - Train, Round 101 : loss => 1.5871689261812152,  accuracy: 0.5792929292929294, gradient_norm : 433.19538237225566
[2025-09-17 14:06:24,168][flp2p.graph_runner][INFO] - Test, Round 101 : loss => 1.576806587561138,  accuracy: 0.5814376706096451
[2025-09-17 14:06:28,010][flp2p.graph_runner][INFO] - Train, Round 102 : loss => 1.6711254892746608,  accuracy: 0.5874444444444443, gradient_norm : 418.86122974276776
[2025-09-17 14:06:28,916][flp2p.graph_runner][INFO] - Test, Round 102 : loss => 1.6529707420303161,  accuracy: 0.5763052208835341
[2025-09-17 14:06:33,232][flp2p.graph_runner][INFO] - Train, Round 103 : loss => 1.7369926125714272,  accuracy: 0.5482323232323233, gradient_norm : 403.6415897689882
[2025-09-17 14:06:34,229][flp2p.graph_runner][INFO] - Test, Round 103 : loss => 1.7228777342675154,  accuracy: 0.546617915904936
[2025-09-17 14:06:38,536][flp2p.graph_runner][INFO] - Train, Round 104 : loss => 1.6568947876944686,  accuracy: 0.5783838383838384, gradient_norm : 415.49357714164415
[2025-09-17 14:06:39,575][flp2p.graph_runner][INFO] - Test, Round 104 : loss => 1.6501085022489772,  accuracy: 0.5667574931880109
[2025-09-17 14:06:44,002][flp2p.graph_runner][INFO] - Train, Round 105 : loss => 1.70002412109664,  accuracy: 0.5684343434343434, gradient_norm : 429.3858563944546
[2025-09-17 14:06:45,011][flp2p.graph_runner][INFO] - Test, Round 105 : loss => 1.6797357914228674,  accuracy: 0.5623293903548681
[2025-09-17 14:06:49,249][flp2p.graph_runner][INFO] - Train, Round 106 : loss => 1.6751359115947377,  accuracy: 0.5775757575757576, gradient_norm : 411.5858207977462
[2025-09-17 14:06:50,295][flp2p.graph_runner][INFO] - Test, Round 106 : loss => 1.66158488463918,  accuracy: 0.5495412844036697
[2025-09-17 14:06:54,245][flp2p.graph_runner][INFO] - Train, Round 107 : loss => 1.5623645397027333,  accuracy: 0.617111111111111, gradient_norm : 447.1962705578682
[2025-09-17 14:06:55,144][flp2p.graph_runner][INFO] - Test, Round 107 : loss => 1.5391183165717173,  accuracy: 0.596579476861167
[2025-09-17 14:06:59,410][flp2p.graph_runner][INFO] - Train, Round 108 : loss => 1.675075272357825,  accuracy: 0.568939393939394, gradient_norm : 406.02584182703197
[2025-09-17 14:07:00,435][flp2p.graph_runner][INFO] - Test, Round 108 : loss => 1.6635228822846988,  accuracy: 0.5659340659340659
[2025-09-17 14:07:04,782][flp2p.graph_runner][INFO] - Train, Round 109 : loss => 1.7692477744637114,  accuracy: 0.5722727272727273, gradient_norm : 404.5450114764431
[2025-09-17 14:07:05,801][flp2p.graph_runner][INFO] - Test, Round 109 : loss => 1.7536331489818406,  accuracy: 0.5521023765996343
[2025-09-17 14:07:10,230][flp2p.graph_runner][INFO] - Train, Round 110 : loss => 1.714745902292656,  accuracy: 0.589191919191919, gradient_norm : 421.18957217533085
[2025-09-17 14:07:11,259][flp2p.graph_runner][INFO] - Test, Round 110 : loss => 1.697089164744724,  accuracy: 0.5581818181818182
[2025-09-17 14:07:15,603][flp2p.graph_runner][INFO] - Train, Round 111 : loss => 1.5958759894876768,  accuracy: 0.601919191919192, gradient_norm : 425.0317911766897
[2025-09-17 14:07:16,613][flp2p.graph_runner][INFO] - Test, Round 111 : loss => 1.5722288316931605,  accuracy: 0.5987144168962351
[2025-09-17 14:07:20,907][flp2p.graph_runner][INFO] - Train, Round 112 : loss => 1.6714859754750222,  accuracy: 0.5854545454545454, gradient_norm : 419.7550430393537
[2025-09-17 14:07:21,952][flp2p.graph_runner][INFO] - Test, Round 112 : loss => 1.6498210176947776,  accuracy: 0.5733819507748404
[2025-09-17 14:07:26,311][flp2p.graph_runner][INFO] - Train, Round 113 : loss => 1.6415057359319745,  accuracy: 0.5792424242424242, gradient_norm : 421.8949199787212
[2025-09-17 14:07:27,322][flp2p.graph_runner][INFO] - Test, Round 113 : loss => 1.6154465381123804,  accuracy: 0.5663636363636364
[2025-09-17 14:07:31,249][flp2p.graph_runner][INFO] - Train, Round 114 : loss => 1.5512397515773773,  accuracy: 0.6076111111111111, gradient_norm : 432.496737171944
[2025-09-17 14:07:32,184][flp2p.graph_runner][INFO] - Test, Round 114 : loss => 1.5334967612260784,  accuracy: 0.596579476861167
[2025-09-17 14:07:36,624][flp2p.graph_runner][INFO] - Train, Round 115 : loss => 1.6333023820862627,  accuracy: 0.5870707070707071, gradient_norm : 411.4603326454143
[2025-09-17 14:07:37,644][flp2p.graph_runner][INFO] - Test, Round 115 : loss => 1.6081641865475915,  accuracy: 0.5912007332722273
[2025-09-17 14:07:41,615][flp2p.graph_runner][INFO] - Train, Round 116 : loss => 1.5034936147928237,  accuracy: 0.6112777777777777, gradient_norm : 430.54951182706344
[2025-09-17 14:07:42,554][flp2p.graph_runner][INFO] - Test, Round 116 : loss => 1.5036734294699856,  accuracy: 0.6044176706827309
[2025-09-17 14:07:46,918][flp2p.graph_runner][INFO] - Train, Round 117 : loss => 1.6572080091996626,  accuracy: 0.5605050505050505, gradient_norm : 403.6177467393016
[2025-09-17 14:07:47,805][flp2p.graph_runner][INFO] - Test, Round 117 : loss => 1.6571355065613904,  accuracy: 0.5577797998180164
[2025-09-17 14:07:51,101][flp2p.graph_runner][INFO] - Train, Round 118 : loss => 1.6666430980870217,  accuracy: 0.5788383838383838, gradient_norm : 420.42828688399965
[2025-09-17 14:07:52,003][flp2p.graph_runner][INFO] - Test, Round 118 : loss => 1.651018860794249,  accuracy: 0.5659340659340659
[2025-09-17 14:07:55,365][flp2p.graph_runner][INFO] - Train, Round 119 : loss => 1.5893347149545496,  accuracy: 0.6008080808080809, gradient_norm : 431.4079893084467
[2025-09-17 14:07:56,240][flp2p.graph_runner][INFO] - Test, Round 119 : loss => 1.570922054883537,  accuracy: 0.5871559633027523
[2025-09-17 14:07:59,592][flp2p.graph_runner][INFO] - Train, Round 120 : loss => 1.5554066240787505,  accuracy: 0.6056060606060607, gradient_norm : 435.0162189820422
[2025-09-17 14:08:00,471][flp2p.graph_runner][INFO] - Test, Round 120 : loss => 1.5324230223921238,  accuracy: 0.5896269335759782
[2025-09-17 14:08:03,873][flp2p.graph_runner][INFO] - Train, Round 121 : loss => 1.5173515383041267,  accuracy: 0.612929292929293, gradient_norm : 436.1029410957942
[2025-09-17 14:08:04,759][flp2p.graph_runner][INFO] - Test, Round 121 : loss => 1.5014209200258124,  accuracy: 0.6027397260273972
[2025-09-17 14:08:09,086][flp2p.graph_runner][INFO] - Train, Round 122 : loss => 1.5990066011746724,  accuracy: 0.5873737373737373, gradient_norm : 435.5775554485852
[2025-09-17 14:08:10,271][flp2p.graph_runner][INFO] - Test, Round 122 : loss => 1.5692006317447853,  accuracy: 0.5872146118721461
[2025-09-17 14:08:14,963][flp2p.graph_runner][INFO] - Train, Round 123 : loss => 1.5710409985347227,  accuracy: 0.5951515151515151, gradient_norm : 444.05566475772355
[2025-09-17 14:08:16,169][flp2p.graph_runner][INFO] - Test, Round 123 : loss => 1.558103880210631,  accuracy: 0.582427536231884
[2025-09-17 14:08:20,970][flp2p.graph_runner][INFO] - Train, Round 124 : loss => 1.605444939208753,  accuracy: 0.5918686868686869, gradient_norm : 421.2148969574822
[2025-09-17 14:08:22,170][flp2p.graph_runner][INFO] - Test, Round 124 : loss => 1.5780180803956447,  accuracy: 0.575591985428051
[2025-09-17 14:08:26,910][flp2p.graph_runner][INFO] - Train, Round 125 : loss => 1.647232655503533,  accuracy: 0.5733333333333334, gradient_norm : 416.754859173743
[2025-09-17 14:08:28,156][flp2p.graph_runner][INFO] - Test, Round 125 : loss => 1.6347428924993637,  accuracy: 0.5568807339449541
[2025-09-17 14:08:32,875][flp2p.graph_runner][INFO] - Train, Round 126 : loss => 1.5038827287428307,  accuracy: 0.6039898989898991, gradient_norm : 438.0369696697416
[2025-09-17 14:08:34,116][flp2p.graph_runner][INFO] - Test, Round 126 : loss => 1.4906132243600958,  accuracy: 0.5906593406593407
[2025-09-17 14:08:38,882][flp2p.graph_runner][INFO] - Train, Round 127 : loss => 1.5879879248864723,  accuracy: 0.6081818181818182, gradient_norm : 431.5475191314012
[2025-09-17 14:08:40,079][flp2p.graph_runner][INFO] - Test, Round 127 : loss => 1.5816535008495505,  accuracy: 0.5854545454545454
[2025-09-17 14:08:44,849][flp2p.graph_runner][INFO] - Train, Round 128 : loss => 1.552046899542664,  accuracy: 0.6082828282828283, gradient_norm : 419.86434411054705
[2025-09-17 14:08:46,123][flp2p.graph_runner][INFO] - Test, Round 128 : loss => 1.5497348533639916,  accuracy: 0.5868971792538672
[2025-09-17 14:08:50,831][flp2p.graph_runner][INFO] - Train, Round 129 : loss => 1.5687728116006563,  accuracy: 0.6038383838383838, gradient_norm : 424.8488576576158
[2025-09-17 14:08:52,091][flp2p.graph_runner][INFO] - Test, Round 129 : loss => 1.5486041297739987,  accuracy: 0.5918552036199095
[2025-09-17 14:08:56,706][flp2p.graph_runner][INFO] - Train, Round 130 : loss => 1.5708231741731817,  accuracy: 0.6028787878787879, gradient_norm : 430.24902654654693
[2025-09-17 14:08:57,945][flp2p.graph_runner][INFO] - Test, Round 130 : loss => 1.549112734573135,  accuracy: 0.6092896174863388
[2025-09-17 14:09:02,751][flp2p.graph_runner][INFO] - Train, Round 131 : loss => 1.5281786197062694,  accuracy: 0.628131313131313, gradient_norm : 439.4652562917676
[2025-09-17 14:09:03,955][flp2p.graph_runner][INFO] - Test, Round 131 : loss => 1.5201690079735928,  accuracy: 0.6156648451730419
[2025-09-17 14:09:08,650][flp2p.graph_runner][INFO] - Train, Round 132 : loss => 1.592644077720064,  accuracy: 0.5867676767676768, gradient_norm : 418.81215747957026
[2025-09-17 14:09:09,887][flp2p.graph_runner][INFO] - Test, Round 132 : loss => 1.5817713356257355,  accuracy: 0.5638686131386861
[2025-09-17 14:09:14,648][flp2p.graph_runner][INFO] - Train, Round 133 : loss => 1.4887497665304126,  accuracy: 0.612020202020202, gradient_norm : 447.4533255064733
[2025-09-17 14:09:15,892][flp2p.graph_runner][INFO] - Test, Round 133 : loss => 1.4576905807362328,  accuracy: 0.5985533453887885
[2025-09-17 14:09:19,709][flp2p.graph_runner][INFO] - Train, Round 134 : loss => 1.4145771898825963,  accuracy: 0.6146666666666666, gradient_norm : 435.4743084743151
[2025-09-17 14:09:20,517][flp2p.graph_runner][INFO] - Test, Round 134 : loss => 1.4087279089936264,  accuracy: 0.6056056056056056
[2025-09-17 14:09:23,842][flp2p.graph_runner][INFO] - Train, Round 135 : loss => 1.41679989695549,  accuracy: 0.6382323232323234, gradient_norm : 442.0474875980175
[2025-09-17 14:09:24,737][flp2p.graph_runner][INFO] - Test, Round 135 : loss => 1.4087144084669772,  accuracy: 0.6206581352833638
[2025-09-17 14:09:28,116][flp2p.graph_runner][INFO] - Train, Round 136 : loss => 1.5622227271397908,  accuracy: 0.605909090909091, gradient_norm : 437.85189792665875
[2025-09-17 14:09:29,010][flp2p.graph_runner][INFO] - Test, Round 136 : loss => 1.5478095748513476,  accuracy: 0.5896269335759782
[2025-09-17 14:09:32,368][flp2p.graph_runner][INFO] - Train, Round 137 : loss => 1.4456325348579522,  accuracy: 0.6311616161616163, gradient_norm : 424.26556657294435
[2025-09-17 14:09:33,244][flp2p.graph_runner][INFO] - Test, Round 137 : loss => 1.4487708117863902,  accuracy: 0.6063926940639269
[2025-09-17 14:09:36,543][flp2p.graph_runner][INFO] - Train, Round 138 : loss => 1.4884438489422653,  accuracy: 0.6266666666666665, gradient_norm : 438.60579357093087
[2025-09-17 14:09:37,406][flp2p.graph_runner][INFO] - Test, Round 138 : loss => 1.4645421170475044,  accuracy: 0.6119673617407072
[2025-09-17 14:09:40,739][flp2p.graph_runner][INFO] - Train, Round 139 : loss => 1.6517718109217556,  accuracy: 0.5683838383838382, gradient_norm : 411.8010164259058
[2025-09-17 14:09:41,655][flp2p.graph_runner][INFO] - Test, Round 139 : loss => 1.6374421777190082,  accuracy: 0.5647810218978102
[2025-09-17 14:09:44,979][flp2p.graph_runner][INFO] - Train, Round 140 : loss => 1.5572746452057,  accuracy: 0.6013131313131312, gradient_norm : 424.9471069240926
[2025-09-17 14:09:45,857][flp2p.graph_runner][INFO] - Test, Round 140 : loss => 1.542347765390756,  accuracy: 0.5834845735027223
[2025-09-17 14:09:49,179][flp2p.graph_runner][INFO] - Train, Round 141 : loss => 1.4984532912572226,  accuracy: 0.6154040404040404, gradient_norm : 435.79381605646154
[2025-09-17 14:09:50,048][flp2p.graph_runner][INFO] - Test, Round 141 : loss => 1.4860430365283739,  accuracy: 0.6018264840182649
[2025-09-17 14:09:53,381][flp2p.graph_runner][INFO] - Train, Round 142 : loss => 1.4102399023193302,  accuracy: 0.6317676767676766, gradient_norm : 437.93894311211693
[2025-09-17 14:09:54,273][flp2p.graph_runner][INFO] - Test, Round 142 : loss => 1.4017325058878012,  accuracy: 0.6156648451730419
[2025-09-17 14:09:57,572][flp2p.graph_runner][INFO] - Train, Round 143 : loss => 1.5172571326747084,  accuracy: 0.6051010101010101, gradient_norm : 434.6243321326563
[2025-09-17 14:09:58,601][flp2p.graph_runner][INFO] - Test, Round 143 : loss => 1.497305614685295,  accuracy: 0.6043755697356427
[2025-09-17 14:10:03,282][flp2p.graph_runner][INFO] - Train, Round 144 : loss => 1.3652246538436774,  accuracy: 0.6423232323232323, gradient_norm : 416.64572420837976
[2025-09-17 14:10:04,519][flp2p.graph_runner][INFO] - Test, Round 144 : loss => 1.3762795696519825,  accuracy: 0.6310502283105023
[2025-09-17 14:10:09,249][flp2p.graph_runner][INFO] - Train, Round 145 : loss => 1.4396197659499717,  accuracy: 0.6186868686868687, gradient_norm : 435.7403959014168
[2025-09-17 14:10:10,477][flp2p.graph_runner][INFO] - Test, Round 145 : loss => 1.4211302171385223,  accuracy: 0.6152450090744102
[2025-09-17 14:10:15,189][flp2p.graph_runner][INFO] - Train, Round 146 : loss => 1.4505472242832185,  accuracy: 0.6281818181818182, gradient_norm : 441.2654430065477
[2025-09-17 14:10:16,411][flp2p.graph_runner][INFO] - Test, Round 146 : loss => 1.4627956659062762,  accuracy: 0.6050955414012739
[2025-09-17 14:10:21,089][flp2p.graph_runner][INFO] - Train, Round 147 : loss => 1.3212196651733283,  accuracy: 0.6584343434343435, gradient_norm : 461.6855192501002
[2025-09-17 14:10:22,324][flp2p.graph_runner][INFO] - Test, Round 147 : loss => 1.3436725553599271,  accuracy: 0.6263636363636363
[2025-09-17 14:10:26,810][flp2p.graph_runner][INFO] - Train, Round 148 : loss => 1.3857096962856523,  accuracy: 0.635050505050505, gradient_norm : 435.6460807686051
[2025-09-17 14:10:27,666][flp2p.graph_runner][INFO] - Test, Round 148 : loss => 1.3706176623906174,  accuracy: 0.639269406392694
[2025-09-17 14:10:31,022][flp2p.graph_runner][INFO] - Train, Round 149 : loss => 1.508895267410712,  accuracy: 0.6196969696969697, gradient_norm : 427.62758264674926
[2025-09-17 14:10:31,883][flp2p.graph_runner][INFO] - Test, Round 149 : loss => 1.4904704999967213,  accuracy: 0.5985401459854015
[2025-09-17 14:10:35,221][flp2p.graph_runner][INFO] - Train, Round 150 : loss => 1.3153229292595026,  accuracy: 0.6497979797979797, gradient_norm : 439.4970567539065
[2025-09-17 14:10:36,094][flp2p.graph_runner][INFO] - Test, Round 150 : loss => 1.2986780627069143,  accuracy: 0.6411657559198543
[2025-09-17 14:10:39,433][flp2p.graph_runner][INFO] - Train, Round 151 : loss => 1.2923503378123948,  accuracy: 0.6605555555555555, gradient_norm : 458.2268335510005
[2025-09-17 14:10:40,325][flp2p.graph_runner][INFO] - Test, Round 151 : loss => 1.289980396777527,  accuracy: 0.6533212010919017
[2025-09-17 14:10:44,164][flp2p.graph_runner][INFO] - Train, Round 152 : loss => 1.5715867163556996,  accuracy: 0.5935858585858586, gradient_norm : 430.52347263194656
[2025-09-17 14:10:45,410][flp2p.graph_runner][INFO] - Test, Round 152 : loss => 1.5391507473609902,  accuracy: 0.6066176470588235
[2025-09-17 14:10:50,188][flp2p.graph_runner][INFO] - Train, Round 153 : loss => 1.4294778140205326,  accuracy: 0.6253030303030302, gradient_norm : 433.58664286095114
[2025-09-17 14:10:51,449][flp2p.graph_runner][INFO] - Test, Round 153 : loss => 1.40962036959214,  accuracy: 0.6179159049360147
[2025-09-17 14:10:56,152][flp2p.graph_runner][INFO] - Train, Round 154 : loss => 1.3810271071665214,  accuracy: 0.6366666666666667, gradient_norm : 459.602889028939
[2025-09-17 14:10:57,385][flp2p.graph_runner][INFO] - Test, Round 154 : loss => 1.369366972796354,  accuracy: 0.6253418413855971
[2025-09-17 14:11:01,674][flp2p.graph_runner][INFO] - Train, Round 155 : loss => 1.371946934759617,  accuracy: 0.6280555555555556, gradient_norm : 441.9120558119249
[2025-09-17 14:11:02,756][flp2p.graph_runner][INFO] - Test, Round 155 : loss => 1.370602243636028,  accuracy: 0.6104417670682731
[2025-09-17 14:11:07,466][flp2p.graph_runner][INFO] - Train, Round 156 : loss => 1.3381771369413895,  accuracy: 0.650050505050505, gradient_norm : 445.6357975134129
[2025-09-17 14:11:08,720][flp2p.graph_runner][INFO] - Test, Round 156 : loss => 1.337632403609301,  accuracy: 0.6358645928636779
[2025-09-17 14:11:13,430][flp2p.graph_runner][INFO] - Train, Round 157 : loss => 1.3499145852796959,  accuracy: 0.6595454545454545, gradient_norm : 453.48992696603233
[2025-09-17 14:11:14,632][flp2p.graph_runner][INFO] - Test, Round 157 : loss => 1.3417069569270683,  accuracy: 0.6566757493188011
[2025-09-17 14:11:19,370][flp2p.graph_runner][INFO] - Train, Round 158 : loss => 1.3899815069003538,  accuracy: 0.6331818181818182, gradient_norm : 435.040642408344
[2025-09-17 14:11:20,617][flp2p.graph_runner][INFO] - Test, Round 158 : loss => 1.379663402980024,  accuracy: 0.6090909090909091
[2025-09-17 14:11:25,392][flp2p.graph_runner][INFO] - Train, Round 159 : loss => 1.2878362781170642,  accuracy: 0.6591919191919191, gradient_norm : 423.5439807457835
[2025-09-17 14:11:26,572][flp2p.graph_runner][INFO] - Test, Round 159 : loss => 1.2777981256526676,  accuracy: 0.6530054644808743
[2025-09-17 14:11:31,305][flp2p.graph_runner][INFO] - Train, Round 160 : loss => 1.3456778771949538,  accuracy: 0.6585858585858585, gradient_norm : 436.1120697714443
[2025-09-17 14:11:32,570][flp2p.graph_runner][INFO] - Test, Round 160 : loss => 1.3433451240482053,  accuracy: 0.6391659111514053
[2025-09-17 14:11:37,318][flp2p.graph_runner][INFO] - Train, Round 161 : loss => 1.3720220049222311,  accuracy: 0.6519191919191918, gradient_norm : 434.8910190537337
[2025-09-17 14:11:38,545][flp2p.graph_runner][INFO] - Test, Round 161 : loss => 1.3726001145296158,  accuracy: 0.6321525885558583
[2025-09-17 14:11:43,312][flp2p.graph_runner][INFO] - Train, Round 162 : loss => 1.3517017544218988,  accuracy: 0.6455050505050506, gradient_norm : 441.5589577973752
[2025-09-17 14:11:44,558][flp2p.graph_runner][INFO] - Test, Round 162 : loss => 1.3680966797759808,  accuracy: 0.6051188299817185
[2025-09-17 14:11:49,346][flp2p.graph_runner][INFO] - Train, Round 163 : loss => 1.348559369282289,  accuracy: 0.6347979797979797, gradient_norm : 438.20402007709566
[2025-09-17 14:11:50,608][flp2p.graph_runner][INFO] - Test, Round 163 : loss => 1.338120844688794,  accuracy: 0.6149684400360685
[2025-09-17 14:11:55,411][flp2p.graph_runner][INFO] - Train, Round 164 : loss => 1.3108317680431134,  accuracy: 0.6468686868686869, gradient_norm : 439.7657584135734
[2025-09-17 14:11:56,661][flp2p.graph_runner][INFO] - Test, Round 164 : loss => 1.302874377803369,  accuracy: 0.64
[2025-09-17 14:12:01,440][flp2p.graph_runner][INFO] - Train, Round 165 : loss => 1.2717229754635782,  accuracy: 0.6626262626262627, gradient_norm : 457.4571699435891
[2025-09-17 14:12:02,650][flp2p.graph_runner][INFO] - Test, Round 165 : loss => 1.2824668380347166,  accuracy: 0.6509090909090909
[2025-09-17 14:12:07,327][flp2p.graph_runner][INFO] - Train, Round 166 : loss => 1.2352841008793225,  accuracy: 0.671969696969697, gradient_norm : 433.07370841886774
[2025-09-17 14:12:08,605][flp2p.graph_runner][INFO] - Test, Round 166 : loss => 1.2396846186920176,  accuracy: 0.6563916591115141
[2025-09-17 14:12:12,946][flp2p.graph_runner][INFO] - Train, Round 167 : loss => 1.2452883914113044,  accuracy: 0.6721666666666667, gradient_norm : 501.6854579781927
[2025-09-17 14:12:14,040][flp2p.graph_runner][INFO] - Test, Round 167 : loss => 1.2640102178307633,  accuracy: 0.6673366834170854
[2025-09-17 14:12:18,794][flp2p.graph_runner][INFO] - Train, Round 168 : loss => 1.3930652808059345,  accuracy: 0.6565656565656566, gradient_norm : 435.6803757394584
[2025-09-17 14:12:20,024][flp2p.graph_runner][INFO] - Test, Round 168 : loss => 1.3731216191699154,  accuracy: 0.6626947754353804
[2025-09-17 14:12:24,693][flp2p.graph_runner][INFO] - Train, Round 169 : loss => 1.2706495387084555,  accuracy: 0.6720707070707069, gradient_norm : 434.2279740189722
[2025-09-17 14:12:25,939][flp2p.graph_runner][INFO] - Test, Round 169 : loss => 1.2638891781846138,  accuracy: 0.6684931506849315
[2025-09-17 14:12:30,643][flp2p.graph_runner][INFO] - Train, Round 170 : loss => 1.2822952567627937,  accuracy: 0.6725252525252524, gradient_norm : 425.4846263241671
[2025-09-17 14:12:31,876][flp2p.graph_runner][INFO] - Test, Round 170 : loss => 1.28258499848158,  accuracy: 0.6481312670920693
[2025-09-17 14:12:36,606][flp2p.graph_runner][INFO] - Train, Round 171 : loss => 1.2524792915040797,  accuracy: 0.6761616161616161, gradient_norm : 430.3705078683963
[2025-09-17 14:12:37,871][flp2p.graph_runner][INFO] - Test, Round 171 : loss => 1.2565951158666655,  accuracy: 0.6495882891125343
[2025-09-17 14:12:42,687][flp2p.graph_runner][INFO] - Train, Round 172 : loss => 1.239884658835151,  accuracy: 0.6704040404040404, gradient_norm : 473.9810612754321
[2025-09-17 14:12:43,905][flp2p.graph_runner][INFO] - Test, Round 172 : loss => 1.2386365045151209,  accuracy: 0.6675799086757991
[2025-09-17 14:12:48,615][flp2p.graph_runner][INFO] - Train, Round 173 : loss => 1.4148881653944652,  accuracy: 0.6375252525252524, gradient_norm : 440.81774900010436
[2025-09-17 14:12:49,804][flp2p.graph_runner][INFO] - Test, Round 173 : loss => 1.4139986943708707,  accuracy: 0.6429223744292237
[2025-09-17 14:12:54,537][flp2p.graph_runner][INFO] - Train, Round 174 : loss => 1.2566508476481293,  accuracy: 0.6736868686868687, gradient_norm : 430.0968428057227
[2025-09-17 14:12:55,771][flp2p.graph_runner][INFO] - Test, Round 174 : loss => 1.2605717322501269,  accuracy: 0.6618181818181819
[2025-09-17 14:13:00,471][flp2p.graph_runner][INFO] - Train, Round 175 : loss => 1.1123505662788045,  accuracy: 0.6989393939393941, gradient_norm : 474.5485451225835
[2025-09-17 14:13:01,767][flp2p.graph_runner][INFO] - Test, Round 175 : loss => 1.16266530752182,  accuracy: 0.6526891522333638
[2025-09-17 14:13:06,106][flp2p.graph_runner][INFO] - Train, Round 176 : loss => 1.3218174156546594,  accuracy: 0.6608888888888889, gradient_norm : 437.46392394026896
[2025-09-17 14:13:07,195][flp2p.graph_runner][INFO] - Test, Round 176 : loss => 1.3257981744429532,  accuracy: 0.6369107321965898
[2025-09-17 14:13:11,997][flp2p.graph_runner][INFO] - Train, Round 177 : loss => 1.1522723391200558,  accuracy: 0.6935858585858586, gradient_norm : 474.692838168838
[2025-09-17 14:13:13,272][flp2p.graph_runner][INFO] - Test, Round 177 : loss => 1.161303635931363,  accuracy: 0.6678832116788321
[2025-09-17 14:13:17,584][flp2p.graph_runner][INFO] - Train, Round 178 : loss => 1.2421686521172524,  accuracy: 0.6725, gradient_norm : 414.85433664281425
[2025-09-17 14:13:18,754][flp2p.graph_runner][INFO] - Test, Round 178 : loss => 1.25498022603893,  accuracy: 0.6559679037111334
[2025-09-17 14:13:23,409][flp2p.graph_runner][INFO] - Train, Round 179 : loss => 1.1995165314638254,  accuracy: 0.6895454545454546, gradient_norm : 432.24728832322927
[2025-09-17 14:13:24,291][flp2p.graph_runner][INFO] - Test, Round 179 : loss => 1.2131073612726584,  accuracy: 0.6535648994515539
[2025-09-17 14:13:27,337][flp2p.graph_runner][INFO] - Train, Round 180 : loss => 1.1486306964357693,  accuracy: 0.6863888888888888, gradient_norm : 410.90611988381306
[2025-09-17 14:13:28,132][flp2p.graph_runner][INFO] - Test, Round 180 : loss => 1.1609111894184434,  accuracy: 0.670020120724346
[2025-09-17 14:13:31,441][flp2p.graph_runner][INFO] - Train, Round 181 : loss => 1.1700480923508152,  accuracy: 0.6828787878787879, gradient_norm : 465.0044172401709
[2025-09-17 14:13:32,344][flp2p.graph_runner][INFO] - Test, Round 181 : loss => 1.1885130743457846,  accuracy: 0.6547945205479452
[2025-09-17 14:13:35,724][flp2p.graph_runner][INFO] - Train, Round 182 : loss => 1.1808991349104678,  accuracy: 0.6864646464646466, gradient_norm : 515.1674576525918
[2025-09-17 14:13:36,597][flp2p.graph_runner][INFO] - Test, Round 182 : loss => 1.2261380751927693,  accuracy: 0.6485013623978202
[2025-09-17 14:13:39,922][flp2p.graph_runner][INFO] - Train, Round 183 : loss => 1.1448091474446382,  accuracy: 0.7000000000000002, gradient_norm : 444.619980593682
[2025-09-17 14:13:40,818][flp2p.graph_runner][INFO] - Test, Round 183 : loss => 1.1706984910347007,  accuracy: 0.6801470588235294
[2025-09-17 14:13:44,161][flp2p.graph_runner][INFO] - Train, Round 184 : loss => 1.3105660862994917,  accuracy: 0.6486363636363637, gradient_norm : 485.3615669239774
[2025-09-17 14:13:45,039][flp2p.graph_runner][INFO] - Test, Round 184 : loss => 1.3111982066952559,  accuracy: 0.6571952337305225
[2025-09-17 14:13:48,363][flp2p.graph_runner][INFO] - Train, Round 185 : loss => 1.025963329275449,  accuracy: 0.7086868686868686, gradient_norm : 485.02597518462494
[2025-09-17 14:13:49,225][flp2p.graph_runner][INFO] - Test, Round 185 : loss => 1.0593409539634868,  accuracy: 0.6755270394133822
[2025-09-17 14:13:52,613][flp2p.graph_runner][INFO] - Train, Round 186 : loss => 1.1481241431200142,  accuracy: 0.6884343434343435, gradient_norm : 447.38547061012747
[2025-09-17 14:13:53,488][flp2p.graph_runner][INFO] - Test, Round 186 : loss => 1.1489270032267191,  accuracy: 0.6763901549680948
[2025-09-17 14:13:56,530][flp2p.graph_runner][INFO] - Train, Round 187 : loss => 1.153540321290493,  accuracy: 0.6796666666666666, gradient_norm : 490.80391870236724
[2025-09-17 14:13:57,333][flp2p.graph_runner][INFO] - Test, Round 187 : loss => 1.154756648032687,  accuracy: 0.6646525679758308
[2025-09-17 14:14:00,713][flp2p.graph_runner][INFO] - Train, Round 188 : loss => 1.2531790592453695,  accuracy: 0.6534848484848484, gradient_norm : 424.4991516968158
[2025-09-17 14:14:01,561][flp2p.graph_runner][INFO] - Test, Round 188 : loss => 1.264775107620628,  accuracy: 0.6242038216560509
[2025-09-17 14:14:04,603][flp2p.graph_runner][INFO] - Train, Round 189 : loss => 1.2228449843327205,  accuracy: 0.6753888888888888, gradient_norm : 492.75348576484146
[2025-09-17 14:14:05,415][flp2p.graph_runner][INFO] - Test, Round 189 : loss => 1.2407734971400628,  accuracy: 0.6520438683948155
[2025-09-17 14:14:08,758][flp2p.graph_runner][INFO] - Train, Round 190 : loss => 1.1158636562752,  accuracy: 0.7009595959595959, gradient_norm : 473.67083582930985
[2025-09-17 14:14:09,639][flp2p.graph_runner][INFO] - Test, Round 190 : loss => 1.150040416687102,  accuracy: 0.6645396536007293
[2025-09-17 14:14:12,984][flp2p.graph_runner][INFO] - Train, Round 191 : loss => 1.2596293930754516,  accuracy: 0.6691414141414141, gradient_norm : 431.04202955286036
[2025-09-17 14:14:13,871][flp2p.graph_runner][INFO] - Test, Round 191 : loss => 1.2520334244428213,  accuracy: 0.6535648994515539
[2025-09-17 14:14:17,205][flp2p.graph_runner][INFO] - Train, Round 192 : loss => 1.2203161965716969,  accuracy: 0.6883333333333334, gradient_norm : 404.81710885964674
[2025-09-17 14:14:18,075][flp2p.graph_runner][INFO] - Test, Round 192 : loss => 1.234819517476839,  accuracy: 0.6645396536007293
[2025-09-17 14:14:21,489][flp2p.graph_runner][INFO] - Train, Round 193 : loss => 1.0347562000607,  accuracy: 0.711111111111111, gradient_norm : 541.8660735756497
[2025-09-17 14:14:22,358][flp2p.graph_runner][INFO] - Test, Round 193 : loss => 1.1090457931406101,  accuracy: 0.6809872029250457
[2025-09-17 14:14:25,726][flp2p.graph_runner][INFO] - Train, Round 194 : loss => 1.2233269650827754,  accuracy: 0.6827777777777777, gradient_norm : 420.8592195796882
[2025-09-17 14:14:26,602][flp2p.graph_runner][INFO] - Test, Round 194 : loss => 1.2426481748697225,  accuracy: 0.6672710788757933
[2025-09-17 14:14:29,946][flp2p.graph_runner][INFO] - Train, Round 195 : loss => 1.1078156074791243,  accuracy: 0.6953030303030303, gradient_norm : 434.43250915388256
[2025-09-17 14:14:30,821][flp2p.graph_runner][INFO] - Test, Round 195 : loss => 1.126855277093974,  accuracy: 0.6636363636363637
[2025-09-17 14:14:34,201][flp2p.graph_runner][INFO] - Train, Round 196 : loss => 1.0870074385043347,  accuracy: 0.7061616161616161, gradient_norm : 424.6644496774698
[2025-09-17 14:14:35,064][flp2p.graph_runner][INFO] - Test, Round 196 : loss => 1.112857950323771,  accuracy: 0.6791934005499541
[2025-09-17 14:14:38,423][flp2p.graph_runner][INFO] - Train, Round 197 : loss => 1.139813602512533,  accuracy: 0.6893939393939396, gradient_norm : 413.21852357428475
[2025-09-17 14:14:39,294][flp2p.graph_runner][INFO] - Test, Round 197 : loss => 1.1478275543956618,  accuracy: 0.6727438468550593
[2025-09-17 14:14:42,650][flp2p.graph_runner][INFO] - Train, Round 198 : loss => 1.2630307775555234,  accuracy: 0.6719191919191919, gradient_norm : 482.15841102964333
[2025-09-17 14:14:43,517][flp2p.graph_runner][INFO] - Test, Round 198 : loss => 1.2677673807355754,  accuracy: 0.6532479414455626
[2025-09-17 14:14:46,870][flp2p.graph_runner][INFO] - Train, Round 199 : loss => 1.0951083982532674,  accuracy: 0.7097979797979798, gradient_norm : 503.5058129254105
[2025-09-17 14:14:47,749][flp2p.graph_runner][INFO] - Test, Round 199 : loss => 1.1337637603555095,  accuracy: 0.684931506849315
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 001: loss=2.3065, accuracy=0.0761, gradient_norm=301.9340, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 002: loss=2.3041, accuracy=0.0804, gradient_norm=299.5180, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 003: loss=2.3030, accuracy=0.0818, gradient_norm=297.2967, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 004: loss=2.2962, accuracy=0.0898, gradient_norm=293.1065, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 005: loss=2.2857, accuracy=0.1105, gradient_norm=287.6444, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 006: loss=2.2972, accuracy=0.0904, gradient_norm=292.9584, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 007: loss=2.2852, accuracy=0.1207, gradient_norm=293.4229, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 008: loss=2.2803, accuracy=0.1201, gradient_norm=290.4595, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 009: loss=2.2749, accuracy=0.1270, gradient_norm=282.5602, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 010: loss=2.2715, accuracy=0.1549, gradient_norm=284.1119, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 011: loss=2.2752, accuracy=0.1421, gradient_norm=286.9855, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 012: loss=2.2723, accuracy=0.1439, gradient_norm=287.2063, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 013: loss=2.2662, accuracy=0.1680, gradient_norm=293.0349, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 014: loss=2.2620, accuracy=0.1759, gradient_norm=292.4393, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 015: loss=2.2788, accuracy=0.1375, gradient_norm=293.9221, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 016: loss=2.2631, accuracy=0.1684, gradient_norm=288.7531, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 017: loss=2.2471, accuracy=0.2201, gradient_norm=287.5956, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 018: loss=2.2545, accuracy=0.1876, gradient_norm=288.5062, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 019: loss=2.2378, accuracy=0.2241, gradient_norm=287.8618, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 020: loss=2.2509, accuracy=0.1997, gradient_norm=292.9833, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 021: loss=2.2382, accuracy=0.2440, gradient_norm=295.7428, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 022: loss=2.2386, accuracy=0.2248, gradient_norm=300.4462, 
[2025-09-17 14:14:47,750][__main__][INFO] - Train, Round 023: loss=2.2216, accuracy=0.2843, gradient_norm=299.3993, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 024: loss=2.2242, accuracy=0.2812, gradient_norm=304.3864, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 025: loss=2.2177, accuracy=0.2939, gradient_norm=305.3578, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 026: loss=2.2075, accuracy=0.3159, gradient_norm=310.8339, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 027: loss=2.1878, accuracy=0.3565, gradient_norm=315.8196, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 028: loss=2.2148, accuracy=0.2617, gradient_norm=303.1674, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 029: loss=2.1816, accuracy=0.3498, gradient_norm=321.3254, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 030: loss=2.1996, accuracy=0.2959, gradient_norm=314.8513, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 031: loss=2.1645, accuracy=0.3491, gradient_norm=332.9848, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 032: loss=2.1863, accuracy=0.3049, gradient_norm=323.8603, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 033: loss=2.1799, accuracy=0.3302, gradient_norm=322.7051, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 034: loss=2.1969, accuracy=0.2654, gradient_norm=317.4263, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 035: loss=2.1591, accuracy=0.3609, gradient_norm=335.8001, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 036: loss=2.1661, accuracy=0.3533, gradient_norm=332.7537, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 037: loss=2.1629, accuracy=0.3428, gradient_norm=328.4086, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 038: loss=2.1386, accuracy=0.3745, gradient_norm=343.2705, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 039: loss=2.1759, accuracy=0.2845, gradient_norm=321.6683, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 040: loss=2.1136, accuracy=0.4119, gradient_norm=355.0128, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 041: loss=2.1546, accuracy=0.3260, gradient_norm=340.7157, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 042: loss=2.1338, accuracy=0.3530, gradient_norm=340.7537, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 043: loss=2.1389, accuracy=0.3364, gradient_norm=338.2227, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 044: loss=2.1379, accuracy=0.3425, gradient_norm=341.7554, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 045: loss=2.1086, accuracy=0.3918, gradient_norm=352.9512, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 046: loss=2.1266, accuracy=0.3674, gradient_norm=344.8619, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 047: loss=2.1013, accuracy=0.4041, gradient_norm=353.5823, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 048: loss=2.0977, accuracy=0.3916, gradient_norm=357.9731, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 049: loss=2.1002, accuracy=0.3882, gradient_norm=350.1845, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 050: loss=2.0883, accuracy=0.4095, gradient_norm=356.1919, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 051: loss=2.0450, accuracy=0.4478, gradient_norm=379.5999, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 052: loss=2.0991, accuracy=0.3681, gradient_norm=347.8689, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 053: loss=2.0336, accuracy=0.4810, gradient_norm=385.2381, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 054: loss=2.0426, accuracy=0.4529, gradient_norm=379.3704, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 055: loss=2.0540, accuracy=0.4157, gradient_norm=368.1371, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 056: loss=2.0448, accuracy=0.4447, gradient_norm=371.7550, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 057: loss=2.0293, accuracy=0.4527, gradient_norm=370.5938, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 058: loss=2.0255, accuracy=0.4267, gradient_norm=376.0557, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 059: loss=1.9958, accuracy=0.4666, gradient_norm=391.7008, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 060: loss=2.0200, accuracy=0.4484, gradient_norm=377.8673, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 061: loss=2.0259, accuracy=0.4479, gradient_norm=376.6360, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 062: loss=1.9629, accuracy=0.4869, gradient_norm=405.8934, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 063: loss=1.9946, accuracy=0.4867, gradient_norm=383.5026, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 064: loss=1.9785, accuracy=0.4829, gradient_norm=392.2735, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 065: loss=1.9556, accuracy=0.4799, gradient_norm=401.5516, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 066: loss=1.9796, accuracy=0.4777, gradient_norm=385.2055, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 067: loss=1.9526, accuracy=0.4855, gradient_norm=392.6282, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 068: loss=1.9353, accuracy=0.4993, gradient_norm=401.6479, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 069: loss=1.9736, accuracy=0.4829, gradient_norm=383.7956, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 070: loss=2.0086, accuracy=0.4306, gradient_norm=361.8652, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 071: loss=2.0047, accuracy=0.4848, gradient_norm=386.5661, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 072: loss=1.9108, accuracy=0.5191, gradient_norm=407.2199, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 073: loss=1.8674, accuracy=0.5179, gradient_norm=411.2995, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 074: loss=1.9432, accuracy=0.4801, gradient_norm=387.5787, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 075: loss=1.9143, accuracy=0.4992, gradient_norm=406.8648, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 076: loss=1.9097, accuracy=0.5109, gradient_norm=401.5177, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 077: loss=1.9279, accuracy=0.5081, gradient_norm=390.8866, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 078: loss=1.8877, accuracy=0.4977, gradient_norm=407.3615, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 079: loss=1.8522, accuracy=0.5249, gradient_norm=417.5114, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 080: loss=1.8807, accuracy=0.5220, gradient_norm=402.0788, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 081: loss=1.9030, accuracy=0.5079, gradient_norm=391.1745, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 082: loss=1.8332, accuracy=0.5577, gradient_norm=427.1555, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 083: loss=1.8024, accuracy=0.5410, gradient_norm=426.2246, 
[2025-09-17 14:14:47,751][__main__][INFO] - Train, Round 084: loss=1.8647, accuracy=0.5460, gradient_norm=401.2001, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 085: loss=1.7328, accuracy=0.5887, gradient_norm=445.9560, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 086: loss=1.8163, accuracy=0.5496, gradient_norm=419.6490, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 087: loss=1.7524, accuracy=0.5394, gradient_norm=421.2650, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 088: loss=1.8457, accuracy=0.5003, gradient_norm=396.0776, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 089: loss=1.7681, accuracy=0.5768, gradient_norm=439.0673, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 090: loss=1.7943, accuracy=0.5394, gradient_norm=414.2970, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 091: loss=1.7882, accuracy=0.5305, gradient_norm=411.2398, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 092: loss=1.7609, accuracy=0.5660, gradient_norm=434.4119, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 093: loss=1.7975, accuracy=0.5451, gradient_norm=418.9778, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 094: loss=1.8133, accuracy=0.5354, gradient_norm=393.5501, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 095: loss=1.7597, accuracy=0.5599, gradient_norm=426.7624, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 096: loss=1.7421, accuracy=0.5537, gradient_norm=423.4509, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 097: loss=1.7399, accuracy=0.5694, gradient_norm=422.9546, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 098: loss=1.7422, accuracy=0.5502, gradient_norm=402.7662, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 099: loss=1.7132, accuracy=0.5677, gradient_norm=428.7522, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 100: loss=1.7112, accuracy=0.5534, gradient_norm=425.0338, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 101: loss=1.7204, accuracy=0.5624, gradient_norm=410.8104, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 102: loss=1.5872, accuracy=0.5793, gradient_norm=433.1954, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 103: loss=1.6711, accuracy=0.5874, gradient_norm=418.8612, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 104: loss=1.7370, accuracy=0.5482, gradient_norm=403.6416, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 105: loss=1.6569, accuracy=0.5784, gradient_norm=415.4936, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 106: loss=1.7000, accuracy=0.5684, gradient_norm=429.3859, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 107: loss=1.6751, accuracy=0.5776, gradient_norm=411.5858, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 108: loss=1.5624, accuracy=0.6171, gradient_norm=447.1963, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 109: loss=1.6751, accuracy=0.5689, gradient_norm=406.0258, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 110: loss=1.7692, accuracy=0.5723, gradient_norm=404.5450, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 111: loss=1.7147, accuracy=0.5892, gradient_norm=421.1896, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 112: loss=1.5959, accuracy=0.6019, gradient_norm=425.0318, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 113: loss=1.6715, accuracy=0.5855, gradient_norm=419.7550, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 114: loss=1.6415, accuracy=0.5792, gradient_norm=421.8949, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 115: loss=1.5512, accuracy=0.6076, gradient_norm=432.4967, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 116: loss=1.6333, accuracy=0.5871, gradient_norm=411.4603, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 117: loss=1.5035, accuracy=0.6113, gradient_norm=430.5495, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 118: loss=1.6572, accuracy=0.5605, gradient_norm=403.6177, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 119: loss=1.6666, accuracy=0.5788, gradient_norm=420.4283, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 120: loss=1.5893, accuracy=0.6008, gradient_norm=431.4080, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 121: loss=1.5554, accuracy=0.6056, gradient_norm=435.0162, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 122: loss=1.5174, accuracy=0.6129, gradient_norm=436.1029, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 123: loss=1.5990, accuracy=0.5874, gradient_norm=435.5776, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 124: loss=1.5710, accuracy=0.5952, gradient_norm=444.0557, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 125: loss=1.6054, accuracy=0.5919, gradient_norm=421.2149, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 126: loss=1.6472, accuracy=0.5733, gradient_norm=416.7549, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 127: loss=1.5039, accuracy=0.6040, gradient_norm=438.0370, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 128: loss=1.5880, accuracy=0.6082, gradient_norm=431.5475, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 129: loss=1.5520, accuracy=0.6083, gradient_norm=419.8643, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 130: loss=1.5688, accuracy=0.6038, gradient_norm=424.8489, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 131: loss=1.5708, accuracy=0.6029, gradient_norm=430.2490, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 132: loss=1.5282, accuracy=0.6281, gradient_norm=439.4653, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 133: loss=1.5926, accuracy=0.5868, gradient_norm=418.8122, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 134: loss=1.4887, accuracy=0.6120, gradient_norm=447.4533, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 135: loss=1.4146, accuracy=0.6147, gradient_norm=435.4743, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 136: loss=1.4168, accuracy=0.6382, gradient_norm=442.0475, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 137: loss=1.5622, accuracy=0.6059, gradient_norm=437.8519, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 138: loss=1.4456, accuracy=0.6312, gradient_norm=424.2656, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 139: loss=1.4884, accuracy=0.6267, gradient_norm=438.6058, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 140: loss=1.6518, accuracy=0.5684, gradient_norm=411.8010, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 141: loss=1.5573, accuracy=0.6013, gradient_norm=424.9471, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 142: loss=1.4985, accuracy=0.6154, gradient_norm=435.7938, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 143: loss=1.4102, accuracy=0.6318, gradient_norm=437.9389, 
[2025-09-17 14:14:47,752][__main__][INFO] - Train, Round 144: loss=1.5173, accuracy=0.6051, gradient_norm=434.6243, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 145: loss=1.3652, accuracy=0.6423, gradient_norm=416.6457, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 146: loss=1.4396, accuracy=0.6187, gradient_norm=435.7404, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 147: loss=1.4505, accuracy=0.6282, gradient_norm=441.2654, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 148: loss=1.3212, accuracy=0.6584, gradient_norm=461.6855, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 149: loss=1.3857, accuracy=0.6351, gradient_norm=435.6461, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 150: loss=1.5089, accuracy=0.6197, gradient_norm=427.6276, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 151: loss=1.3153, accuracy=0.6498, gradient_norm=439.4971, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 152: loss=1.2924, accuracy=0.6606, gradient_norm=458.2268, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 153: loss=1.5716, accuracy=0.5936, gradient_norm=430.5235, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 154: loss=1.4295, accuracy=0.6253, gradient_norm=433.5866, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 155: loss=1.3810, accuracy=0.6367, gradient_norm=459.6029, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 156: loss=1.3719, accuracy=0.6281, gradient_norm=441.9121, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 157: loss=1.3382, accuracy=0.6501, gradient_norm=445.6358, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 158: loss=1.3499, accuracy=0.6595, gradient_norm=453.4899, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 159: loss=1.3900, accuracy=0.6332, gradient_norm=435.0406, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 160: loss=1.2878, accuracy=0.6592, gradient_norm=423.5440, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 161: loss=1.3457, accuracy=0.6586, gradient_norm=436.1121, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 162: loss=1.3720, accuracy=0.6519, gradient_norm=434.8910, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 163: loss=1.3517, accuracy=0.6455, gradient_norm=441.5590, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 164: loss=1.3486, accuracy=0.6348, gradient_norm=438.2040, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 165: loss=1.3108, accuracy=0.6469, gradient_norm=439.7658, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 166: loss=1.2717, accuracy=0.6626, gradient_norm=457.4572, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 167: loss=1.2353, accuracy=0.6720, gradient_norm=433.0737, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 168: loss=1.2453, accuracy=0.6722, gradient_norm=501.6855, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 169: loss=1.3931, accuracy=0.6566, gradient_norm=435.6804, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 170: loss=1.2706, accuracy=0.6721, gradient_norm=434.2280, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 171: loss=1.2823, accuracy=0.6725, gradient_norm=425.4846, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 172: loss=1.2525, accuracy=0.6762, gradient_norm=430.3705, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 173: loss=1.2399, accuracy=0.6704, gradient_norm=473.9811, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 174: loss=1.4149, accuracy=0.6375, gradient_norm=440.8177, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 175: loss=1.2567, accuracy=0.6737, gradient_norm=430.0968, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 176: loss=1.1124, accuracy=0.6989, gradient_norm=474.5485, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 177: loss=1.3218, accuracy=0.6609, gradient_norm=437.4639, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 178: loss=1.1523, accuracy=0.6936, gradient_norm=474.6928, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 179: loss=1.2422, accuracy=0.6725, gradient_norm=414.8543, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 180: loss=1.1995, accuracy=0.6895, gradient_norm=432.2473, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 181: loss=1.1486, accuracy=0.6864, gradient_norm=410.9061, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 182: loss=1.1700, accuracy=0.6829, gradient_norm=465.0044, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 183: loss=1.1809, accuracy=0.6865, gradient_norm=515.1675, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 184: loss=1.1448, accuracy=0.7000, gradient_norm=444.6200, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 185: loss=1.3106, accuracy=0.6486, gradient_norm=485.3616, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 186: loss=1.0260, accuracy=0.7087, gradient_norm=485.0260, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 187: loss=1.1481, accuracy=0.6884, gradient_norm=447.3855, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 188: loss=1.1535, accuracy=0.6797, gradient_norm=490.8039, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 189: loss=1.2532, accuracy=0.6535, gradient_norm=424.4992, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 190: loss=1.2228, accuracy=0.6754, gradient_norm=492.7535, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 191: loss=1.1159, accuracy=0.7010, gradient_norm=473.6708, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 192: loss=1.2596, accuracy=0.6691, gradient_norm=431.0420, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 193: loss=1.2203, accuracy=0.6883, gradient_norm=404.8171, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 194: loss=1.0348, accuracy=0.7111, gradient_norm=541.8661, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 195: loss=1.2233, accuracy=0.6828, gradient_norm=420.8592, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 196: loss=1.1078, accuracy=0.6953, gradient_norm=434.4325, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 197: loss=1.0870, accuracy=0.7062, gradient_norm=424.6644, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 198: loss=1.1398, accuracy=0.6894, gradient_norm=413.2185, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 199: loss=1.2630, accuracy=0.6719, gradient_norm=482.1584, 
[2025-09-17 14:14:47,753][__main__][INFO] - Train, Round 200: loss=1.0951, accuracy=0.7098, gradient_norm=503.5058, 
[2025-09-17 14:14:47,753][__main__][INFO] - Test, Round 001: loss=2.2906, accuracy=0.1006, 
[2025-09-17 14:14:47,753][__main__][INFO] - Test, Round 002: loss=2.2879, accuracy=0.0946, 
[2025-09-17 14:14:47,753][__main__][INFO] - Test, Round 003: loss=2.2880, accuracy=0.1093, 
[2025-09-17 14:14:47,753][__main__][INFO] - Test, Round 004: loss=2.2801, accuracy=0.1098, 
[2025-09-17 14:14:47,753][__main__][INFO] - Test, Round 005: loss=2.2668, accuracy=0.1551, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 006: loss=2.2797, accuracy=0.1163, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 007: loss=2.2696, accuracy=0.1389, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 008: loss=2.2626, accuracy=0.1774, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 009: loss=2.2586, accuracy=0.1676, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 010: loss=2.2534, accuracy=0.2356, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 011: loss=2.2614, accuracy=0.1773, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 012: loss=2.2570, accuracy=0.1922, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 013: loss=2.2517, accuracy=0.2049, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 014: loss=2.2474, accuracy=0.2049, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 015: loss=2.2638, accuracy=0.1648, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 016: loss=2.2465, accuracy=0.2106, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 017: loss=2.2310, accuracy=0.2646, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 018: loss=2.2384, accuracy=0.2370, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 019: loss=2.2207, accuracy=0.2748, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 020: loss=2.2360, accuracy=0.2363, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 021: loss=2.2212, accuracy=0.2845, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 022: loss=2.2213, accuracy=0.2728, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 023: loss=2.2052, accuracy=0.3068, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 024: loss=2.2097, accuracy=0.3010, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 025: loss=2.2002, accuracy=0.3220, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 026: loss=2.1899, accuracy=0.3430, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 027: loss=2.1689, accuracy=0.3870, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 028: loss=2.1989, accuracy=0.2960, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 029: loss=2.1626, accuracy=0.3601, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 030: loss=2.1825, accuracy=0.3434, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 031: loss=2.1434, accuracy=0.3878, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 032: loss=2.1700, accuracy=0.3373, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 033: loss=2.1649, accuracy=0.3580, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 034: loss=2.1824, accuracy=0.2970, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 035: loss=2.1391, accuracy=0.3700, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 036: loss=2.1461, accuracy=0.3735, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 037: loss=2.1486, accuracy=0.3562, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 038: loss=2.1184, accuracy=0.3903, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 039: loss=2.1601, accuracy=0.3306, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 040: loss=2.0912, accuracy=0.4273, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 041: loss=2.1372, accuracy=0.3505, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 042: loss=2.1163, accuracy=0.3814, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 043: loss=2.1203, accuracy=0.3511, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 044: loss=2.1189, accuracy=0.3586, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 045: loss=2.0925, accuracy=0.4090, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 046: loss=2.1114, accuracy=0.3975, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 047: loss=2.0814, accuracy=0.4084, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 048: loss=2.0807, accuracy=0.3892, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 049: loss=2.0808, accuracy=0.3989, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 050: loss=2.0744, accuracy=0.4226, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 051: loss=2.0213, accuracy=0.4547, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 052: loss=2.0842, accuracy=0.3996, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 053: loss=2.0109, accuracy=0.4571, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 054: loss=2.0190, accuracy=0.4647, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 055: loss=2.0338, accuracy=0.4108, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 056: loss=2.0256, accuracy=0.4709, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 057: loss=2.0027, accuracy=0.4704, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 058: loss=2.0013, accuracy=0.4443, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 059: loss=1.9715, accuracy=0.4619, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 060: loss=1.9981, accuracy=0.4281, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 061: loss=2.0076, accuracy=0.4623, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 062: loss=1.9378, accuracy=0.4689, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 063: loss=1.9790, accuracy=0.4905, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 064: loss=1.9552, accuracy=0.4671, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 065: loss=1.9333, accuracy=0.4630, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 066: loss=1.9618, accuracy=0.4745, 
[2025-09-17 14:14:47,754][__main__][INFO] - Test, Round 067: loss=1.9343, accuracy=0.4681, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 068: loss=1.9152, accuracy=0.4873, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 069: loss=1.9531, accuracy=0.4927, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 070: loss=1.9941, accuracy=0.4251, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 071: loss=1.9750, accuracy=0.4896, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 072: loss=1.8779, accuracy=0.5082, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 073: loss=1.8530, accuracy=0.4975, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 074: loss=1.9251, accuracy=0.4781, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 075: loss=1.8920, accuracy=0.4891, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 076: loss=1.8859, accuracy=0.5113, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 077: loss=1.9092, accuracy=0.5032, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 078: loss=1.8625, accuracy=0.4982, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 079: loss=1.8352, accuracy=0.5228, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 080: loss=1.8589, accuracy=0.5064, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 081: loss=1.8876, accuracy=0.5059, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 082: loss=1.8127, accuracy=0.5434, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 083: loss=1.7792, accuracy=0.5396, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 084: loss=1.8527, accuracy=0.5141, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 085: loss=1.7155, accuracy=0.5756, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 086: loss=1.7939, accuracy=0.5205, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 087: loss=1.7320, accuracy=0.5302, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 088: loss=1.8358, accuracy=0.4920, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 089: loss=1.7438, accuracy=0.5507, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 090: loss=1.7698, accuracy=0.5336, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 091: loss=1.7766, accuracy=0.5245, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 092: loss=1.7461, accuracy=0.5649, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 093: loss=1.7725, accuracy=0.5399, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 094: loss=1.7878, accuracy=0.5365, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 095: loss=1.7270, accuracy=0.5395, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 096: loss=1.7201, accuracy=0.5622, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 097: loss=1.7228, accuracy=0.5374, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 098: loss=1.7213, accuracy=0.5374, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 099: loss=1.6971, accuracy=0.5425, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 100: loss=1.6950, accuracy=0.5413, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 101: loss=1.7075, accuracy=0.5565, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 102: loss=1.5768, accuracy=0.5814, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 103: loss=1.6530, accuracy=0.5763, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 104: loss=1.7229, accuracy=0.5466, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 105: loss=1.6501, accuracy=0.5668, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 106: loss=1.6797, accuracy=0.5623, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 107: loss=1.6616, accuracy=0.5495, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 108: loss=1.5391, accuracy=0.5966, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 109: loss=1.6635, accuracy=0.5659, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 110: loss=1.7536, accuracy=0.5521, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 111: loss=1.6971, accuracy=0.5582, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 112: loss=1.5722, accuracy=0.5987, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 113: loss=1.6498, accuracy=0.5734, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 114: loss=1.6154, accuracy=0.5664, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 115: loss=1.5335, accuracy=0.5966, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 116: loss=1.6082, accuracy=0.5912, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 117: loss=1.5037, accuracy=0.6044, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 118: loss=1.6571, accuracy=0.5578, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 119: loss=1.6510, accuracy=0.5659, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 120: loss=1.5709, accuracy=0.5872, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 121: loss=1.5324, accuracy=0.5896, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 122: loss=1.5014, accuracy=0.6027, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 123: loss=1.5692, accuracy=0.5872, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 124: loss=1.5581, accuracy=0.5824, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 125: loss=1.5780, accuracy=0.5756, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 126: loss=1.6347, accuracy=0.5569, 
[2025-09-17 14:14:47,755][__main__][INFO] - Test, Round 127: loss=1.4906, accuracy=0.5907, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 128: loss=1.5817, accuracy=0.5855, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 129: loss=1.5497, accuracy=0.5869, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 130: loss=1.5486, accuracy=0.5919, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 131: loss=1.5491, accuracy=0.6093, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 132: loss=1.5202, accuracy=0.6157, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 133: loss=1.5818, accuracy=0.5639, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 134: loss=1.4577, accuracy=0.5986, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 135: loss=1.4087, accuracy=0.6056, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 136: loss=1.4087, accuracy=0.6207, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 137: loss=1.5478, accuracy=0.5896, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 138: loss=1.4488, accuracy=0.6064, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 139: loss=1.4645, accuracy=0.6120, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 140: loss=1.6374, accuracy=0.5648, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 141: loss=1.5423, accuracy=0.5835, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 142: loss=1.4860, accuracy=0.6018, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 143: loss=1.4017, accuracy=0.6157, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 144: loss=1.4973, accuracy=0.6044, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 145: loss=1.3763, accuracy=0.6311, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 146: loss=1.4211, accuracy=0.6152, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 147: loss=1.4628, accuracy=0.6051, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 148: loss=1.3437, accuracy=0.6264, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 149: loss=1.3706, accuracy=0.6393, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 150: loss=1.4905, accuracy=0.5985, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 151: loss=1.2987, accuracy=0.6412, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 152: loss=1.2900, accuracy=0.6533, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 153: loss=1.5392, accuracy=0.6066, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 154: loss=1.4096, accuracy=0.6179, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 155: loss=1.3694, accuracy=0.6253, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 156: loss=1.3706, accuracy=0.6104, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 157: loss=1.3376, accuracy=0.6359, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 158: loss=1.3417, accuracy=0.6567, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 159: loss=1.3797, accuracy=0.6091, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 160: loss=1.2778, accuracy=0.6530, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 161: loss=1.3433, accuracy=0.6392, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 162: loss=1.3726, accuracy=0.6322, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 163: loss=1.3681, accuracy=0.6051, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 164: loss=1.3381, accuracy=0.6150, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 165: loss=1.3029, accuracy=0.6400, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 166: loss=1.2825, accuracy=0.6509, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 167: loss=1.2397, accuracy=0.6564, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 168: loss=1.2640, accuracy=0.6673, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 169: loss=1.3731, accuracy=0.6627, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 170: loss=1.2639, accuracy=0.6685, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 171: loss=1.2826, accuracy=0.6481, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 172: loss=1.2566, accuracy=0.6496, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 173: loss=1.2386, accuracy=0.6676, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 174: loss=1.4140, accuracy=0.6429, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 175: loss=1.2606, accuracy=0.6618, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 176: loss=1.1627, accuracy=0.6527, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 177: loss=1.3258, accuracy=0.6369, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 178: loss=1.1613, accuracy=0.6679, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 179: loss=1.2550, accuracy=0.6560, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 180: loss=1.2131, accuracy=0.6536, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 181: loss=1.1609, accuracy=0.6700, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 182: loss=1.1885, accuracy=0.6548, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 183: loss=1.2261, accuracy=0.6485, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 184: loss=1.1707, accuracy=0.6801, 
[2025-09-17 14:14:47,756][__main__][INFO] - Test, Round 185: loss=1.3112, accuracy=0.6572, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 186: loss=1.0593, accuracy=0.6755, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 187: loss=1.1489, accuracy=0.6764, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 188: loss=1.1548, accuracy=0.6647, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 189: loss=1.2648, accuracy=0.6242, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 190: loss=1.2408, accuracy=0.6520, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 191: loss=1.1500, accuracy=0.6645, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 192: loss=1.2520, accuracy=0.6536, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 193: loss=1.2348, accuracy=0.6645, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 194: loss=1.1090, accuracy=0.6810, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 195: loss=1.2426, accuracy=0.6673, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 196: loss=1.1269, accuracy=0.6636, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 197: loss=1.1129, accuracy=0.6792, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 198: loss=1.1478, accuracy=0.6727, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 199: loss=1.2678, accuracy=0.6532, 
[2025-09-17 14:14:47,757][__main__][INFO] - Test, Round 200: loss=1.1338, accuracy=0.6849, 
